<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="搬运工 + 践行者" type="application/atom+xml">






<meta name="description" content="做一个懂业务的程序员">
<meta property="og:type" content="website">
<meta property="og:title" content="搬运工 + 践行者">
<meta property="og:url" content="http://blog.com/page/83/index.html">
<meta property="og:site_name" content="搬运工 + 践行者">
<meta property="og:description" content="做一个懂业务的程序员">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="搬运工 + 践行者">
<meta name="twitter:description" content="做一个懂业务的程序员">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.com/page/83/">





  <title>搬运工 + 践行者</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">搬运工 + 践行者</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">记录学习的技能和遇到的问题</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/05/08/如何查看和设置文件句柄数/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/08/如何查看和设置文件句柄数/" itemprop="url">如何查看和设置文件句柄数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-08T12:12:57+08:00">
                2019-05-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/bash/" itemprop="url" rel="index">
                    <span itemprop="name">bash</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/bash/文件描述符/" itemprop="url" rel="index">
                    <span itemprop="name">文件描述符</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="如何查看和设置文件句柄数"><a href="#如何查看和设置文件句柄数" class="headerlink" title="如何查看和设置文件句柄数"></a>如何查看和设置文件句柄数</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="http://arganzheng.life/linux-open-files-limit.html" target="_blank" rel="noopener">http://arganzheng.life/linux-open-files-limit.html</a></p>
</blockquote>
<h2 id="1-系统级别限制-System-Wide-Limit"><a href="#1-系统级别限制-System-Wide-Limit" class="headerlink" title="1. 系统级别限制(System-Wide Limit)"></a>1. 系统级别限制(System-Wide Limit)</h2><p>Set this higher than user-limit set above.</p>
<p>配置文件：<code>/etc/sysctl.conf</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fs.file-max = 2097152</span><br></pre></td></tr></table></figure>
<p>然后运行: <code>sysctl -p</code>让其生效。</p>
<p>这个命令会增加系统级别（所有用户）可以打开的文件句柄数。</p>
<p>可以通过<code>/proc/sys/fs/file-max</code>或者<code>sysctl fs.file-max</code> 验证:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/sys/fs/file-max</span><br><span class="line">2097152</span><br></pre></td></tr></table></figure>
<p>还可以通过<code>/proc/sys/fs/file-nr</code>文件查看整个系统目前使用的文件句柄数量：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># cat /proc/sys/fs/file-nr</span><br><span class="line">3391    969     52427</span><br><span class="line">|        |       |</span><br><span class="line">|        |       |</span><br><span class="line">|        |       maximum open file descriptors</span><br><span class="line">|        total free allocated file descriptors</span><br><span class="line">total allocated file descriptors</span><br><span class="line">(the number of file descriptors allocated since boot)</span><br></pre></td></tr></table></figure>
<p><strong>打开的文件描述符是=column 1 – column 2</strong>; 也就是 3391 - 969 = 2325 在上面的例子中。</p>
<p><strong>TIPS</strong> 也可以通过修改<code>/proc/sys/fs/file-max</code>修改系统最大文件句柄数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;2097152&quot; &gt; /proc/sys/fs/file-max</span><br></pre></td></tr></table></figure>
<h2 id="2-用户级别限制-Per-User-Limit"><a href="#2-用户级别限制-Per-User-Limit" class="headerlink" title="2. 用户级别限制(Per-User Limit)"></a>2. 用户级别限制(Per-User Limit)</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;你也可以单独为某个用户配置最大文件句柄数，如 mysql, httpd，等。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;使用<code>ulimit</code>命令可以查看或者动态设置每个用户的资源限制：</p>
<blockquote>
<p>ulimit refers to the per-user limitations for various resources.</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ ulimit -a</span><br><span class="line">core file size          (blocks, -c) unlimited</span><br><span class="line">data seg size           (kbytes, -d) unlimited</span><br><span class="line">file size               (blocks, -f) unlimited</span><br><span class="line">pending signals                 (-i) 1549357</span><br><span class="line">max locked memory       (kbytes, -l) 64</span><br><span class="line">max memory size         (kbytes, -m) unlimited</span><br><span class="line">open files                      (-n) 65536</span><br><span class="line">pipe size            (512 bytes, -p) 8</span><br><span class="line">POSIX message queues     (bytes, -q) 819200</span><br><span class="line">stack size              (kbytes, -s) 10240</span><br><span class="line">cpu time               (seconds, -t) unlimited</span><br><span class="line">max user processes              (-u) 30720</span><br><span class="line">virtual memory          (kbytes, -v) unlimited</span><br><span class="line">file locks                      (-x) unlimited</span><br></pre></td></tr></table></figure>
<p>对应的配置文件在 <code>/etc/security/limits.conf</code>中:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">*         hard    nofile      500000</span><br><span class="line">*         soft    nofile      500000</span><br><span class="line">root      hard    nofile      500000</span><br><span class="line">root      soft    nofile      500000</span><br><span class="line">httpd     hard    nofile      500000</span><br><span class="line">httpd 	  soft    nofile      50000</span><br><span class="line">elasticsearch  -  nofile      65536</span><br></pre></td></tr></table></figure>
<p>This change will only take effect the next time the elasticsearch user opens a new session.</p>
<p>可以切换用户验证：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># su - httpd</span><br><span class="line">$ ulimit -Hn</span><br><span class="line">$ ulimit -Sn</span><br></pre></td></tr></table></figure>
<p>如果要修改当前session的limit值，可以直接使用ulimit -n newValue：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ulimit -n 65536</span><br></pre></td></tr></table></figure>
<p>The new limit is only applied during the current session.</p>
<p><strong><code>/etc/security/limits.d/90-nproc.conf</code>文件的优先级高于<code>/etc/security/limits.conf</code></strong></p>
<h2 id="3-进程级别限制-Per-Process-Limit"><a href="#3-进程级别限制-Per-Process-Limit" class="headerlink" title="3. 进程级别限制(Per-Process Limit)"></a>3. 进程级别限制(Per-Process Limit)</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>一般来说，不需要单独为某个进程设置最大的可用句柄数，因为进程会继承父进程的最大可用句柄数，而这个数一般来说就是上面的<code>ulimit -n</code>得到的值</strong>。当然，如果想要修改这个值，可用通过<code>ulimit -n xxx</code>把它设置成新的值。但是需要注意的是，不同于系统和用户级别，进程级别的文件句柄数限制必须单个进程单独设置，一般来说是在启动的时候使用ulimit命令设置:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">LIMIT=&quot;/bin/limit -n 30960&quot;</span><br><span class="line">SUPERVISE=&quot;/home/work/psop_v2/supervise/bin/supervise&quot;</span><br><span class="line"></span><br><span class="line">START_COMMAND=&quot;$&#123;SUPERVISE&#125; -p $&#123;STA_DIR&#125; -f \&quot;$&#123;LIMIT&#125; $&#123;BIN_DIR&#125;/run.sh\&quot;&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>说明：这里的<code>/bin/limit</code>应该是百度自己搞的命令，本质上相对于ulimit，不知道为什么要自己搞一个。。</p>
<p>可以通过<code>/proc/&lt;pid&gt;/limits</code>检查某个进程的资源限制情况：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/8411/limits</span><br><span class="line">Limit                     Soft Limit           Hard Limit           Units</span><br><span class="line">Max cpu time              unlimited            unlimited            seconds</span><br><span class="line">Max file size             unlimited            unlimited            bytes</span><br><span class="line">Max data size             unlimited            unlimited            bytes</span><br><span class="line">Max stack size            10485760             unlimited            bytes</span><br><span class="line">Max core file size        unlimited            unlimited            bytes</span><br><span class="line">Max resident set          unlimited            unlimited            bytes</span><br><span class="line">Max processes             30720                30720                processes</span><br><span class="line">Max open files            30960                30960                files</span><br><span class="line">Max locked memory         65536                65536                bytes</span><br><span class="line">Max address space         unlimited            unlimited            bytes</span><br><span class="line">Max file locks            unlimited            unlimited            locks</span><br><span class="line">Max pending signals       1549357              1549357              signals</span><br><span class="line">Max msgqueue size         819200               819200               bytes</span><br><span class="line">Max nice priority         0                    0</span><br><span class="line">Max realtime priority     0                    0</span><br><span class="line">Max realtime timeout      unlimited            unlimited            us</span><br></pre></td></tr></table></figure>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ol>
<li><a href="https://easyengine.io/tutorials/linux/increase-open-files-limit/" target="_blank" rel="noopener">Increase “Open Files Limit”</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/setting-system-settings.html" target="_blank" rel="noopener">Configuring system settings</a></li>
<li><a href="https://docs.mongodb.com/manual/reference/ulimit/" target="_blank" rel="noopener">UNIX ulimit Settings</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/05/08/ElasticSearch如何支持深度分页/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/08/ElasticSearch如何支持深度分页/" itemprop="url">ElasticSearch如何支持深度分页</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-08T12:12:57+08:00">
                2019-05-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/Elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">Elasticsearch</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/Elasticsearch/搜索引擎/" itemprop="url" rel="index">
                    <span itemprop="name">搜索引擎</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/Elasticsearch/搜索引擎/Lucene/" itemprop="url" rel="index">
                    <span itemprop="name">Lucene</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ElasticSearch如何支持深度分页"><a href="#ElasticSearch如何支持深度分页" class="headerlink" title="ElasticSearch如何支持深度分页"></a>ElasticSearch如何支持深度分页</h1><h2 id="分布式环境下的分页"><a href="#分布式环境下的分页" class="headerlink" title="分布式环境下的分页"></a>分布式环境下的分页</h2><p>ES本身是支持分页查询的，使用方式跟MySQL非常类似：</p>
<ul>
<li>from: Indicates the number of initial results that should be skipped, defaults to 0</li>
<li>size: Indicates the number of results that should be returned, defaults to 10</li>
</ul>
<p>如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_search?size=5&amp;from=10</span><br></pre></td></tr></table></figure>
<p>但是跟MySQL不同，ES是分布式存储的，查询结果一般都是跨多个分片的(spans multiple shards)，每个shard产生自己的排序结果，最后协调节点(coordinating node)对所有分片返回结果进行汇总排序截断返回给客户端。所以深度分页（分页深度）或者一次请求很多结果（分页大小）都会极大降低ES的查询性能。所以ES就默认限制最多只能访问前1w个文档。这是通过<code>index.max_result_window</code>控制的。</p>
<p>之前在使用Aerospike实现图数据库的时候就遇到这个问题（<a href="http://arganzheng.life/aerospike-udf.html" target="_blank" rel="noopener">Aerospike UDF学习笔记</a>） ，Aerospike本身不支持排序分页（包括简单的截断也不支持。。），但是它有一个Stream UDFs机制，可以实现这个功能：简单来说就是先在所有的node节点进行排序和截断(map)，最后在client端汇总做最后的排序和截断(reduce)，其实就是一个分布式的归并排序Merge Sort算法。</p>
<p>这个实现方式跟ES分页的实现方式是一样的。只不过ES是内建的，不需要你自己实现。但是两者都有一个巨大的性能问题，就是深度分页。假设某个index有 5 个primary shard。我们要获取第1000页的内容，页面大小是10，那么需要排序的文档数是 10001~10010 (pageSize <em> pageNumber)。那么每个分片需要本地排序产生前10010条记录，然后协调节点/聚合层(Coordinating node/Aggregator)需要对5个主分片返回的 10010 </em> 5 = 50050 （docs * Shards）条记录进行排序，最后只返回10条数据给客户端。其他的50040条全部都扔掉了。</p>
<p>也就是说为了返回第 pageNumber 页的数据，一共需要对 <code>pageSize * pageNumber * shardNumber</code> 个文档进行排序。最后只返回 pageSize 条数据，性价比真心不高。</p>
<p>但是现实中确实有需要深度遍历(scan)某个index的场景，那么怎么解决呢？</p>
<h2 id="解决方案1：服务端缓存——Scan-and-scroll-API"><a href="#解决方案1：服务端缓存——Scan-and-scroll-API" class="headerlink" title="解决方案1：服务端缓存——Scan and scroll API"></a>解决方案1：服务端缓存——Scan and scroll API</h2><p>从上面的分析我们可以看出，为了返回某一页记录，其实我们抛弃了其他的大部分已经排好序的结果。那么简单点就是把这个结果缓存起来，下次就可以用上了。根据这个思路，ES提供了<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html" target="_blank" rel="noopener">Scroll</a> API。它概念上有点像传统数据库的游标(cursor)。</p>
<p>scroll调用本质上是实时创建了一个快照(snapshot)，然后保持这个快照一个指定的时间，这样，下次请求的时候就不需要重新排序了。从这个方面上来说，scroll就是一个服务端的缓存。既然是缓存，就会有下面两个问题：</p>
<ol>
<li>一致性问题。ES的快照就是产生时刻的样子了，在过期之前的所有修改它都视而不见。</li>
<li>服务端开销。ES这里会为每一个scroll操作保留一个查询上下文(Search context)。ES默认会合并多个小的索引段(segment)成大的索引段来提供索引速度，在这个时候小的索引段就会被删除。但是在scroll的时候，如果ES发现有索引段正处于使用中，那么就不会对它们进行合并。这意味着需要更多的文件描述符以及比较慢的索引速度。</li>
</ol>
<p>其实这里还有第三个问题，但是它不是缓存的问题，而是因为ES采用的游标机制导致的。就是你只能顺序的扫描，不能随意的跳页。而且还要求客户每次请求都要带上”游标”。</p>
<p>可以使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html" target="_blank" rel="noopener">nodes stats API</a> 查看有多少个查询上下文:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_nodes/stats/indices/search</span><br></pre></td></tr></table></figure>
<p>scroll接口使用方式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /old_index/_search?scroll=1m  // =&gt; 1. Keep the scroll window open for 1 minute.</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125;&#125;,</span><br><span class="line">    &quot;sort&quot; : [&quot;_doc&quot;],  // =&gt; 2. _doc is the most efficient sort order.</span><br><span class="line">    &quot;size&quot;:  1000 // =&gt; 3. Although we specified a size of 1,000, we get back many more documents. </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>说明</strong></p>
<ol>
<li><code>scroll=1m</code>表示保持这个快照的存活时间，这里是1分钟。</li>
<li>深度分页其实最大的开销还是排序，<code>_doc</code>字段排序其实就是自然顺序。</li>
<li>虽然这里我们指定了<code>size=1000</code>，但是实际上这个请求是分发给每一个分片的，所以我们每次获取 <code>n &lt;= size * number_of_primary_shards</code>个文档。</li>
</ol>
<p>服务端会返回一个<code>_scroll_id</code>字段，这是一个Base-64编码的字符串。下一次请求就可以把这个 <code>_scroll_id</code> 带上请求 <code>_search/scroll</code>来获取下一个批次的数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_search/scroll // =&gt; 1. should not include the index or type name — these are specified in the original search request instead.</span><br><span class="line">&#123;</span><br><span class="line">    &quot;scroll&quot;: &quot;1m&quot;, // =&gt; 2. The scroll parameter tells Elasticsearch to keep the search context open for another 1m.</span><br><span class="line">    &quot;scroll_id&quot; : &quot;cXVlcnlUaGVuRmV0Y2g7NTsxMDk5NDpkUmpiR2FjOFNhNnlCM1ZDMWpWYnRROzEwOTk1OmRSamJHYWM4U2E2eUIzVkMxalZidFE7MTA5OTM6ZFJqYkdhYzhTYTZ5QjNWQzFqVmJ0UTsxMTE5MDpBVUtwN2lxc1FLZV8yRGVjWlI2QUVBOzEwOTk2OmRSamJHYWM4U2E2eUIzVkMxalZidFE7MDs=&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>说明</strong></p>
<ol>
<li>服务端将返回下一个批次数据，并且会返回一个新的<code>_score_id</code>，下次请求把新的<code>_score_id</code>带上就可以请求下一个批次了。</li>
<li><code>scroll=1m</code> 只要确保 &gt;= 每一个批次的消费时间即可，因为每一次scroll请求都会设置下一个过期时间。</li>
</ol>
<p>当scroll过期后，查询上下文(Search Context)会自动被删除。因为保持查询上下文是很昂贵的，所以如果已经处理完某个scroll返回的数据，可以使用 clear-scroll API显式删除它:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DELETE /_search/scroll</span><br><span class="line">&#123;</span><br><span class="line">    &quot;scroll_id&quot; : &quot;DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以支持批量删除:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DELETE /_search/scroll</span><br><span class="line">&#123;</span><br><span class="line">    &quot;scroll_id&quot; : [</span><br><span class="line">      &quot;DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==&quot;,</span><br><span class="line">      &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAAAxZrUllkUVlCa1NqNmRMaUhiQlZkMWFBAAAAAAAAAAIWa1JZZFFZQmtTajZkTGlIYkJWZDFhQQAAAAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>也可以一次性删除所有:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /_search/scroll/_all</span><br></pre></td></tr></table></figure>
<h3 id="Sliced-Scroll"><a href="#Sliced-Scroll" class="headerlink" title="Sliced Scroll"></a>Sliced Scroll</h3><p>Scoll每次会返回一个批次，如果你觉得这个批次还太大，那么你可以对这个批次进行分片——称之为<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html#scroll-scan" target="_blank" rel="noopener">Sliced Scroll</a>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/tweet/_search?scroll=1m</span><br><span class="line">&#123;</span><br><span class="line">    &quot;slice&quot;: &#123;</span><br><span class="line">        &quot;id&quot;: 0,  	// 1. =&gt; The id of the slice</span><br><span class="line">        &quot;max&quot;: 2 	// 2. =&gt; The maximum number of slices</span><br><span class="line"></span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;title&quot; : &quot;elasticsearch&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">GET /twitter/tweet/_search?scroll=1m</span><br><span class="line">&#123;</span><br><span class="line">    &quot;slice&quot;: &#123;</span><br><span class="line">        &quot;id&quot;: 1, 	// 1. =&gt; The id of the slice</span><br><span class="line">        &quot;max&quot;: 2	// 2. =&gt; The maximum number of slices</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;title&quot; : &quot;elasticsearch&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>说明: the maximum number of slices allowed per scroll is limited to 1024 and can be updated using the <code>index.max_slices_per_scroll</code> index setting to bypass this limit.</p>
<p><strong>TIPS</strong></p>
<p>scroll特别适合做全表扫描，ES的reindex接口内部就是使用scroll机制实现的。</p>
<h2 id="解决方案2：Search-After"><a href="#解决方案2：Search-After" class="headerlink" title="解决方案2：Search After"></a>解决方案2：Search After</h2><p>Scroll API相对于from+size方式当然是性能好很多，但是也有如下问题：</p>
<ol>
<li>Search context开销不小。</li>
<li>是一个临时快照，并不是实时的分页结果。</li>
</ol>
<p>针对这些问题，ES 5.0 开始推出了 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/search-request-search-after.html" target="_blank" rel="noopener">Search After</a> 机制可以提供了更实时的游标(live cursor)。它的思想是利用上一页的分页结果来提高下一页的分页请求。</p>
<p>假设请求第一页的请求如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/tweet/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;title&quot; : &quot;elasticsearch&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;sort&quot;: [</span><br><span class="line">        &#123;&quot;date&quot;: &quot;asc&quot;&#125;,</span><br><span class="line">        &#123;&quot;_id&quot;: &quot;desc&quot;&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意，这里为了避免sort字段相同值的导致排序不确定，这里增加了 <code>_id</code> 字段。</p>
<p>返回的结果会包含每个文档的sort字段的sort value。这个就是上面所说的 “live cursor”。</p>
<p>使用最后一个文档的sort value作为search after请求值，我们就可以这样子请求下一页结果了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/tweet/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;title&quot; : &quot;elasticsearch&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;search_after&quot;: [1463538857, &quot;654323&quot;],</span><br><span class="line">    &quot;sort&quot;: [</span><br><span class="line">        &#123;&quot;date&quot;: &quot;asc&quot;&#125;,</span><br><span class="line">        &#123;&quot;_id&quot;: &quot;desc&quot;&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意到from变成了search_after了。现在是通过search_after来确定分页的开始位置。</p>
<p>search_after使用方式上跟scroll很像，但是相对于scroll它是无状态的(stateless)，没有search context开销；而且它是每次请求都实时计算的，所以也没有一致性问题（相反，有索引变化的话，每次排序顺序会变化呢）。但是比起from+size方式，还是有同样的问题没法解决：就是只能顺序的翻页，不能随意跳页。</p>
<p>这个排序分页方案其实在app分页中大量使用。</p>
<p>由于app端的分页比较特殊，比如后台数据会近实时的发生变化，所以采用常规的分页算法 <code>[(totalRecord + pageSize - 1) / pageSize]</code> 是会有问题的。如果仍采用这种算法，当上推刷新时，就有可能加载到上一页已经看过的数据，比如用户当前正在看第2页的历史数据，如果此时后台数据源新增了一条数据，那么当用户继续上推操作查看第3页的历史数据时，就会把第2页的最后一条数据获取，并且会把该条数据作为第3页的第一条数据进行展示，这样是有问题的。所以在数据表设计时，需要在表中增加一个自增的orderId字段参与分页，然后分页时，需要将第一页的最后一条数据的orderId回传到后台，后台拿着这个orderId进行条件判断查询并且集合上面的分页算法就可以避免上面的问题（在新闻类的app中，经常使用createdTime作为orderId）。另一方便，app的滑动翻页其实就是顺序翻页，所以特别适合这种分页方式。</p>
<p>在redis中可以使用<a href="https://redis.io/topics/data-types-intro#redis-sorted-sets" target="_blank" rel="noopener">Sorted Set</a>来实现。具体的分页命令是 <a href="http://redisdoc.com/sorted_set/zrevrangebyscore.html" target="_blank" rel="noopener">ZREVRANGEBYSCORE</a>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]</span><br><span class="line"></span><br><span class="line">返回有序集 key 中， score 值介于 max 和 min 之间(默认包括等于 max 或 min )的所有的成员。有序集成员按 score 值递减(从大到小)的次序排列。</span><br><span class="line"></span><br><span class="line">具有相同 score 值的成员按字典序的逆序(reverse lexicographical order )排列。</span><br><span class="line"></span><br><span class="line">除了成员按 score 值递减的次序排列这一点外， ZREVRANGEBYSCORE 命令的其他方面和 ZRANGEBYSCORE 命令一样。</span><br><span class="line"></span><br><span class="line">可用版本：</span><br><span class="line">&gt;= 2.2.0</span><br><span class="line">时间复杂度:</span><br><span class="line">O(log(N)+M)， N 为有序集的基数， M 为结果集的基数。</span><br><span class="line">返回值:</span><br><span class="line">指定区间内，带有 score 值(可选)的有序集成员的列表。</span><br></pre></td></tr></table></figure>
<h2 id="终极解决方案"><a href="#终极解决方案" class="headerlink" title="终极解决方案?"></a>终极解决方案?</h2><p>这篇文章: <a href="https://tech.shutterstock.com/2017/05/09/efficiently-handling-deep-pagination-in-a-distributed-search-engine/" target="_blank" rel="noopener">Efficiently Handling Deep Pagination In A Distributed Search Engine</a> 介绍了一种方式，可以以牺牲一定的分页准确性来大幅度的提高分页性能，有点意思。 这里简单介绍</p>
<p>首先引入一个 Shard Factor 的概念：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Shard Factor = shards.rows / (start + rows)</span><br></pre></td></tr></table></figure>
<p>其中shards.rows就是每个分片需要返回的排序数据。start和rows就是ES的from和size。</p>
<p>根据一个<a href="https://tech.shutterstock.com/wp-content/uploads/2017/05/estimate_shard_rows.py_.zip" target="_blank" rel="noopener">计算公式</a>，可以得出如下结论：</p>
<blockquote>
<p>With 4 shards, we found that for results [0-1,000], we needed a shard factor or 38% to guarantee 99% accuracy, but for results above 1,000, 28% was sufficient. With 100 shards, we found that for results 0-1,000, we needed a shard factor or 6% to guarantee 99% accuracy, but for results above 1,000, 2% was sufficient. … This means we were able to get very near 100% accuracy, while still achieving effectively linear speedup as we distributed our search engine across more shards.</p>
</blockquote>
<p>思路非常简单，效果非常明显，有机会的话可以试试。不过前提是底层存储引擎支持指定返回排序数据的大小。Solr是支持的（<a href="https://lucene.apache.org/solr/4_2_1/solr-solrj/org/apache/solr/common/params/ShardParams.html#SHARDS_ROWS" target="_blank" rel="noopener">shards.rows</a>）这篇文章也是基于Solr实现的，但是ES目前并不支持。</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ol>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html" target="_blank" rel="noopener">Elasticsearch Reference [6.1] » Search APIs » Request Body Search » Scroll</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/scroll.html" target="_blank" rel="noopener">Elasticsearch: The Definitive Guide [2.x] » Getting Started » Distributed Search Execution » Scroll</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/search-request-search-after.html" target="_blank" rel="noopener">Elasticsearch Reference [6.1] » Search APIs » Request Body Search » Search After</a></li>
<li><a href="https://tech.shutterstock.com/2017/05/09/efficiently-handling-deep-pagination-in-a-distributed-search-engine/" target="_blank" rel="noopener">Efficiently Handling Deep Pagination In A Distributed Search Engine</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/08/掌握它才说明你真正懂Elasticsearch/" itemprop="url">掌握它才说明你真正懂Elasticsearch</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-08T12:12:57+08:00">
                2019-05-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/Elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">Elasticsearch</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/Elasticsearch/搜索引擎/" itemprop="url" rel="index">
                    <span itemprop="name">搜索引擎</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/Elasticsearch/搜索引擎/Lucene/" itemprop="url" rel="index">
                    <span itemprop="name">Lucene</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="掌握它才说明你真正懂Elasticsearch"><a href="#掌握它才说明你真正懂Elasticsearch" class="headerlink" title="掌握它才说明你真正懂Elasticsearch"></a>掌握它才说明你真正懂Elasticsearch</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="https://www.jianshu.com/p/28fb017be7a7" target="_blank" rel="noopener">https://www.jianshu.com/p/28fb017be7a7</a></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Elasticsearch</code> 基于<code>Lucene</code>，隐藏其复杂性，并提供简单易用的 <code>Restful API</code>接口、<code>Java API</code>接口。所以理解 ES 的关键在于理解 Lucene 的基本原理。</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/2b2ea0116acb161d6db018bb8210a19f.jpg-wh_651x-s_382023973.jpg" alt="img"></p>
<h2 id="Lucene-简介"><a href="#Lucene-简介" class="headerlink" title="Lucene 简介"></a>Lucene 简介</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Lucene</code> 是一种高性能、可伸缩的信息搜索(<code>IR</code>)库，在 2000 年开源，最初由鼎鼎大名的 <code>Doug Cutting</code>开发，是基于 Java 实现的高性能的开源项目。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>Lucene</code>采用了基于倒排表的设计原理，可以非常高效地实现文本查找，在底层采用了分段的存储模式，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能</strong>。</p>
<h2 id="核心模块"><a href="#核心模块" class="headerlink" title="核心模块"></a>核心模块</h2><p><code>Lucene</code> 的写流程和读流程如下图所示：</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/39e869b50faaf0b9054fec177f8ccc0c.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 1：<code>Lucene</code>的写流程和读流程</strong></p>
<p>其中，虚线箭头(a、b、c、d)表示写索引的主要过程，实线箭头(1-9)表示查询的主要过程。</p>
<p><code>Lucene</code> 中的主要模块及模块说明如下：</p>
<ul>
<li><code>analysis</code>：主要负责词法分析及语言处理，也就是我们常说的<strong>分词</strong>，通过该模块可最终形成存储或者搜索的最小单元<code>Term</code>。</li>
<li><code>index</code> 模块：主要负责<strong>索引的创建工作</strong>。</li>
<li><code>store</code> 模块：主要负责<strong>索引的读写</strong>，主要是对文件的一些操作，其主要目的是抽象出和平台文件系统无关的存储。</li>
<li><code>queryParser</code> 模块：主要负责<strong>语法分析</strong>，把我们的查询语句生成 <code>Lucene</code> 底层可以识别的条件。</li>
<li><code>search</code> 模块：主要负责对<strong>索引的搜索工作</strong>。</li>
<li><code>similarity</code> 模块：主要负责<strong>相关性打分和排序</strong>的实现。</li>
</ul>
<h2 id="核心术语"><a href="#核心术语" class="headerlink" title="核心术语"></a>核心术语</h2><p>下面介绍 <code>Lucene</code>中的核心术语：</p>
<ul>
<li><p><strong><code>Term</code>：是索引里最小的存储和查询单元</strong>，对于英文来说一般是指一个单词，对于中文来说一般是指一个分词后的词。</p>
</li>
<li><p><strong>词典(<code>Term Dictionary</code>，也叫作字典)：是 <code>Term</code> 的集合</strong>。词典的数据结构可以有很多种，每种都有自己的优缺点。</p>
</li>
</ul>
<p>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如：排序数组通过二分查找来检索数据：<code>HashMap</code>(哈希表)比排序数组的检索速度更快，但是会浪费存储空间。<code>FST(finite-state transducer)</code>有更高的数据压缩率和查询效率，因为词典是常驻内存的，而 <code>FST</code> 有很好的压缩率，所以 <code>FST</code> 在<code>Lucene</code> 的最新版本中有非常多的使用场景，也是默认的词典数据结构。</p>
<ul>
<li><p><strong>倒排序(<code>Posting List</code>)：一篇文章通常由多个词组成，倒排表记录的是某个词在哪些文章中出现过</strong>。</p>
</li>
<li><p><strong>正向信息：原始的文档信息，可以用来做排序、聚合、展示等</strong>。</p>
</li>
<li><p><strong>段(<code>Segment</code>)：索引中最小的独立存储单元</strong>。<strong>一个索引文件由一个或者多个段组成</strong>。<strong>在<code>Luence</code> 中的段有不变性，也就是说段一旦生成，在其上只能有读操作，不能有写操作</strong>。</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Lucene</code> 的底层存储格式如下图所示，由词典和倒排序两部分组成，其中的词典就是 <code>Term</code>的集合：</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/a2a6cd073330531bcb2bef05abf05a63.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 2：Lucene 的底层存储格式</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>词典中的 <code>Term</code> 指向的文档链表的集合，叫做倒排表</strong>。词典和倒排表是 <code>Lucene</code>中很重要的两种数据结构，是实现快速检索的重要基石。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>词典和倒排表是分两部分存储的，在倒排序中不但存储了文档编号，还存储了词频等信息</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在上图所示的词典部分包含三个词条(<code>Term</code>)：<code>Elasticsearch、Lucene 和 Solr</code>。词典数据是查询的入口，所以这部分数据是以 <code>FST</code>的形式存储在内存中的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在倒排表中，<code>“Lucene”</code>指向有序链表 3，7，15，30，35，67，表示字符串<code>“Lucene”</code>在文档编号为3、7、15、30、35、67的文章中出现过，<code>Elasticsearch</code> 和 <code>Solr</code>同理。</p>
<h2 id="检索方式"><a href="#检索方式" class="headerlink" title="检索方式"></a>检索方式</h2><p>在 <code>Lucene</code> 的查询过程中的主要检索方式有以下四种：</p>
<h3 id="单个词查询"><a href="#单个词查询" class="headerlink" title="单个词查询"></a>单个词查询</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;指对一个 <code>Term</code> 进行查询。比如，若要查找包含字符串<code>“Lucene”</code>的文档，则只需在词典中找到 <code>Term “Lucene”</code>，再获得在倒排表中对应的文档链表即可</p>
<h3 id="AND"><a href="#AND" class="headerlink" title="AND"></a>AND</h3><p>指对<strong>多个集合求交集</strong>。比如，若要查找既包含字符串<code>“Lucene”</code>又包含字符串<code>“Solr”</code>的文档，则查找步骤如下：</p>
<ul>
<li>在词典中找到 <code>Term “Lucene”</code>，得到<code>“Lucene”</code>对应的文档链表。</li>
<li>在词典中找到 <code>Term  “Solr”</code>，得到<code>“Solr”</code>对应的文档链表。</li>
<li>合并链表，对两个文档链表做交集运算，合并后的结果既包含<code>“Lucene”</code>也包含<code>“Solr”</code>。</li>
</ul>
<h3 id="OR"><a href="#OR" class="headerlink" title="OR"></a>OR</h3><p>指<strong>多个集合求并集</strong>。比如，若要查找包含字符串<code>“Luence”</code>或者包含字符串<code>“Solr”</code>的文档，则查找步骤如下：</p>
<ul>
<li><p>在词典中找到 <code>Term “Lucene”</code>，得到“Lucene”对应的文档链表。</p>
</li>
<li><p>在词典中找到 <code>Term “Solr”</code>，得到“Solr”对应的文档链表。</p>
</li>
<li><p>合并链表，对两个文档链表做并集运算，合并后的结果包含<code>“Lucene”</code>或者包含<code>“Solr”</code>。</p>
</li>
</ul>
<h3 id="NOT"><a href="#NOT" class="headerlink" title="NOT"></a>NOT</h3><p>指对<strong>多个集合求差集</strong>。比如，若要查找包含字符串<code>“Solr”</code>但不包含字符串<code>“Lucene”</code>的文档，则查找步骤如下：</p>
<ul>
<li><p>在词典中找到 <code>Term “Lucene”</code>，得到<code>“Lucene”</code>对应的文档链表。</p>
</li>
<li><p>在词典中找到 <code>Term “Solr”</code>，得到<code>“Solr”</code>对应的文档链表。</p>
</li>
<li><p>合并链表，对两个文档链表做差集运算，用包含<code>“Solr”</code>的文档集减去包含<code>“Lucene”</code>的文档集，运算后的结果就是包含<code>“Solr”</code>但不包含<code>“Lucene”</code>。</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上述四种查询方式，我们不难发现，由于 <strong><code>Lucene</code>是以倒排表的形式存储的</strong>。所以<strong>在 <code>Lucene</code> 的查找过程中只需在词典中找到这些 <code>Term</code>，根据 <code>Term</code> 获得文档链表，然后根据具体的查询条件对链表进行交、并、差等操作，就可以准确地查到我们想要的结果</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相对于在关系型数据库中的<code>“Like”</code>查找要做全表扫描来说，这种思路是非常高效的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然在索引创建时要做很多工作，但这种一次生成、多次使用的思路也是非常高明的。</p>
<p><strong>分段存储</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在早期的全文检索中<strong>为整个文档集合建立了一个很大的倒排索引，并将其写入磁盘中，如果索引有更新，就需要重新全量创建一个索引来替换原来的索引</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;缺陷：<strong>在数据量很大时效率很低，并且由于创建一次索引的成本很高，所以对数据的更新不能过于频繁，也就不能保证实效性</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在，在搜索中引入了段的概念(<strong>将一个索引文件拆分为多个子文件，则每个子文件叫做段</strong>)，<strong>每个段都是一个独立的可被搜索的数据集，并且段具有不变性，一旦索引的数据被写入硬盘，就不可修改</strong>。</p>
<p>在分段的思想下，对数据写操作的过程如下：</p>
<ul>
<li>新增：当有新的数据需要创建索引时，由于段不变性，所以选择<strong>新建一个段来存储新增的数据</strong>。</li>
<li>删除：当需要删除数据时，由于数据所在的段只可读，不可写，所以<strong><code>Lucene</code> 在索引文件新增一个 <code>.del</code>的文件，用来专门存储被删除的数据 id</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当查询时，被删除的数据还是可以被查到的，只是<strong>在进行文档链表合并时，才把已经删除的数据过滤掉</strong>。 <strong>被删除的数据在进行段合并时才会被真正被移除</strong>。</p>
<ul>
<li>更新：更新的操作其实就是删除和新增的组合，<strong>先在<code>.del</code>文件中记录旧数据，再在新段中添加一条更新后的数据</strong>。</li>
</ul>
<p>段不可变性的优点如下：</p>
<ul>
<li><strong>不需要锁</strong>：因为数据不会更新，所以不用考虑多线程下的读写不一致情况。</li>
<li><strong>可以常驻内存</strong>：段在被加载到内存后，由于具有不变性，所以只要内存的空间足够大，就可以长时间驻存，大部分查询请求会直接访问内存，而不需要访问磁盘，使得查询的性能有很大的提升。</li>
<li><strong>缓存友好</strong>：在段的声明周期内始终有效，不需要在每次数据更新时被重建。</li>
<li><strong>增量创建</strong>：分段可以做到增量创建索引，可以轻量级地对数据进行更新，由于每次创建的成本很低，所以可以频繁地更新数据，使系统接近实时更新。</li>
</ul>
<p>段不可变性的缺点如下：</p>
<ul>
<li>删除：当对数据进行删除时，旧数据不会被马上删除，而是在<code>.del</code>文件中被标记为删除。而旧数据只能等到段更新时才能真正地被移除，这样会<strong>有大量的空间浪费</strong>。</li>
<li>更新：更新数据由删除和新增这两个动作组成。若有一条数据频繁更新，则会有大量的空间浪费。</li>
<li>新增：由于索引具有不变性，所以每次新增数据时，都需要新增一个段来存储数据。<strong>当段数量太多时，对服务器的资源(如文件句柄)的消耗会非常大，查询的性能也会受到影响</strong>。</li>
<li>过滤：<strong>在查询后需要对已经删除的旧数据进行过滤，这增加了查询的负担</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了提升写的性能，<code>Lucene</code>并没有每新增一条数据就增加一个段，而是<strong>采用延迟写的策略，每当有新增的数据时，就将其先写入内存中，然后批量写入磁盘中</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;若有一个段被写到硬盘，就会生成一个提交点，<strong>提交点就是一个用来记录所有提交后的段信息的文件</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个段一旦拥有了提交点，就说明这个段只有读的权限，失去了写的权限;相反，<strong>当段在内存中时，就只有写数据的权限，而不具备读数据的权限，所以也就不能被检索了</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从严格意义上来说，<code>Lucene</code> 或者 <code>Elasticsearch</code>并不能被称为实时的搜索引擎，只能被称为<strong>准实时</strong>的搜索引擎。</p>
<p>写索引的流程如下：</p>
<ul>
<li>新数据被写入时，并没有被直接写到硬盘中，而是被<strong>暂时写到内存中</strong>。<strong><code>Lucene</code> 默认是一秒钟，或者当内存中数据量达到一定阶段时，再批量提交到磁盘中</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，默认的时间和数据量的大小是可以通过参数控制的。通过延时写的策略，可以减少数据往磁盘上写的次数，从而提升整体的写入性能，如图 3。</p>
<ul>
<li>在达到出触发条件以后，会将内存中缓存的数据<strong>一次性写入磁盘中，并生成提交点</strong>。</li>
<li><strong>清空内存</strong>，等待新的数据写入，如下图所示。</li>
</ul>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/a51e1f25854f23b14c8258e64f2bd7cc.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 3：Elasticsearch 写索引</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上述流程可以看出，数据先被暂时缓存在内存中，在达到一定的条件再被一次性写入硬盘中，这种做法可以大大提升数据写入的书单。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是<strong>数据先被暂时存放在内存中，并没有真正持久化到磁盘中，所以如果这时出现断电等不可控的情况，就会丢失数据，为此，<code>Elasticsearch</code>添加了事务日志，来保证数据的安全</strong>。</p>
<h2 id="段合并策略"><a href="#段合并策略" class="headerlink" title="段合并策略"></a>段合并策略</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然分段比每次都全量创建索引有更高的效率，但是由于在每次新增数据时都会新增一个段，所以<strong>经过长时间的的积累，会导致在索引中存在大量的段</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>当索引中段的数量太多时，不仅会严重消耗服务器的资源，还会影响检索的性能</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为索引检索的过程是：<strong>查询所有段中满足查询条件的数据，然后对每个段里查询的结果集进行合并，所以为了控制索引里段的数量，我们必须定期进行段合并操作</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是如果每次合并全部的段，则会造成很大的资源浪费，特别是“大段”的合并。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以<strong><code>Lucene</code> 现在的段合并思路是：根据段的大小将段进行分组，再将属于同一组的段进行合并</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是由于对于超级大的段的合并需要消耗更多的资源，所以 <code>Lucene</code> 会在段的大小达到一定规模，或者段里面的数据量达到一定条数时，不会再进行合并。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以 <strong><code>Lucene</code> 的段合并主要集中在对中小段的合并上</strong>，这样既可以避免对大段进行合并时消耗过多的服务器资源，也可以很好地控制索引中段的数量。</p>
<p>段合并的主要参数如下：</p>
<ul>
<li><code>mergeFactor</code>：每次合并时参与合并的最少数量，当同一组的段的数量达到此值时开始合并，如果小于此值则不合并，这样做可以减少段合并的频率，其默认值为 10。</li>
<li><code>SegmentSize</code>：指段的实际大小，单位为字节。</li>
<li><code>minMergeSize</code>：小于这个值的段会被分到一组，这样可以加速小片段的合并。</li>
<li><code>maxMergeSize</code>：若有一段的文本数量大于此值，就不再参与合并，因为大段合并会消耗更多的资源。</li>
</ul>
<p>段合并相关的动作主要有以下两个：</p>
<ul>
<li><strong>对索引中的段进行分组，把大小相近的段分到一组</strong>，主要由 <code>LogMergePolicy1</code> 类来处理。</li>
<li><strong>将属于同一分组的段合并成一个更大的段</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在段合并前对段的大小进行了标准化处理，通过<code>logMergeFactorSegmentSize</code> 计算得出。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中 <code>MergeFactor</code> 表示一次合并的段的数量，<code>Lucene</code> 默认该数量为 10;<code>SegmentSize</code> 表示段的实际大小。通过上面的公式计算后，段的大小更加紧凑，对后续的分组更加友好。</p>
<p>段分组的步骤如下：</p>
<p>①根据段生成的时间对段进行排序，然后根据上述标准化公式计算每个段的大小并且存放到段信息中，后面用到的描述段大小的值都是标准化后的值，如图 4 所示：</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/c0c20ddf55d97008677be4f38caf034b.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 4：Lucene 段排序</strong></p>
<p>②<strong>在数组中找到最大的段，然后生成一个由最大段的标准化值作为上限，减去 <code>LEVEL_LOG_SPAN</code>(默认值为 0.75)后的值作为下限的区间，小于等于上限并且大于下限的段，都被认为是属于同一组的段，可以合并</strong>。</p>
<p>③在确定一个分组的上下限值后，就需要查找属于这个分组的段了，具体过程是：创建两个指针(在这里使用指针的概念是为了更好地理解)<code>start</code> 和 <code>end</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>start</code> 指向数组的第 1 个段，<code>end</code> 指向第 <code>start+MergeFactor</code> 个段，然后从 <strong><code>end</code> 逐个向前查找落在区间的段</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>当找到第 1 个满足条件的段时，则停止，并把当前段到 <code>start</code>之间的段统一分到一个组，无论段的大小是否满足当前分组的条件</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图 5 所示，第 2 个段明显小于该分组的下限，但还是被分到了这一组。</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/142369c09ce8cb4c2ac0fdf68b12cc16.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 5：Lucene 段分组</strong></p>
<p>这样做的好处如下：</p>
<ul>
<li>增加段合并的概率，避免由于段的大小参差不齐导致段难以合并。</li>
<li>简化了查找的逻辑，使代码的运行效率更高。</li>
</ul>
<p>④在分组找到后，需要<strong>排除不参加合并的“超大”段，然后判断剩余的段是否满足合并的条件</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图 5 所示，<code>mergeFactor=5</code>，而找到的满足合并条件的段的个数为 4，所以不满足合并的条件，暂时不进行合并，继续找寻下一个组的上下限。</p>
<p>⑤由于在第 4 步并没有找到满足段合并的段的数量，所以这一分组的段不满足合并的条件，继续进行下一分组段的查找。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;具体过程是：将 start 指向 end，在剩下的段(从<code>end</code>指向的元素开始到数组的最后一个元素)中寻找最大的段，在找到最大的值后再减去 <code>LEVEL_LOG_SPAN</code> 的值，再生成一下分组的区间值。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后把 <code>end</code> 指向数组的第<code>start+MergeFactor</code>个段，逐个向前查找第 1 个满足条件的段：重复第 3 步和第 4 步。</p>
<p>⑥<strong>如果一直没有找到满足合并条件的段，则一直重复第 5 步，直到遍历完整个数组</strong>，如图 6 所示：</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/eb1f1c5a40780aaa0e7e24c7006ebc4a.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 6：Lucene 段分组二</strong></p>
<p>⑦在找到满足条件的 <code>mergeFactor</code> 个段时，就需要开始合并了。但是在满足合并条件的段大于 <code>mergeFactor</code>时，就需要进行多次合并。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;也就是说<strong>每次依然选择 <code>mergeFactor</code> 个段进行合并，直到该分组的所有段合并完成，再进行下一分组的查找合并操作</strong>。</p>
<p>⑧通过上述几步，如果找到了满足合并要求的段，则将会进行段的合并操作。</p>
<p>因为<strong>索引里面包含了正向信息和反向信息，所以段合并的操作分为两部分</strong>：</p>
<ul>
<li><strong>一个是正向信息合并，例如存储域、词向量、标准化因子等</strong>。</li>
<li><strong>一个是反向信息的合并，例如词典、倒排表等</strong>。</li>
</ul>
<p><strong>在段合并时，除了需要对索引数据进行合并，还需要移除段中已经删除的数据</strong>。</p>
<h2 id="Lucene-相似度打分"><a href="#Lucene-相似度打分" class="headerlink" title="Lucene 相似度打分"></a>Lucene 相似度打分</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们在前面了解到，<code>Lucene</code> 的查询过程是：首先在词典中查找每个 <code>Term</code>，根据 <code>Term</code> 获得每个 <code>Term</code>所在的文档链表;然后根据查询条件对链表做交、并、差等操作，链表合并后的结果集就是我们要查找的数据。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样做可以完全避免对关系型数据库进行全表扫描，可以大大提升查询效率。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，当我们一次查询出很多数据时，这些数据和我们的查询条件又有多大关系呢?其文本相似度是多少?</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本节会回答这个问题，并介绍 <strong><code>Lucene</code> 最经典的两个文本相似度算法：基于向量空间模型的算法和基于概率的算法(<code>BM25</code>)</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果对此算法不太感兴趣，那么只需了解对文本相似度有影响的因子有哪些，哪些是正向的，哪些是逆向的即可，不需要理解每个算法的推理过程。但是这两个文本相似度算法有很好的借鉴意义。</p>
<h2 id="Elasticsearch-简介"><a href="#Elasticsearch-简介" class="headerlink" title="Elasticsearch 简介"></a>Elasticsearch 简介</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Elasticsearch</code> 是使用 <code>Java</code> 编写的一种开源搜索引擎，它在内部使用 <code>Luence</code>做索引与搜索，通过对 <code>Lucene</code> 的封装，提供了一套简单一致的 <code>RESTful API</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Elasticsearch</code> 也是一种分布式的搜索引擎架构，可以很简单地扩展到上百个服务节点，并支持 <code>PB</code> 级别的数据查询，使系统具备高可用和高并发性。</p>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><p><code>Elasticsearch</code> 的核心概念如下：</p>
<ul>
<li><code>Cluster</code>：集群，由一个或多个 <code>Elasticsearch</code> 节点组成。</li>
<li><code>Node</code>：节点，组成 <code>Elasticsearch</code> 集群的服务单元，同一个集群内节点的名字不能重复。通常在一个节点上分配一个或者多个分片。</li>
<li><strong><code>Shards</code>：分片，当索引上的数据量太大的时候，我们通常会将一个索引上的数据进行水平拆分，拆分出来的每个数据库叫作一个分片</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一个多分片的索引中写入数据时，<strong>通过路由来确定具体写入那一个分片中，所以在创建索引时需要指定分片的数量，并且分片的数量一旦确定就不能更改</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分片后的索引带来了规模上(数据水平切分)和性能上(并行执行)的提升。<strong>每个分片都是 Luence 中的一个索引文件，每个分片必须有一个主分片和零到多个副本分片</strong>。</p>
<ul>
<li><strong>Replicas：备份也叫作副本，是指对主分片的备份</strong>。主分片和备份分片都可以对外提供查询服务，<strong>写操作时先在主分片上完成，然后分发到备份上</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>当主分片不可用时，会在备份的分片中选举出一个作为主分片</strong>，所以备份不仅可以提升系统的高可用性能，还可以提升搜索时的并发性能。但是<strong>若副本太多的话，在写操作时会增加数据同步的负担</strong>。</p>
<ul>
<li><code>Index</code>：索引，由一个和多个分片组成，通过索引的名字在集群内进行唯一标识。</li>
<li><code>Type</code>：类别，指<strong>索引内部的逻辑分区</strong>，通过 Type 的名字在索引内进行唯一标识。在查询时如果没有该值，则表示在整个索引中查询。</li>
<li><code>Document</code>：文档，<strong>索引中的每一条数据叫作一个文档</strong>，类似于关系型数据库中的一条数据通过 _id 在 Type 内进行唯一标识。</li>
<li><code>Settings</code>：对集群中索引的定义，比如一个索引默认的分片数、副本数等信息。</li>
<li><code>Mapping</code>：类似于关系型数据库中的表结构信息，用于定义索引中字段(Field)的存储类型、分词方式、是否存储等信息。<code>Elasticsearch</code> 中的 <code>Mapping</code> 是可以动态识别的。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果没有特殊需求，则不需要手动创建 <code>Mapping</code>，因为 <code>Elasticsearch</code> 会自动根据数据格式识别它的类型，但是当需要对某些字段添加特殊属性(比如：定义使用其他分词器、是否分词、是否存储等)时，就需要手动设置 Mapping 了。一个索引的 Mapping 一旦创建，若已经存储了数据，就不可修改了。</p>
<ul>
<li><strong><code>Analyzer</code>：字段的分词方式的定义</strong>。一个<code>Analyzer</code> 通常由一个 <code>Tokenizer</code>、零到多个 <code>Filter</code>组成。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如默认的标准<code>Analyzer</code> 包含一个标准的 <code>Tokenizer</code> 和三个 <code>Filter</code>：<code>Standard Token Filter、Lower Case Token Filter、Stop Token Filter</code>。</p>
<h3 id="节点分类"><a href="#节点分类" class="headerlink" title="节点分类"></a>节点分类</h3><h4 id="主节点-Master-Node"><a href="#主节点-Master-Node" class="headerlink" title="主节点(Master Node)"></a>主节点(<code>Master Node</code>)</h4><p><strong>主节点负责创建索引、删除索引、分配分片、追踪集群中的节点状态等工作</strong>。<code>Elasticsearch</code> 中的主节点的工作量相对较轻。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>用户的请求可以发往任何一个节点，并由该节点负责分发请求、收集结果等操作，而并不需要经过主节点转发</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过在配置文件中设置<code>node.master=true</code>来设置该节点成为候选主节点(但该节点不一定是主节点，<strong>主节点是集群在候选节点中选举出来的</strong>)</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>在<code>Elasticsearch</code> 集群中只有候选节点才有选举权和被选举权。其他节点是不参与选举工作的</strong>。</p>
<h4 id="数据节点-Data-Node"><a href="#数据节点-Data-Node" class="headerlink" title="数据节点(Data Node)"></a>数据节点(Data Node)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>数据节点，负责数据的存储和相关具体操作，比如索引数据的创建、修改、删除、搜索、聚合</strong>。所以，数据节点对机器配置要求比较高，首先需要有足够的磁盘空间来存储数据，其次数据操作对系统 <code>CPU、Memory 和 I/O 的性能消耗都很大。</code></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常随着集群的扩大，需要增加更多的数据节点来提高可用性。通过在配置文件中设置 <code>node.data=true</code> 来设置该节点成为数据节点。</p>
<h4 id="客户端节点-Client-Node"><a href="#客户端节点-Client-Node" class="headerlink" title="客户端节点(Client Node)"></a>客户端节点(Client Node)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>就是既不做候选主节点也不做数据节点的节点，只负责请求的分发、汇总等，也就是下面要说到的协调节点的角色</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其实任何一个节点都可以完成这样的工作，<strong>单独增加这样的节点更多地是为了提高并发性</strong>。</p>
<p>可在配置文件中设置该节点成为数据节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node.master=false</span><br><span class="line">node.data=false</span><br></pre></td></tr></table></figure>
<h4 id="部落节点-Tribe-Node"><a href="#部落节点-Tribe-Node" class="headerlink" title="部落节点(Tribe Node)"></a>部落节点(Tribe Node)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>部落节点可以跨越多个集群，它可以接收每个集群的状态，然后合并成一个全局集群的状态</strong>。</p>
<p>它可以读写所有集群节点上的数据，在配置文件中通过如下设置使节点成为部落节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tribe:  </span><br><span class="line">	one:    </span><br><span class="line">    	cluster.name: cluster_one  </span><br><span class="line">    two: </span><br><span class="line">    	cluster.name: cluster_two</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为 <code>Tribe Node</code> 要在<code>Elasticsearch 7.0 以后移除</code>，所以不建议使用。</p>
<h4 id="协调节点-Coordinating-Node"><a href="#协调节点-Coordinating-Node" class="headerlink" title="协调节点(Coordinating Node)"></a>协调节点(Coordinating Node)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>协调节点，是一种角色，而不是真实的<code>Elasticsearch</code>的节点，我们没有办法通过配置项来配置哪个节点为协调节点</strong>。<strong>集群中的任何节点都可以充当协调节点的角色</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>当一个节点 A 收到用户的查询请求后，会把查询语句分发到其他的节点，然后合并各个节点返回的查询结果，最好返回一个完整的数据集给用户</strong>。在这个过程中，节点 A 扮演的就是协调节点的角色。由此可见，协调节点会对 <code>CPU、Memory 和 I/O</code> 要求比较高。</p>
<h3 id="集群状态"><a href="#集群状态" class="headerlink" title="集群状态"></a>集群状态</h3><ul>
<li><code>Green</code>：绿色，健康。<strong>所有的主分片和副本分片都可正常工作</strong>，集群 100% 健康。</li>
<li><code>Yellow</code>：黄色，预警。所有的主分片都可以正常工作，但<strong>至少有一个副本分片是不能正常工作的</strong>。此时集群可以正常工作，但是集群的高可用性在某种程度上被弱化。</li>
<li><code>Red</code>：红色，集群不可正常使用。<strong>集群中至少有一个分片的主分片及它的全部副本分片都不可正常工作</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这时虽然集群的查询操作还可以进行，但是也只能返回部分数据(其他正常分片的数据可以返回)，而分配到这个分片上的写入请求将会报错，最终会导致数据的丢失。</p>
<h3 id="3C-和脑裂"><a href="#3C-和脑裂" class="headerlink" title="3C 和脑裂"></a>3C 和脑裂</h3><h4 id="共识性-Consensus"><a href="#共识性-Consensus" class="headerlink" title="共识性(Consensus)"></a>共识性(Consensus)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;共识性是分布式系统中最基础也最主要的一个组件，<strong>在分布式系统中的所有节点必须对给定的数据或者节点的状态达成共识</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然现在有很成熟的共识算法如<code>Raft、Paxos</code>等，也有比较成熟的开源软件如 <code>Zookeeper</code>。但是 <code>Elasticsearch</code> 并没有使用它们，而是自己实现共识系统<code>zen discovery</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Elasticsearch</code> 之父 <code>Shay Banon</code> 解释了其中主要的原因：“<code>zen discovery</code>是 <code>Elasticsearch</code> 的一个核心的基础组件，<code>zen discovery</code> 不仅能够实现共识系统的选择工作，还能够很方便地监控集群的读写状态是否健康。当然，我们也不保证其后期会使用<code>Zookeeper</code> 代替现在的 <code>zen discovery</code>”。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>zen discovery</code> 模块以“八卦传播”<code>(Gossip)</code>的形式实现了单播<code>(Unicat)</code>：单播不同于多播<code>(Multicast)</code>和广播<code>(Broadcast)</code></strong>。<strong>节点间的通信方式是一对一的</strong>。</p>
<h4 id="并发-Concurrency"><a href="#并发-Concurrency" class="headerlink" title="并发(Concurrency)"></a>并发(Concurrency)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Elasticsearch</code>是一个分布式系统。<strong>写请求在发送到主分片时，同时会以并行的形式发送到备份分片，但是这些请求的送达时间可能是无序的</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这种情况下，<code>Elasticsearch</code> 用<strong>乐观并发控制(<code>Optimistic Concurrency Control</code>)</strong>来保证新版本的数据不会被旧版本的数据覆盖。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;乐观并发控制是一种乐观锁，另一种常用的乐观锁即多版本并发控制(<code>Multi-Version Concurrency Control</code>)。</p>
<p>它们的主要区别如下：</p>
<ul>
<li>乐观并发控制(<code>OCC</code>)：是一种用来解决写-写冲突的无锁并发控制，认为<strong>事务间的竞争不激烈时，就先进行修改，在提交事务前检查数据有没有变化，如果没有就提交，如果有就放弃并重试</strong>。乐观并发控制类似于自选锁，<strong>适用于低数据竞争且写冲突比较少的环境</strong>。</li>
<li>多版本并发控制(<code>MVCC</code>)：是一种用来解决读-写冲突的无所并发控制，也就是<strong>为事务分配单向增长的时间戳，为每一个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样<strong>在读操作不用阻塞操作且写操作不用阻塞读操作的同时，避免了脏读和不可重复读</strong>。</p>
<h4 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性(Consistency)"></a>一致性(Consistency)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Elasticsearch</code>集群保证写一致性的方式是<strong>在写入前先检查有多少个分片可供写入，如果达到写入条件，则进行写操作，否则，<code>Elasticsearch</code> 会等待更多的分片出现，默认为一分钟</strong>。</p>
<p>有如下三种设置来判断是否允许写操作：</p>
<ul>
<li><p><code>One</code>：只要主分片可用，就可以进行写操作。</p>
</li>
<li><p><code>All</code>：只有当主分片和所有副本都可用时，才允许写操作。</p>
</li>
<li><p><code>Quorum</code>(k-wu-wo/reng，法定人数)：是 <code>Elasticsearch</code> 的默认选项。<strong>当有大部分的分片可用时才允许写操作</strong>。其中，对“大部分”的计算公式为 <code>int((primary+number_of_replicas)/2)+1</code>。</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Elasticsearch</code> 集群保证读写一致性的方式是，为了保证搜索请求的返回结果是最新版本的文档，备份可以被设置为 <code>Sync</code>(默认值)，<strong>写操作在主分片和备份分片同时完成后才会返回写请求的结果</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样，无论搜索请求至哪个分片都会返回最新的文档。但是如果我们的应用对写要求很高，就可以通过设置 <code>replication=async</code> 来提升写的效率，如果设置 <code>replication=async</code>，则只要主分片的写完成，就会返回写成功。</p>
<h4 id="脑裂"><a href="#脑裂" class="headerlink" title="脑裂"></a>脑裂</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>在 <code>Elasticsearch</code>集群中主节点通过 <code>Ping</code> 命令来检查集群中的其他节点是否处于可用状态，同时非主节点也会通过 <code>Ping</code>来检查主节点是否处于可用状态</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当集群网络不稳定时，有可能会发生一个节点<code>Ping</code> 不通 <code>Master</code> 节点，则会认为<code>Master</code> 节点发生了故障，然后重新选出一个 <code>Maste</code>r 节点，这就会导致在一个集群内出现多个 <code>Master</code> 节点。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>当在一个集群中有多个 Master 节点时，就有可能会导致数据丢失</strong>。<strong>我们称这种现象为脑裂</strong>。</p>
<h3 id="事务日志"><a href="#事务日志" class="headerlink" title="事务日志"></a>事务日志</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们在上面了解到，<code>Lucene</code> 为了加快写索引的速度，采用了延迟写入的策略。虽然这种策略提高了写入的效率，但其最大的弊端是，如果数据在内存中还没有持久化到磁盘上时发生了类似断电等不可控情况，就<strong>可能丢失数据</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>为了避免丢失数据，<code>Elasticsearch</code> 添加了事务日志(<code>Translog</code>)，事务日志记录了所有还没有被持久化磁盘的数据</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Elasticsearch</code> 写索引的具体过程如下：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先，当有数据写入时，为了提升写入的速度，并没有数据直接写在磁盘上，而是先写入到内存中，但是为了防止数据的丢失，会<strong>追加一份数据到事务日志里</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>因为内存中的数据还会继续写入，所以内存中的数据并不是以段的形式存储的，是检索不到的</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总之，<code>Elasticsearch</code>是一个准实时的搜索引擎，而不是一个实时的搜索引擎。</p>
<p>此时的状态如图 7 所示：</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/dc7e4d4adbb1dd61bde05555d000c34c.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 7：Elasticsearch 写数据的过程</strong></p>
<p>然后，<strong>当达到默认的时间(1 秒钟)或者内存的数据达到一定量时，会触发一次刷新(Refresh)</strong>。</p>
<p>刷新的主要步骤如下：</p>
<ul>
<li>将内存中的数据刷新到一个新的段中，但是该段并没有持久化到硬盘中，而是<strong>缓存在操作系统的文件缓存系统中</strong>。虽然数据还在内存中，但是内存里的数据和文件缓存系统里的数据有以下区别：</li>
</ul>
<ol>
<li><p>内存使用的是 <code>JVM</code> 的内存，而文件缓存系统使用的是操作系统的内存;</p>
</li>
<li><p>内存的数据不是以段的形式存储的，并且可以继续向内存里写数据。文件缓存系统中的数据是以段的形式存储的，所以只能读，不能写;</p>
</li>
<li><p>内存中的数据是搜索不到，文件缓存系统中的数据是可以搜索的。</p>
</li>
</ol>
<ul>
<li><strong>打开保存在文件缓存系统中的段，使其可被搜索</strong>。</li>
<li><strong>清空内存，准备接收新的数据</strong>。<strong>日志不做清空处理</strong>。</li>
</ul>
<p>此时的状态如图 8 所示：</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/74e7ea1d37b00e22252145f93d857b7f.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 8：Elasticsearch 写数据的过程</strong></p>
<p>最后，刷新(<code>Flush</code>)。<strong>当日志数据的大小超过 512MB 或者时间超过 30 分钟时，需要触发一次刷新</strong>。</p>
<p>刷新的主要步骤如下：</p>
<ul>
<li>在文件缓存系统中创建一个新的段，并把内存中的数据写入，使其可被搜索。</li>
<li>清空内存，准备接收新的数据。</li>
<li><strong>将文件系统缓存中的数据通过 Fsync 函数刷新到硬盘中</strong>。</li>
<li>生成提交点。</li>
<li><strong>删除旧的日志，创建一个空的日志</strong>。</li>
</ul>
<p>此时的状态如图 9 所示：</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/970f1ba435b83da539a4ee2b6be70707.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 9：Elasticsearch 写数据的过程</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由上面索引创建的过程可知，<strong>内存里面的数据并没有直接被刷新(<code>Flush</code>)到硬盘中，而是被刷新(<code>Refresh</code>)到了文件缓存系统中，这主要是因为持久化数据十分耗费资源，频繁地调用会使写入的性能急剧下降</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以 <code>Elasticsearch</code>，为了提高写入的效率，利用了文件缓存系统和内存来加速写入时的性能，并使用日志来防止数据的丢失。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>在需要重启时，Elasticsearch 不仅要根据提交点去加载已经持久化过的段，还需要根据 Translog 里的记录，把未持久化的数据重新持久化到磁盘上</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据上面对 <code>Elasticsearch</code>，写操作流程的介绍，我们可以整理出一个索引数据所要经历的几个阶段，以及每个阶段的数据的存储方式和作用，如图 10 所示：</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/d023189158faa9c537386b293e736d39.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 10：Elasticsearch 写操作流程</strong></p>
<h3 id="在集群中写索引"><a href="#在集群中写索引" class="headerlink" title="在集群中写索引"></a>在集群中写索引</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设我们有如图 11 所示(图片来自官网)的一个集群，该集群由三个节点组成(<code>Node 1、Node 2 和 Node 3</code>)，包含一个由两个主分片和每个主分片由两个副本分片组成的索引。</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/98b8d747a7cc5a63445297e48fe655ae.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 11：写索引</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，标星号的 Node 1 是 Master 节点，负责管理整个集群的状态;p1 和 p2 是主分片;r0 和 r1 是副本分片。<strong>为了达到高可用，Master 节点避免将主分片和副本放在同一个节点</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>将数据分片是为了提高可处理数据的容量和易于进行水平扩展，为分片做副本是为了提高集群的稳定性和提高并发量</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在主分片挂掉后，会从副本分片中选举出一个升级为主分片，当副本升级为主分片后，由于少了一个副本分片，所以集群状态会从 Green 改变为 Yellow，但是此时集群仍然可用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一个集群中有一个分片的主分片和副本分片都挂掉后，集群状态会由 Yellow 改变为 Red，集群状态为 Red 时集群不可正常使用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由上面的步骤可知，<strong>副本分片越多，集群的可用性就越高，但是由于每个分片都相当于一个 <code>Lucene</code>的索引文件，会占用一定的文件句柄、内存及 CPU，并且分片间的数据同步也会占用一定的网络带宽，所以，索引的分片数和副本数并不是越多越好</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;写索引时只能写在主分片上，然后同步到副本上，那么，一个数据应该被写在哪个分片上呢?</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图 10 所示，如何知道一个数据应该被写在 p0 还是 p1 上呢答案就是<code>路由(routing)</code>，路由公式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shard = hash(routing) % number_of_primary_shards</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，<code>Routing</code> 是一个可选择的值，默认是文档的 _id(文档的唯一主键，文档在创建时，如果文档的 _id 已经存在，则进行更新，如果不存在则创建)。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;后面会介绍如何通过自定义 <code>Routing</code> 参数使查询落在一个分片中，而不用查询所有的分片，从而提升查询的性能。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Routing</code> 通过 <code>Hash 函数</code>生成一个数字，将这个数字除以 <code>number_of_primary_shards</code>(分片的数量)后得到余数。这个分布在 0 到 <code>number_of_primary_shards - 1</code> 之间的余数，就是我们所寻求的文档所在分片的位置。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这也就说明了<strong>一旦分片数定下来就不能再改变的原因，因为分片数改变之后，所有之前的路由值都会变得无效，前期创建的文档也就找不到了</strong>。由于在 <code>Elasticsearch</code> 集群中每个节点都知道集群中的文档的存放位置(通过路由公式定位)，所以每个节点都有处理读写请求的能力。<strong>在一个写请求被发送到集群中的一个节点后，此时，该节点被称为协调点(<code>Coordinating Node</code>)，协调点会根据路由公式计算出需要写到哪个分片上，再将请求转发到该分片的主分片节点上</strong>。</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/a6666e6ab2709541ac64e7fc88388063.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>图 12：写索引</strong></p>
<p>写操作的流程如下(参考图 11，图片来自官网)：</p>
<ul>
<li>客户端向 <code>Node 1</code>(协调节点)发送写请求。</li>
<li>Node 1 通过文档的 _id(默认是 _id，但不表示一定是 _id)确定文档属于哪个分片(在本例中是编号为 0 的分片)。请求会被转发到主分片所在的节点 Node 3 上。</li>
<li>Node 3 在主分片上执行请求，如果成功，则将请求并行转发到 Node 1 和 Node 2 的副本分片上。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>一旦所有的副本分片都报告成功(默认)，则 Node 3 将向协调节点报告成功，协调节点向客户端报告成功</strong>。</p>
<h3 id="集群中的查询流程"><a href="#集群中的查询流程" class="headerlink" title="集群中的查询流程"></a>集群中的查询流程</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据<code>Routing</code>字段进行的单个文档的查询，在 <code>Elasticsearch</code>集群中可以在主分片或者副本分片上进行。</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/670e22b5568b5f88dbcef62c50f03f84.jpg" alt="img"></p>
<p>查询字段刚好是 <code>Routing</code>的分片字段如“_id”的查询流程如下：</p>
<ul>
<li><strong>客户端向集群发送查询请求，集群再随机选择一个节点作为协调点</strong>(Node 1)，负责处理这次查询。<ul>
<li>Node 1 使用文档的 <code>routing id</code>来计算要查询的文档在哪个分片上(在本例中落在了 0 分片上)分片 0 的副本分片存在所有的三个节点上。</li>
</ul>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>在这种情况下，协调节点可以把请求转发到分片的任意节点</strong>，本例将请求转发到 Node 2 上。</p>
<ul>
<li>Node 2 执行查找，并将查找结果返回给协调节点 Node 1，Node 1 再将文档返回给客户端。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当一个搜索请求被发送到某个节点时，这个节点就变成了协调节点(Node 1)。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>协调节点的任务是广播查询请求到所有分片(主分片或者副本分片)，并将它们的响应结果整合成全局排序后的结果集合</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由上面步骤 3 所示，<strong>默认返回给协调节点并不是所有的数据，而是只有文档的 id 和得分 score</strong>，因为我们最后只返回给用户 size 条数据，所以这样做的好处是可以节省很多带宽，特别是 from 很大时。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>协调节点对收集回来的数据进行排序后，找到要返回的 size 条数据的 id，再根据 id 查询要返回的数据</strong>，比如 title、content 等。</p>
<p><img src="//blog.com/2019/05/08/掌握它才说明你真正懂Elasticsearch/38a8e5bb26375c6894b6dffd62681c39.jpg" alt="img"></p>
<p>取回数据等流程如下：</p>
<ul>
<li>Node 3 进行二次排序来找出要返回的文档 id，并向相关的分片提交多个获得文档详情的请求。</li>
<li>每个分片加载文档，并将文档返回给 Node 3。</li>
<li>一旦所有的文档都取回了，Node 3 就返回结果给客户端。</li>
</ul>
<p><strong>协调节点收集各个分片查询出来的数据，再进行二次排序，然后选择需要被取回的文档</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如，如果我们的查询指定了<code>{&quot;from&quot;: 20, &quot;size&quot;: 10}</code>，那么我们<strong>需要在每个分片中查询出来得分最高的 20+10 条数据，协调节点在收集到 30×n(n 为分片数)条数据后再进行排序</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;排序位置在 0-20 的结果会被丢弃，只有从第 21 个开始的 10 个结果需要被取回。这些文档可能来自多个甚至全部分片。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由上面的搜索策略可以知道，<strong>在查询时深翻(Deep Pagination)并不是一种好方法</strong>。<strong>因为深翻时，from 会很大，这时的排序过程可能会变得非常沉重，会占用大量的 CPU、内存和带宽</strong>。因为这个原因，所以强烈建议慎重使用深翻。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>分片可以减少每个片上的数据量，加快查询的速度，但是在查询时，协调节点要在收集数(from+size)×n 条数据后再做一次全局排序</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>若这个数据量很大，则也会占用大量的 CPU、内存、带宽等，并且分片查询的速度取决于最慢的分片查询的速度，所以分片数并不是越多越好</strong>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/05/08/CopyOnWrite思想在Kafka源码中的运用/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/08/CopyOnWrite思想在Kafka源码中的运用/" itemprop="url">CopyOnWrite思想在Kafka源码中的运用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-08T12:12:57+08:00">
                2019-05-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/写时复制/" itemprop="url" rel="index">
                    <span itemprop="name">写时复制</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CopyOnWrite思想在Kafka源码中的运用"><a href="#CopyOnWrite思想在Kafka源码中的运用" class="headerlink" title="CopyOnWrite思想在Kafka源码中的运用"></a><strong>CopyOnWrite思想在Kafka源码中的运用</strong></h1><h2 id="1、读多写少的场景下引发的问题？"><a href="#1、读多写少的场景下引发的问题？" class="headerlink" title="1、读多写少的场景下引发的问题？"></a>1、读多写少的场景下引发的问题？</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大家可以设想一下现在我们的<strong>内存里有一个<code>ArrayList</code>，这个<code>ArrayList</code>默认情况下肯定是线程不安全的</strong>，要是多个线程并发读和写这个<code>ArrayList</code>可能会有问题。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;好，问题来了，我们应该<strong>怎么让这个ArrayList变成线程安全的呢</strong>？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有一个非常简单的办法，对这个<code>ArrayList</code>的访问都加上线程同步的控制。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如说一定要在<code>synchronized</code>代码段来对这个<code>ArrayList</code>进行访问，这样的话，就能同一时间就让一个线程来操作它了，或者是用<code>ReadWriteLock</code>读写锁的方式来控制，都可以。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们假设就是用<code>ReadWriteLock</code>读写锁的方式来控制对这个<code>ArrayList</code>的访问。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样多个读请求可以同时执行从<code>ArrayList</code>里读取数据，但是读请求和写请求之间互斥，写请求和写请求也是互斥的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大家看看，代码大概就是类似下面这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public Object read() &#123;</span><br><span class="line"></span><br><span class="line">    lock.readLock().lock();</span><br><span class="line"></span><br><span class="line">   // 对ArrayList读取</span><br><span class="line"></span><br><span class="line">    lock.readLock().unlock();</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public void write() &#123;</span><br><span class="line"></span><br><span class="line">    lock.writeLock().lock();</span><br><span class="line"></span><br><span class="line">    // 对ArrayList写</span><br><span class="line"></span><br><span class="line">    lock.writeLock().unlock();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大家想想，类似上面的代码有什么问题呢？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>最大的问题，其实就在于写锁和读锁的互斥</strong>。假设写操作频率很低，读操作频率很高，是写少读多的场景。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>那么偶尔执行一个写操作的时候，是不是会加上写锁，此时大量的读操作过来是不是就会被阻塞住，无法执行？</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个就是读写锁可能遇到的最大的问题。</p>
<h2 id="2、引入-CopyOnWrite-思想解决问题"><a href="#2、引入-CopyOnWrite-思想解决问题" class="headerlink" title="2、引入 CopyOnWrite 思想解决问题"></a><strong>2、引入 CopyOnWrite 思想解决问题</strong></h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个时候就要引入<code>CopyOnWrite</code>思想来解决问题了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;他的思想就是，<strong>不用加什么读写锁，锁统统给我去掉，有锁就有问题，有锁就有互斥，有锁就可能导致性能低下，你阻塞我的请求，导致我的请求都卡着不能执行</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么他怎么保证多线程并发的安全性呢？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很简单，顾名思义，利用“<code>CopyOnWrite</code>”的方式，这个英语翻译成中文，大概就是“<strong>写数据的时候利用拷贝的副本来执行</strong>”。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;你在读数据的时候，其实不加锁也没关系，大家左右都是一个读罢了，互相没影响。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问题主要是在写的时候，写的时候你既然不能加锁了，那么就得采用一个策略。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假如说你的<code>ArrayList</code>底层是一个数组来存放你的列表数据，那么这时比如你要修改这个数组里的数据，你就必须先拷贝这个数组的一个副本。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后你<strong>可以在这个数组的副本里写入你要修改的数据，但是在这个过程中实际上你都是在操作一个副本而已</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样的话，读操作是不是可以同时正常的执行？这个写操作对读操作是没有任何的影响的吧！</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大家看下面的图，一起来体会一下这个过程：</p>
<p><img src="//blog.com/2019/05/08/CopyOnWrite思想在Kafka源码中的运用/2.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关键问题来了，那那个<strong>写线程现在把副本数组给修改完了，现在怎么才能让读线程感知到这个变化呢？</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>关键点来了，划重点！</strong>这里要配合上<code>volatile</code>关键字的使用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;笔者之前写过文章，给大家解释过<code>volatile</code>关键字的使用，<strong>核心就是让一个变量被写线程给修改之后，立马让其他线程可以读到这个变量引用的最近的值</strong>，这就是<code>volatile</code>最核心的作用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以一旦写线程搞定了副本数组的修改之后，那么就可以用<strong><code>volatile</code>写的方式，把这个副本数组赋值给volatile修饰的那个数组的引用变量了</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;只要一赋值给那个<code>volatile</code>修饰的变量，立马就会对读线程可见，大家都能看到最新的数组了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面是<code>JDK</code>里的 <code>CopyOnWriteArrayList</code> 的源码。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大家看看写数据的时候，他是怎么拷贝一个数组副本，然后修改副本，接着通过volatile变量赋值的方式，把修改好的数组副本给更新回去，立马让其他线程可见的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">   // 这个数组是核心的，因为用volatile修饰了</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 只要把最新的数组对他赋值，其他线程立马可以看到最新的数组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   private transient volatile Object[] array;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   public boolean add(E e) &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       final ReentrantLock lock = this.lock;</span><br><span class="line"></span><br><span class="line">       lock.lock();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       try &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">           Object[] elements = getArray();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">           int len = elements.length;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">           // 对数组拷贝一个副本出来</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">           Object[] newElements = Arrays.copyOf(elements, len + 1);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">           // 对副本数组进行修改，比如在里面加入一个元素</span><br><span class="line"></span><br><span class="line">           newElements[len] = e;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">           // 然后把副本数组赋值给volatile修饰的变量</span><br><span class="line"></span><br><span class="line">           setArray(newElements);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">           return true;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       &#125; finally &#123;</span><br><span class="line"></span><br><span class="line">           lock.unlock();</span><br><span class="line"></span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后<strong>大家想，因为是通过副本来进行更新的，万一要是多个线程都要同时更新呢？那搞出来多个副本会不会有问题？</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然不能多个线程同时更新了，这个时候就是看上面源码里，<strong>加入了<code>lock</code>锁的机制，也就是同一时间只有一个线程可以更新</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么更新的时候，会对读操作有任何的影响吗？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;绝对不会，因为读操作就是非常简单的对那个数组进行读而已，不涉及任何的锁。而且只要他更新完毕对<code>volatile</code>修饰的变量赋值，那么读线程立马可以看到最新修改后的数组，这是<code>volatile</code>保证的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private E get(Object[] a, int index) &#123;</span><br><span class="line">     // 最简单的对数组进行读取       </span><br><span class="line">     return (E) a[index];</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样就完美解决了我们之前说的读多写少的问题。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>如果用读写锁互斥的话，会导致写锁阻塞大量读操作，影响并发性能</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是<strong>如果用了<code>CopyOnWriteArrayList</code>，就是用空间换时间，更新的时候基于副本更新，避免锁，然后最后用<code>volatile</code>变量来赋值保证可见性，更新的时候对读线程没有任何的影响！</strong></p>
<h2 id="3、CopyOnWrite-思想在Kafka源码中的运用"><a href="#3、CopyOnWrite-思想在Kafka源码中的运用" class="headerlink" title="3、CopyOnWrite 思想在Kafka源码中的运用"></a>3、CopyOnWrite 思想在Kafka源码中的运用</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Kafka的内核源码中，有这么一个场景，客户端在向<code>Kafka</code>写数据的时候，会把消息先写入客户端本地的内存缓冲，然后在内存缓冲里<strong>形成一个<code>Batch</code>之后再一次性发送到<code>Kafka</code>服务器上去</strong>，这样有助于提升吞吐量。</p>
<p>话不多说，大家看下图：</p>
<p><img src="//blog.com/2019/05/08/CopyOnWrite思想在Kafka源码中的运用/3.webp" alt="img">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个时候<code>Kafka</code>的内存缓冲用的是什么数据结构呢？大家看源码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">private final ConcurrentMap&lt;topicpartition, deque&lt;=&quot;&quot; span=&quot;&quot;&gt;</span><br><span class="line">          batches = new CopyOnWriteMap&lt;TopicPartition, Deque&gt;();</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个数据结构就是核心的用来存放写入内存缓冲中的消息的数据结构，要看懂这个数据结构需要对很多Kafka内核源码里的概念进行解释，这里先不展开。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是大家关注一点，他是自己实现了一个<code>CopyOnWriteMap</code>，这个<code>CopyOnWriteMap采用的</code>就是CopyOnWrite`思想。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们来看一下这个<code>CopyOnWriteMap</code>的源码实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">// 典型的volatile修饰普通Map</span><br><span class="line"></span><br><span class="line">  private volatile Mapmap;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  @Override</span><br><span class="line">  public synchronized V put(K k, V v) &#123;</span><br><span class="line">      // 更新的时候先创建副本，更新副本，然后对volatile变量赋值写回去</span><br><span class="line">      Mapcopy = new HashMap(this.map);</span><br><span class="line"></span><br><span class="line">      V prev = copy.put(k, v);</span><br><span class="line">      </span><br><span class="line">      this.map = Collections.unmodifiableMap(copy);</span><br><span class="line"></span><br><span class="line">      return prev;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  @Override</span><br><span class="line">  public V get(Object k) &#123;</span><br><span class="line">      // 读取的时候直接读volatile变量引用的map数据结构，无需锁</span><br><span class="line">      return map.get(k);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以<code>Kafka</code>这个核心数据结构在这里之所以采用<code>CopyOnWriteMap</code>思想来实现，就是因为这个<code>Map</code>的<code>key-value对</code>，其实没那么频繁更新。也就是<code>TopicPartition-Deque</code>这个<code>key-value对</code>，更新频率很低。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是他的get操作却是高频的读取请求，因为会高频的读取出来一个<code>TopicPartition</code>对应的<code>Deque</code>数据结构，来对这个队列进行入队出队等操作，所以对于这个map而言，高频的是其get操作。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个时候，<strong>Kafka就采用了<code>CopyOnWrite</code>思想来实现这个<code>Map</code>，避免更新<code>key-value</code>的时候阻塞住高频的读操作，实现无锁的效果，优化线程并发的性能</strong>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/05/08/聊聊并发-Java中的Copy-On-Write容器/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/08/聊聊并发-Java中的Copy-On-Write容器/" itemprop="url">聊聊并发-Java中的Copy-On-Write容器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-08T12:12:57+08:00">
                2019-05-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/写时复制/" itemprop="url" rel="index">
                    <span itemprop="name">写时复制</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="聊聊并发-Java中的Copy-On-Write容器"><a href="#聊聊并发-Java中的Copy-On-Write容器" class="headerlink" title="聊聊并发-Java中的Copy-On-Write容器"></a>聊聊并发-Java中的Copy-On-Write容器</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="http://ifeve.com/java-copy-on-write/" target="_blank" rel="noopener">http://ifeve.com/java-copy-on-write/</a></p>
</blockquote>
<p>​        Copy-On-Write简称COW，是一种用于程序设计中的优化策略。其基本思路是，从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略。从JDK1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器,它们是CopyOnWriteArrayList和CopyOnWriteArraySet。CopyOnWrite容器非常有用，可以在非常多的并发场景中使用到。</p>
<h2 id="什么是CopyOnWrite容器"><a href="#什么是CopyOnWrite容器" class="headerlink" title="什么是CopyOnWrite容器"></a>什么是CopyOnWrite容器</h2><p>　　CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。</p>
<h2 id="CopyOnWriteArrayList的实现原理"><a href="#CopyOnWriteArrayList的实现原理" class="headerlink" title="CopyOnWriteArrayList的实现原理"></a>CopyOnWriteArrayList的实现原理</h2><p>　　在使用CopyOnWriteArrayList之前，我们先阅读其源码了解下它是如何实现的。以下代码是向CopyOnWriteArrayList中add方法的实现（向CopyOnWriteArrayList里添加元素），可以发现在添加的时候是需要加锁的，否则多线程写的时候会Copy出N个副本出来。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Appends the specified element to the end of this list.</span><br><span class="line">     *</span><br><span class="line">     * @param e element to be appended to this list</span><br><span class="line">     * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;)</span><br><span class="line">     */</span><br><span class="line">    public boolean add(E e) &#123;</span><br><span class="line">    final ReentrantLock lock = this.lock;</span><br><span class="line">    lock.lock();</span><br><span class="line">    try &#123;</span><br><span class="line">        Object[] elements = getArray();</span><br><span class="line">        int len = elements.length;</span><br><span class="line">        Object[] newElements = Arrays.copyOf(elements, len + 1);</span><br><span class="line">        newElements[len] = e;</span><br><span class="line">        setArray(newElements);</span><br><span class="line">        return true;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p> 　　读的时候不需要加锁，如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public E get(int index) &#123;</span><br><span class="line">    return get(getArray(), index);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 　　JDK中并没有提供CopyOnWriteMap，我们可以参考CopyOnWriteArrayList来实现一个，基本代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Collection;</span><br><span class="line">import java.util.Map;</span><br><span class="line">import java.util.Set;</span><br><span class="line"> </span><br><span class="line">public class CopyOnWriteMap&lt;K, V&gt; implements Map&lt;K, V&gt;, Cloneable &#123;</span><br><span class="line">    private volatile Map&lt;K, V&gt; internalMap;</span><br><span class="line"> </span><br><span class="line">    public CopyOnWriteMap() &#123;</span><br><span class="line">        internalMap = new HashMap&lt;K, V&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public V put(K key, V value) &#123;</span><br><span class="line"> </span><br><span class="line">        synchronized (this) &#123;</span><br><span class="line">            Map&lt;K, V&gt; newMap = new HashMap&lt;K, V&gt;(internalMap);</span><br><span class="line">            V val = newMap.put(key, value);</span><br><span class="line">            internalMap = newMap;</span><br><span class="line">            return val;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public V get(Object key) &#123;</span><br><span class="line">        return internalMap.get(key);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public void putAll(Map&lt;? extends K, ? extends V&gt; newData) &#123;</span><br><span class="line">        synchronized (this) &#123;</span><br><span class="line">            Map&lt;K, V&gt; newMap = new HashMap&lt;K, V&gt;(internalMap);</span><br><span class="line">            newMap.putAll(newData);</span><br><span class="line">            internalMap = newMap;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 　　实现很简单，只要了解了CopyOnWrite机制，我们可以实现各种CopyOnWrite容器，并且在不同的应用场景中使用。</p>
<h2 id="CopyOnWrite的应用场景"><a href="#CopyOnWrite的应用场景" class="headerlink" title="CopyOnWrite的应用场景"></a>CopyOnWrite的应用场景</h2><p>　　CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">package com.ifeve.book;</span><br><span class="line"> </span><br><span class="line">import java.util.Map;</span><br><span class="line"> </span><br><span class="line">import com.ifeve.book.forkjoin.CopyOnWriteMap;</span><br><span class="line"> </span><br><span class="line">/**</span><br><span class="line"> * 黑名单服务</span><br><span class="line"> *</span><br><span class="line"> * @author fangtengfei</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class BlackListServiceImpl &#123;</span><br><span class="line"> </span><br><span class="line">    private static CopyOnWriteMap&lt;String, Boolean&gt; blackListMap = new CopyOnWriteMap&lt;String, Boolean&gt;(</span><br><span class="line">            1000);</span><br><span class="line"> </span><br><span class="line">    public static boolean isBlackList(String id) &#123;</span><br><span class="line">        return blackListMap.get(id) == null ? false : true;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public static void addBlackList(String id) &#123;</span><br><span class="line">        blackListMap.put(id, Boolean.TRUE);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    /**</span><br><span class="line">     * 批量添加黑名单</span><br><span class="line">     *</span><br><span class="line">     * @param ids</span><br><span class="line">     */</span><br><span class="line">    public static void addBlackList(Map&lt;String,Boolean&gt; ids) &#123;</span><br><span class="line">        blackListMap.putAll(ids);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 　　代码很简单，但是使用CopyOnWriteMap需要注意两件事情：</p>
<p>　　1. 减少扩容开销。根据实际需要，初始化CopyOnWriteMap的大小，避免写时CopyOnWriteMap扩容的开销。</p>
<p>　　2. 使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。如使用上面代码里的addBlackList方法。</p>
<h2 id="CopyOnWrite的缺点"><a href="#CopyOnWrite的缺点" class="headerlink" title="CopyOnWrite的缺点"></a>CopyOnWrite的缺点</h2><p>　　CopyOnWrite容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。所以在开发的时候需要注意一下。</p>
<p>　　<strong>内存占用问题</strong>。因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比如说200M左右，那么再写入100M数据进去，内存就会占用300M，那么这个时候很有可能造成频繁的Yong GC和Full GC。之前我们系统中使用了一个服务由于每晚使用CopyOnWrite机制更新大对象，造成了每晚15秒的Full GC，应用响应时间也随之变长。</p>
<p>　　针对内存占用问题，可以通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是10进制的数字，可以考虑把它压缩成36进制或64进制。或者不使用CopyOnWrite容器，而使用其他的并发容器，如<a href="http://ifeve.com/concurrenthashmap/" target="_blank" rel="noopener">ConcurrentHashMap</a>。</p>
<p>　　<strong>数据一致性问题</strong>。CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/82/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/82/">82</a><span class="page-number current">83</span><a class="page-number" href="/page/84/">84</a><span class="space">&hellip;</span><a class="page-number" href="/page/147/">147</a><a class="extend next" rel="next" href="/page/84/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">刘泽明</p>
              <p class="site-description motion-element" itemprop="description">做一个懂业务的程序员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">731</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">394</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">237</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘泽明</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
