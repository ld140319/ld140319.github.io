<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="搬运工 + 践行者" type="application/atom+xml">






<meta name="description" content="做一个懂业务的程序员">
<meta property="og:type" content="website">
<meta property="og:title" content="搬运工 + 践行者">
<meta property="og:url" content="http://blog.com/page/31/index.html">
<meta property="og:site_name" content="搬运工 + 践行者">
<meta property="og:description" content="做一个懂业务的程序员">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="搬运工 + 践行者">
<meta name="twitter:description" content="做一个懂业务的程序员">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.com/page/31/">





  <title>搬运工 + 践行者</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">搬运工 + 践行者</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">记录学习的技能和遇到的问题</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/06/30/孤儿进程与僵尸进程/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/30/孤儿进程与僵尸进程/" itemprop="url">孤儿进程与僵尸进程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-06-30T12:12:57+08:00">
                2019-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/守护进程/" itemprop="url" rel="index">
                    <span itemprop="name">守护进程</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/守护进程/PHP/" itemprop="url" rel="index">
                    <span itemprop="name">PHP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="孤儿进程与僵尸进程"><a href="#孤儿进程与僵尸进程" class="headerlink" title="孤儿进程与僵尸进程"></a>孤儿进程与僵尸进程</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="https://www.cnblogs.com/Anker/p/3271773.html" target="_blank" rel="noopener">https://www.cnblogs.com/Anker/p/3271773.html</a><br><br></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们知道在<code>unix/linux</code>中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程 到底什么时候结束。 当一个 进程完成它的工作终止之后，它的父进程需要调用<code>wait()</code>或者<code>waitpid()</code>系统调用取得子进程的终止状态。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</strong></p>
<p><strong>问题及危害</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>unix</code>提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。这种机制就是: 在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号<code>the process ID,</code>退出状态<code>the termination status of the process</code>,运行时间<code>the amount of CPU time taken by the process</code>等)。直到父进程通过<code>wait / waitpid</code>来取时才释放。 但这样就导致了问题，<strong>如果进程不调用wait / waitpid的话，</strong> <strong>那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。</strong></p>
<p>　　<strong>孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上</strong>，<code>init</code>进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤儿进程的父进程设置为<code>init</code>，而<code>init</code>进程会循环地<code>wait()</code>它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，<code>init</code>进程就会代表党和政府出面处理它的一切善后工作。<strong>因此孤儿进程并不会有什么危害。</strong></p>
<p>　　<strong>任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。</strong>这是每个进程在结束时都要经过的阶段。如果子进程在<code>exit()</code>之后，父进程没有来得及处理，这时<code>ps</code>命令就能看到<strong>子进程的状态是“Z”</strong>。如果父进程能及时 处理，可能用<code>ps</code>命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。  如果父进程在子进程结束之前退出，则子进程将由<code>init</code>接管。<code>init</code>将会以父进程的身份对僵尸状态的子进程进行处理。</p>
<p><strong>僵尸进程危害场景</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，<strong>系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程</strong>。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大 量僵死进程的那个元凶枪毙掉（也就是通过<code>kill</code>发送<code>SIGTERM</code>或者<code>SIGKILL</code>信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被<code>init</code>进程接管，<code>init</code>进程会<code>wait()</code>这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/06/30/数据库中间件详解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/30/数据库中间件详解/" itemprop="url">数据库中间件详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-06-30T10:12:57+08:00">
                2019-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/" itemprop="url" rel="index">
                    <span itemprop="name">数据库优化</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/" itemprop="url" rel="index">
                    <span itemprop="name">数据库设计</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/读写分离/" itemprop="url" rel="index">
                    <span itemprop="name">读写分离</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/读写分离/分库分表/" itemprop="url" rel="index">
                    <span itemprop="name">分库分表</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据库中间件详解"><a href="#数据库中间件详解" class="headerlink" title="数据库中间件详解"></a>数据库中间件详解</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="https://mp.weixin.qq.com/s/XisPkWGkB-a3dR2lrEjkwQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/XisPkWGkB-a3dR2lrEjkwQ</a></p>
</blockquote>
<p><br></p>
<h2 id="1-数据库拆分过程及挑战"><a href="#1-数据库拆分过程及挑战" class="headerlink" title="1 数据库拆分过程及挑战"></a>1 数据库拆分过程及挑战</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;互联网当下的数据库拆分过程基本遵循的顺序是：<strong>垂直拆分、读写分离、分库分表(水平拆分)</strong>。每个拆分过程都能解决业务上的一些问题，但同时也面临了一些挑战。 </p>
<h3 id="1-1-垂直拆分"><a href="#1-1-垂直拆分" class="headerlink" title="1.1 垂直拆分"></a>1.1 垂直拆分</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于一个刚上线的互联网项目来说，由于前期活跃用户数量并不多，并发量也相对较小，所以此时企业一般都会选择将所有数据存放在一个数据库 中进行访问操作。举例来说，对于一个电商系统，其用户模块和产品模块的表刚开始都是位于一个库中。</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlDAScxnTaTdDBT2dB1cCRVzFxw1mNTJCZsGric2dE01JOZ0sicuVTXzkw.png" alt="Image"></p>
<p>其中：<code>user、useraccount</code>表属于用户模块，<code>productcategory、product</code>表属于产品模块</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;刚开始，可能公司的技术团队规模比较小，所有的数据都位于一个库中。随着公司业务的发展，技术团队人员也得到了扩张，划分为不同的技术小组，不同的小组负责不同的业务模块。例如A小组负责用户模块，B小组负责产品模块。此时数据库也迎来了第一次拆分：垂直拆分。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里的<strong>垂直拆分，指的是将一个包含了很多表的数据库，根据表的功能的不同，拆分为多个小的数据库，每个库包含部分表</strong>。下图演示将上面提到的<code>db_eshop</code>库，拆分为<code>db_user</code>库和<code>db_product</code>库。</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlI5xC0KADJpg9h06zu18czhK21yibgbeuDZRcHXIKXeuJM9mKPLVWTHw.png" alt="Image"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>通常来说，垂直拆分，都是根据业务来对一个库中的表进行拆分的</strong>。关于垂直拆分，还有另一种说法，<strong>将一个包含了很多字段的大表拆分为多个小表，每个表包含部分字段</strong>，这种情况在实际开发中基本很少遇到。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;垂直拆分的另一个典型应用场景是服务化<code>(SOA)</code>改造。在服务化的背景下，除了<strong>业务上需要进行拆分，底层的存储也需要进行隔离</strong>。 垂直拆分会使得单个用户请求的响应时间变长，原因在于，在单体应用的场景下，所有的业务都可以在一个节点内部完成，而垂直拆分之后，通常会需要进行<code>RPC</code>调用。然后虽然<strong>单个请求的响应时间增加了，但是整个服务的吞吐量确会大大的增加</strong>。</p>
<h3 id="1-2-读写分离"><a href="#1-2-读写分离" class="headerlink" title="1.2 读写分离"></a>1.2 读写分离</h3><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随着业务的不断发展，用户数量和并发量不断上升。这时如果仅靠单个数据库实例来支撑所有访问压力,几乎是在 自寻死路 。以产品库为例，可能库中包含了几万种商品，并且每天新增几十种，而产品库每天的访问了可能有几亿甚至几十亿次。<strong>数据库读的压力太大，单台<code>mysql</code>实例扛不住，此时大部分 <code>Mysql DBA</code>就会将数据库设置成 读写分离状态 </strong>。也就是一个 <code>Master</code> 节点(主库)对应多个 <code>Salve</code> 节点(从库)。<strong>可以将<code>slave</code>节点的数据理解为<code>master</code>节点数据的全量备份</strong>。</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlQyP8p8Jib1xqgsbrRsicuY4iaA2aqUiaEhBf0RsZPYicmv8qTuHjEtToI3A.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>master</code>节点接收用户的写请求，并写入到本地二进制文件(<code>binary log</code>)中。<code>slave</code>通过一个<code>I/O</code>线程与<code>Master</code>建立连接，发送<code>binlog dump</code>指令。<code>Master</code>会将<code>binlog</code>数据推送给<code>slave</code>，<code>slave</code>将接收到的<code>binlog</code>保存到本地的中继日志(<code>relay log</code>)中，最后，<code>slave</code>通过另一个线程<code>SQL thread</code>应用本地的<code>relay log</code>，将数据同步到<code>slave</code>库中。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关于<code>mysql</code>主从复制，内部包含很多细节。例如<code>binlog</code>格式分为<code>statement</code>、<code>row</code>和<code>mixed</code>，<code>binlog</code>同步方式又可以划分为：<strong>异步</strong>、<strong>半同步</strong>和<strong>同步</strong>。复制可以基于<strong>binlogFile+position</strong>，也可以基于<strong>GTID</strong>。通常，这些都是<code>DBA</code>负责维护的，业务<code>RD</code>无感知。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在DBA将<code>mysql</code>配置成主从复制集群的背景下，开发同学所需要做的工作是：当更新数据时，应用将数据写入<code>master</code>主库，主库将数据同步给多个<code>slave</code>从库。当查询数据时，应用选择某个<code>slave</code>节点读取数据。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlm6lvbuyvzHoJ5Kp85y6MKlkghzibSdd3KXKib5kRbSIEib6Gkq9ArleibQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="Image"></p>
<h4 id="1-2-1-读写分离的优点"><a href="#1-2-1-读写分离的优点" class="headerlink" title="1.2.1 读写分离的优点"></a>1.2.1 读写分离的优点</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样通过配置多个<code>slave</code>节点，可以有效的避免过大的访问量对单个库造成的<strong>读压力</strong>。</p>
<h4 id="1-2-1-读写分离的挑战"><a href="#1-2-1-读写分离的挑战" class="headerlink" title="1.2.1 读写分离的挑战"></a>1.2.1 读写分离的挑战</h4><p><strong>1 对于DBA而言，多了很多集群运维工作</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如<strong>集群搭建、主从切换、从库扩容、缩容</strong>等。例如<code>master</code>配置了多个<code>slave</code>节点，如果其中某个<code>slave</code>节点挂了，那么之后的读请求，我们应用将其转发到正常工作的<code>slave</code>节点上。另外，如果新增了<code>slave</code>节点，应用也应该感知到，可以将读请求转发到新的<code>slave</code>节点上。</p>
<p><strong>2 对于开发人员而言</strong></p>
<ul>
<li><strong>基本读写分离功能</strong>：对<code>sql</code>类型进行判断，如果是<code>select</code>等读请求，就走从库，如果是<code>insert</code>、<code>update</code>、<code>delete等写请求</code>，就走主库。</li>
<li><strong>主从数据同步延迟问题</strong>：因为数据是从<code>master</code>节点通过网络同步给多个<code>slave</code>节点，因此必然存在延迟。因此有可能出现我们在<code>master</code>节点中已经插入了数据，但是从<code>slave</code>节点却读取不到的问题。对于一些强一致性的业务场景，要求插入后必须能读取到，因此对于这种情况，我们需要<strong>提供一种方式，让读请求也可以走主库，而主库上的数据必然是最新的</strong>。</li>
<li><strong>事务问题</strong>：如果一个事务中同时包含了读请求(如<code>select</code>)和写请求(如<code>insert</code>)，如果读请求走从库，写请求走主库，由于跨了多个库，那么本地事务已经无法控制，属于分布式事务的范畴。而分布式事务非常复杂且效率较低。因此<strong>对于读写分离，目前主流的做法是，事务中的所有<code>sql</code>统一都走主库，由于只涉及到一个库，本地事务就可以搞定</strong>。</li>
<li><strong>感知集群信息变更：</strong>如果访问的数据库集群信息变更了，例如主从切换了，写流量就要到新的主库上；又例如增加了从库数量，流量需要可以打到新的从库上；又或者某个从库延迟或者失败率比较高，应该将这个从库进行隔离，读流量尽量打到正常的从库上 </li>
</ul>
<h3 id="1-3-分库分表"><a href="#1-3-分库分表" class="headerlink" title="1.3 分库分表"></a>1.3 分库分表</h3><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;经过垂直分区后的 <code>Master/Salve</code>模式完全可以承受住难以想象的高并发访问操作，但是否可以永远 高枕无忧 了？答案是否定的，一旦业务表中的数据量大了，从维护和性能角度来看，无论是任何的 <code>CRUD</code> 操作，对于数据库而言都是一件极其耗费资源的事情。即便设置了索引， 仍然无法掩盖<strong>因为数据量过大从而导致的数据库性能下降</strong>的事实 ，因此这个时候 <code>Mysql DBA</code> 或许就该对数据库进行 <strong>水平分区</strong> （<code>sharding</code>，即分库分表 ）。<strong>经过水平分区设置后的业务表，必然能够将原本一张表维护的海量数据分配给 N 个子表进行存储和维护</strong>。</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>水平分表从具体实现上又可以分为3种：只分表、只分库、分库分表</strong>，下图展示了这三种情况：</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlBSLSL6u5EMO5LJWWcPbAGtVghJQxHDiaLV5QY8SMvgiaVia4MuhF9a56g.png" alt="img"></p>
<p><strong>只分表</strong>：</p>
<p>​        将<code>db</code>库中的<code>user</code>表拆分为2个分表，<code>user_0</code>和<code>user_1</code>，这两个表还位于同一个库中。  </p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;适用场景：<strong>如果库中的多个表中只有某张表或者少数表数据量过大，那么只需要针对这些表进行拆分，其他表保持不变</strong>。</p>
<p><strong>只分库</strong>：</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将<code>db</code>库拆分为<code>db_0</code>和<code>db_1</code>两个库，同时在<code>db_0</code>和<code>db_1</code>库中各自新建一个<code>user</code>表，<code>db_0.user</code>表和<code>db_1.user</code>表中各自只存原来的<code>db.user</code>表中的部分数据。</p>
<p><strong>分库分表</strong>：</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将<code>db库</code>拆分为<code>db_0</code>和<code>db_1</code>两个库，<code>db_0</code>中包含<code>user_0</code>、<code>user_1</code>两个分表，<code>db_1</code>中包含<code>user_2</code>、<code>user_3</code>两个分表。</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下图演示了在分库分表的情况下，数据是如何拆分的：假设<code>db</code>库的user表中原来有<code>4000W</code>条数据，现在将<code>db</code>库拆分为2个分库<code>db_0</code>和<code>db_1</code>，<code>user</code>表拆分为<code>user_0、user_1、user_2、user_3</code>四个分表，每个分表存储<code>1000W</code>条数据。</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlmCX6XQxQKkW5MOccPGlbnibKQywiaVfDjaGvoNDTcHmmArcerXic5ic8EA.png" alt="img"></p>
<h4 id="1-3-1-分库分表的好处"><a href="#1-3-1-分库分表的好处" class="headerlink" title="1.3.1 分库分表的好处"></a>1.3.1 分库分表的好处</h4><p>如果说读写分离实现了数据库<strong>读能力的水平扩展</strong>，那么分库分表就是实现了<strong>写能力的水平扩展</strong>。   </p>
<p><strong>1 存储能力的水平扩展</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在读写分离的情况下，每个集群中的<code>master</code>和<code>slave</code>基本上数据是完全一致的，从存储能力来说，在存在海量数据的情况下，可能由于磁盘空间的限制，无法存储所有的数据。而在分库分表的情况下，我们可以搭建多个<code>mysql</code>主从复制集群，每个集群只存储部分分片的数据，实现存储能力的水平扩展。</p>
<p><strong>2 写能力的水平扩展</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>在读写分离的情况下，由于每个集群只有一个<code>master</code>，所有的写操作压力都集中在这一个节点上，在写入并发非常高的情况下，这里会成为整个系统的瓶颈</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;而在分库分表的情况下，每个分片所属的集群都有一个<code>master</code>节点，都可以执行写入操作，实现<strong>写能力的水平扩展</strong>。此外减小建立索引开销，降低写操作的锁操作耗时等，都会带来很多显然的好处。 </p>
<h4 id="1-3-2-分库分表的挑战"><a href="#1-3-2-分库分表的挑战" class="headerlink" title="1.3.2 分库分表的挑战"></a>1.3.2 分库分表的挑战</h4><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分库分表的挑战主要体现在4个方面：基本的数据库增删改功能，分布式id，分布式事务，动态扩容，下面逐一进行讲述。 </p>
<p><strong>挑战1：基本的数据库增删改功能</strong>   </p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于开发人员而言，虽然分库分表的，但是其还是希望能和单库单表那样的去操作数据库。例如我们要批量插入四条用户记录，并且希望根据用户的id字段，确定这条记录插入哪个库的哪张表。例如1号记录插入user_1表，2号记录插入user_2表，3号记录插入user_3表，4号记录插入user_0表，以此类推。<code>sql</code>如下所示：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">user</span>(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">1</span>,”tianshouzhi”),(<span class="number">2</span>,”huhuamin”), (<span class="number">3</span>,”wanghanao”),(<span class="number">4</span>,”luyang”)</span><br></pre></td></tr></table></figure>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这样的<code>sql</code>明显是无法执行的，因为我们已经对库和表进行了拆分,这种<code>sql</code>语法只能操作<code>mysql</code>的单个库和单个表。所以必须将<code>sql</code>改成4条如下所示，然后分别到每个库上去执行。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> user_1(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">1</span>,”tianshouzhi”);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> user_2(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">2</span>,”huhuamin”);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> user_3(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">3</span>,”wanghanao”);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> user_0(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span>  (<span class="number">4</span>,”luyang”);</span><br></pre></td></tr></table></figure>
<p>具体流程可以用下图进行描述：</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xl3JictkiaNUKb6UxRO38JGsicnrKXY7rI3REufJUkFNrVbCwvjYAmPqlgQ.png" alt="Image.png"></p>
<p>解释如下：</p>
<p>​    <strong><code>sql</code>解析</strong>：首先对<code>sql</code>进行解析，得到需要插入的四条记录的id字段的值分别为1,2,3,4</p>
<p>​    <strong><code>sql</code>路由</strong>：<code>sql</code>路由包括库路由和表路由。库路由用于确定这条记录应该插入哪个库，表路由用于确定这条记录应该插入哪个表。</p>
<p>​    <strong><code>sql</code>改写</strong>：因为一条记录只能插入到一个库中，而上述批量插入的语法将会在 每个库中都插入四条记录，明显是不合适的，因此需要对<code>sql</code>进行改写，每个库只插入一条记录。</p>
<p>​    <strong><code>sql</code>执行</strong>：一条<code>sql</code>经过改写后变成了多条<code>sql</code>，为了提升效率应该并发的到不同的库上去执行，而不是按照顺序逐一执行</p>
<p>​    <strong>结果集合并</strong>：每个<code>sql</code>执行之后，都会有一个执行结果，我们需要对分库分表的结果集进行合并，从而得到一个完整的结果。</p>
<p><strong>挑战2：分布式id</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>在分库分表后，我们不能再使用<code>mysql</code>的自增主键。因为在插入记录的时候，不同的库生成的记录的自增<code>id</code>可能会出现冲突</strong>。因此需要有一个全局的<code>id</code>生成器。目前分布式<code>id</code>有很多中方案，其中一个比较轻量级的方案是<code>twitter</code>的<code>snowflake</code>算法。</p>
<p><strong>挑战3：分布式事务</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>分布式事务是分库分表绕不过去的一个坎，因此涉及到了同时更新多个数据库</strong>。例如上面的批量插入记录到四个不同的库，如何保证要么同时成功，要么同时失败。</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关于分布式事务，<code>mysql</code>支持<code>XA</code>事务，但是效率较低。柔性事务是目前比较主流的方案，柔性事务包括：最大努力通知型、可靠消息最终一致性方案以及<code>TCC</code>两阶段提交。但是无论<code>XA</code>事务还是柔性事务，实现起来都是非常复杂的。</p>
<p><strong>挑战4：动态扩容</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;动态扩容指的是增加分库分表的数量。例如原来的user表拆分到2个库的四张表上。现在我们希望将分库的数量变为4个，分表的数量变为8个。这种情况下一般要伴随着数据迁移。例如在4张表的情况下，id为7的记录，<code>7%4=3</code>，因此这条记录位于user_3这张表上。但是现在分表的数量变为了8个，而<code>7%8=7</code>，而user_0这张表上根本就没有id=7的这条记录，因此<strong>如果不进行数据迁移的话，就会出现记录找不到的情况</strong>。</p>
<h2 id="2-主流数据库中间件设计方案"><a href="#2-主流数据库中间件设计方案" class="headerlink" title="2 主流数据库中间件设计方案"></a>2 主流数据库中间件设计方案</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>数据库中间件的主要作用是向应用程序开发人员屏蔽读写分离和分库分表面临的挑战，并隐藏底层实现细节，使得开发人员可以像操作单库单表那样去操作数据</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在介绍分库分表的主流设计方案前，我们首先回顾一下在单个库的情况下，应用的架构，可以用下图进行描述： </p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlcoYicoP81LJicib45V9WZiaC3GAaMJrCAwg7MFHcTAmoj6k8tbJBndROHw.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到在操作单库单表的情况下，我们是直接在应用中通过数据连接池(<code>connection pool</code>)与数据库建立连接，进行读写操作。 而对于读写分离和分库分表，应用都要操作多个数据库实例，在这种情况下，我们就需要使用到数据库中间件。</p>
<h3 id="2-1-设计方案"><a href="#2-1-设计方案" class="headerlink" title="2.1 设计方案"></a>2.1 设计方案</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;典型的数据库中间件设计方案有2种：<code>proxy</code>、<code>smart-client</code>。下图演示了这两种方案的架构：</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xl9NBEYjiakrzUaJ4pgJ1MXeTsraZ5cx1bAibADG4MugpibUX1qUnYVWs0w.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到不论是<code>proxy</code>还是<code>smart-client</code>，底层都操作了多个数据库实例。不论是分库分表，还是读写分离，都是在数据库中间件层面对业务开发同学进行屏蔽。</p>
<h4 id="2-1-1-proxy模式"><a href="#2-1-1-proxy模式" class="headerlink" title="2.1.1 proxy模式"></a>2.1.1 proxy模式</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们独立部署一个代理服务，这个代理服务背后管理多个数据库实例。而在应用中，我们<strong>通过一个普通的数据源(<code>c3p0、druid、dbcp</code>等)与代理服务器建立连接，所有的<code>sql</code>操作语句都是发送给这个代理，由这个代理去操作底层数据库，得到结果并返回给应用</strong>。<strong>在这种方案下，分库分表和读写分离的逻辑对开发人员是完全透明的</strong>。</p>
<p><strong>优点：</strong></p>
<p><strong>1.  多语言支持</strong>。也就是说，不论你用的php、java或是其他语言，都可以支持。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以<code>mysql</code>数据库为例，<strong>如果<code>proxy</code>本身实现了<code>mysql</code>的通信协议，那么你可以就将其看成一个<code>mysql</code> 服务器</strong>。<code>mysql</code>官方团队为不同语言提供了不同的客户端驱动，如<code>java</code>语言的<code>mysql-connector-java</code>，<code>python</code>语言的<code>mysql-connector-python</code>等等。因此<strong>不同语言的开发者都可以使用<code>mysql</code>官方提供的对应的驱动来与这个代理服务器建通信</strong>。</p>
<p><strong>2.  对业务开发同学透明</strong>。由于可以把<code>proxy</code>当成<code>mysql</code>服务器，理论上业务同学不需要进行太多代码改造，既可以完成接入。</p>
<p><strong>缺点：</strong></p>
<p><strong>1.  实现复杂</strong>。因为<code>proxy</code>需要实现被代理的数据库<code>server</code>端的通信协议，实现难度较大。通常我们看到一些<code>proxy</code>模式的数据库中间件，实际上只能代理某一种数据库，如<code>mysql</code>。几乎没有数据库中间件，可以同时代理多种数据库(<code>sqlserver、PostgreSQL、Oracle</code>)。</p>
<p><strong>2.  proxy本身需要保证高可用</strong>。由于应用本来是直接访问数据库，现在改成了访问<code>proxy</code>，意味着<code>proxy</code>必须保证高可用。否则，数据库没有宕机，<code>proxy</code>挂了，导致数据库无法正常访问，就尴尬了。 </p>
<p><strong>3. 租户隔离</strong> 。可能有多个应用访问<code>proxy</code>代理的底层数据库，必然会对<code>proxy</code>自身的内存、网络、cpu等产生资源竞争，<code>proxy</code>需要需要具备隔离的能力。</p>
<h4 id="2-1-2-smart-client模式"><a href="#2-1-2-smart-client模式" class="headerlink" title="2.1.2 smart-client模式"></a>2.1.2 smart-client模式</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>业务代码需要进行一些改造，引入支持读写分离或者分库分表的功能的<code>sdk</code>，这个就是我们的<code>smart-client</code></strong>。通常<code>smart-client</code>是在连接池或者<code>driver</code>的基础上进行了一层封装，<code>smart-client</code>内部与不同的库建立连接。应用程序产生的<code>sql</code>交给<code>smart-client</code>进行处理，其内部对<code>sql</code>进行必要的操作，例如在读写分离情况下，选择走从库还是主库；在分库分表的情况下，进行<code>sql</code>解析、<code>sql</code>改写等操作，然后路由到不同的分库，将得到的结果进行合并，返回给应用。</p>
<p><strong>优点：</strong></p>
<p><strong>1. 实现简单</strong>。<strong><code>proxy</code>需要实现数据库的服务端协议，但是<code>smart-client</code>不需要实现客户端通信协议</strong>。原因在于，大多数据数据库厂商已经针对不同的语言提供了相应的数据库驱动<code>driver</code>，例如<code>mysq</code>l针对<code>java</code>语言提供了<code>mysql-connector-java</code>驱动，针对<code>python</code>提供了<code>mysql-connector-python</code>驱动，客户端的通信协议已经在<code>driver</code>层面做过了。因此<code>smart-client</code>模式的中间件，<strong>通常只需要在此基础上进行封装即可</strong>。</p>
<p><strong>2.  天然去中心化</strong>。<code>smart-client</code>的方式，<strong>由于本身以<code>sdk</code>的方式，被应用直接引入，随着应用部署到不同的节点上，且直连数据库，中间不需要有代理层</strong>。因此相较于<code>proxy</code>言，除了网络资源之外，基本上不存在任何其他资源的竞争，也不需要考虑高可用的问题。只要应用的节点没有全部宕机，就可以访问数据库。(这里的高可用是相比<code>proxy</code>而言，数据库本身的高可用还是需要保证的)</p>
<p><strong>缺点：</strong></p>
<p><strong>1.  通常仅支持某一种语言</strong>。例如<code>tddl、zebra、sharding-jdbc</code>都是使用<code>java</code>语言开发，因此对于使用其他语言的用户，就无法使用这些中间件。如果其他语言要使用，那么就要开发多语言客户端。</p>
<p><strong>2. 版本升级困难</strong>。因为应用使用数据源代理就是引入一个<code>jar</code>包的依赖，在有多个应用都对某个版本的<code>jar</code>包产生依赖时，一旦这个版本有<code>bug</code>，所有的应用都需要升级。而数据库代理升级则相对容易，因为服务是单独部署的，只要升级这个代理服务器，所有连接到这个代理的应用自然也就相当于都升级了。</p>
<h3 id="2-2-业界产品"><a href="#2-2-业界产品" class="headerlink" title="2.2 业界产品"></a>2.2 业界产品</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无论是<code>proxy</code>，还是<code>smart-client</code>，二者的作用都是类似的。以下列出了这两种方案目前已有的实现以及各自的优缺点：</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlzpZk35AqDSyYNk7LbZE2HXia0jr1FvW6utxaPADnInvtMIibZ5N6QiaEg.png" alt="img"></p>
<h4 id="proxy实现"><a href="#proxy实现" class="headerlink" title="proxy实现"></a>proxy实现</h4><p>目前的已有的实现方案有：</p>
<ul>
<li>阿里巴巴开源的<code>cobar</code></li>
<li>阿里云上的<code>drds</code></li>
<li><code>mycat</code>团队在<code>cobar</code>基础上开发的<code>mycat</code></li>
<li><code>mysql</code>官方提供的<code>mysql-proxy</code></li>
<li>奇虎360在<code>mysql-proxy</code>基础开发的<code>atlas</code>(只支持分表，不支持分库)</li>
<li>当当网开源的<code>sharing-sphere</code></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前除了<code>mycat、sharing-sphere</code>，其他几个开源项目基本已经没有维护，<code>sharing-sphere</code>前一段时间已经进去了<code>Apache</code> 软件基金会孵化器。</p>
<h4 id="smart-client实现"><a href="#smart-client实现" class="headerlink" title="smart-client实现"></a>smart-client实现</h4><p>目前的实现方案有：</p>
<ul>
<li><p>阿里巴巴开源的<code>tddl</code>，已很久没维护</p>
</li>
<li><p>大众点评开源的<code>zebra</code>，大众点评的<code>zebra</code>开源版本代码已经很久没有更新，不过最近美团上市，重新开源大量内部新的功能特性，并计划长期维持。</p>
</li>
<li><p>当当网开源的<code>sharding-jdbc</code>，目前算是做的比较好的，文档资料比较全。和<code>sharding-sphere</code>一起进入了<code>Apache</code>孵化器。</p>
</li>
<li><p>蚂蚁金服的<code>zal</code></p>
</li>
</ul>
<h3 id="3-读写分离核心要点"><a href="#3-读写分离核心要点" class="headerlink" title="3 读写分离核心要点"></a>3 读写分离核心要点</h3><h4 id="3-1-基本路由功能"><a href="#3-1-基本路由功能" class="headerlink" title="3.1 基本路由功能"></a>3.1 基本路由功能</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基本路由路功能主要是解决在读写分离的情况下，如何实现一些基本的路由功能，这个过程通常可以通过下图进行描述：</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlT2niaK9qS1PVqXwd2OdXm9DeQdhJSzM6BZqTtZVxRRxHwFibgG98qz5Q.png" alt="img"></p>
<h5 id="3-1-1-sql类型判断"><a href="#3-1-1-sql类型判断" class="headerlink" title="3.1.1 sql类型判断"></a>3.1.1 sql类型判断</h5><p>主要是判断出来<code>sql</code>是读还是写<code>sql</code>，将读<code>sql</code>到从库上去执行，写<code>sql</code>去主库上执行</p>
<p><code>write</code>语句：<code>insert、update、delete、create、alter、truncate</code>…</p>
<p><code>query</code>语句：<code>select、show、desc、explain</code>… </p>
<h5 id="3-1-2-强制走主库"><a href="#3-1-2-强制走主库" class="headerlink" title="3.1.2 强制走主库"></a>3.1.2 强制走主库</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有的时候，对于一些强一致性的场景，需要写入后，必须能读取到数据。由于主从同步存在延迟，可能会出现主库写入，而从库查不到的情况。这次时候，我们需要使用<strong>强制走主库的功能</strong>。具体实现上有2种方案：<code>hint</code>或<code>API</code></p>
<p>​    <strong>hint</strong>，就是开发人员在<code>sql</code>上做一些特殊的标记，数据库中间件识别到这个标记，就知道这个<code>sql</code>需要走主库，如： </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*master*/</span><span class="keyword">select</span> * <span class="keyword">from</span> table_xx</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里的<code>/*master*/</code>就是一个<code>hint</code>，表示需要走主库。不同的数据库中间件强制走主库的<code>hint</code>可能不同，例如<code>zebra</code>的hint为<code>/*zebra:w+*/</code>，<code>hint</code>到底是什么样是无所谓的，其作用仅仅就是一个标记而已。<strong>之所以将<code>hint</code>写在<code>/*…*/</code>中，是因为这是标准的<code>sql</code>注释语法</strong>。<strong>即使数据库中间件未能识别这个<code>hint</code>，也不会导致<code>sql</code>语法错误</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>api：</strong>主要是通过代码的方式来添加<code>sql</code>走主库的标识，<code>hint</code>通常只能加在某个<code>sql</code>上。如果我们希望<strong>多个<code>sql</code>同时都走主库，也不希望加<code>hint</code></strong>，则可以通过<code>api</code>的方式，其内部主要利用语言的<code>thread local</code>线程上下文特性，如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ForceMasterHelper.forceMaster()    <span class="comment">//…执行多条sqlForceMasterHelper.clear()</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在<code>api</code>标识范围内执行的<code>sql</code>，都会走主库。具体<code>API</code>到底应该是什么样，如何使用，也是由相应的数据库中间件来决定的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>特别的，对于一些特殊的<code>sql</code>，例如 <code>select last_insert_id；</code>或者<code>select @@identity</code>等，这类<code>sql</code>总是需要走主库</strong>。 这些<code>sql</code>是要获得最后一个插入记录的id，插入操作只可能发生在主库上。</p>
<h4 id="3-2-从库路由策略"><a href="#3-2-从库路由策略" class="headerlink" title="3.2 从库路由策略"></a>3.2 从库路由策略</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常在一个集群中，只会有一个<code>master</code>，但是有多个<code>slave</code>。当判断是一个读请求时，如何判断选择哪个slave呢？</p>
<p>一些简单的选择策略包括：</p>
<ul>
<li>随机选择(<code>random</code>)</li>
<li>按照权重进行选择(<code>weight</code>)</li>
<li>或者轮训(<code>round-robin</code>)</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;特别的，对于一些跨<code>IDC</code>(数据中心)部署的数据库集群，通常需要有<strong>就近路由</strong>的策略，如下图： </p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlIT3lHAQmT2iaq7kUvH4iaM1zIULibEiaPSPfibOQsiaXPIoibpPjMiaGCxknTg.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;图中，在IDC2部署了一个<code>master</code>，在IDC1和IDC2各部署了一个<code>slave</code>，应用app部署在IDC1。显然当app接收到一个查询请求时，应该优先查询与其位于同一个数据中心的<code>slave1</code>，而不是跨数据中心去查询<code>slave2</code>，这就是就近路由的概念。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然一个数据中心内，可能会部署多个<code>slave</code>，也需要进行选择，因此就近路由通常和一些基本的路由策略结合使用。另外，对于就近路由，通常也会有一个层级，例如同机房、同中心、同区域、跨区域等。 </p>
<h4 id="3-3-HA、Scalable相关"><a href="#3-3-HA、Scalable相关" class="headerlink" title="3.3 HA、Scalable相关"></a>3.3 HA、Scalable相关</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据库中间件除了需要具备上述提到的读写分离功能来访问底层的数据库集群。也需要一套<strong>支持高可用、动态扩展</strong>的体系：</p>
<ul>
<li>从<code>HA</code>的角度来说，例如主库宕机了，那么应该从从库选择一个作为新的主库。开源的<code>MHA</code>可以帮助我们完成这个事；然而，<code>MHA</code>只能在主库宕机的情况下，完成主从切换，对于仅仅是一个从库宕机的情况下，<code>MHA</code>通常是无能为力的。因此，通常都会在<code>MHA进</code>行改造，使其支持更多的HA能力要求。</li>
<li>从<code>Scalable</code>角度来说，例如读<code>qps</code>实在太高，需要加一些从库，来分担读流量。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事实上，<strong>无论是<code>HA</code>，还是<code>Scalable</code>，对于数据库中间件(不论是<code>proxy</code>或者<code>smart-client</code>)来说，只是配置信息发生了变更</strong>。 </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>因此，通常我们会将所有的配置变更信息写到一个配置中心，然后配置心中监听这个配置的变更</strong>，例如主从切换，只需要把最新的主从信息设置到配置中心；增加从库，把新从库<code>ip</code>、<code>port</code>等信息放到配置中心。数据库中间件通过对这些配置信息变更进行监听，当配置发生变更时，实时的应用最新的配置信息即可。</p>
<p>​        因此，一个简化的数据库中间件的高可用架构通常如下所示： </p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlZBCzOKvumNib8ceIfYmZG62GQTusIrp6NUjK4qklaExr0l0ycgibv7ZQ.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;监控服务对集群进行监控，当发生变更时，将变更的信息<code>push</code>到配置中心中，数据库中间件(<code>proxy</code>或<code>smart-client</code>)接收到配置变更，应用最新的配置。而整个过程，<strong>对于业务代码基本是无感知的</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于配置中心的选择，有很多，例如百度的<code>disconf</code>、阿里的<code>diamond</code>、点评开源的<code>lion</code>、携程开源的<code>apollo</code>等，也可以使用<code>etcd</code>、<code>consul</code>。<strong>通常如果没有历史包袱的话，建议使用携程开源的apollo</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;特别需要注意的一点是，<strong>通常监控服务监控到集群信息变更，推送到配置中心，再到数据库中间件，必然存在一些延迟</strong>。对于一些场景，例如主从切换，没有办法做到彻底的业务无感知。当然，对于多个从库中，某个从库宕机的情况下，是可以做到业务无感知的。例如，某个从库失败，数据库中间件，自动从其他正常的从库进行重试。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外，<strong>上图中的<code>HA</code>方案强依赖于配置中心</strong>，如果某个数据库集群上建立了很多库，这个集群发生变更时，将会存在大量的配置信息需要推送。又或者，如果数据库集群是多机房部署的，在某个机房整体宕机的情况下(例如光纤被挖断了，或者机房宕机演练)，也会存在大量的配置信息需要推送。如果配置中心，推送有延迟，业务会有非常明显的感知。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，通常我们会<strong>在客户端进行一些轻量级的HA保障</strong>。例如，根据数据库返回异常的<code>sqlstate</code>和<code>vendor code</code>，判断异常的严重级别，确定数据库实例能否正常提供服务，如果不能正常提供服务，则自动将其进行隔离，并启动异步线程进行检测数据库实例是否恢复。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，很多数据库中间件，也会提供一些<strong>限流</strong>和<strong>降级</strong>的功能，计算<code>sql</code>的唯一标识(有些称之为<code>sql</code>指纹)，对于一些烂<code>sql</code>，导致数据库压力变大的情况，可以实时的进行拦截，直接抛出异常，不让这些<code>sql</code>打到后端数据库上去。 </p>
<h3 id="4-分库分表核心要点"><a href="#4-分库分表核心要点" class="headerlink" title="4 分库分表核心要点"></a>4 分库分表核心要点</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从业务开发的角度来说，其不关心底层是否是分库分表了，其还是希望想操作单个数据库实例那样编写<code>sql</code>，那么数据库中间件就需要对其屏蔽所有底层的复杂逻辑。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下图演示了一个数据库表(<code>user</code>表)在分库分表情况下，数据库中间件内部是如何执行一个批量插入<code>sql</code>的：</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/mvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlMHagsmgHHXaIAolIYsFM8gfdXwZBSglDVThvMpNpuibeI1jOp12Vn7A.webp" alt="img"></p>
<p>数据库中间件主要对应用屏蔽了以下过程：</p>
<ul>
<li><strong>sql解析</strong>：首先对<code>sql</code>进行解析，得到抽象语法树，从语法树中得到一些关键<code>sql</code>信息</li>
<li><strong>sql路由</strong>：<code>sql</code>路由包括库路由和表路由。库路由用于确定这条记录应该操作哪个分库，表路由用于确定这条记录应该操作哪个分表。</li>
<li><strong>sql改写</strong>：将<code>sql</code>改写成正确的执行方式。例如，对于一个批量插入<code>sql</code>，同时插入4条记录。但实际上用户希望4个记录分表存储到一个分表中，那么就要对sql进行改写成4条<code>sql</code>，每个<code>sql</code>都只能插入1条记录。</li>
<li><strong>sql执行</strong>：一条<code>sql</code>经过改写后可能变成了多条<code>sql</code>，为了提升效率应该并发的去执行，而不是按照顺序逐一执行</li>
<li><strong>结果集合并</strong>：每个<code>sql</code>执行之后，都会有一个执行结果，我们需要对分库分表的结果集进行合并，从而得到一个完整的结果。 </li>
</ul>
<h4 id="4-1-SQL解析"><a href="#4-1-SQL解析" class="headerlink" title="4.1 SQL解析"></a>4.1 SQL解析</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用户执行只是一条<code>sql</code>，并传入相关参数。数据库中间件内部需要通过<code>sql</code>解析器，对<code>sql</code>进行解析。可以将<code>sql</code>解析，类比为<code>xml</code>解析，<code>xml</code>解析的最终结果是得到一个<code>document</code>对象，而<code>sql</code>解析最终得到一个抽象语法树(<code>AST</code>)。通过这个语法树，我们可以很简单的获取到<code>sql</code>的一些执行，例如当前执行的<code>sql</code>类型，查询了那些字段，数据库表名，<code>where</code>条件，<code>sql</code>的参数等一系列信息。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>通常来说，对于<code>sql</code>解析，内部需要经过词法(<code>lex</code>)解析和语法(<code>Syntax</code>)解析两个阶段，最终得到一个语法树</strong>。 </p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlBsICmKjib9WPn4PTSzjId24vQw84iccUQ47NiboDjVmB1T14mDw6p1XLg.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>SQL</code>解析器的内部实现原理对业务同学是屏蔽的，业务同学也感知不到。一些数据库中间件采用了第三方开源的<code>sql</code>解析器，也有一些自研<code>sql</code>解析器。例如<code>mycat、zebra</code>采用的都是<code>druid</code>解析器，<code>shard-jdbc</code>一开始也用的是<code>druid</code>解析器，后面自研了解析器。目前较为流行的<code>sql</code>解析器包括：</p>
<ul>
<li><code>FoundationDB SQL Parser</code></li>
<li><code>Jsqlparser</code></li>
<li><code>Druid SQL Parser</code></li>
</ul>
<p>​        其中，其中<code>Fdbparser</code>和<code>jsqlparser</code>都是基于<code>javacc</code>实现的。</p>
<p>​        <code>mycat</code>团队曾经做过一个性能测试，<code>druid</code>解析器的解析性能通常能达到基于<code>javacc</code>生成的<code>sql</code>解析器10~20倍。本人也进行过类似的测试，得出的结论基本一致。</p>
<p>​        如何对比不同的<code>sql</code>解析器的好坏呢？主要是考虑以下两点：</p>
<p><strong>解析性能：</strong><code>druid</code>最好。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>druid</code>采用的是预测分析法，它只需要从字符的第一个到最后一个遍历一遍，就同时完成了词法解析和语法解析，语法树也已经构造完成。</p>
<p><strong>数据库方言：</strong><code>druid</code>支持的最多。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>SQL-92、SQL-99</code>等都是标准<code>SQL</code>，<code>mysql/oracle/pg/sqlserver/odps</code>等都是方言，<code>sql-parser</code>需要针对不同的方言进行特别处理。<code>Druid</code>的<code>sql parser</code>是目前支持各种数据语法最完备的<code>SQL Parser</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注：这里说的仅仅是基于<code>Java</code>实现的<code>SQL</code>解析器，<code>druid</code>是比较好的。大部分同学可能知道<code>druid</code>是一个为监控而生的连接池，事实上，<code>druid</code>另一大特性，就是它的<code>SQL</code>解析器。很多开源的数据库中间件，例如<code>zebra</code>、<code>sharding-jdbc</code>等，都使用了<code>druid</code>解析器。(<code>sharding-jdbc</code>后来自研了解析器)。虽然<code>SQL</code>解析是<code>druid</code>的一大亮点，不过<code>github</code>上也因为<code>SQL</code>解析的<code>bug</code>，收到了不少<code>issue</code>。</p>
<h4 id="4-2-SQL路由"><a href="#4-2-SQL路由" class="headerlink" title="4.2 SQL路由"></a>4.2 SQL路由</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;路由规则是分库分表的基础，其规定了数据应该按照怎样的规则路由到不同的分库分表中。对于一个数据库中间件来说，通常是<strong>支持用户自定义任何路由规则的</strong>。<strong>路由规则本质上是一个脚本表达式，数据库中间件通过内置的脚本引擎对表达式进行计算，确定最终要操作哪些分库、分表</strong>。常见的路由规则包括哈希取模，按照日期等。</p>
<p>​        下图展示了<code>user</code>表进行分库分表后(2个分库，每个分库2个分表)，并如何根据<code>id</code>进行路由的规则： </p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xltNMMictztrsysejCyhRdL1pavKiaXHOq23k2rwtSzumgeqeoZ05kg8eg.png" alt="img"></p>
<p>路由分则分为：</p>
<ul>
<li>库规则：用于确定到哪一个分库</li>
<li>表规则：用于确定到哪一个分表</li>
</ul>
<p>在上例中，我们使用<code>id</code>来作为计算分表、分表，因此把<code>id</code>字段就称之为路由字段，或者分区字段。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要注意的是，<strong>不管执行的是INSERT、UPDATE、DELETE、SELECT语句，SQL中都应该包含这个路由字段</strong>。否则，对于插入语句来说，就不知道插入到哪个分库或者分表；对于<code>UPDATE、DELETE、SELECT</code>语句而言，则更为严重，因为不知道操作哪个分库分表，意味着必须要对所有分表都进行操作。<strong><code>SELECT</code>聚合所有分表的内容，极容易内存溢出，<code>UPDATE、DELETE</code>更新、删除所有的记录，非常容易误更新、删除数据</strong>。因此，一些数据库中间件，对于<code>SQL</code>可能有一些限制，例如<code>UPDATE、DELETE</code><strong>必须要带上分区字段</strong>，或者指定过滤条件。 </p>
<h4 id="4-3-SQL改写"><a href="#4-3-SQL改写" class="headerlink" title="4.3 SQL改写"></a>4.3 SQL改写</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面已经介绍过，如一个批量插入语句，如果记录要插入到不同的分库分表中，那么就需要对<code>SQL</code>进行改写。 例如，将以下<code>SQL</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">user</span>(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">1</span>,”tianshouzhi”),(<span class="number">2</span>,”huhuamin”), (<span class="number">3</span>,”wanghanao”),(<span class="number">4</span>,”luyang”)</span><br></pre></td></tr></table></figure>
<p>​        改写为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">insert into user_1(id,name) values (1,”tianshouzhi”);</span><br><span class="line">insert into user_2(id,name) values (2,”huhuamin”);</span><br><span class="line">insert into user_3(id,name) values (3,”wanghanao”);</span><br><span class="line">insert into user_0(id,name) values  (4,”luyang”);</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里只是一个简单的案例，<strong>通常对于INSERT、UPDATE、DELETE等，改写相对简单</strong>。比较复杂的是<code>SELECT</code>语句的改写，对于一些复杂的<code>SELECT语句</code>，改写过程中会进行一些优化，例如将子查询改成<code>JOIN</code>，过滤条件下推等。因为<code>SQL</code>改写很复杂，所以很多数据库中间件并不支持复杂的<code>SQL</code>(通常有一个支持的<code>SQL</code>)，只能支持一些简单的<code>OLTP</code>场景。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然也有一些数据库中间件，不满足于只支持<code>OLTP</code>，在迈向<code>OLAP</code>的方向上进行了更多的努力。例如阿里的<code>TDDL</code>、蚂蚁的<code>Zda</code>l、大众点评的<code>zebra</code>，都引入了<code>apache calcite</code>，尝试对复杂的查询<code>SQL</code>(例如嵌套子查询，<code>join</code>等)进行支持，通过过滤条件下推，流式读取，并结合<code>RBO</code>(基于规则的优化)、<code>CBO</code>(基于代价的优化)来对一些简单的<code>OLAP</code>场景进行支持。</p>
<h4 id="4-4-SQL执行"><a href="#4-4-SQL执行" class="headerlink" title="4.4 SQL执行"></a>4.4 SQL执行</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>当经过<code>SQL</code>改写阶段后，会产生多个<code>SQL</code>，需要到不同的分片上去执行，通常我们会使用一个线程池，将每个<code>SQL</code>包装成一个任务，提交到线程池里面并发的去执行，以提升效率</strong>。</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlpQ1ddLnzG7AVZDAINJc5bT1M6H9Aw9p2iaQpcoyiaFbbAkibJur8CiarYQ.png" alt="img"></p>
<p>​    这些执行的<code>SQL</code>中，如果有一个失败，则整体失败，返回异常给业务代码。 =》 <strong>部分失败，数据不一致，分布式事务</strong> </p>
<h4 id="4-5-结果集合并"><a href="#4-5-结果集合并" class="headerlink" title="4.5 结果集合并"></a>4.5 结果集合并</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结果集合并，是数据库中间件的一大难点，需要<code>case by case</code>的分析，主要是考虑实现的复杂度，以及执行的效率问题，对于一些复杂的<code>SQL</code>，可能并不支持。例如：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>对于查询条件：</strong>大部分中间件都支持<code>=、IN</code>作为查询条件，且可以作为分区字段。但是<strong>对于<code>NIT IN、BETWEEN…AND、LIKE,NOT LIKE</code>等，只能作为普通的查询条件，因为根据这些条件，无法记录到底是在哪个分库或者分表，只能全表扫描</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>聚合函数：</strong>大部分中间件都支持<code>MAX、MIN、COUNT、SUM</code>，但是对于<code>AVG</code>可能只是部分支持。另外，如果是函数嵌套、分组(<code>GROUP BY</code>)聚合，可能也有一些数据库中间件不支持。 =&gt; <strong>全库全表扫描</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>子查询：</strong>分为<code>FROM</code>部分的子查询和<code>WHERE</code>部分的子查询。大部分中对于子查询的支持都是非常有限，例如语法上兼容，但是<strong>无法识别子查询中的分区字段</strong>，或者要求子查询的表名必须与外部查询表名相同，又或者只能支持一级嵌套子查询。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>JOIN：</strong>对于<code>JOIN</code>的支持通常很复杂，如果做不到过滤条件下推和流式读取，在中间件层面，基本无法对JOIN进行支持，因为<strong>不可能把两个表的所有分表，全部拿到内存中来进行<code>JOIN</code>，内存早就崩了</strong>。当然也有一些取巧的办法，一个是<strong><code>Binding Table</code></strong>，另外一个是<strong>小表广播</strong>(见后文)。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>分页排序：</strong>通常中间件都是支持<code>ORDER BY</code>和<code>LIMIT</code>的。但是<strong>在分库分表的情况下，分页的效率较低</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如对于limit 100，10 ORDER BY id。表示按照id排序，从第100个位置开始取10条记录。那么，大部分数据库中间件实际上是要从每个分表都查询110(100+10)条记录，拿到<strong>内存中进行重新排序</strong>，然后取出10条。假设有10个分表，那么实际上要查询1100条记录，而最终只过滤出了10记录。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>因此，在分页的情况下，通常建议使用<code>&quot;where id &gt; ? limit 10”</code>的方式来进行查询，应用记住每次查询的最大的记录id。之后查询时，每个分表只需要从这个id之后，取10条记录即可，而不是取<code>offset + rows</code>条记录，最后再在内存中排序取全局top 10</strong>。 </p>
<p>关于<code>JOIN</code>的特属说明：</p>
<p><strong>Binding Table：</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>适用于两个表之间存在关联关系，路由规则相同</strong>。例如，有<code>user</code>表和<code>user_account</code>表，由于<code>user_account</code>与<code>user</code>表强关联，我们可以将这<strong>两个表的路由规则设置为完全一样，那么对于某个特定用户的信息，其所在的<code>user</code>分表和<code>user_account</code>分表必然唯一同一个分库下，后缀名相同的分表中</strong>。在<code>join</code>时，某一个分库内的<code>join</code>，就可以拿到这个用户以及账号的完整信息，而不需要进行跨库<code>join</code>，这样就不需要把用户的数据库拿到内存中来进行<code>join</code>。 </p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xl3ezjbdI7tVfPvVoMBh71m8lNJ2WA8I3Xj356mls9aXIWhjzUbKFA6Q.png" alt="img"></p>
<p><strong>小表广播：</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>小表广播通常是某一个表的数据量比较少</strong>， 例如部门表<code>department</code>。另外一个表数据量比较大，例如<code>user</code>。此时<code>user</code>需要进行分库分表，但是<code>department</code>不需要进行分库分表。为了达到<code>JOIN</code>的目的，我们可以<strong>将 <code>department</code>表在每个分库内都实时同步一份完整的数据</strong>。这样，<strong>在<code>JOIN</code>的时候，数据库中间件只需要将分库<code>JOIN</code>的结果进行简单合并即可</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下图演示了小表广播的流程，用户在更新<code>department</code>表时，总是更新分库<code>db0</code>的<code>department</code>表，同步组件将变更信息同步到其他分库中。 </p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlwFEwmHGsdoupJe59zj1FtPrILeHIzmLdzr6cdXNnZg3RxxwzXHDPDg.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注：图中的同步组件指的是一般是伪装成数据库的从库，解析源库<code>binlog</code>，插入目标库。有一些开源的组件，如<code>canal、puma</code>可以实现这个功能，当然这些组件的应用场景非常广泛，不仅限于此。</p>
<h4 id="4-6-二级索引"><a href="#4-6-二级索引" class="headerlink" title="4.6 二级索引"></a>4.6 二级索引</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常情况下，分库分表的时候，分区字段只有一个。例如对于用户表<code>user</code>，按照<code>user_id</code>字段进行分区，那么之后查询某个用户的信息，只能根据user_id作为分区字段。<strong>使用其他字段，则需要扫描所有分表，效率很低</strong>。但是又有根据其他字段查询某个用户信息的需求，例如根据手机号<code>phone_id</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此时，我们可以将按照<code>user_id</code>插入的数据，进行一份<strong>全量拷贝</strong>。<strong>通过同步组件，重新按照<code>phone_id</code>插入到另一个分库分表集群中，这个集群就成为二级索引，或者叫辅维度同步</strong>。此后，对于根据<code>user_id</code>的操作，就在原来的分库分表集群中进行操作；根据<code>phone_id</code>的操作，就到二级索引集群中去进行操作。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>需要注意的是，对于更新操作，只能操作原集群，二级索引集群只能执行查询操作</strong>。<strong>原集群的增量数据变更信息，实时的通过同步组件，同步到二级索引集群中</strong>。 </p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xl2KVM1WrS169PzVEblzhCw5j1QXwreZoF3CxbZEPBnNuWl5PsnrNwrg.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注：这是一个很常见的面试题。阿里的一些面试官，比较喜欢问。一些面试者，可能自己想到了这个方案，因为考虑到这样比较浪费资源，就自行排除了。事实上，这点资源相对于满足业务需求来说，都不是事。</p>
<h4 id="4-7-分布式id生成器"><a href="#4-7-分布式id生成器" class="headerlink" title="4.7 分布式id生成器"></a>4.7 分布式id生成器</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分库分表的情况下，数据库的自增主键已经无法使用。所以要使用一个分布式的id生成器。分布式事务id生成器要满足以下条件：<strong>唯一、趋势递增(减少落库时的索引开销)、高性能、高可用</strong>。</p>
<p>目前主流的分布式id生成方案都有第三方组件依赖，如：</p>
<ul>
<li><p>基于<code>zk</code></p>
</li>
<li><p>基于<code>mysql</code></p>
</li>
<li><p>基于缓存</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>twitter</code>的<code>snowflake</code>算法是一个完全去中心化的分布式id算法，但是限制<code>workid</code>最多能有1024，也就是说，应用规模不能超过1024。虽然可以进行细微的调整，但是总是有数量的限制。 </p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外，美团之前在github开源了一个<code>lea</code>f组件，是用于生成分布式id的，感兴趣的读者可以研究一下。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里提出一种支持动态扩容的去中心化分布式id生成方案，此方案的优势，除了保证唯一、趋势递增，没有第三方依赖，支持存储的动态扩容之外，还具有以下优势：</p>
<ul>
<li><strong>支持按照时间范围查询，或者 时间范围+ip查询，可以直接走主键索引</strong>；</li>
<li><strong>每秒的最大序列id就是某个ip的qps</strong>等</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">12位日期+10位IP+6位序列ID+4位数据库扩展位</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<p><strong>12位日期：</strong>格式为<code>yyMMddHHmmss</code>，意味着本方案的id生成策略可以使用到2099年，把时间部分前置，从而保证趋势递增。</p>
<p><strong>10位ip：</strong>利用<code>ip to decimal</code>算法将12位的ip转为10进制数字。通过ip地址，来保证全局唯一。如果ip地址被回收重复利用了，也不用担心id的唯一性，因为日期部分还在变化。</p>
<p><strong>6位序列id：</strong>意味着每秒最多支持生成100百万个<code>id(0~999999)</code>。不足6位前置补0，如<code>000123</code>。</p>
<p><strong>4位数据库扩展位：</strong>为了实现不迁移数据的情况下，实现动态扩容，其中<strong>2位表示<code>DB</code>，2位表示<code>TB</code>，最多可扩容到10000张表（0000~9999）</strong>。假设每张表存储1000万数据，则总共可以支持存储1000亿条数据。 </p>
<p>关于数据库扩展位实现动态扩容图解：</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlSmk2icbBOy8ELI6owtZZIpI2ZEpbBzfMsvmTIPCvibEVlMc5mYGFrruQ.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先明确一点，<strong>路由策略始终根据数据库最后四位，确定某一条记录要到哪个分库的哪个分表中</strong>。例如<code>xxxx0001</code>，意味着这条记录肯定是在00分库的01分表上。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接着，就要在id的生成策略上做文章。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设初始状态为两个分库<code>db_00</code>,<code>db_01</code>，每个分库里面有10张分表，<code>tb_00~tb_09</code>。此时，<strong>业务要保证生成id的时候，始终保证db的两位在00~01之间，tb的两位始终在00~09之间（随机生成，与系列id无关）</strong>。路由策略根据这些id，可以找到正确的分库分表。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在需要扩容到10个分库，每个分表10个分表。那么DBA首先将新增的分库：<code>db_02~db_09</code>创建好，每个分库里面再创建10个分表：<code>tb_01~tb_09</code>。业务同学在此基础上，<strong>将id生成策略改成：db的两位在00~09之间，tb的两位规则维持不变(只是分库数变了，每个分库的分表数没变)</strong>。而由于路由从策略是根据最后四位确定到哪个分库，哪个分表，当这些新的分库分表扩展位id出现时，自然可以插入到新的分库分表中。也就实现了动态扩容，而无需迁移数据。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，新的分库分表中，一开始数据是没有数据的，所以数据是不均匀的，可以调整id扩展位中<code>db</code>和<code>tb</code>生成某个值的概率，使得落到新的分库分表中的概率相对大一点点(不宜太大)，等到数据均匀后，再重新调整成完全随机。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>此方案的核心思想是，预分配未来的可能使用到的最大资源数量</strong>。通常，100个分库，每个分库100张分表，能满足绝大部分应用的数据存储。如果<code>100</code>个分库都在不同的mysql实例上，假设每个<code>mysql</code>实例都是4T的磁盘，那么可以存储<code>400T</code>的数据，基本上可以满足绝大部分业务的需求。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，这个方案不完美。如果超过这个值，这种方案可能就不可行了。然而，通常一个技术方案，可以保证在5~10年之间不需要在架构上做变动，应该就算的上一个好方案了。如果你追求的是完美的方案，可能类似于<code>TIDB</code>这种可以实现自动扩容的数据库产品更适合，不过目前来说，<code>TIDB</code>等类似产品还是无法取代传统的关系型数据库的。说不定等到5~10年后，这些产品更成熟了，你再迁移过去也不迟。</p>
<h4 id="4-7-分布式事务"><a href="#4-7-分布式事务" class="headerlink" title="4.7 分布式事务"></a>4.7 分布式事务</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分库分表的情况下，由于操作多个分库，此时就涉及到分布式事务。例如执行一个批量插入<code>SQL</code>，如果记录要插入到不同的分库中，就无法保证一致性。因此，通常情况下，数据库中间件，只会保证单个分库的事务，也就是说，业务方在创建一个事务的时候，必须要保证事务中的所有操作，必须最终都在一个分库中执行。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事实上，在微服务的架构下，事务的问题更加复杂，如下图</p>
<p><img src="//blog.com/2019/06/30/数据库中间件详解/xmvcWIfCQiaBPjFzlDCBcW33a97Bicm0xlApS3vicuJDSZbiaBZRAjicUvss8fCOZoJ8sJxaIoWAdgHDJe41hRxlW5g.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Service A</code>在执行某个操作时，需要操作数据库，同时调用<code>Service B</code>和<code>Service C</code>，<code>Service B</code>底层操作的数据库是分库分表的，<code>Service C</code>也要操作数据库。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种场景下，保证事务的一致性就非常麻烦。一些常用的一致性算法如：<code>paxios</code>协议、<code>raft协议</code>也无法解决这个问题，因为<strong>这些协议都是资源层面的一致性</strong>。<strong>在微服务架构下，已经将事务的一致性上升到了业务的层面</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果仅仅考虑分库分表，一些同学可能会想到<code>XA</code>，但是性能很差，对数据库的版本也有要求，例如必须使用<code>mysql 5.7</code>，官方还建议将事务隔离级别设置为串行化，这是无法容忍的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于分布式事务的应用场景，并不是仅仅分库分表，因此通常都是会有一个专门的团队来做分布式事务，并不一定是数据库中间件团队来做。例如，<code>sharding-jdbc</code>就使用了华为开源的一套微服务架构解决方案<code>service comb</code>中的<code>saga</code>组件，来实现分布式事务最终一致性。阿里也有类似的组件，在内部叫<code>TXC</code>，在阿里云上叫<code>GTS</code>，最近开源到了<code>GitHub</code>上叫<code>fescar（Fast &amp; Easy Commit And Rollback)</code>。蚂蚁金服也有类似的组件，叫<code>DTX</code>，支持<code>FMT</code>模式和<code>TCC</code>模式。其中<code>FMT</code>模式就类似于<code>TXC</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>总体来说，实际上<code>TCC</code>更能满足业务的需求，虽然接入更加复杂</strong>。关于<code>fescar</code>，最近比较火，这是<code>java</code>写的，具体可以参考：<a href="https://github.com/alibaba/fescar。" target="_blank" rel="noopener">https://github.com/alibaba/fescar。</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/06/30/分库分表/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/30/分库分表/" itemprop="url">分库分表</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-06-30T10:12:57+08:00">
                2019-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/" itemprop="url" rel="index">
                    <span itemprop="name">数据库优化</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/" itemprop="url" rel="index">
                    <span itemprop="name">数据库设计</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/读写分离/" itemprop="url" rel="index">
                    <span itemprop="name">读写分离</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/读写分离/分库分表/" itemprop="url" rel="index">
                    <span itemprop="name">分库分表</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h1><blockquote>
<p>需要重新做一个会员系统,一个会员表有30多个字段,有一半是不常用到的, 另外会员表里面有很多僵尸会员,啰嗦了那么多,开始正式话题:</p>
<p>会员表是按照办卡日期或ID进行水平分表好,<br>还是按照常用字段和不常用字段进行垂直分割的好?  </p>
</blockquote>
<h2 id="分表基本思想"><a href="#分表基本思想" class="headerlink" title="分表基本思想"></a>分表基本思想</h2><p>​    分区的思想，垂直分区和水平分区，<strong>水平分区是指将表的数据行存储在不同的partition中，垂直分区是指将table拆分成多个表，并通过PK 链接在一起</strong></p>
<p>​    垂直分区的出发点是<strong>column 太宽</strong>，并且不常用，如果存在这样的column，垂直分区效果好；</p>
<p>​    水平分区的出发点是有些row 不常用，这样，<strong>将常用的rows 存储在一个partition中，使查询的范围缩小到一个partition中，减少query的时间消耗，提高性能</strong>    </p>
<p><strong>列太多 =》 垂直拆分</strong></p>
<p><strong>行太多 =》水平拆分</strong></p>
<h3 id="水平分表纬度"><a href="#水平分表纬度" class="headerlink" title="水平分表纬度"></a>水平分表纬度</h3><p>​    <strong>汇总表    =》 活跃度、时间、用户ID</strong></p>
<p>​    可以用<strong>表/缓存</strong>来保存<strong>分区键与常用查询条件的映射关系</strong></p>
<h3 id="垂直分表数据聚合"><a href="#垂直分表数据聚合" class="headerlink" title="垂直分表数据聚合"></a>垂直分表数据聚合</h3><p>​    <strong>视图</strong></p>
<h2 id="为什么要垂直分表？"><a href="#为什么要垂直分表？" class="headerlink" title="为什么要垂直分表？"></a>为什么要垂直分表？</h2><p>在这里我可能在个人的知识范畴内说几点，如果有不同的看法，或者发现错误，希望大家提出。</p>
<h3 id="行溢出"><a href="#行溢出" class="headerlink" title="行溢出"></a>行溢出</h3><p>​    这个主要是大字段的拆分，因为字段本身可能非常大，超出行的可变长度，这个是在使用varchar可变类型情况下，因为数据库的行格式会存储变长字段的长度，而这个存储的字段最多就2字节，这样的话可变长度最多就可以达到65535，达到这个长度的话，计算了一下，一行数据的可变长度的列总和不超过64k左右（没精准算），超过的话会溢出行到blob页，这里还衍生了个问题，因为<strong>页存储就16k，而一行数据就远远超出，这样就失去了b+树的意义了，所以一般mysql会拆分前缀存储额外数据到额外页，一页保持至少两行数据</strong></p>
<h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>mysql的查询缓存具体是根据查询语句来的，这里具体可以去看《高性能MYSQL》一书，大概表达的意思是查询语句不能有变量或者函数，例如current_timestamp之类的，这样不会有缓存，有点跑偏了。这里的意思是，垂直拆分表后，有些字段是常修改的，例如用户的个性签名之类的，而更新操作会让查询缓存无效，所以垂直拆分会优化查询效率。</p>
<h3 id="数据页的影响"><a href="#数据页的影响" class="headerlink" title="数据页的影响"></a>数据页的影响</h3><p>​    页是什么呢？页应该算作数据库的存储最小单位，在mysql中例如，insert_buffer_pool，AIO，<strong>索引查找都是以页为单位，首先垂直拆分表的话，随着字段的减少，每页里面的数据行也会增多，理论上页里面的数据行越多性能越好</strong><br>例如图中所示假如未分表之前页分布是这样的，如果要查询id=1和id=9的话可能是需要两次索引查询，两次磁盘IO，这里为啥说页1和页3呢，因为异步IO的可能性，innodb不会去等待第一个扫描结果，而是先扫描，然后去取数据，例如如果是id=1和id=6，根据page判断数据是相邻页，因为页是顺序存储的，所以会合并也就一次磁盘IO取出两页数据。</p>
<p>像上面这样，<strong>页里的行数增多，就可以减少一部分磁盘的IO，这样也就增加了查询效率</strong></p>
<h3 id="对写入更新的影响"><a href="#对写入更新的影响" class="headerlink" title="对写入更新的影响"></a>对写入更新的影响</h3><p>​    写入和更新其实还是页的问题，同样的问题，页的减少，就会影响脏页的刷新，insert_buffer的mergy，这样都会影响iops，<strong>如果页的减少，数据也会存储更有顺序性，对于写入与读取的话，顺序读比离散读要快，性能也能得到提升</strong></p>
<h2 id="分库基本思想"><a href="#分库基本思想" class="headerlink" title="分库基本思想"></a>分库基本思想</h2><h3 id="水平分库"><a href="#水平分库" class="headerlink" title="水平分库"></a>水平分库</h3><p>​      Sharding的基本思想就要把一个数据库切分成多个部分放到不同的数据库(server)上，从而缓解单一数据库的性能问题。不太严格的讲，对于海量数据的数据库，如果是因为表多而数据多，这时候适合使用垂直切分，即把关系紧密（比如同一模块）的表切分出来放在一个server上。如果表并不多，但每张表的数据非常多，这时候适合水平切分，即<strong>把表的数据按某种规则（比如按ID散列）切分到多个数据库(server)上</strong>。当然，现实中更多是这两种情况混杂在一起，这时候需要根据实际情况做出选择，也可能会综合使用垂直与水平切分，从而将原有数据库切分成类似矩阵一样可以无限扩充的数据库(server)阵列。</p>
<h3 id="垂直分库"><a href="#垂直分库" class="headerlink" title="垂直分库"></a>垂直分库</h3><p>​      垂直切分的最大特点就是规则简单，实施也更为方便，尤其<strong>适合各业务之间的耦合度非常低，相互影响很小，业务逻辑非常清晰的系统</strong>。在这种系统中，可以很容易做到<strong>将不同业务模块所使用的表分拆到不同的数据库中。根据不同的表来进行拆分，对应用程序的影响也更小，拆分规则也会比较简单清晰</strong>。（这也就是所谓的”share nothing”）。</p>
<p><img src="//blog.com/2019/06/30/分库分表/0_12958577041KqK.gif" alt="img"></p>
<p>​      水平切分于垂直切分相比，相对来说稍微复杂一些。因为要将同一个表中的不同数据拆<br>分到不同的数据库中，对于应用程序来说，拆分规则本身就较根据表名来拆分更为复杂，后<br>期的数据维护也会更为复杂一些。</p>
<p><img src="//blog.com/2019/06/30/分库分表/0_1295857710BUth.gif" alt="img"></p>
<p>​      让我们从普遍的情况来考虑数据的切分：一方面，一个库的所有表通常不可能由某一张表全部串联起来，这句话暗含的意思是，水平切分几乎都是针对一小搓一小搓（实际上就是垂直切分出来的块）关系紧密的表进行的，而不可能是针对所有表进行的。另一方面，一些负载非常高的系统，即使仅仅只是单个表都无法通过单台数据库主机来承担其负载，这意味着单单是垂直切分也不能完全解决问明。因此多数系统会将垂直切分和水平切分联合使用，<strong>先对系统做垂直切分，再针对每一小搓表的情况选择性地做水平切分。从而将整个数据库切分成一个分布式矩阵</strong>。</p>
<p><img src="//blog.com/2019/06/30/分库分表/0_1295857852VJcX.gif" alt="img"></p>
<h3 id="切分策略"><a href="#切分策略" class="headerlink" title="切分策略"></a>切分策略</h3><p>​      <strong>切分是按先垂直切分再水平切分的步骤进行的。垂直切分的结果正好为水平切分做好了铺垫。垂直切分的思路就是分析表间的聚合关系，把关系紧密的表放在一起</strong>。多数情况下可能是同一个模块，或者是同一“聚集”。这里的“聚集”正是领域驱动设计里所说的聚集。在垂直切分出的表聚集内，找出“根元素”（这里的“根元素”就是领域驱动设计里的“聚合根”），按“根元素”进行水平切分，也就是从“根元素”开始，把所有和它直接与间接关联的数据放入一个shard里。这样出现跨shard关联的可能性就非常的小。应用程序就不必打断既有的表间关联。比如：对于社交网站，几乎所有数据最终都会关联到某个用户上，基于用户进行切分就是最好的选择。再比如论坛系统，用户和论坛两个模块应该在垂直切分时被分在了两个shard里，对于论坛模块来说，Forum显然是聚合根，因此按Forum进行水平切分，把Forum里所有的帖子和回帖都随Forum放在一个shard里是很自然的。</p>
<p>​      对于共享数据数据，如果是只读的字典表，每个shard里维护一份应该是一个不错的选择，这样不必打断关联关系。如果是一般数据间的跨节点的关联，就必须打断。</p>
<p>​      <strong>需要特别说明的是：当同时进行垂直和水平切分时，切分策略会发生一些微妙的变化。比如：在只考虑垂直切分的时候，被划分到一起的表之间可以保持任意的关联关系，因此你可以按“功能模块”划分表格，但是一旦引入水平切分之后，表间关联关系就会受到很大的制约，通常只能允许一个主表（以该表ID进行散列的表）和其多个次表之间保留关联关系，也就是说：当同时进行垂直和水平切分时，在垂直方向上的切分将不再以“功能模块”进行划分，而是需要更加细粒度的垂直切分，而这个粒度与领域驱动设计中的“聚合”概念不谋而合，甚至可以说是完全一致，每个shard的主表正是一个聚合中的聚合根！这样切分下来你会发现数据库分被切分地过于分散了（shard的数量会比较多，但是shard里的表却不多），为了避免管理过多的数据源，充分利用每一个数据库服务器的资源，可以考虑将业务上相近，并且具有相近数据增长速率（主表数据量在同一数量级上）的两个或多个shard放到同一个数据源里，每个shard依然是独立的，它们有各自的主表，并使用各自主表ID进行散列，不同的只是它们的散列取模（即节点数量）必需是一致的。</strong></p>
<h3 id="分库后存在的问题"><a href="#分库后存在的问题" class="headerlink" title="分库后存在的问题"></a>分库后存在的问题</h3><h4 id="1-分布式事务"><a href="#1-分布式事务" class="headerlink" title="1. 分布式事务"></a>1. 分布式事务</h4><blockquote>
<p>方案一：使用分布式事务</p>
</blockquote>
<p>​    优点：交由数据库管理，简单有效<br>​    缺点：性能代价高，特别是shard越来越多时</p>
<blockquote>
<p>方案二：由应用程序和数据库共同控制</p>
</blockquote>
<p>​     原理：将一个跨多个数据库的分布式事务分拆成多个仅处于单个数据库上面的小事务，并通过应用程序来总控<br>​           各个小事务。<br>​     优点：性能上有优势<br>​     缺点：需要应用程序在事务控制上做灵活设计。如果使用了spring的事务管理，改动起来会面临一定的困难。</p>
<blockquote>
<p>方案三：消息队列+补偿机制</p>
</blockquote>
<h4 id="2-跨节点Join的问题"><a href="#2-跨节点Join的问题" class="headerlink" title="2. 跨节点Join的问题"></a>2. 跨节点Join的问题</h4><p>​        只要是实行切分，跨节点Join的问明是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。</p>
<p>​    解决方案：<strong>分两次查询实现</strong>，在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。</p>
<h4 id="3-跨节点的count-order-by-group-by以及聚合函数问题"><a href="#3-跨节点的count-order-by-group-by以及聚合函数问题" class="headerlink" title="3. 跨节点的count,order by,group by以及聚合函数问题"></a>3. 跨节点的count,order by,group by以及聚合函数问题</h4><p>​      这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。</p>
<p>​    解决方案：与解决跨节点join问题的类似，<strong>分别在各个节点上得到结果后在应用程序端进行合并</strong>。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。</p>
<h2 id="水平分库分表策略"><a href="#水平分库分表策略" class="headerlink" title="水平分库分表策略"></a>水平分库分表策略</h2><p>介绍一种方案</p>
<p>预估行数：10亿<br>需要表数：10亿 / 500w = 200<br>分成10个库，每个库20张表<br>使用：<strong>客户端每个库对应一个主机，库 – scheme_(hash(id) % 10)（根据库名获取mysql主机配置），表名</strong></p>
<ul>
<li>.table_(hash(id) % 20)<br>扩展：以库为单位搭建主从，当主从无延迟时修改客户端配置；停止主从，观察一段时间后，删除原主库上的库即可</li>
<li>常用的hash算法<br>md5 + substr前多少位：缺点分库分表数只能是16的幂<br><strong>sprintf(%u, crc32(…)) % mod</strong></li>
</ul>
<h2 id="分库示例演示"><a href="#分库示例演示" class="headerlink" title="分库示例演示"></a>分库示例演示</h2><h4 id="第一部分：实施策略"><a href="#第一部分：实施策略" class="headerlink" title="第一部分：实施策略"></a>第一部分：实施策略</h4><p><img src="//blog.com/2019/06/30/分库分表/67a6a651gw1ducq4lmzyzj.jpg" alt="img"></p>
<h4 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h4><p>对数据库进行分库分表(Sharding化)前，需要开发人员充分了解系统业务逻辑和数据库schema.一个好的建议是绘制一张数据库ER图或领域模型图，以这类图为基础划分shard,直观易行，可以确保开发人员始终保持清醒思路。对于是选择数据库ER图还是领域模型图要根据项目自身情况进行选择。如果项目使用数据驱动的开发方式，团队以数据库ER图作为业务交流的基础，则自然会选择数据库ER图，如果项目使用的是领域驱动的开发方式，并通过OR-Mapping构建了一个良好的领域模型，那么领域模型图无疑是最好的选择。就我个人来说，更加倾向使用领域模型图，因为进行切分时更多的是以业务为依据进行分析判断，领域模型无疑更加清晰和直观。</p>
<h4 id="分析阶段"><a href="#分析阶段" class="headerlink" title="分析阶段"></a>分析阶段</h4><h5 id="垂直切分"><a href="#垂直切分" class="headerlink" title="垂直切分"></a>垂直切分</h5><p>垂直切分的依据原则是：将业务紧密，表间关联密切的表划分在一起，例如同一模块的表。结合已经准备好的数据库ER图或领域模型图，仿照活动图中的泳道概念，一个泳道代表一个shard，把所有表格划分到不同的泳道中。下面的分析示例会展示这种做法。当然，你也可以在打印出的ER图或模型图上直接用铅笔圈，一切取决于你自己的喜好。</p>
<h5 id="水平切分"><a href="#水平切分" class="headerlink" title="水平切分"></a>水平切分</h5><p>垂直切分后，需要对shard内表格的数据量和增速进一步分析，以确定是否需要进行水平切分。</p>
<p><strong>2.1</strong>若划分到一起的表格数据增长缓慢，在产品上线后可遇见的足够长的时期内均可以由单一数据库承载，则不需要进行水平切分，所有表格驻留同一shard,所有表间关联关系会得到最大限度的保留，同时保证了书写SQL的自由度，不易受join、group by、order by等子句限制。</p>
<p><strong>2.2</strong> 若划分到一起的表格数据量巨大，增速迅猛，需要进一步进行水平分割。进一步的水平分割就这样进行：</p>
<p><strong>2.2.1</strong>.结合业务逻辑和表间关系，将当前shard划分成多个更小的shard,通常情况下，这些更小的shard每一个都只包含一个主表（将以该表ID进行散列的表）和多个与其关联或间接关联的次表。这种一个shard一张主表多张次表的状况是水平切分的必然结果。这样切分下来，shard数量就会迅速增多。如果每一个shard代表一个独立的数据库，那么管理和维护数据库将会非常麻烦，而且这些小shard往往只有两三张表，为此而建立一个新库，利用率并不高，因此，<strong>在水平切分完成后可再进行一次“反向的Merge”,即：将业务上相近，并且具有相近数据增长速率（主表数据量在同一数量级上）的两个或多个shard放到同一个数据库上，在逻辑上它们依然是独立的shard，有各自的主表，并依据各自主表的ID进行散列，不同的只是它们的散列取模（即节点数量）必需是一致的。这样，每个数据库结点上的表格数量就相对平均了</strong></p>
<p><strong>2.2.2.</strong> <strong>所有表格均划分到合适的shard之后，所有跨越shard的表间关联都必须打断，在书写sql时，跨shard的join、group by、order by都将被禁止，需要在应用程序层面协调解决这些问题</strong></p>
<p>特别想提一点：经水平切分后，shard的粒度往往要比只做垂直切割的粒度要小，原单一垂直shard会被细分为一到多个以一个主表为中心关联或间接关联多个次表的shard，此时的shard粒度与领域驱动设计中的“聚合”概念不谋而合，甚至可以说是完全一致，每个shard的主表正是一个聚合中的聚合根！</p>
<h4 id="实施阶段"><a href="#实施阶段" class="headerlink" title="实施阶段"></a>实施阶段</h4><p>​    如果项目在开发伊始就决定进行分库分表，则严格按照分析设计方案推进即可。如果是在中期架构演进中实施，除搭建实现sharding逻辑的基础设施外(关于该话题会在下篇文章中进行阐述)，还需要对原有SQL逐一过滤分析，修改那些因为sharding而受到影响的sql.</p>
<h4 id="示例演示"><a href="#示例演示" class="headerlink" title="示例演示"></a>示例演示</h4><p>本文选择一个人尽皆知的应用：jpetstore来演示如何进行分库分表(sharding)在分析阶段的工作。由于一些个人原因，演示使用的jpetstore来自原ibatis官方的一个Demo版本，SVN地址为：<a href="http://mybatis.googlecode.com/svn/tags/java_release_2.3.4-726/jpetstore-5。关于jpetstore的业务逻辑这里不再介绍，这是一个非常简单的电商系统原型，其领域模型如下图：" target="_blank" rel="noopener">http://mybatis.googlecode.com/svn/tags/java_release_2.3.4-726/jpetstore-5。关于jpetstore的业务逻辑这里不再介绍，这是一个非常简单的电商系统原型，其领域模型如下图：</a></p>
<p><img src="//blog.com/2019/06/30/分库分表/67a6a651tw1dv5vr1tskuj.jpg" alt="img"></p>
<p><strong>图2. jpetstore领域模型</strong></p>
<p>由于系统较简单，我们很容易从模型上看出，其主要由三个模块组成：用户，产品和订单。那么垂直切分的方案也就出来了。接下来看水平切分，如果我们从一个实际的宠物店出发考虑，可能出现数据激增的单表应该是Account和Order,因此这两张表需要进行水平切分。对于Product模块来说，如果是一个实际的系统，Product和Item的数量都不会很大，因此只做垂直切分就足够了，也就是（Product，Category，Item，Iventory，Supplier）五张表在一个数据库结点上（没有水平切分，不会存在两个以上的数据库结点）。<strong>但是作为一个演示，我们假设产品模块也有大量的数据需要我们做水平切分</strong>，那么分析来看，这个模块要拆分出两个shard:一个是（Product（主），Category），另一个是（Item（主），Iventory，Supplier），<strong>同时，我们认为：这两个shard在数据增速上应该是相近的，且在业务上也很紧密</strong>，那么我们可以<strong>把这两个shard放在同一个数据库节点上，Item和Product数据在散列时取一样的模</strong>。根据前文介绍的图纸绘制方法，我们得到下面这张sharding示意图：</p>
<p><img src="//blog.com/2019/06/30/分库分表/67a6a651tw1dv5vpue9s3j.jpg" alt="img"></p>
<p><strong>图3. jpetstore sharding示意图</strong></p>
<p>对于这张图再说明几点：</p>
<p><strong>1.使用泳道表示物理shard（一个数据库结点）</strong></p>
<p><strong>2.若垂直切分出的shard进行了进一步的水平切分，但公用一个物理shard的话，则用虚线框住，表示其在逻辑上是一个独立的shard。</strong></p>
<p><strong>3.深色实体表示主表</strong></p>
<p><strong>4.X表示需要打断的表间关联</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/06/30/数据库拆分过程及挑战/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/30/数据库拆分过程及挑战/" itemprop="url">数据库拆分过程及挑战</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-06-30T10:12:57+08:00">
                2019-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/" itemprop="url" rel="index">
                    <span itemprop="name">数据库优化</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/" itemprop="url" rel="index">
                    <span itemprop="name">数据库设计</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/读写分离/" itemprop="url" rel="index">
                    <span itemprop="name">读写分离</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/读写分离/分库分表/" itemprop="url" rel="index">
                    <span itemprop="name">分库分表</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据库拆分过程及挑战"><a href="#数据库拆分过程及挑战" class="headerlink" title="数据库拆分过程及挑战"></a>数据库拆分过程及挑战</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="http://www.tianshouzhi.com/api/tutorials/dragon/362" target="_blank" rel="noopener">http://www.tianshouzhi.com/api/tutorials/dragon/362</a></p>
</blockquote>
<p><br></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;互联网当下的数据库拆分过程基本遵循的顺序是：<strong>垂直拆分、读写分离、分库分表(水平拆分)</strong>。每个拆分过程都能解决业务上的一些问题，但同时也面临了一些挑战。</p>
<h2 id="1-垂直拆分"><a href="#1-垂直拆分" class="headerlink" title="1 垂直拆分"></a>1 垂直拆分</h2><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于一个刚上线的互联网项目来说，由于前期活跃用户数量并不多，并发量也相对较小，所以此时企业一般都会选择将所有数据存放在一个数据库 中进行访问操作。</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;举例来说，对于一个电商系统，其用户模块和产品模块的表刚开始都是位于一个<code>db_eshop</code>库中。</p>
<p><img src="//blog.com/2019/06/30/数据库拆分过程及挑战/1510498732075074602.png" alt="Image.png"></p>
<p>其中：<code>user</code>表和<code>user_account</code>表属于用户模块，<code>product_category</code>表和<code>product</code>表属于产品模块</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;刚开始，可能公司的技术团队规模比较小，因此整个技术团队共同维护<code>db_eshop</code>库。随着公司业务的发展，技术团队人员也得到了扩张，划分为不同的技术小组，不同的小组负责不同的业务模块。例如A小组负责用户模块，B小组负责产品模块。此时数据库也迎来了第一次拆分：垂直拆分。</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里的<strong>垂直拆分，指的是将一个包含了很多表的数据库，根据表的功能的不同，拆分为多个小的数据库，每个库包含部分表</strong>。下图演示将上面提到的<code>db_eshop</code>库，拆分为<code>db_user</code>库和<code>db_product</code>库。</p>
<p><img src="//blog.com/2019/06/30/数据库拆分过程及挑战/1510498758162045122.png" alt="Image.png"></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>关于垂直拆分，还有另一种说法，将一个包含了很多字段的大表拆分为多个小表，每个表包含部分字段。而笔者认为，根据表功能的不同的对数据库进行拆分，这种情况更加常见</strong>。</p>
<blockquote>
<p>垂直分表主要是为了提升查询效率，是MySQL可以一次性加载更多的行，将一些非必要字段或大字段选择性加载（通过join）</p>
</blockquote>
<h2 id="2-读写分离"><a href="#2-读写分离" class="headerlink" title="2 读写分离"></a>2 读写分离</h2><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随着后续的市场推广力度不断加强，用户数量和并发量不断上升。这时如果仅靠一个数据库来支撑所有访问压力,几乎是在 自寻死路 。以产品库为例，可能库中包含了几万种商品，并且每天新增几十种，而产品库每天的访问了可能有几亿甚至几十亿次。数据库读的压力太大，单台<code>mysql</code>实例扛不住，此时大部分 <strong><code>Mysql DBA</code> 就会将数据库设置成 读写分离状态 ，也就是一个 <code>Master</code> 节点(主库)对应多个<code>Salve</code> 节点(从库)</strong>。<strong>可以将<code>slave</code>节点的数据理解为<code>master</code>节点数据的全量备份</strong>。</p>
<p><img src="//blog.com/2019/06/30/数据库拆分过程及挑战/1510498779276077397.png" alt="Image.png"></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>master</code>节点只有一个且可读可写，<code>slave</code>节点有多个且只可以读。新增产品时，应用将数据写入<code>master</code>主库，主库将数据同步给多个<code>slave</code>从库。当查询产品时，应用选择某个<code>salve</code>节点读取数据。</p>
<p><strong>读写分离的优点：</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样通过配置多个<code>slave</code>节点，可以有效的避免过大的访问量对单个库造成的压力。</p>
<p><strong>读写分离的挑战：</strong></p>
<p>1、对于DBA而言，需要配置数据库主从同步</p>
<p>​     关于如何配置数据库的主从同步，这个目前方案已经很成熟。以<code>mysql</code>为例：</p>
<p>​     可以参考官方文档：<a href="https://dev.mysql.com/doc/refman/5.7/en/replication.html，" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/replication.html，</a></p>
<p>​     笔者也写了一篇文章介绍如何通过mysql_multi的方式配置主从同步：<a href="http://www.tianshouzhi.com/api/tutorials/mysql" target="_blank" rel="noopener">http://www.tianshouzhi.com/api/tutorials/mysql</a>。</p>
<p>2、对于开发人员而言，必须要对<code>sql</code>类型进行判断，如果是<code>select</code>等读请求，就走从库，如果是<code>insert</code>、<code>update</code>、<code>delete</code>等写请求，就走主库。此外还有一些其他的问题要考虑：</p>
<ul>
<li><strong>主从数据同步延迟问题：</strong>因为数据是从<code>master</code>节点通过网络同步给多个<code>slave</code>节点，因此必然存在延迟。因此有可能出现我们在<code>master</code>节点中已经插入了数据，但是从<code>slave</code>节点却读取不到的问题。<strong>对于一些强一致性的业务场景，要求插入后必须能读取到，因此对于这种情况，我们需要提供一种方式，让读请求也可以走主库，而主库上的数据必然是最新的</strong>。</li>
<li><strong>事务问题：</strong>如果一个事务中同时包含了读请求(如<code>select</code>)和写请求(如<code>insert</code>)，如果读请求走从库，写请求走主库，由于跨了多个库，那么<code>jdbc</code>本地事务已经无法控制，属于分布式事务的范畴。而分布式事务非常复杂且效率较低。因此<strong>对于读写分离，目前主流的做法是，事务中的所有<code>sql</code>统一都走主库，由于只涉及到一个库，<code>jdbc</code>本地事务就可以搞定</strong>。</li>
<li><strong>高可用的考虑：</strong>例如<code>master</code>配置了多个<code>slave</code>节点，如果其中某个<code>slave</code>节点挂了，那么之后的读请求，我们应用将其转发到正常工作的<code>slave</code>节点上。另外，如果新增了<code>slave</code>节点，应用也应该感知到，可以将读请求转发到新的<code>slave</code>节点上。</li>
</ul>
<h2 id="3-分库分表"><a href="#3-分库分表" class="headerlink" title="3 分库分表"></a>3 分库分表</h2><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;经过垂直分区后的 <code>Master/Salve</code>模式完全可以承受住难以想象的高并发访问操作，但是否可以永远 高枕无忧 了？答案是否定的，一旦业务表中的数据量大了，从维护和性能角度来看，无论是任何的 <code>CRUD</code> 操作，对于数据库而言都是一件极其耗费资源的事情。即便设置了索引， 仍然无法掩盖<strong>因为数据量过大从而导致的数据库性能下降</strong>的事实 ，因此这个时候 <code>Mysql DBA</code> 或许就该对数据库进行 水平分区 （<code>sharding</code>，即分库分表 ）。<strong>经过水平分区设置后的业务表，必然能够将原本一张表维护的海量数据分配给 N 个子表进行存储和维护</strong>。</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>水平分表从具体实现上又可以分为3种：只分表、只分库、分库分表</strong>，下图展示了这三种情况：</p>
<p><img src="//blog.com/2019/06/30/数据库拆分过程及挑战/1510498804787053892.png" alt="Image.png"></p>
<p><strong>只分表</strong>：</p>
<p>​        将<code>db</code>库中的<code>user</code>表拆分为2个分表，<code>user_0</code>和<code>user_1</code>，这两个表还位于同一个库中。  </p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;适用场景：<strong>如果库中的多个表中只有某张表或者少数表数据量过大，那么只需要针对这些表进行拆分，其他表保持不变</strong>。</p>
<p><strong>只分库</strong>：</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将<code>db</code>库拆分为<code>db_0</code>和<code>db_1</code>两个库，同时在<code>db_0</code>和<code>db_1</code>库中各自新建一个<code>user</code>表，<code>db_0.user</code>表和<code>db_1.user</code>表中各自只存原来的<code>db.user</code>表中的部分数据。</p>
<p><strong>分库分表</strong>：</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将<code>db库</code>拆分为<code>db_0</code>和<code>db_1</code>两个库，<code>db_0</code>中包含<code>user_0</code>、<code>user_1</code>两个分表，<code>db_1</code>中包含<code>user_2</code>、<code>user_3</code>两个分表。</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下图演示了在分库分表的情况下，数据是如何拆分的：假设<code>db</code>库的user表中原来有<code>4000W</code>条数据，现在将<code>db</code>库拆分为2个分库<code>db_0</code>和<code>db_1</code>，<code>user</code>表拆分为<code>user_0、user_1、user_2、user_3</code>四个分表，每个分表存储<code>1000W</code>条数据。</p>
<p><img src="//blog.com/2019/06/30/数据库拆分过程及挑战/1510498823627017102.png" alt="Image.png"></p>
<p><strong>分库的好处：</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>降低单台机器的负载压力</strong></p>
<p><strong>分表的好处：</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>提高数据操作的效率</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;举个例子说明，比如<code>user</code>表中现在有<code>4000w</code>条数据，此时我们需要在这个表中增加（<code>insert</code>）一条新的数据，<code>insert</code>完毕后，数据库会针对这张表重新建立索引，<code>4000w</code>行数据建立索引的系统开销还是不容忽视的。但是反过来，假如我们将这个表分成4 个<code>table</code>呢，从<code>user_0</code>一直到<code>user_3</code>，<code>4000w</code>行数据平均下来，每个子表里边就只有<code>1000W</code>行数据，这时候我们向一张 只有<code>1000W</code>行数据的<code>table</code>中<code>insert</code>数据后建立索引的时间就会下降，从而提高<code>DB</code>的运行时效率，提高了<code>DB</code>的并发量。当然分表的好处还不知这些，还有诸如写操作的锁操作等，都会带来很多显然的好处。</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分库分表的挑战主要体现在4个方面：基本的数据库增删改功能，分布式id，分布式事务，动态扩容，下面逐一进行讲述。 </p>
<p><strong>挑战1：基本的数据库增删改功能</strong>   </p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于开发人员而言，虽然分库分表的，但是其还是希望能和单库单表那样的去操作数据库。例如我们要批量插入四条用户记录，并且希望根据用户的id字段，确定这条记录插入哪个库的哪张表。例如1号记录插入user_1表，2号记录插入user_2表，3号记录插入user_3表，4号记录插入user_0表，以此类推。<code>sql</code>如下所示：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">user</span>(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">1</span>,”tianshouzhi”),(<span class="number">2</span>,”huhuamin”), (<span class="number">3</span>,”wanghanao”),(<span class="number">4</span>,”luyang”)</span><br></pre></td></tr></table></figure>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这样的<code>sql</code>明显是无法执行的，因为我们已经对库和表进行了拆分,这种<code>sql</code>语法只能操作<code>mysql</code>的单个库和单个表。所以必须将<code>sql</code>改成4条如下所示，然后分别到每个库上去执行。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> user_1(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">1</span>,”tianshouzhi”);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> user_2(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">2</span>,”huhuamin”);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> user_3(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">3</span>,”wanghanao”);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> user_0(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span>  (<span class="number">4</span>,”luyang”);</span><br></pre></td></tr></table></figure>
<p>具体流程可以用下图进行描述：</p>
<p><img src="//blog.com/2019/06/30/数据库拆分过程及挑战/1510498838422075385.png" alt="Image.png"></p>
<p>解释如下：</p>
<p>​    <strong><code>sql</code>解析</strong>：首先对<code>sql</code>进行解析，得到需要插入的四条记录的id字段的值分别为1,2,3,4</p>
<p>​    <strong><code>sql</code>路由</strong>：<code>sql</code>路由包括库路由和表路由。库路由用于确定这条记录应该插入哪个库，表路由用于确定这条记录应该插入哪个表。</p>
<p>​    <strong><code>sql</code>改写</strong>：因为一条记录只能插入到一个库中，而上述批量插入的语法将会在 每个库中都插入四条记录，明显是不合适的，因此需要对<code>sql</code>进行改写，每个库只插入一条记录。</p>
<p>​    <strong><code>sql</code>执行</strong>：一条<code>sql</code>经过改写后变成了多条<code>sql</code>，为了提升效率应该并发的到不同的库上去执行，而不是按照顺序逐一执行</p>
<p>​    <strong>结果集合并</strong>：每个<code>sql</code>执行之后，都会有一个执行结果，我们需要对分库分表的结果集进行合并，从而得到一个完整的结果。</p>
<p><strong>挑战2：分布式id</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>在分库分表后，我们不能再使用<code>mysql</code>的自增主键。因为在插入记录的时候，不同的库生成的记录的自增<code>id</code>可能会出现冲突</strong>。因此需要有一个全局的<code>id</code>生成器。目前分布式<code>id</code>有很多中方案，其中一个比较轻量级的方案是<code>twitter</code>的<code>snowflake</code>算法。</p>
<p><strong>挑战3：分布式事务</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>分布式事务是分库分表绕不过去的一个坎，因此涉及到了同时更新多个数据库</strong>。例如上面的批量插入记录到四个不同的库，如何保证要么同时成功，要么同时失败。</p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关于分布式事务，<code>mysql</code>支持<code>XA</code>事务，但是效率较低。柔性事务是目前比较主流的方案，柔性事务包括：最大努力通知型、可靠消息最终一致性方案以及<code>TCC</code>两阶段提交。但是无论<code>XA</code>事务还是柔性事务，实现起来都是非常复杂的。</p>
<p><strong>挑战4：动态扩容</strong></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;动态扩容指的是增加分库分表的数量。例如原来的user表拆分到2个库的四张表上。现在我们希望将分库的数量变为4个，分表的数量变为8个。这种情况下一般要伴随着数据迁移。例如在4张表的情况下，id为7的记录，<code>7%4=3</code>，因此这条记录位于user_3这张表上。但是现在分表的数量变为了8个，而<code>7%8=7</code>，而user_0这张表上根本就没有id=7的这条记录，因此<strong>如果不进行数据迁移的话，就会出现记录找不到的情况</strong>。</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在上面我们已经看到了，读写分离和分库分表带来的好处，但是也面临了极大的挑战。如果由业务开发人员来完成这些工作，难度比较大。因此就有一些公司专门来做一些数据库中间件，对业务开发人员屏蔽底层的繁琐细节，开发人员使用了这些中间件后，不论是读写分离还是分库分表，都可以像操作单库单表那样去操作。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/06/30/异地多活场景下的数据同步之道/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/30/异地多活场景下的数据同步之道/" itemprop="url">异地多活场景下的数据同步之道</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-06-30T10:12:57+08:00">
                2019-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/" itemprop="url" rel="index">
                    <span itemprop="name">数据库优化</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/" itemprop="url" rel="index">
                    <span itemprop="name">数据库设计</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据库/数据库优化/数据库设计/异地多活/" itemprop="url" rel="index">
                    <span itemprop="name">异地多活</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="异地多活场景下的数据同步之道"><a href="#异地多活场景下的数据同步之道" class="headerlink" title="异地多活场景下的数据同步之道"></a>异地多活场景下的数据同步之道</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="http://www.tianshouzhi.com/api/tutorials/canal/404" target="_blank" rel="noopener">http://www.tianshouzhi.com/api/tutorials/canal/404</a></p>
</blockquote>
<p><br></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在当今互联网行业，大多数人互联网从业者对”单元化”、”异地多活”这些词汇已经耳熟能详。而数据同步是异地多活的基础，所有具备数据存储能力的组件如：数据库、缓存、MQ等，数据都可以进行同步，形成一个庞大而复杂的数据同步拓扑。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 本文将先从概念上介绍单元化、异地多活、就近访问等基本概念。之后，将以数据库为例，讲解在数据同步的情况下，如何解决数据回环、数据冲突、数据重复等典型问题。</p>
<h2 id="1-什么是单元化"><a href="#1-什么是单元化" class="headerlink" title="1 什么是单元化"></a>1 什么是单元化</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果仅仅从”单元化”这个词汇的角度来说，我们可以理解为将数据划分到多个单元进行存储。<strong>“单元”是一个抽象的概念，通常与数据中心<code>(IDC)</code>概念相关，一个单元可以包含多个<code>IDC</code>，也可以只包含一个<code>IDC</code></strong>。本文假设一个单元只对应一个<code>IDC</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;考虑一开始只有一个<code>IDC</code>的情况，所有用户的数据都会写入同一份底层存储中，如下图所示：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553799816852058067.png" alt="A5535FE5-E813-467C-9517-C875CE73AD6E.png"></p>
<p>​      这种架构是大多数据中小型互联网公司采用的方案，存在以下几个问题：</p>
<p>​      <strong>1 不同地区的用户体验不同。</strong>一个<code>IDC</code>必然只能部署在一个地区，例如部署在北京，那么北京的用户访问将会得到快速响应；但是对于上海的用户，访问延迟一般就会大一点，上海到北京的一个<code>RTT</code>可能有<code>20ms</code>左右。</p>
<p>​      <strong>2 容灾问题。</strong>这里容灾不是单台机器故障，而是指机房断电，自然灾害，或者光纤被挖断等重大灾害。一旦出现这种问题，将无法正常为用户提供访问，甚至出现数据丢失的情况。这并不是不可能，例如：2015年，支付宝杭州某数据中心的光缆就被挖断过；2018年9月，云栖大会上，蚂蚁金服当场把杭州两个数据中心的网线剪断。      </p>
<p>​     为了解决这些问题，我们<strong>可以将服务部署到多个不同的<code>IDC</code>中，不同<code>IDC</code>之间的数据互相进行同步</strong>。如下图：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553799856174005134.png" alt="45516634-38BB-4670-846B-EEF228D7C083.png">    </p>
<p>​      通过这种方式，我们可以解决单机房遇到的问题：</p>
<p>​      <strong>1 用户体验。</strong>不同的用户可以选择离自己最近的机房进行访问</p>
<p>​      <strong>2 容灾问题。</strong>当一个机房挂了之后，我们可以将这个机房用户的流量调度到另外一个正常的机房，由于不同机房之间的数据是实时同步的，用户流量调度过去后，也可以正常访问数据 (故障发生那一刻的少部分数据可能会丢失)。</p>
<p>​         需要注意的是，关于容灾，存在一个容灾级别的划分，例如：单机故障，机架(<code>rack</code>)故障，机房故障，城市级故障等。我们这里只讨论机房故障和城市故障。</p>
<ul>
<li><strong>机房容灾 :</strong> 上面的案例中，我们使用了2个<code>IDC</code>，但是2个<code>IDC</code>并不能具备机房容灾能力。至少需要3个<code>IDC</code>，例如，一些基于多数派协议的一致性组件，如<code>zookeeper，redis、etcd、consul</code>等，需要得到大部分节点的同意。例如我们部署了3个节点，在只有2个机房的情况下， 必然是一个机房部署2个节点，一个机房部署一个节点。当部署了2个节点的机房挂了之后，只剩下一个节点，无法形成多数派。<strong>在3机房的情况下，每个机房部署一个节点，任意一个机房挂了，还剩2个节点，还是可以形成多数派</strong>。<strong>这也就是我们常说的”两地三中心”</strong>。</li>
<li><strong>城市级容灾：</strong>在发生重大自然灾害的情况下，可能整个城市的机房都无法访问。一些组件，例如蚂蚁的<code>ocean base</code>，<strong>为了达到城市级容灾的能力，使用的是”三地五中心”的方案</strong>。<strong>这种情况下，3个城市分别拥有2、2、1个机房。当整个城市发生灾难时，其他两个城市依然至少可以保证有3个机房依然是存活的，同样可以形成多数派</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;小结：如果仅仅是考虑不同地区的用户数据就近写入距离最近的<code>IDC</code>，这是纯粹意义上的”单元化”。不同单元的之间数据实时进行同步，相互备份对方的数据，才能做到真正意义上”异地多活”。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实现单元化，技术层面我们要解决的事情很多，例如：流量调度，即如何让用户就近访问附近的<code>IDC</code>；数据互通，如何实现不同机房之间数据的相互同步。流量调度不在本文的讨论范畴内，数据同步是本文讲解的重点。</p>
<h2 id="2-如何进行数据同步"><a href="#2-如何进行数据同步" class="headerlink" title="2 如何进行数据同步"></a>2 如何进行数据同步</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要同步的组件有很多，例如数据库，缓存等，这里以多个<code>Mysql</code>集群之间的数据同步为例进行讲解，实际上缓存的同步思路也是类似。</p>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了了解如何对不同<code>mysql</code>的数据相互进行同步，我们先了解一下<code>mysql</code>主从复制的基本架构，如下图所示：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553799901046013442.png" alt="4D3194AA-AA7F-4039-862C-A36C213682F3.png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常一个<code>mysql</code>集群有一主多从构成。用户的数据都是写入主库<code>Master</code>，<code>Master</code>将数据写入到本地二进制日志<code>binary log</code>中。从库<code>Slave</code>启动一个<code>IO</code>线程(<code>I/O Thread</code>)从主从同步<code>binlog</code>，写入到本地的<code>relay log</code>中，同时<code>slave</code>还会启动一个<code>SQL Thread</code>，读取本地的<code>relay log</code>，写入到本地，从而实现数据同步。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于这个背景知识，我们就可以考虑自己编写一个组件，其作用类似与<code>mysql slave</code>，也是去主库上拉取<code>binlog</code>，只不过<code>binlog</code>不是保存到本地，而是将<code>binlog</code>转换成<code>sql</code>插入到目标<code>mysql</code>集群中，实现数据的同步。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这并非是一件不可能完成的事，<code>MySQL</code>官网上已经提供好所有你自己编写一个<code>mysql slave</code>同步<code>binlog</code>所需的相关背景知识，访问这个链接：<a href="https://dev.mysql.com/doc/internals/en/client-server-protocol.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/internals/en/client-server-protocol.html</a>，你将可以看到<code>mysql</code> 客户端与服务端的通信协议。下图红色框中展示了<code>Mysql</code>主从复制的相关协议：</p>
<p>​        <img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553799959845000213.png" alt="186219A8-AEBD-416D-8922-41BC38E4ADDD.png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，笔者的目的并不是希望读者真正的按照这里的介绍尝试编写一个<code>mysql</code> 的<code>slave</code>，只是想告诉读者，模拟<code>mysql slave</code>拉取<code>binlog</code>并非是一件很神奇的事，只要你的网络基础知识够扎实，完全可以做到。然而，这是一个庞大而复杂的工作。以一人之力，要完成这个工作，需要占用你大量的时间。好在，现在已经有很多开源的组件，已经实现了按照这个协议可以模拟成一个<code>mysql</code>的<code>slave</code>，拉取<code>binlog</code>。例如：</p>
<ul>
<li>阿里巴巴开源的<code>canal</code></li>
<li>美团开源的<code>puma</code></li>
<li><code>linkedin</code>开源的<code>databus</code></li>
</ul>
<p>​       …</p>
<p>​      你可以利用这些组件来完成数据同步，而不必重复造轮子。 假设你采用了上面某个开源组件进行同步，需要明白的是这个组件都要完成最基本的2件事：</p>
<p><strong>1. 从源库拉取binlog并进行解析，我们把这部分功能称之为binlog syncer</strong>；</p>
<p><strong>2. 将获取到的binlog转换成SQL插入目标库，这个功能称之为sql writer</strong>；</p>
<p>​      为什么划分成两块独立的功能？因为<code>binlog</code>订阅解析的实际应用场景并不仅仅是数据同步，如下图：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553799975249069934.png" alt="FF321AD8-D6D8-4F33-A5D6-6C49046F3B1B.png"></p>
<p>​        如图所示，我们可以通过<code>binlog</code>来：</p>
<ul>
<li>实时更新搜索引擎，如<code>es</code>中的索引信息</li>
<li>实时更新<code>redis</code>中的缓存</li>
<li>发送到<code>kafka</code>供下游消费，由业务方自定义业务逻辑处理等</li>
<li>…</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，<strong>通常我们把<code>binlog syncer</code>单独作为一个模块，其只负责解析从数据库中拉取并解析<code>binlog</code>，并在内存中缓存(或持久化存储)</strong>。<strong>另外，<code>binlog syncer</code>另外提一个<code>sdk</code>，业务方通过这个<code>sdk</code>从<code>binlog syncer</code>中获取解析后的<code>binlog</code>信息，然后完成自己的特定业务逻辑处理</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;显然，在数据同步的场景下，我们可以<strong>基于这个<code>sdk</code>，编写一个组件专门用于将<code>binlog</code>转换为<code>sql</code>，插入目标库，实现数据同步</strong>，如下图所示：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553800001980003298.png" alt="DE4517E2-5FB8-419B-9BF7-0982751EC6A1.png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;北京用户的数据不断写入离自己最近的机房的<code>DB</code>，通过<code>binlog syncer</code>订阅这个库<code>binlog</code>，然后下游的<code>binlog writer</code>将<code>binlog</code>转换成<code>SQL</code>，插入到目标库。上海用户类似，只不过方向相反，不再赘述。通过这种方式，我们可以实时的将两个库的数据同步到对端。当然事情并非这么简单，我们有一些重要的事情需要考虑。</p>
<h3 id="2-1-如何获取全量-增量的历史数据？"><a href="#2-1-如何获取全量-增量的历史数据？" class="headerlink" title="2.1 如何获取全量+增量的历史数据？"></a>2.1 如何获取全量+增量的历史数据？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常，<code>mysql</code>不会保存所有的历史<code>binlog</code>。原因在于，对于一条记录，可能我们会更新多次，这依然是一条记录，但是针对每一次更新操作，都会产生一条<code>binlog</code>记录，这样就会存在大量的<code>binlog</code>，很快会将磁盘占满。因此<code>DBA</code>通常会通过一些配置项，来定时清理<code>binlog</code>，只保留最近一段时间内的<code>binlog</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 例如，<strong>官方版的<code>mysql</code>提供了<code>expire_logs_days</code>配置项，可以设置保存<code>binlog</code>的天数，笔者这里设置为0，表示默认不清空，如果将这个值设置大于0，则只会保存指定的天数</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外一些<code>mysql</code>的分支，如<code>percona server</code>，还可以指定保留<code>binlog</code>文件的个数。我们可以<strong>通过<code>show binary logs</code>来查看当前<code>mysql</code>存在多少个<code>binlog</code>文件</strong>，如下图：</p>
<p>​          <img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553800099994043124.png" alt="BCA34A87-ACAA-4182-B8F6-26E46F900B72.png">    </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常，如果<code>binlog</code>如果从来没被清理过，那么<code>binlog</code>文件名字后缀通常是000001，如果不是这个值，则说明可能已经被清理过。当然，这也不是绝对，例如执行<code>&quot;reset master”</code>命令，可以将所有的<code>binlog</code>清空，然后从000001重新开始计数。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Whatever!</code>我们知道了，<code>binlog</code>可能不会一直保留，所以直接同步<code>binlog</code>，可能只能获取到部分数据。因此，<strong>通常的策略是，由DBA先<code>dump</code>一份源库的完整数据快照，增量部分，再通过<code>binlog</code>订阅解析进行同步</strong>。</p>
<h3 id="2-2-如何解决重复插入？"><a href="#2-2-如何解决重复插入？" class="headerlink" title="2.2 如何解决重复插入？"></a>2.2 如何解决重复插入？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;考虑以下情况下，源库中的一条记录没有唯一索引。对于这个记录的<code>binlog</code>，通过<code>sql writer</code>将<code>binlog</code>转换成<code>sql</code>插入目标库时，抛出了异常，此时我们并不知道知道是否插入成功了，则需要进行重试。如果之前已经是插入目标库成功，只是目标库响应时网络超时(<code>socket timeout</code>)了，导致的异常，这个时候重试插入，就会存在多条记录，造成数据不一致。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，<strong>通常，在数据同步时，通常会限制记录必须有要有主键或者唯一索引</strong>。</p>
<h3 id="2-3-如何解决唯一索引冲突？"><a href="#2-3-如何解决唯一索引冲突？" class="headerlink" title="2.3 如何解决唯一索引冲突？"></a>2.3 如何解决唯一索引冲突？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 由于两边的库都存在数据插入，如果都使用了同一个唯一索引，那么在同步到对端时，将会产生唯一索引冲突。对于这种情况，<strong>通常建议是使用一个全局唯一的分布式ID生成器来生成唯一索引，保证不会产生冲突</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外，<strong>如果真的产生冲突了，同步组件应该将冲突的记录保存下来，以便之后的问题排查</strong>。</p>
<h3 id="2-4-对于DDL语句如何处理？"><a href="#2-4-对于DDL语句如何处理？" class="headerlink" title="2.4 对于DDL语句如何处理？"></a>2.4 对于DDL语句如何处理？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果数据库表中已经有大量数据，例如千万级别、或者上亿，这个时候对于这个表的<code>DDL</code>变更，将会变得非常慢，可能会需要几分钟甚至更长时间，而<code>DDL</code>操作是会锁表的，这必然会对业务造成极大的影响。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，<strong>同步组件通常会对DDL语句进行过滤，不进行同步</strong>。<strong>DBA在不同的数据库集群上，通过一些在线DDL工具(如gh-ost)，进行表结构变更</strong>。</p>
<h3 id="2-5-如何解决数据回环问题？"><a href="#2-5-如何解决数据回环问题？" class="headerlink" title="2.5 如何解决数据回环问题？"></a>2.5 如何解决数据回环问题？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据回环问题，是数据同步过程中，最重要的问题。我们针对<code>INSERT、UPDATE、DELETE</code>三个操作来分别进行说明：</p>
<h5 id="INSERT操作"><a href="#INSERT操作" class="headerlink" title="INSERT操作"></a>INSERT操作</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设在A库插入数据，A库产生<code>binlog</code>，之后同步到B库，B库同样也会产生<code>binlog</code>。<strong>由于是双向同步，这条记录，又会被重新同步回A库</strong>。<strong>由于A库应存在这条记录了，产生冲突</strong>。</p>
<h5 id="UPDATE操作"><a href="#UPDATE操作" class="headerlink" title="UPDATE操作"></a>UPDATE操作</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先考虑针对A库某条记录R只有一次更新的情况，将R更新成R1，之后R1这个<code>binlog</code>会被同步到B库，B库又将R1同步会A库。<strong>对于这种情况下，A库将不会产生<code>binlog</code></strong>。<strong>因为A库记录当前是R1，B库同步回来的还是R1，意味着值没有变</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>在一个更新操作并没有改变某条记录值的情况下，<code>mysql</code>是不会产生<code>binlog</code>，相当于同步终止</strong>。下图演示了当更新的值没有变时，<code>mysql</code>实际上不会做任何操作：</p>
<p>​    <img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553800088512023791.png" alt="4CDD3898-382B-464C-9DD9-D26628F22930.png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图演示了，数据中原本有一条记录<code>(1,&quot;tianshouzhi”)</code>，之后执行一个<code>update</code>语句，将<code>id=1</code>的记录的<code>name</code>值再次更新为<code>”tianshouzhi”</code>，意味着值并没有变更。这个时候，我们看到<code>mysql</code> 返回的影响的记录函数为0，也就是说，并不会产生真是的更新操作。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然而，这并不意味<code>UPDATE</code> 操作没有问题，事实上，其比<code>INSERT</code>更加危险。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;考虑A库的记录R被连续更新了2次，第一次更新成R1，第二次被更新成R2；这两条记录变更信息都被同步到B库，B也产生了R1和R2。由于B的数据也在往A同步，B的R1会被先同步到A，而A现在的值是R2，由于值不一样，将会被更新成R1，并产生新的<code>binlog</code>；此时B的R2再同步会A，发现A的值是R1，又更新成R2，也产生<code>binlog</code>。由于B同步回A的操作，让A又产生了新的<code>binlog</code>，A又要同步到B，如此反复，陷入<strong>无限循环</strong>中。</p>
<h5 id="DELETE操作"><a href="#DELETE操作" class="headerlink" title="DELETE操作"></a>DELETE操作</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同样存在先后顺序问题。例如先插入一条记录，再删除。B在A删除后，又将插入的数据同步回A，接着再将A的删除操作也同步回A，每次都会产生<code>binlog</code>，陷入<strong>无限回环</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 关于数据回环问题，笔者有着血的教训，曾经因为笔者的误操作，将一个库的数据同步到了自身，最终也导致无限循环，原因分析与上述提到的<code>UPDATE、DELETE</code>操作类似，读者可自行思考。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;针对上述数据同步到过程中可能会存在的数据回环问题，最终会导致数据无限循环，因此我们必须要解决这个问题。由于存在多种解决方案，我们将在稍后统一进行讲解。</p>
<h3 id="2-6-数据同步架构设计"><a href="#2-6-数据同步架构设计" class="headerlink" title="2.6 数据同步架构设计"></a>2.6 数据同步架构设计</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在，让我们先把思路先从解决数据同步的具体细节问题转回来，从更高的层面讲解数据同步的架构应该如何设计。稍后的内容中，我们将讲解各种避免数据回环的各种解决方案。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面的架构中，只涉及到2个<code>DB</code>的数据同步，如果有多个<code>DB</code>数据需要相互同步的情况下，架构将会变得非常复杂。例如：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553800183434036156.png" alt="25B67740-7B28-473C-B3AB-403784A6F969.png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个图演示的是四个<code>DB</code>之间数据需要相互同步，这种拓扑结构非常复杂。为了解决这种问题，我们可以将数据写入到一个数据中转站，例如<code>MQ</code>中进行保存，如下：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553800198953061866.png" alt="22DB304C-796B-40A1-BDC0-6E9F03B6F235.png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们<strong>在不同的机房各部署一套<code>MQ</code>集群，这个机房的<code>binlog syncer</code>将需要同步的<code>DB binlog</code>数据写入<code>MQ</code>对应的<code>Topic</code>中</strong>。<strong>对端机房如果需要同步这个数据，只需要通过<code>binlog writer</code>订阅这个<code>topic</code>，消<code>topic</code>中的<code>binlog</code>数据，插入到目标库中即可</strong>。一些<code>MQ</code>支持<code>consumer group</code>的概念，不同的<code>consumer group</code>的消费位置<code>offset</code>相互隔离，从而达到一份数据，同时供多个消费者进行订阅的能力。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，一些<code>binlog</code>订阅解析组件，可能实现了类似于<code>MQ</code>的功能，此时，则不需要独立部署<code>MQ</code>。    </p>
<h2 id="3-数据同步回环问题解决方案"><a href="#3-数据同步回环问题解决方案" class="headerlink" title="3 数据同步回环问题解决方案"></a>3 数据同步回环问题解决方案</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据回环问题有多种解决方案，通过排除法，一一进行讲解。</p>
<h4 id="3-1-往目标库插入不生成binlog"><a href="#3-1-往目标库插入不生成binlog" class="headerlink" title="3.1 往目标库插入不生成binlog"></a>3.1 往目标库插入不生成binlog</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在<code>mysql</code>中，我们可以设置<code>session</code>变量，来控制当前会话上的更新操作，不产生<code>binlog</code>。这样当往目标库插入数据时，由于不产生<code>binlog</code>，也就不会被同步会源库了。为了演示这个效果，笔者清空了本机上的所有<code>binlog</code>(执行<code>reset master</code>)，现在如下图所示：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553800266500042268.png" alt="9AA9AEA8-87FE-428A-BCD7-83FCEA67D140.png"></p>
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;忽略这两个<code>binlog event</code>，<code>binlog</code>文件格式最开始就是这两个<code>event</code>。</p>
<p>​        接着，笔者执行<code>set sql_log_bin=0</code>，然后插入一条语句，最后可以看到的确没有产生新的<code>binlog</code>事件：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553800285462027592.png" alt="EBDAD92F-71EC-47C3-953E-F61854D32F88.png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>通过这种方式，貌似可以解决数据回环问题</strong>。<strong>目标库不产生<code>binlog</code>，就不会被同步会源库</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，<strong>答案是否定的</strong>。<strong>我们是往目标库的<code>master</code>插入数据，如果不产生<code>binlog</code>，目标库的<code>slave</code>也无法同步数据，主从数据不一致</strong>。所以，需要排除这种方案。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 提示：如果恢复<code>set sql_log_bin=1</code>，插入语句是会产生<code>binlog</code>，读者可以自行模拟。</p>
<h4 id="3-2-控制binlog同步方向"><a href="#3-2-控制binlog同步方向" class="headerlink" title="3.2 控制binlog同步方向"></a>3.2 控制binlog同步方向</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;既然不产生<code>binlog</code>不能解决问题。那么换一种思路，可以产生<code>binlog</code>。<strong>当把一个<code>binlog</code>转换成<code>sql</code>时，插入某个库之前，我们先判断这条记录是不是原本就是这个库产生的，如果是，那么就抛弃，也可以避免回环问题</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 现在问题就变为，如何给<code>binlog</code>加个标记，表示其实那个<code>mysql</code>集群产生的。这也有几种方案，下面一一讲述。</p>
<h5 id="3-2-1-ROW模式下记录sql"><a href="#3-2-1-ROW模式下记录sql" class="headerlink" title="3.2.1 ROW模式下记录sql"></a>3.2.1 ROW模式下记录sql</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>mysql</code>主从同步，<code>binlog</code>复制一般有3种模式。<code>STATEMENT，ROW，MIXED</code>。默认情况下，<code>STATEMENT</code>模式只记录<code>SQL</code>语句，<code>ROW</code>模式只记录字段变更前后的值，<code>MIXED</code>模式是二者混合。<strong><code>binlog</code>同步一般使用的都是<code>ROW</code>模式，高版本<code>Mysql</code>主从同步默认也是<code>ROW</code>模式</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们想采取的方案是，<strong>在执行的<code>SQL</code>之前加上一段特殊标记，表示这个<code>SQL</code>的来源</strong>。例如</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*IDC1:DB1*/</span><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">users</span>(<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="string">"tianbowen"</span>)</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中<code>/*IDC1:DB1*/</code>是一个注释，表示这个<code>SQL</code>原始在是<code>IDC1</code>的<code>DB1</code>中产生的。之后，在同步的时候，解析出<code>SQL</code>中的<code>IDC</code>信息，就能判断出是不是自己产生的数据。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然而，<code>ROW</code>模式下，默认只记录变更前后的值，不记录<code>SQL</code>。所以，我们要通过一个开关，让<code>Mysql</code>在<code>ROW</code>模式下也记录<code>INSERT、UPDATE、DELETE</code>的<code>SQL</code>语句。具体做法是，在<code>mysql</code>的配置文件中，添加以下配置：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">binlog_rows_query_log_events =1</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个配置可以让<code>mysql</code>在<code>binlog</code>中产生<code>ROWS_QUERY_LOG_EVENT</code>类型的<code>binlog</code>事件，其记录的就是执行的<code>SQL</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>通过这种方式，我们就记录下的一个<code>binlog</code>最初是由哪一个集群产生的，之后在同步的时候，<code>sql writer</code>判断目标机房和当前<code>binlog</code>中包含的机房相同，则抛弃这条数据，从而避免回环</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种思路，功能上没问题，但是在实践中，确非常麻烦。首先，让业务对执行的每条<code>sql</code>都加上一个这样的标识，几乎不可能。另外，如果忘记加了，就不知道数据的来源了。如果采用这种方案，可以考虑在数据库访问层中间件层面添加支持在<code>sql</code>之前增加<code>/*..*/</code>的功能，统一对业务屏蔽。即使这样，也不完美，不能保证所有的<code>sql</code>都通过中间件来来写入，例如<code>DBA</code>的一些日常运维操作，或者手工通过<code>mysql</code>命令行来操作数据库时，肯定会存在没有添加机房信息的情况。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总的来说，这个方案不是那么完美。</p>
<h5 id="3-2-2-通过附加表记录binlog产生源集群信息"><a href="#3-2-2-通过附加表记录binlog产生源集群信息" class="headerlink" title="3.2.2 通过附加表记录binlog产生源集群信息"></a>3.2.2 通过附加表记录binlog产生源集群信息</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种方案目前很多公司使用。大致思路是，在<code>db</code>中都加一张额外的表，例如叫<code>direction</code>，记录一个<code>binlog</code>产生的源集群的信息。例如</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`direction`</span> (  </span><br><span class="line">    <span class="string">`idc`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">not</span> <span class="literal">null</span>, </span><br><span class="line">    <span class="string">`db_cluster`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>idc</code>字段用于记录某条记录原始产生的<code>IDC</code>，<code>db_cluster</code>用于记录原始产生的数据库集群</strong>(注意这里要使用集群的名称，不能是<code>server_id</code>，因为可能会发生主从切换)。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设用户在<code>IDC1</code>的库A插入的一条记录(也可以在事务中插入多条记录，单条记录，即使不开启事务，<code>mysql</code>默认也会开启事务)：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">users</span>(<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="string">"tianshouzhi”);</span></span><br><span class="line"><span class="string">COMMIT;</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么<strong>A库数据<code>binlog</code>通过<code>sql writer</code>同步到目标库B时，<code>sql writer</code>可以提前对事务中的信息可以进行一些修改</strong>，如下所示：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="comment">-- 往目标库同步时，首先额外插入一条记录，表示这个事务中的数据都是A产生的。</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> direction(idc,db_cluster) <span class="keyword">values</span>(<span class="string">"IDC1”,"</span>DB_A”)</span><br><span class="line"><span class="comment">-- 插入原来的记录信息</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">users</span>(<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="string">"tianshouzhi”);</span></span><br><span class="line"><span class="string"> COMMIT;</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>之后B库的数据往A同步时，就可以根据<code>binlog</code>中的第一条记录的信息，判断这个记录原本就是A产生的，进行抛弃，通过这种方式来避免回环</strong>。这种方案已经已经过很多的公司的实际验证。</p>
<h5 id="3-2-3-通过GTID"><a href="#3-2-3-通过GTID" class="headerlink" title="3.2.3 通过GTID"></a>3.2.3 通过GTID</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Mysql 5.6</code>引入了<code>GTID</code>(全局事务id)的概念，极大的简化的<code>DBA</code>的运维。在数据同步的场景下，<code>GTID</code>依然也可以发挥极大的威力。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>GTID</code>由2个部分组成：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server_uuid:transaction_id</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中<code>server_uuid</code>是<code>mysql</code>随机生成的，全局唯一。<code>transaction_id</code>事务id，默认情况下每次插入一个事务，<code>transaction_id</code>自增1。注意，这里并不会对<code>GTID</code>进行全面的介绍，仅说明其在数据同步的场景下，如何避免回环、数据重复插入的问题。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>GTID</code>提供了一个会话级变量<code>gtid_next</code>，指示如何产生下一个<code>GTID</code>。可能的取值如下:</p>
<ul>
<li><code>AUTOMATIC</code>: 自动生成下一个<code>GTID</code>，实现上是分配一个当前实例上尚未执行过的序号最小的<code>GTID</code>。</li>
<li><code>ANONYMOUS</code>: 设置后执行事务不会产生<code>GTID</code>，显式指定的<code>GTID</code>。</li>
</ul>
<p>​    默认情况下，是<code>AUTOMATIC</code>，也就是自动生成的，例如我们执行<code>sql</code>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">users</span>(<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="string">"tianbowen”);</span></span><br></pre></td></tr></table></figure>
<p>​    产生的<code>binlog</code>信息如下：</p>
<p><img src="//blog.com/2019/06/30/异地多活场景下的数据同步之道/1553800512393063442.png" alt="20BBA7C4-FAB0-4C2A-B1BB-D84ABFC5DB39.png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到，<code>GTID</code>会在每个事务(<code>Query-&gt;...-&gt;Xid</code>)之前，设置这个事务下一次要使用到的<code>GTID</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从源库订阅<code>binlog</code>的时候，由于这个<code>GTID</code>也可以被解析到，之后在往目标库同步数据的时候，我们可以显示的的指定这个<code>GTID</code>，不让目标自动生成。也就是说，往目标库，同步数据时，变成了2条<code>SQL</code>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> GTID_NEXT= <span class="string">'09530823-4f7d-11e9-b569-00163e121964:1’</span></span><br><span class="line"><span class="string">insert into users(name) values("tianbowen")</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>由于我们显示指定了<code>GTID</code>，目标库就会使用这个<code>GTID</code>当做当前事务ID，不会自动生成</strong>。同样，这个操作也会在目标库产生<code>binlog</code>信息，需要同步回源库。再往源库同步时，我们按照相同的方式，先设置<code>GTID</code>，在执行解析<code>binlog</code>后得到的<code>SQL</code>，还是上面的内容</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> GTID_NEXT= <span class="string">'09530823-4f7d-11e9-b569-00163e121964:1'</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">users</span>(<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="string">"tianbowen"</span>)</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>由于这个GTID在源库中已经存在了，插入记录将会被忽略，演示如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SET GTID_NEXT= '09530823-4f7d-11e9-b569-00163e121964:1';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">mysql&gt; insert into users(name) values("tianbowen");</span><br><span class="line">Query OK, 0 rows affected (0.01 sec) <span class="comment">#注意这里，影响的记录行数为0</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意这里，对于一条<code>insert</code>语句，其影响的记录函数居然为0，也就会插入并没有产生记录，也就不会产生<code>binlog</code>，避免了循环问题。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如何做到的呢？<strong><code>mysql</code>会记录自己执行过的所有<code>GTID</code>，当判断一个<code>GTID</code>已经执行过，就会忽略</strong>。通过如下<code>sql</code>查看：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global variables like "gtid_executed";</span><br><span class="line">+<span class="comment">---------------+------------------------------------------+</span></span><br><span class="line">| Variable_name | Value                                    |</span><br><span class="line">+<span class="comment">---------------+------------------------------------------+</span></span><br><span class="line">| gtid_executed | 09530823-4f7d-11e9-b569-00163e121964:1-5 |</span><br><span class="line">+<span class="comment">---------------+------------------------------------------+</span></span><br></pre></td></tr></table></figure>
<p>​        上述<code>value</code>部分，冒号”:”前面的是<code>server_uuid</code>，冒号后面的1-5，是一个范围，表示已经执行过1，2，3，4，5这个几个<code>transaction_id</code>。这里就能解释了，在<code>GTID</code>模式的情况下，为什么前面的插入语句影响的记录函数为0了。</p>
<p>​        显然，<code>GTID</code>除了可以帮助我们避免数据回环问题，还可以帮助我们解决数据重复插入的问题，<strong>对于一条没有主键或者唯一索引的记录，即使重复插入也没有，只要<code>GTID</code>已经执行过，之后的重复插入都会忽略</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，我们还可以做得更加细致，不需要每次都往目标库设置<code>GTID_NEXT</code>，这毕竟是一次网络通信。<strong><code>sql writer</code>在往目标库插入数据之前，先判断目标库的<code>server_uuid</code>是不是和当前<code>binlog</code>事务信息携带的<code>server_uuid</code>相同，如果相同，则可以直接丢弃</strong>。</p>
<p>查看目标库的<code>gtid</code>，可以通过以下<code>sql</code>执行：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like "server_uuid";</span><br><span class="line">+<span class="comment">---------------+--------------------------------------+</span></span><br><span class="line">| Variable_name | Value                                |</span><br><span class="line">+<span class="comment">---------------+--------------------------------------+</span></span><br><span class="line">| server_uuid   | 09530823-4f7d-11e9-b569-00163e121964 |</span><br><span class="line">+<span class="comment">---------------+--------------------------------------+</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>GTID</code>应该算是一个终极的数据回环解决方案，<code>mysql</code>原生自带，比添加一个辅助表的方式更轻量，开销也更低</strong>。需要注意的是，这倒并不是一定说<code>GTID</code>的方案就比辅助表好，因为辅助表可以添加机房等额外信息。在一些场景下，如果下游需要知道这条记录原始产生的机房，还是需要使用辅助表。</p>
<h2 id="4-开源组件介绍canal-otter"><a href="#4-开源组件介绍canal-otter" class="headerlink" title="4 开源组件介绍canal/otter"></a>4 开源组件介绍canal/otter</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面深入讲解了单元化场景下数据同步的基础知识。读者可能比较感兴趣的是，哪些开源组件在这些方面做的比较好。笔者建议的首选，是<code>canal/otter</code>组合。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>canal</code>的作用就是类似于前面所述的<code>binlog syncer</code>，拉取解析<code>binlog</code>。<code>otter</code>是<code>canal</code>的客户端，专门用于进行数据同步，类似于前文所讲解的<code>sql writer</code></strong>。并且，<code>canal</code>的最新版本已经实现了<code>GTID</code>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/30/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/30/">30</a><span class="page-number current">31</span><a class="page-number" href="/page/32/">32</a><span class="space">&hellip;</span><a class="page-number" href="/page/147/">147</a><a class="extend next" rel="next" href="/page/32/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">刘泽明</p>
              <p class="site-description motion-element" itemprop="description">做一个懂业务的程序员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">731</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">394</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">237</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘泽明</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
