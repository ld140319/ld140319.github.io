<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="搬运工 + 践行者" type="application/atom+xml">






<meta name="description" content="做一个懂业务的程序员">
<meta property="og:type" content="website">
<meta property="og:title" content="搬运工 + 践行者">
<meta property="og:url" content="http://blog.com/page/20/index.html">
<meta property="og:site_name" content="搬运工 + 践行者">
<meta property="og:description" content="做一个懂业务的程序员">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="搬运工 + 践行者">
<meta name="twitter:description" content="做一个懂业务的程序员">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.com/page/20/">





  <title>搬运工 + 践行者</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">搬运工 + 践行者</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">记录学习的技能和遇到的问题</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/08/21/写缓冲change buffer/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/21/写缓冲change buffer/" itemprop="url">写缓冲change buffer</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-21T12:12:57+08:00">
                2019-08-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/MySql/" itemprop="url" rel="index">
                    <span itemprop="name">MySql</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/MySql/Innodb/" itemprop="url" rel="index">
                    <span itemprop="name">Innodb</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/MySql/Innodb/buffer/" itemprop="url" rel="index">
                    <span itemprop="name">buffer</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="写缓冲change-buffer"><a href="#写缓冲change-buffer" class="headerlink" title="写缓冲change buffer"></a>写缓冲change buffer</h1><blockquote>
<p>原文地址：<a href="https://mp.weixin.qq.com/s/PF21mUtpM8-pcEhDN4dOIw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/PF21mUtpM8-pcEhDN4dOIw</a></p>
</blockquote>
<h2 id="为什么需要写缓冲change-buffer"><a href="#为什么需要写缓冲change-buffer" class="headerlink" title="为什么需要写缓冲change buffer"></a>为什么需要写缓冲change buffer</h2><p>简单回顾一下：</p>
<p><img src="//blog.com/2019/08/21/写缓冲change buffer/1.jpg" alt="img"></p>
<p>（1）<code>MySQL</code>数据存储包含内存与磁盘<strong>两个部分</strong>；</p>
<p>（2）内存缓冲池(<code>buffer pool</code>)以页为单位，缓存最热的数据页(<code>data page</code>)与索引页(<code>index page</code>)；</p>
<p>（3）<code>InnoDB</code>以变种<code>LRU</code>算法管理缓冲池，并能够解决“<strong>预读失效</strong>”与“<strong>缓冲池污染</strong>”的问题；</p>
<p>毫无疑问，对于读请求，缓冲池能够减少磁盘<code>IO</code>，提升性能。问题来了，<strong>那写请求呢？</strong></p>
<p><strong>情况一</strong></p>
<p>假如要修改页号为4的索引页，而这个页正好在缓冲池内。</p>
<p><img src="//blog.com/2019/08/21/写缓冲change buffer/2.jpg" alt="img"></p>
<p>如上图序号1-2：</p>
<p>（1）直接修改缓冲池中的页，一次内存操作；</p>
<p>（2）写入<code>redo log</code>，一次磁盘顺序写操作；</p>
<p>这样的效率是最高的。</p>
<p><em>画外音：像写日志这种<strong>顺序写</strong>，每秒几万次没问题。</em></p>
<p><strong>是否会出现一致性问题呢？</strong></p>
<p>并不会。</p>
<p>（1）读取，会命中缓冲池的页；</p>
<p>（2）缓冲池<code>LRU</code>数据淘汰，会将“脏页”刷回磁盘；</p>
<p>（3）数据库异常奔溃，能够从<code>redo log</code>中恢复数据；</p>
<p><strong>什么时候缓冲池中的页，会刷到磁盘上呢？</strong></p>
<p>定期刷磁盘，而不是每次刷磁盘，能够降低磁盘<code>IO</code>，提升<code>MySQL</code>的性能。</p>
<p><em>画外音：<strong>批量写</strong>，是常见的优化手段。</em></p>
<p><strong>情况二</strong></p>
<p>假如要修改页号为40的索引页，而这个页正好<strong>不</strong>在缓冲池内。</p>
<p><img src="//blog.com/2019/08/21/写缓冲change buffer/3.jpg" alt="img"></p>
<p>此时麻烦一点，如上图需要1-3：</p>
<p>（1）先把需要为40的索引页，从磁盘加载到缓冲池，一次磁盘随机读操作；</p>
<p>（2）修改缓冲池中的页，一次内存操作；</p>
<p>（3）写入<code>redo log</code>，一次磁盘顺序写操作；</p>
<p>没有命中缓冲池的时候，<strong>至少产生一次磁盘IO</strong>，对于写多读少的业务场景，<strong>是否还有优化的空间呢？</strong></p>
<p>这即是InnoDB考虑的问题，又是本文将要讨论的写缓冲(<code>change buffer</code>)。</p>
<p><em>画外音：从名字容易看出，<strong>写缓冲是降低磁盘<code>IO</code>，提升数据库写性能的一种机制</strong>。</em></p>
<h2 id="什么是InnoDB的写缓冲？"><a href="#什么是InnoDB的写缓冲？" class="headerlink" title="什么是InnoDB的写缓冲？"></a>什么是InnoDB的写缓冲？</h2><p>在MySQL 5.5之前，叫插入缓冲(<code>insert buffer</code>)，只针对<code>insert</code>做了优化；现在对<code>delete</code>和<code>update</code>也有效，叫做写缓冲(<code>change buffer</code>)。</p>
<p>它是一种应用在<strong>非唯一普通索引页</strong>(<code>non-unique secondary index page</code>)不在缓冲池中，对页进行了写操作，并不会立刻将磁盘页加载到缓冲池，而<strong>仅仅记录缓冲变更(<code>buffer changes</code>)，等未来数据被读取时，再将数据合并<code>(merge</code>)恢复到缓冲池中</strong>的技术。写缓冲的目的是降低写操作的磁盘IO，提升数据库性能。</p>
<p><em>画外音：R了狗了，这个句子，好长。</em></p>
<p><strong>InnoDB加入写缓冲优化，上文“情况二”流程会有什么变化？</strong></p>
<p>假如要修改页号为40的索引页，而这个页正好<strong>不</strong>在缓冲池内。</p>
<p><img src="//blog.com/2019/08/21/写缓冲change buffer/4.jpg" alt="img"></p>
<p>加入写缓冲优化后，流程优化为：</p>
<p>（1）在写缓冲中记录这个操作，一次内存操作；</p>
<p>（2）写入<code>redo log</code>，一次磁盘顺序写操作；</p>
<p>其性能与，这个索引页在缓冲池中，相近。</p>
<p><em>画外音：可以看到，40这一页，并没有加载到缓冲池中。</em></p>
<p><strong>是否会出现一致性问题呢？</strong></p>
<p>也不会。</p>
<p>（1）数据库异常奔溃，能够从<code>redo log</code>中恢复数据；</p>
<p>（2）写缓冲不只是一个内存结构，它也会被<strong>定期刷盘</strong>到写缓冲系统表空间；</p>
<p>（3）<strong>数据读取时，有另外的流程，将数据合并到缓冲池</strong>；</p>
<p>不妨设，稍后的一个时间，有请求查询索引页40的数据。</p>
<p><img src="//blog.com/2019/08/21/写缓冲change buffer/5.jpg" alt="img"></p>
<p>此时的流程如序号1-3：</p>
<p>（1）载入索引页，缓冲池未命中，这次磁盘<code>IO</code>不可避免；</p>
<p>（2）从写缓冲读取相关信息；</p>
<p>（3）恢复索引页，放到缓冲池<code>LRU</code>里；</p>
<p><em>画外音：可以看到，40这一页，在真正被读取时，才会被加载到缓冲池中。</em></p>
<p>还有一个遗漏问题，<strong>为什么写缓冲优化，仅适用于非唯一普通索引页呢？</strong></p>
<p>如果索引设置了唯一(<code>unique</code>)属性，在进行修改操作时，<code>InnoDB</code>必须进行唯一性检查。也就是说，<strong>索引页即使不在缓冲池，磁盘上的页读取无法避免(否则怎么校验是否唯一？)，此时就应该直接把相应的页放入缓冲池再进行修改，而不应该再整写缓冲这个幺蛾子</strong>。</p>
<p>除了数据页被访问，<strong>还有哪些场景会触发刷写缓冲中的数据呢？</strong></p>
<p>还有这么几种情况，会刷写缓冲中的数据：</p>
<p>（1）有一个后台线程，会认为数据库空闲时；</p>
<p>（2）数据库缓冲池不够用时；</p>
<p>（3）数据库正常关闭时；</p>
<p>（4）<code>redo log</code>写满时；</p>
<p><em>画外音：几乎不会出现redo log写满，此时整个数据库处于无法写入的不可用状态。</em></p>
<h2 id="什么业务场景，适合开启InnoDB的写缓冲机制？"><a href="#什么业务场景，适合开启InnoDB的写缓冲机制？" class="headerlink" title="什么业务场景，适合开启InnoDB的写缓冲机制？"></a>什么业务场景，适合开启InnoDB的写缓冲机制？</h2><p>先说什么时候不适合，如上文分析，当：</p>
<p>（1）<strong>数据库都是唯一索引</strong>；</p>
<p>（2）或者，<strong>写入一个数据后，会立刻读取它</strong>；</p>
<p>这两类场景，在写操作进行时（进行后），本来就要进行进行页读取，本来相应页面就要入缓冲池，此时写缓存反倒成了负担，增加了复杂度。</p>
<p>什么时候适合使用写缓冲，如果：</p>
<p>（1）<strong>数据库大部分是非唯一索引</strong>；</p>
<p>（2）<strong>业务是写多读少，或者不是写后立刻读取</strong>；</p>
<p>可以使用写缓冲，将原本每次写入都需要进行磁盘IO的SQL，优化定期批量写磁盘。</p>
<p><em>画外音：例如，账单流水业务。</em></p>
<h2 id="对应InnoDB里哪些参数？"><a href="#对应InnoDB里哪些参数？" class="headerlink" title="对应InnoDB里哪些参数？"></a>对应InnoDB里哪些参数？</h2><p>有两个比较重要的参数。</p>
<p><img src="//blog.com/2019/08/21/写缓冲change buffer/6.jpg" alt="img"></p>
<p><strong>参数</strong>：<code>innodb_change_buffer_max_size</code></p>
<p><strong>介绍</strong>：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。</p>
<p><em>画外音：写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了。</em></p>
<p><strong>参数</strong>：<code>innodb_change_buffering</code></p>
<p><strong>介绍</strong>：配置哪些写操作启用写缓冲，可以设置成<code>all/none/inserts/deletes</code>等。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li><strong>写时，写内存页，write ahead log，保证不丢</strong>。</li>
<li><strong>多个写内存页以后，批量刷磁盘</strong>。</li>
<li><strong>用缓冲区避免每次都写磁盘</strong>。</li>
<li><strong>用顺序写代替随机写，提高写性能</strong>。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/08/18/数据库与缓存一致性/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/18/数据库与缓存一致性/" itemprop="url">数据库与缓存一致性</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-18T12:12:57+08:00">
                2019-08-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据一致性问题/" itemprop="url" rel="index">
                    <span itemprop="name">数据一致性问题</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据一致性问题/数据库与缓存/" itemprop="url" rel="index">
                    <span itemprop="name">数据库与缓存</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据一致性问题/数据库与缓存/缓存/" itemprop="url" rel="index">
                    <span itemprop="name">缓存</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据一致性问题/数据库与缓存/缓存/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据库与缓存一致性"><a href="#数据库与缓存一致性" class="headerlink" title="数据库与缓存一致性"></a>数据库与缓存一致性</h1><p><img src="//blog.com/2019/08/18/数据库与缓存一致性/640.webp" alt="img"></p>
<h2 id="文章结构"><a href="#文章结构" class="headerlink" title="文章结构"></a>文章结构</h2><p>本文由以下三个部分组成：</p>
<p>1、讲解缓存更新策略<br>2、对每种策略进行缺点分析<br>3、针对缺点给出改进方案</p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>​    先做一个说明，<strong>从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案</strong>。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案。</p>
<p>在这里，我们讨论<strong>三种</strong>更新策略：</p>
<ol>
<li>先更新数据库，再更新缓存</li>
<li>先删除缓存，再更新数据库</li>
<li>先更新数据库，再删除缓存</li>
</ol>
<p>应该没人问我，为什么没有先更新缓存，再更新数据库这种策略。</p>
<h3 id="1-先更新数据库，再更新缓存"><a href="#1-先更新数据库，再更新缓存" class="headerlink" title="1. 先更新数据库，再更新缓存"></a><strong>1. 先更新数据库，再更新缓存</strong></h3><p>这套方案，大家是普遍反对的。为什么呢？有如下两点原因。</p>
<p><strong>原因一（线程安全角度）</strong></p>
<p>同时有请求A和请求B进行更新操作，那么会出现</p>
<p>（1）线程A更新了数据库<br>（2）线程B更新了数据库<br>（3）线程B更新了缓存<br>（4）线程A更新了缓存</p>
<p>这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。</p>
<p><strong>网络延迟 =》脏数据</strong></p>
<p><strong>原因二（业务场景角度）</strong></p>
<p>有如下两点：</p>
<p>（1）如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，<strong>缓存就被频繁的更新，浪费性能</strong>。</p>
<p>（2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过<strong>一系列复杂的计算</strong>再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是<strong>浪费性能</strong>的。显然，删除缓存更为适合。</p>
<p>接下来讨论的就是争议最大的，先删缓存，再更新数据库。还是先更新数据库，再删缓存的问题。</p>
<h3 id="2-先删缓存，再更新数据库"><a href="#2-先删缓存，再更新数据库" class="headerlink" title="2. 先删缓存，再更新数据库"></a><strong>2. 先删缓存，再更新数据库</strong></h3><p>该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形：</p>
<p>（1）请求A进行写操作，删除缓存<br>（2）请求B查询发现缓存不存在<br>（3）请求B去数据库查询得到旧值<br>（4）请求B将旧值写入缓存<br>（5）请求A将新值写入数据库</p>
<p>上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</p>
<p>那么，<strong>如何解决呢？采用延时双删策略</strong>。</p>
<p>伪代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String key,Object data)</span></span>&#123;</span><br><span class="line">        redis.delKey(key);</span><br><span class="line">        db.updateData(data);</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        redis.delKey(key);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>转化为中文描述就是：</p>
<p>（1）先淘汰缓存<br>（2）再写数据库（这两步和原来一样）<br>（3）休眠1秒，再次淘汰缓存</p>
<p>这么做，可以将1秒内所造成的缓存脏数据，再次删除。</p>
<p><strong>那么，这个1秒怎么确定的，具体该休眠多久呢？</strong></p>
<p>针对上面的情形，读者应该<strong>自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据</strong>。</p>
<p><strong>如果你用了mysql的读写分离架构怎么办？</strong></p>
<p>ok，在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。</p>
<p>（1）请求A进行写操作，删除缓存<br>（2）请求A将数据写入数据库了，<br>（3）请求B查询缓存发现，缓存没有值<br>（4）请求B去从库查询，这时，还<strong>没有完成主从同步，因此查询到的是旧值</strong><br>（5）请求B将旧值写入缓存<br>（6）数据库完成主从同步，从库变为新值</p>
<p>上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，<strong>睡眠时间修改为在主从同步的延时时间基础上，加几百ms</strong>。</p>
<p><strong>采用这种同步淘汰策略，吞吐量降低怎么办？</strong></p>
<p>ok，那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。</p>
<p><strong>第二次删除,如果删除失败怎么办？</strong></p>
<p>这是个非常好的问题，因为第二次删除失败，就会出现如下情形。还是有两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库：</p>
<p>（1）请求A进行写操作，删除缓存<br>（2）请求B查询发现缓存不存在<br>（3）请求B去数据库查询得到旧值<br>（4）请求B将旧值写入缓存<br>（5）请求A将新值写入数据库<br>（6）请求A试图去删除请求B写入对缓存值，结果失败了。</p>
<p>ok，这也就是说。如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。</p>
<p><strong>如何解决呢？</strong></p>
<p>具体解决方案，且看博主对第(3)种更新策略的解析。</p>
<h3 id="3-先更新数据库，再删缓存"><a href="#3-先更新数据库，再删缓存" class="headerlink" title="3. 先更新数据库，再删缓存"></a><strong>3. 先更新数据库，再删缓存</strong></h3><p>首先，先说一下。老外提出了一个缓存更新套路，名为《Cache-Aside pattern》（<a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside）。其中就指出：" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside）。其中就指出：</a></p>
<ul>
<li><strong>失效：</strong>应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。</li>
<li><strong>命中：</strong>应用程序从cache中取数据，取到后返回。</li>
<li><strong>更新：</strong>先把数据存到数据库中，成功后，再让缓存失效。</li>
</ul>
<p>另外，知名社交网站facebook也在论文《Scaling Memcache at Facebook》（<a href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf）中提出，他们用的也是先更新数据库，再删缓存的策略。" target="_blank" rel="noopener">https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf）中提出，他们用的也是先更新数据库，再删缓存的策略。</a></p>
<p><strong>这种情况不存在并发问题么？</strong></p>
<p>不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生：</p>
<p>（1）缓存刚好失效<br>（2）请求A查询数据库，得一个旧值<br>（3）请求B将新值写入数据库<br>（4）请求B删除缓存<br>（5）请求A将查到的旧值写入缓存</p>
<p>ok，如果发生上述情况，确实是会发生脏数据。</p>
<p><strong>然而，发生这种情况的概率又有多少呢？</strong></p>
<p>发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。</p>
<p>假设，有人非要抬杠，有强迫症，一定要解决怎么办？</p>
<p><strong>如何解决上述并发问题？</strong></p>
<p>首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。</p>
<p><strong>还有其他造成不一致的原因么？</strong></p>
<p>有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。</p>
<h3 id="4-重试机制"><a href="#4-重试机制" class="headerlink" title="4. 重试机制"></a>4. 重试机制</h3><h5 id="消息队列（异步检查）"><a href="#消息队列（异步检查）" class="headerlink" title="消息队列（异步检查）"></a>消息队列（异步检查）</h5><p><img src="//blog.com/2019/08/18/数据库与缓存一致性/641.webp" alt="img"><br>流程如下所示：</p>
<p>（1）更新数据库数据；<br>（2）缓存因为种种问题删除失败<br>（3）将需要删除的key发送至消息队列<br>（4）自己消费消息，获得需要删除的key<br>（5）继续重试删除操作，直到成功</p>
<p>然而，该方案有一个缺点，<strong>对业务线代码造成大量的侵入</strong>。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。</p>
<h5 id="订阅binlog"><a href="#订阅binlog" class="headerlink" title="订阅binlog"></a>订阅binlog</h5><h6 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h6><p><img src="//blog.com/2019/08/18/数据库与缓存一致性/643.webp" alt="img"></p>
<p>流程如下：</p>
<ul>
<li>1、更新数据库数据；</li>
<li>2、MySQL 将数据更新日志写入 binlog 中；</li>
<li>3、Canal 订阅 &amp; 消费 MySQL binlog，并提取出被更新数据的表名及 ID；</li>
<li>4、调用应用删除缓存接口；</li>
<li>5、删除缓存数据；</li>
<li>6、Redis 不可用时，将更新数据的表名及 ID 发送到 MQ 中；</li>
<li>7、应用接收到消息后，删除缓存，如果删除缓存确认 MQ 消息被消费，如果删除缓存失败，则让消息重新入队列，进行多次尝试删除缓存操作，直到缓存删除成功为止。</li>
</ul>
<p>像电商详情页这种高并发的场景，要尽量避免用户请求回源到数据库，所以会把数据都持久化到 Redis 中，那么相应的缓存架构也要做些调整。</p>
<h6 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h6><p><img src="//blog.com/2019/08/18/数据库与缓存一致性/644.webp" alt="img"></p>
<p>流程如下：</p>
<ul>
<li>1、更新数据库数据；</li>
<li>2、MySQL 将数据更新日志写入 binlog 中；</li>
<li>3、Canal 订阅 &amp; 消费 MySQL binlog，并提取出被更新数据的表名及 ID；</li>
<li>4、将更新数据的表名及 ID 发送到 MQ 中；</li>
<li>5、应用订阅 &amp; 消费数据更新消息；</li>
<li>6、从数据库中拉取最新的数据；</li>
<li>7、更新缓存数据，如果更新缓存失败，则让消息重新入队列，进行多次尝试更新缓存操作，直到缓存更新成功为止。</li>
</ul>
<p>此方案中，把数据更新的消息发送到 MQ 中，主要避免数据更新洪峰时，造成从数据库获取数据压力过大，起到削峰的作用。通过 Canal 就可以把最新数据发到 MQ 以及应用，为什么还要从数据库中获取最新数据？因为当消息过多时，MQ 消息可能出现积压，应用收到时可能已经是“旧”消息，通过去数据库取一次，以保证缓存数据是最新的。</p>
<p><strong>备注说明：</strong>上述的订阅binlog程序在mysql中有现成的中间件叫<strong>canal</strong>，可以完成订阅binlog日志的功能</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/08/18/缓存技术使用的实践与思考/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/18/缓存技术使用的实践与思考/" itemprop="url">缓存技术使用的实践与思考</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-18T12:12:57+08:00">
                2019-08-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据一致性问题/" itemprop="url" rel="index">
                    <span itemprop="name">数据一致性问题</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据一致性问题/数据库与缓存/" itemprop="url" rel="index">
                    <span itemprop="name">数据库与缓存</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据一致性问题/数据库与缓存/缓存/" itemprop="url" rel="index">
                    <span itemprop="name">缓存</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/数据一致性问题/数据库与缓存/缓存/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="缓存技术使用的实践与思考"><a href="#缓存技术使用的实践与思考" class="headerlink" title="缓存技术使用的实践与思考"></a>缓存技术使用的实践与思考</h1><blockquote>
<p>原文地址：<a href="https://yq.aliyun.com/articles/714402" target="_blank" rel="noopener">https://yq.aliyun.com/articles/714402</a></p>
</blockquote>
<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;按照现在流行的互联网分层架构模型，最简单的架构当属Web响应层+DB存储层的架构。从最开始的单机混合部署Web和DB，到后来将二者拆分到不同物理机以避免共享机器硬件带来的性能瓶颈，再随着流量的增长，Web应用变为集群部署模式，而DB则衍生出主从机来保证高可用，同时便于实现读写分离。这一连串系统架构的升级，本质上是为了追求更高的性能，达到更低的延时。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;高德作为一款国民级别的导航软件，导航路线的数据质量是由数据中心统一管理的。为了保证数据的鲜度，数据中心需要对不断变化的现实道路数据进行收集，将这些变化的信息保存到数据库中，从而保证导航数据的鲜度；另一方面数据中心内部多部门协调生产数据的时候，会产生海量请求查询最新生产的数据，这就要求数据的管理者要控制数据库连接数，降低请求的响应耗时，同时也需要保证返回数据的实时性。在平衡数据鲜度和性能之间，高德数据中心针对不同的业务场景使用了不同的策略，达到了数据变更和缓存同步低延迟的目标，同时保障了系统的稳定性。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文将提及的缓存技术则是提升性能的另一把利刃。然而任何技术都是有可为有可不为，没有最好的技术只有最适合的技术，因此在使用缓存之前，我们也需要了解下引入缓存模块所带来的好处和坏处。</p>
<h2 id="缘起：为何使用缓存"><a href="#缘起：为何使用缓存" class="headerlink" title="缘起：为何使用缓存"></a>缘起：为何使用缓存</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在应用对外提供服务时，其稳定性受到诸多因素影响，其中比较重要的有CPU、内存、IO(磁盘IO、网络IO)等，这些硬件资源十分宝贵，因此对于那些<strong>需要经过复杂计算才能得到结果的</strong>，或者<strong>需要频繁读取磁盘数据</strong>的，最好将结果缓存起来，避免资源的重复消耗。</p>
<h3 id="CPU瓶颈"><a href="#CPU瓶颈" class="headerlink" title="CPU瓶颈"></a>CPU瓶颈</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果项目中有很多正则表达式计算，或者某个计算结果是多次中间结果合并后才得出的，且CPU的使用率一直居高不下，那么就可以考虑是否应该将这些结果缓存起来，<strong>根据特定Key直接获取Value结果，减少中间链路的传递过程，减少CPU的使用率</strong>。</p>
<h3 id="IO瓶颈"><a href="#IO瓶颈" class="headerlink" title="IO瓶颈"></a>IO瓶颈</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;众所周知，从磁盘获取数据受到磁盘转速、寻道速度、磁盘缓冲区大小等诸多因素影响，这些因素决定了磁盘的<code>IOPS</code>，同时我们也知道对于数据的读写来说，<strong>CPU的缓存读写速度&gt; 内存的读写速度 &gt;磁盘的读写速度</strong>。虽然磁盘内部也配备了缓存以匹配内存的读写速度，但其容量毕竟是有限的，那么当磁盘的<code>IOPS</code>无法进一步提升的时候，便会想到将数据缓存到内存中，从而降低磁盘的访问压力。<strong>这一策略常被应用于缓解DB数据库的数据访问压力</strong>。</p>
<h2 id="选择本地缓存和分布式缓存的考量点"><a href="#选择本地缓存和分布式缓存的考量点" class="headerlink" title="选择本地缓存和分布式缓存的考量点"></a>选择本地缓存和分布式缓存的考量点</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;既然可以使用缓存来提升系统吞吐能力，那么紧接着遇到的问题就是选择本地缓存，还是分布式缓存？什么时候需要使用多级缓存呢？接下来，让我们聊一聊在使用缓存优化项目的过程中，本地缓存和分布式缓存的应用场景和优缺点。</p>
<h3 id="本地缓存的优缺点和应用场景"><a href="#本地缓存的优缺点和应用场景" class="headerlink" title="本地缓存的优缺点和应用场景"></a>本地缓存的优缺点和应用场景</h3><h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><p>统一进程带来了以下优势：</p>
<ul>
<li>由于本地缓存和应用在同一个进程中，因而其<strong>稳定性很高，达到了和应用同生共死的境界</strong>；</li>
<li>由于在同一进程中，<strong>避免了网络数据传输带来的消耗</strong>，所有缓存数据直接从进程所在的内存区域获取即可。</li>
</ul>
<h4 id="劣势"><a href="#劣势" class="headerlink" title="劣势"></a>劣势</h4><p>强耦合性也会导致以下这些劣势：</p>
<ul>
<li>本地缓存和应用共享一片JVM内存，<strong>争抢内存资源，无法水平扩展，且可能造成频繁的GC，影响线上应用的稳定性</strong>。</li>
<li>由于<strong>没有持久化机制，在项目重启后缓存内数据就会丢失，对于高频访问数据，需要对数据进行预热操作</strong>。</li>
<li><strong>多份进程内缓存存储着同样的数据内容，造成内存使用浪费</strong>。</li>
<li><strong>同样的数据存储在不同的本地机器，数据变化后，很难保证数据的一致性</strong>。</li>
</ul>
<h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结合以上优缺点，我们就会想到，如果有一种<strong>数据需要频繁访问，但一旦创建后就轻易不会改变，而且初始创建时就能预估占用的内存空间</strong>，那么这种类型的数据无疑是最适合用本地缓存存储了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;既然有了上述的应用场景，我们反观技术开发中的诉求，发现其实很多优秀的框架已经在这样使用了，比如缓存类<code>class</code>的反射信息，包括<code>field</code>、<code>method</code>等。因为<code>class</code>的数量是有限的，且内容不会轻易改变，在使用时无需再使用反射机制，而只需要从本地缓存读取数据即可。</p>
<h3 id="分布式缓存的优缺点和应用场景"><a href="#分布式缓存的优缺点和应用场景" class="headerlink" title="分布式缓存的优缺点和应用场景"></a>分布式缓存的优缺点和应用场景</h3><h4 id="优势-1"><a href="#优势-1" class="headerlink" title="优势"></a>优势</h4><ul>
<li>数据集中存储，<strong>消除冗余数据，解决整体内存的占用率，易于维护集群建缓存数据的一致性</strong>。</li>
<li><strong>缓存中间件可以对缓存进行统一管理，便于水平扩容</strong>。</li>
</ul>
<h4 id="劣势-1"><a href="#劣势-1" class="headerlink" title="劣势"></a>劣势</h4><ul>
<li><strong>依赖分布式缓存中间件稳定性，一旦挂了，容易造成缓存雪崩</strong>；</li>
<li>由于是跨机器获取缓存数据，因此会造成<strong>数据传输的网络消耗，以及一些序列化/反序列化的时间开销</strong>。</li>
</ul>
<h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于上述缺点中，网络耗时等开销是难免的，而且这些操作耗费的时间在可接受范围内，而对于中间件的稳定性则可以通过<strong>服务降级、限流或者多级缓存</strong>思路来保证。我们主要看中的是它的优点，既然分布式缓存天然能保证缓存一致性，那么我们倾向于将<strong>需要频繁访问却又经常变化的数据</strong>存放于此。</p>
<h3 id="选择缓存框架的衡量标准"><a href="#选择缓存框架的衡量标准" class="headerlink" title="选择缓存框架的衡量标准"></a>选择缓存框架的衡量标准</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在了解了何时使用缓存以及缓存的优缺点后，我们就准备大刀阔斧开始升级系统了，可紧接着的问题也随之出现，对于本地缓存和分布式缓存，到底应该使用什么框架才是最适用的呢？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在的技术百花齐放，不同的技术解决的问题侧重点也不同，对于本地缓存来说，如果无资源竞争的代码逻辑，可以使用<code>HashMap</code>，而对于有资源竞争的多线程程序来说，则可以使用<code>ConcurrentHashMap</code>。但以上二者有个通病就是缓存占用只增不减，没有缓存过期机制、也没有缓存淘汰机制。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么本地缓存是否有更高性能的框架呢？而对于分布式缓存，领域内常用的<code>Redis</code>和<code>Memcache</code>又应该怎样取舍呢？本小节期望通过横向对比的方式，分别给出一个比较通用的缓存框架方案，当然如果有个性化需求的，也可以根据不同缓存框架的特性来取舍。</p>
<p>不同本地缓存框架的横向对比，如下表所示：</p>
<p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/7ff18bb329a8638d5720b2a2f021c934e04717d7.png" alt="1"></p>
<p>总结：如果不需要淘汰算法则选择<code>ConcurrentHashMap</code>，如果需要淘汰算法和一些丰富的<code>API</code>，推荐选择<code>Caffeine</code>。</p>
<p>不同分布式缓存框架的横向对比，如下表所示：</p>
<p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/0e55fd94108118cac6cd69f046ae1d42a2ae9206.png" alt="2"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于存储容量而言，<strong><code>Memcache</code>采用预先分配不同固定大小存储单元的方式，内存空间使用并不紧凑</strong>。如果存储<code>Value</code>对象大小最大为<code>1MB</code>，那么当一个对象有<code>1000KB</code>，那么会存储到大小最匹配<code>1MB</code>的单元中，因此会浪费<code>24KB</code>的内存；而<strong><code>Redis</code>是使用之前才去申请空间，内存使用紧凑，但频繁对内存的扩容和收缩，可能造成内存碎片</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总结：由于<code>Redis</code>具有丰富的数据结构能满足不同的业务场景需求，同时<code>Redis</code>支持持久化，能有效地解决缓存中间件重启后的数据预加载问题，因此<strong>大多数应用场景中还是推荐使用<code>Redis</code></strong>。</p>
<h2 id="缓存框架使用过程的知识点"><a href="#缓存框架使用过程的知识点" class="headerlink" title="缓存框架使用过程的知识点"></a>缓存框架使用过程的知识点</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不论是本地缓存还是分布式缓存，在使用缓存提升性能的时候，必然会考虑缓存命中率的高低，考虑缓存数据的更新和删除策略，考虑数据一致性如何维护，本小节主要针对以上的问题来分析不同实现方案的优缺点。</p>
<h3 id="缓存命中率"><a href="#缓存命中率" class="headerlink" title="缓存命中率"></a>缓存命中率</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;缓存命中率不仅是系统性能的一个侧面指标，也是优化缓存使用方案的一个重要依据。缓存命中率=请求命中数/请求总数。接下来的若干缓存使用策略所围绕的核心考量点就是在保证系统稳定性的同时，旨在提升缓存命中率。</p>
<h3 id="缓存更新策略"><a href="#缓存更新策略" class="headerlink" title="缓存更新策略"></a>缓存更新策略</h3><h4 id="主动请求DB数据，更新缓存"><a href="#主动请求DB数据，更新缓存" class="headerlink" title="主动请求DB数据，更新缓存"></a>主动请求DB数据，更新缓存</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过在集群中的每台机器都部署一套<strong>定时任务</strong>，每隔一段时间就主动向数据库<code>DB</code>请求最新数据，然后更新缓存。这样做的好处是可以<strong>避免缓存击穿的风险，在缓存失效前就主动请求加载<code>DB</code>数据，完成缓存数据更新的无缝连接</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但这样做也<strong>增加了机器的<code>CPU</code>和内存的占用率，因为即使有若干<code>Key</code>的缓存始终不被访问，可还是会被主动加载加载到内存中</strong>。也就是说，<strong>提高了业务抗风险能力，但对<code>CPU</code>和内存资源并不友好</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;详情可参见下图，分布式缓存中存储着<code>DB</code>中的数据，每隔<code>4.9s</code>就会有定时任务执行去更新缓存，而缓存数据失效时间为<code>5s</code>，从而保证缓存中的数据永远存在，避免缓存击穿的风险。但对于<code>Web</code>请求来说，只会访问<code>k1</code>的缓存数据，也即对于<code>k2</code>和<code>k3</code>数据来说，是<strong>无效缓存</strong>。</p>
<p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/f95a0e1a895802e2c505ac7e741c3cb7e585c767.png" alt="3"></p>
<blockquote>
<p>定时任务刷新的另外一个问题就是数据量太大，<strong>缓存数据刷新不及时</strong>，因为是单进程更新所有数据，效率不高</p>
</blockquote>
<h4 id="被动请求DB数据，更新缓存"><a href="#被动请求DB数据，更新缓存" class="headerlink" title="被动请求DB数据，更新缓存"></a>被动请求DB数据，更新缓存</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当有请求到达且发现缓存没数据时，就向<code>DB</code>请求最新数据并更新缓存。这种方案完全可以看做是方案一的互斥方案，它<strong>解决的是机器<code>CPU</code>和内存浪费的问题，内存中存储的数据始终是有用的，但却无法避免缓存失效的瞬间又突然流量峰值带来的缓存击穿问题，在业务上会有一定的风险</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;详情见下图，缓存不会主动加载数据，而是根据<code>Web</code>请求懒加载数据。对于请求<code>k1</code>数据来说，发现缓存没有对应数据，到<code>DB</code>查询，然后放入<code>Cache</code>，这是常规流程；但如果有突发流量，大量请求同时访问<code>k2</code>数据，但<code>Cache</code>中没有数据时，请求就会同时落到<code>DB</code>上，<strong>可能压垮数据库</strong>。</p>
<p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/8b9db1a7b6ccc2c60fcc6b8c78606fd19b84e74a.png" alt="4"></p>
<h3 id="缓存过期策略"><a href="#缓存过期策略" class="headerlink" title="缓存过期策略"></a>缓存过期策略</h3><h4 id="依赖时间的过期策略"><a href="#依赖时间的过期策略" class="headerlink" title="依赖时间的过期策略"></a>依赖时间的过期策略</h4><h5 id="定时删除"><a href="#定时删除" class="headerlink" title="定时删除"></a>定时删除</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于需要删除的<strong>每个<code>Key</code>都配备一个定时器，元素超时时间一到就删除元素，释放元素占用的内存，同时释放定时器自身资源</strong>。其优点是元素的删除很及时，但缺点也很明显，比如为每个<code>Key</code>配备定时器肯定会消耗<code>CPU</code>和内存资源，严重影响性能。这种策略只适合在小数据量且对过期时间又严格要求的场景能使用，一般生产环境都不会使用。</p>
<h5 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;元素过期后并不会立马删除，而是<strong>等到该元素的下一次操作（如：访问、更新等）才会判断是否过期，执行过期删除操作</strong>。这样的好处是节约<code>CPU</code>资源，因为只有当元素真的过期了，才会将其删除，而不用单独管理元素的生命周期。但其对内存不友好，因为如果若干已经过期的元素一直不被访问的话，那就会一直占用内存，造成内存泄漏。</p>
<h5 id="定期删除"><a href="#定期删除" class="headerlink" title="定期删除"></a>定期删除</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上两种元素删除策略各有优缺点，无非是对<code>CPU</code>友好，还是对内存友好。为了结合两者的优点，一方面减少了元素定时器的配备，<strong>只使用一个定时器来统一扫描过期元素</strong>；另一方面加速了判断元素过期的时间间隔，不是被动等待检测过期，而是<strong>间隔一段时间就主动执行元素过期检测任务</strong>。正是由于以上的改进点，此方案是元素过期检测的惯常手段。</p>
<h5 id="业务资源过期后及时释放的几种方案"><a href="#业务资源过期后及时释放的几种方案" class="headerlink" title="业务资源过期后及时释放的几种方案"></a>业务资源过期后及时释放的几种方案</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们假设一个场景，为了保护用户隐私，通常在用户电话和商家电话之间，会使用一个虚拟电话作为沟通的桥梁。业务使用中，往往同一个虚拟号码在一定时间内是可以对相同的用户和商家建立连接的，而当超出这个时间后，这个虚拟号码就不再维护映射关系了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虚拟电话号码的资源是有限的，自然会想到创建一个虚拟号码资源池，管理虚拟号码的创建和释放。比如规定一个虚拟号码维持的关系每次能使用15分钟，那么<strong>过期后要释放虚拟号码</strong>，我们有什么方案呢？</p>
<h6 id="全量数据扫描，依次遍历判断过期时间"><a href="#全量数据扫描，依次遍历判断过期时间" class="headerlink" title="全量数据扫描，依次遍历判断过期时间"></a>全量数据扫描，依次遍历判断过期时间</h6><p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/5ccafc6cb1235f7815ab7cc82224100db183ee61.png" alt="_1"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于<code>DB</code>中存储的以上内容，每天记录都存储着虚拟号码的创建时间，以及经过<code>expire_seconds</code>就会删除此记录。那么需要<strong>配备一个定时任务扫描表中的所有记录，再判断<code>current_time - create_time &gt;expire_seconds</code>，才会删除记录</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>如果数据量很大的情况，就会导致数据删除延迟时间很长</strong>，这并不是可取的方案。那是否有方案能直接获取到需要过期的<code>vr_phone</code>，然后批量过期来解决上述痛点呢？来看看方案二吧。</p>
<h6 id="存储绝对过期时间-BTree索引，批量获取过期的vr-phone列表"><a href="#存储绝对过期时间-BTree索引，批量获取过期的vr-phone列表" class="headerlink" title="存储绝对过期时间+BTree索引，批量获取过期的vr_phone列表"></a>存储绝对过期时间+BTree索引，批量获取过期的vr_phone列表</h6><p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/6c14b33949dfdb21882fbacab19c7fc63447122f.png" alt="_2"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将相对过期时间<code>expire_seconds</code>改为记录过期的时间戳<code>expire_timestamp</code>，同时将其添加<code>BTree</code>索引提高检索效率。仍然使用一个定时器，在获取待删除<code>vr_phone</code>列表时只需要<code>select vr_phone from table where now()&gt;=expire_timestamp</code>即可。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于空间复杂度增加了一个<code>BTree</code>数据结构，而基于<code>BTree</code>来考虑时间复杂度的话，对于元素的新增、修改、删除、查询的平均时间复杂度都是<code>O(logN)</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此方案已经能满足业务使用需求了，那是否还有性能更好的方案呢？</p>
<h6 id="单层定时轮算法"><a href="#单层定时轮算法" class="headerlink" title="单层定时轮算法"></a>单层定时轮算法</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们继续讨论上面的案例，寻找更优的解题思路。下表是<code>DB</code>存储元素：</p>
<p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/6d12e43733faaf240f786cf4ed2021f2f870e7ef.png" alt="_3"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此时<code>DB</code>中不再存储和过期时间相关的数据，而专注于业务数据本身。对于过期的功能我们交给单层定时轮来解决。<strong>其本质是一个环形数组，数组每一格代表1秒，每次新加入的元素放在游标的上一格，而游标所指向的位置就是需要过期的<code>vr_phone</code>列表</strong>。</p>
<p>执行过程：</p>
<p>1、初始化：启动一个<code>timer</code>，每隔1s，在上述环形队列中移动一格，<code>1-&gt;2-&gt;3...-&gt;29-&gt;750-&gt;1...</code>有一个指针来标识有待过期的<code>slot</code>数据</p>
<p>2、新增数据：<strong>当有一个新的<code>vr_phone</code>创建时，存储到指针的上一个<code>slot</code>中</strong>。对于有<code>slot</code>冲突的场景，可以利用链表解决冲突，也可以利用数组解决冲突。链表和数组的考量标准还是依赖于单个<code>slot</code>的数据长度，如果数据过长，那么存储的数组会很长，则需要很大的内存空间才能满足，无法利用内存碎片的空间。</p>
<p>3、过期数据：指针每隔1秒移动一个<code>slot</code>，那么指针指向的<code>slot</code>就是需要过期的数据，因为新增的数据在环形<code>slot</code>转完一圈后，才会被指向到。</p>
<p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/acfe4d481dcebfd96d87a6eaca1f62606dc65eea.png" alt="5"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样一种算法结构，将时间和空间巧妙地结合在了一起。新增元素的时间复杂度为<code>O(1)</code>，直接插入待批量过期的<code>slot</code>的上一个位置即可；获取待删除元素列表时间复杂度也是<code>O(1)</code>，就是待批量过期的<code>slot</code>位置。流行框架<code>Netty、Kafka</code>都有定时轮的影子。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，<strong>单层定时轮只适用于固定时间过期的场景，如果需要管理不同过期时间的元素，那么可以参考”多层定时轮算法”，其实就是模拟现实世界的时针、分针、秒针的概念，建立多个单层定时轮，采用进位和退位的思想来管理元素的过期时间</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上各种元素过期策略各有优缺点，可以根据业务的诉求来取舍。比如<code>Memcache</code>只是用了惰性删除，而<code>Redis</code>则同时使用了惰性删除和定期删除以结合二者的优点。</p>
<h4 id="依赖空间的过期策略"><a href="#依赖空间的过期策略" class="headerlink" title="依赖空间的过期策略"></a>依赖空间的过期策略</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此处只探讨最经典的三种策略<code>FIFO</code>、<code>LRU</code>、<code>LFU</code>的原理及实现方案，对于其它改进算法，感兴趣的同学可以自行查找。</p>
<h5 id="FIFO"><a href="#FIFO" class="headerlink" title="FIFO"></a>FIFO</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>先进先出，当空间不足时，先进入的元素将会被移除</strong>。此方案并<strong>没有考虑元素的使用特性，可能最近频繁访问的一个元素会被移除，从而降低了缓存命中率</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实现：基于<code>LinkedHashMap</code>的钩子函数实现<code>FIFO Map</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 链表头部是最近最少被访问的元素，需要被删除</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FIFOMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> maxSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//LinkedHashMap每次插入数据，默认都是链表tail；当accessOrder=false，元素被访问不会移动位置</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FIFOMap</span><span class="params">(<span class="keyword">int</span> maxSize)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(maxSize, <span class="number">0.75f</span>, <span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">this</span>.maxSize = maxSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//每次put和putAll新增元素的时候都会触发判断;当下面函数=true时，就删除链表head元素</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">removeEldestEntry</span><span class="params">(Map.Entry&lt;K, V&gt; eldest)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> size() &gt; maxSize;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h5><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最近最少使用算法，<strong>当下多次被访问的数据在以后被访问的概率会很大，因此保留最近访问的元素，提高命中率</strong>。可以应对流量突发峰值，因为存储的池子大小是固定的，因此内存占用不可能过多。但也有缺点：<strong>如果一个元素访问存在间歇规律，1分钟前访问1万次，后面30秒无访问，然后再访问一万次，这样就会导致被删除，降低了命中率</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实现：基于<code>LinkedHashMap</code>的钩子函数实现<code>LRUHashMap</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 链表头部是最近最少被访问的元素，需要被删除</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LRUMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> maxSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//LinkedHashMap每次插入数据，默认都是链表tail；当accessOrder=true时，被访问的元素也会放到链表tail</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUMap</span><span class="params">(<span class="keyword">int</span> maxSize)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(maxSize, <span class="number">0.75f</span>, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">this</span>.maxSize = maxSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//每次put和putAll新增元素的时候都会触发判断;当下面函数=true时，就删除链表head元素</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">removeEldestEntry</span><span class="params">(Map.Entry&lt;K, V&gt; eldest)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> size() &gt;= maxSize;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="LFU"><a href="#LFU" class="headerlink" title="LFU"></a>LFU</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最近最少频率使用，根据数据的历史访问频率来淘汰数据，其核心思想是”如果数据过去被访问多次，那么将来被访问的频率也更高”。这种算法针对<code>LRU</code>的缺点进行了优化，记录了元素访问的总次数，选出访问次数最小的元素进行删除。原本的<code>LFU</code>算法要求记录所有元素的访问次数，但考虑到内存成本，改进后的<code>LFU</code>是在有限队列中进行淘汰。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实现：<code>Redis</code>的优先级队列<code>Zset</code>实现，<strong><code>Zset</code>存储元素的数量固定，<code>Value</code>是访问次数，超过<code>size</code>就删除访问次数最小的即可</strong>。但这种删除策略对于有时效性的数据却并不合适，对于排行榜类的数据，如果某个历史剧点击量特别高，那么就始终不会被淘汰，新剧就没有展示的机会。改进方案，可以<strong>将<code>Value</code>存储为入库时间戳+访问次数的值，这样随着时间流逝，历史老剧就可能被淘汰</strong>。</p>
<h2 id="其他影响命中率的因素"><a href="#其他影响命中率的因素" class="headerlink" title="其他影响命中率的因素"></a>其他影响命中率的因素</h2><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>对于数据库中本就不存在的值，缓存中肯定也不会存在，此类数据的查询一定会落到<code>DB</code>上</strong>。为了减少<code>DB</code>访问压力，我们期望将这些数据都可以在缓存中<code>cover</code>住，以下是两种解法。</p>
<h4 id="缓存null值"><a href="#缓存null值" class="headerlink" title="缓存null值"></a>缓存null值</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该方法对于元素是否存在于<code>DB</code>有精准的判断，可如果存在海量<code>null</code>值的数据，则会对内存过度占用。</p>
<h4 id="布隆过滤"><a href="#布隆过滤" class="headerlink" title="布隆过滤"></a>布隆过滤</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用场景是<strong>海量数据，且不要求精准判断和过滤数据</strong>。其思路是借助<code>Hash</code>和<code>bit</code>位思想，将<code>Key</code>值映射成若干<code>Hash</code>值存储到<code>bit</code>数组中。</p>
<p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/889ec2d6891675e3eedfb0b9242db25eae27fcce.png" alt="6"></p>
<p>B. 新增元素时，将元素的<code>Key</code>根据预设的若干<code>Hash</code>函数解析成若干整数，然后定位到<code>bit</code>位数组中，将对应的<code>bit</code>位都改为1。</p>
<p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/1edea49588bd21a699f5ef29e683e637e03ba5e0.png" alt="7"></p>
<p>C. 判断元素是否存在，也是将元素的<code>Key</code>根据<code>Hash</code>函数解析成整数，查询若干<code>bit</code>位的值。只要有一个<code>bit</code>位是0，那么这个<code>Key</code>肯定是新元素，不存在；<strong>如果所有<code>bit</code>位全都是1，那么这个<code>Key</code>很大概率是已经存在的元素，但也有极小的概率是<code>Key3</code>经过若干<code>Hash</code>函数定位到<code>bit</code>数组后都是<code>Hash</code>冲突的，可能造成误判</strong>。</p>
<p><img src="//blog.com/2019/08/18/缓存技术使用的实践与思考/accaaa2a5cec2cc954c759cdf98098966cfbf348.png" alt="8"></p>
<h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;缓存中原本一批数据有值，但<strong>恰好都同时过期了，此时有大量请求过来就都会落到<code>DB</code>上</strong>。避免这种风险也有两种解法。</p>
<h4 id="随机缓存失效时间"><a href="#随机缓存失效时间" class="headerlink" title="随机缓存失效时间"></a>随机缓存失效时间</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对缓存中不同的<code>Key</code>设置不同的缓存失效时间，避免缓存同时失效带来大量请求都落到<code>DB</code>上的情况。</p>
<h4 id="主动加载更新缓存策略，替代缓存过期删除策略"><a href="#主动加载更新缓存策略，替代缓存过期删除策略" class="headerlink" title="主动加载更新缓存策略，替代缓存过期删除策略"></a>主动加载更新缓存策略，替代缓存过期删除策略</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在缓存失效之前就主动到<code>DB</code>中加载最新的数据放到缓存中，从而避免大量请求落到<code>DB</code>的情况。</p>
<h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>大量缓存同时过期，或者缓存中间件不可用</strong>，导致大量请求落到<code>DB</code>，系统停止响应。解法是对缓存设置随机失效时间，同时增加<strong>缓存中间件健康度监测</strong>。</p>
<h2 id="保证业务数据一致性的策略"><a href="#保证业务数据一致性的策略" class="headerlink" title="保证业务数据一致性的策略"></a>保证业务数据一致性的策略</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分析了影响缓存命中率的若干策略和方案后，我们结合实际开发诉求，来分析下缓存是如何降低<code>DB</code>的访问压力，以及<code>DB</code>和缓存中业务数据的一致性如何保证？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;维护数据一致性常用的方案有两种：先操作<code>DB</code>，再操作<code>Cache</code>；先操作<code>Cache</code>，再操作<code>DB</code>。而以上两步操作都期望是全部成功，才能保证操作是原子性的。如果不依赖事务，那么对数据怎样操作才能保证即使流程异常中断，对业务影响也是最小呢？</p>
<h3 id="对于读取操作"><a href="#对于读取操作" class="headerlink" title="对于读取操作"></a>对于读取操作</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为只是读取，不涉及数据修改，因此先读缓存，<code>Cache miss</code>后，读<code>DB</code>数据，然后<code>set cache</code>就足够通用。</p>
<h3 id="对于写入操作"><a href="#对于写入操作" class="headerlink" title="对于写入操作"></a>对于写入操作</h3><h4 id="先操作DB，再操作-delete-update-缓存"><a href="#先操作DB，再操作-delete-update-缓存" class="headerlink" title="先操作DB，再操作(delete/update)缓存"></a>先操作DB，再操作(delete/update)缓存</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当<code>DB</code>数据操作成功，但缓存数据（不论是<code>delete</code>还是<code>update</code>）操作失败，就会导致在未来一段时间内，<strong>缓存中的数据都是历史旧数据</strong>，并没有保证操作的原子性，无法接受。</p>
<h4 id="先操作-delete-update-缓存，再操作DB"><a href="#先操作-delete-update-缓存，再操作DB" class="headerlink" title="先操作(delete/update)缓存，再操作DB"></a>先操作(delete/update)缓存，再操作DB</h4><ul>
<li>第一种方案：当<code>update</code>缓存成功，但操作<code>DB</code>失败，虽然缓存中的数据是最新的了，但这个最新的数据最终并没有更新到<code>DB</code>中，当缓存失效后，还是会从<code>DB</code>中读取到旧的数据，这样就会导致<strong>上下游依赖的数据出现错误，无法接受</strong>。</li>
</ul>
<ul>
<li>第二种方案：先<code>delete</code>缓存，再操作<code>DB</code>数据，我们详细讨论下这种方案：</li>
</ul>
<ol>
<li><p>如果<code>delete</code>就失败了，整体操作失败，相当于事务回滚；</p>
<ol>
<li>如果<code>delete</code>成功，但<code>DB</code>操作失败，此时会引起一次<code>cache miss</code>，紧接着还是会从<code>DB</code>加载旧数据，相当于整体无操作，事务回滚，代价只是一次<code>cache miss</code>；</li>
</ol>
</li>
<li><p>如果<code>delete</code>成功，且<code>DB</code>操作成功，那么整体成功。</p>
<blockquote>
<p>这里缓存可能会有脏数据，delete cache以后，其它某个请求查询，读取DB数据（此时DB操作还未完成），导致缓存里面存储的是脏数据</p>
</blockquote>
</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结论：先<code>delete</code>缓存，再操作<code>DB</code>，能尽可能达到两步处理的原子性效果，即使流程中断对业务影响也是最小的。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于缓存的使用没有绝对的黄金标准，都是根据业务的使用场景来决定什么缓存框架或者缓存策略是最适合的。但对于通用的业务场景来说，以下的缓存框架选择方法应该可以满足大部分场景。</p>
<ul>
<li>对于本地缓存，如果缓存的数量是可估计的，且不会变化的，那么可使用<code>JDK</code>自带的<code>HashMap</code>或<code>ConcurrentHashMap</code>来存储。</li>
<li>对于有按时间过期、自动刷新需求的本地缓存可以使用<code>Caffeine</code>。</li>
<li>对于分布式缓存且要求有丰富数据结构的，推荐使用<code>Redis</code>。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/08/17/微服务架构下静态数据通用缓存机制/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/17/微服务架构下静态数据通用缓存机制/" itemprop="url">微服务架构下静态数据通用缓存机制</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-17T12:12:57+08:00">
                2019-08-17
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/消息队列/" itemprop="url" rel="index">
                    <span itemprop="name">消息队列</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="微服务架构下静态数据通用缓存机制"><a href="#微服务架构下静态数据通用缓存机制" class="headerlink" title="微服务架构下静态数据通用缓存机制"></a>微服务架构下静态数据通用缓存机制</h1><blockquote>
<p>原文地址：<a href="https://www.cnblogs.com/bossma/p/9858847.html" target="_blank" rel="noopener">https://www.cnblogs.com/bossma/p/9858847.html</a></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分布式系统中，特别是最近很火的微服务架构下，有没有或者能不能总结出一个业务静态数据的通用缓存处理机制或方案，这篇文章将结合一些实际的研发经验，尝试理清其中存在的关键问题以及探寻通用的解决之道。</p>
<h2 id="什么是静态数据"><a href="#什么是静态数据" class="headerlink" title="什么是静态数据"></a>什么是静态数据</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里<strong>静态数据是指不经常发生变化或者变化频率比较低的数据</strong>，比如车型库、用户基本信息、车辆基本信息等，车型库这种可能每个月会更新一次，用户和车辆基本信息的变化来源于用户注册、修改，这个操作的频率相对也是比较低的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外这类数据的另一个特点是要求准确率和实时性都比较高，不能出现丢失、错误，以及过长时间的陈旧读。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;具体是不是应该归类为静态数据要看具体的业务，以及对变化频率高低的划分标准。在这里的业务定义中，上边这几类数据都归为静态数据。</p>
<h2 id="为什么需要缓存"><a href="#为什么需要缓存" class="headerlink" title="为什么需要缓存"></a>为什么需要缓存</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在面向用户或车联网的业务场景中，车型信息、用户基本信息和车辆基本信息有着广泛而高频的业务需求，很多数据都需要对其进行关联处理。在这里缓存的目的就是为了提高数据查询效率。静态数据通常都保存在关系型数据库中，这类数据库的IO效率普遍不高，应对高并发的查询往往捉襟见肘。使用缓存可以极大的提升读操作的吞吐量，特别是KV类的缓存，没有复杂的关系操作，时间复杂度一般都在O(1)。注意这里说的缓存指内存缓存。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然除了使用缓存，还可以通过其它手段来提高IO吞吐量，比如读写分离，分库分表，但是这类面向关系型数据库的方案更倾向于同时提高读写效率，对于单纯提升读吞吐量的需求，这类方案不够彻底，不能在有限的资源情况下发挥更好的作用。</p>
<h2 id="通用缓存机制"><a href="#通用缓存机制" class="headerlink" title="通用缓存机制"></a>通用缓存机制</h2><p>下面将直接给出一个我认为的通用处理机制，然后会对其进行分析。</p>
<p><img src="//blog.com/2019/08/17/微服务架构下静态数据通用缓存机制/73642-20190813175605846-1761040322.png" alt="img"></p>
<p>对于某个具体的业务，其涉及到六个核心程序：</p>
<ul>
<li>业务服务：提供对某种业务数据的操作接口，比如车辆服务，提供对车辆基本信息的增删改查服务。</li>
<li>关系数据库：使用若干表持久化业务数据，比如<code>SQLServer、MySQL、Oracle</code>等。</li>
<li><strong>持久化队列</strong>：可独立部署的队列程序，支持数据持久化，比如<code>RabbitMQ、RocketMQ、Kafka</code>等。</li>
<li><strong>缓存处理程序</strong>：从队列接收数据，然后写入缓存。</li>
<li><strong>数据一致处理程序</strong>：负责检查缓存数据库和关系型数据库中数据是否一致，如果不一致则使用关系数据库进行更新。</li>
<li><strong>缓存数据库</strong>（<code>Redis</code>）：支持持久化的缓存数据库，这里直接选了<code>Redis</code>，这个基本是业界标准了。</li>
</ul>
<p>以及两个外部定义：</p>
<ul>
<li>数据生产者：业务静态数据的来源，可以理解为前端APP、Web系统的某个功能或者模块。</li>
<li>数据消费者：需要使用这些业务静态数据的服务或者系统，比如报警系统需要获取车辆对应的用户信息以便发送报警。</li>
</ul>
<p>下面以问答的形式来说明为什么是这样一种机制。</p>
<h3 id="为什么需要业务服务？"><a href="#为什么需要业务服务？" class="headerlink" title="为什么需要业务服务？"></a>为什么需要业务服务？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;既然是微服务架构，当然离不开服务了，因为这里探讨的是业务静态数据，所以是业务服务。不过为了更好的理解，这里还是简单说下服务出现的原因。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当<strong>今业务往往需要在多个终端进行使用</strong>，比如PC、手机、平板等，既有网页的形式，又有APP的形式，另<strong>外某个数据可能在多种不同的业务被需要</strong>，如果将数据操作分布在多个程序中很可能产生数据不一致的情况，另外代码不可避免的冗余，读写性能更很难控制，变更也基本上是不敢变的。<strong>通过一个业务服务可以将对业务数据的操作有序的管理起来，并通过接口的形式对外提供操作能力，代码不用冗余了，性能也好优化了，数据不一致也得到了一定的控制，编写上层应用的人也舒服了</strong>。</p>
<h3 id="为什么不是进程内缓存？"><a href="#为什么不是进程内缓存？" class="headerlink" title="为什么不是进程内缓存？"></a>为什么不是进程内缓存？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很多开发语言都提供了进程内缓存的支持，即使没有提供直接操作缓存的包或库，也可以通过静态变量的方式来实现。对数据的查询请求直接在进程内存完成，效率可以说是杠杠滴了。但是进程内缓存存在两个问题：</p>
<ul>
<li><p><strong>缓存数据的大小</strong>：进程可以缓存数据的大小受限于系统可用内存，同时如果机器上部署了多个服务，某个服务使用了太多的内存，则可能会影响其它服务的正常访问，因此不适合大量数据的缓存。</p>
</li>
<li><p><strong>缓存雪崩</strong>：缓存同时大量过期或者进程重启的情况下，可能产生大量的缓存穿透，过多的请求打到关系数据库上，可能导致关系数据库的崩溃，引发更大的不可用问题。</p>
</li>
</ul>
<h3 id="为什么是Redis？"><a href="#为什么是Redis？" class="headerlink" title="为什么是Redis？"></a>为什么是Redis？</h3><p><code>Redis</code>这类数据库可以解决进程内缓存的两个问题：</p>
<ul>
<li><strong>独立部署，不影响其它业务，还可以做集群，内存扩容比较方便</strong>。</li>
<li><strong>支持数据持久化</strong>，即使<code>Redis</code>重启了，缓存的数据自身就可以很快恢复。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外<code>Redis</code>提供了很好的读写性能，以及方便的水平扩容能力，还支持多种常用数据结构，使用起来比较方便，可以说是通用缓存首选。</p>
<h3 id="为什么需要队列？"><a href="#为什么需要队列？" class="headerlink" title="为什么需要队列？"></a>为什么需要队列？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>队列在这里的目的是为了解耦</strong>，坦白的说这个方案中可以没有队列，业务服务在关系数据库操作完成后，直接更新到缓存也是可以的。 之所以加上这个队列是由于当前的业务开发有很明显的系统拆分的需求，特别是在微服务架构下，为了降低服务之间的耦合，使用队列是个常用选择，在某些开发模型中也是很推崇的，比如<code>Actor</code>模型。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;举个例子，比如新注册一个用户，需要赠送其300积分，同时还要给其发个注册成功的邮件，如果将注册用户、赠送积分、发成功邮件都写到一起执行，会产生两个问题：一是注册操作耗时增加，二是其中某个处理引发整体不可用的几率增大，三是程序的扩展性不好；通多引入队列，将注册信息分别发到积分队列和通知队列，然后由积分模块和通知模块分别处理，用户、积分、通知三个模块的耦合降低了，相互影响变小了，以后再增加注册后的其它处理也就是增加个队列的事，整体的扩展性得到了增强。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;队列作为一种常用的解耦方案，在缓存这里虽然产生的影响不大，但是除了缓存难免同时还会有其它业务处理，所以为了统一处理机制，这里保留了下来。（既然用了，就把它发扬光大。）</p>
<h3 id="为什么队列需要持久化？"><a href="#为什么队列需要持久化？" class="headerlink" title="为什么队列需要持久化？"></a>为什么队列需要持久化？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>持久化是为了解决网络抖动或者崩溃导致数据丢失的问题，在数据从业务服务到队列，队列自身处理，再从队列到缓存处理程序，中间都可能丢失数据</strong>。为了解决丢失数据的问题，需要发送时确认、队列自身持久化、接收时确认；但是需要注意确认机制可能会导致重复数据的产生，因为在未收到确认时就需要重新发送或接收，而数据实际上可能被正常处理，只是确认丢失了；确认机制还会降低队列的吞吐量，但是根据我们的定义业务静态数据的变更频率应该不高，如果同时还需要较高的并发分片是个不错的选择。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里持久化队列推荐选择<code>RabbitMQ</code>，虽然吞吐量支持的不是很大，但是各方面综合不错，并发够用就好。</p>
<h3 id="为什么需要数据一致检查程序？"><a href="#为什么需要数据一致检查程序？" class="headerlink" title="为什么需要数据一致检查程序？"></a>为什么需要数据一致检查程序？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在业务服务操作完关系数据库后，数据发送到队列之前（或者不用队列就是直接写入缓存之前），<strong>业务服务崩溃了，这时候数据就不能更新到缓存了</strong>。还有一种情况是<strong><code>Redis</code>发生了故障转移，<code>master</code>中的更新没有同步到<code>slaver</code></strong>。通过引入这么一个检查程序，定时的检查关系数据库数据和缓存数据的差别，如果缓存数据比较陈旧，则更新之。这样提供了一种极端情况下的挽救措施。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个检查程序的<strong>运行频率需要综合考虑数据库压力和能够承受的数据陈旧时间，不能把数据库查死了，也不能陈旧太久导致大量数据不一致</strong>。可以通过设置上次检查时间点的方式，每次只检查从上次检查时间点（或者最近几次，防止<code>Redis</code>故障转移数据未同步的问题）到本次检查时间点发生变更的数据，这样每次检查只对增量变更，效率更高。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同时需要理解在分布式系统中，微服务架构下，数据不一致是经常出现的，必须在一致性和可用性之间做出权衡，尽力去降低影响，比如使用准实时或最终一致性。</p>
<h3 id="只要数据一致检查程序是不是就够了？"><a href="#只要数据一致检查程序是不是就够了？" class="headerlink" title="只要数据一致检查程序是不是就够了？"></a>只要数据一致检查程序是不是就够了？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设没有缓存处理程序，通过定时同步关系数据库和缓存数据库是不是就够了呢？这还是取决于业务，如果是车型库这种数据，增加一个新的车型，本来之前就没有，时间上并不是很敏感，这个是可以的。但是对于新增了用户或者车辆，数据消费者还是希望能够马上使用最新的数据进行处理，越快越好，这时使用同步或者准同步更新就能更加贴近需求。<strong>数据更新是否及时</strong></p>
<h3 id="为什么不用缓存过期机制？"><a href="#为什么不用缓存过期机制？" class="headerlink" title="为什么不用缓存过期机制？"></a>为什么不用缓存过期机制？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用缓存过期机制可以不需要缓存处理程序和数据一致检查程序，业务服务首先从<code>Redis</code>查询数据，如果数据存在就直接返回，如果不存在则从关系数据库查询，然后写入<code>Redis</code>，然后再返回，这也是一种常用的缓存处理机制，网上可以查询到很多，很多人用的也很好。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是缓存的过期时间是个问题：缓存多长时间过期，<strong>设置的短可以降低数据的陈旧，但是会增加缓存穿透的概率，即使采用随机的缓存过期时间，在<code>Redis</code>重启或者故障转移的情况下还是会可能导致缓存雪崩，雪崩的情况下采用数据预热机制，也可能会导致服务更长时间的不可用；设置的长可以提升缓存的使用率，但是增加了数据陈旧</strong>，在上边对静态数据的定义中对其准确率和实时性都有较高的要求，业务上能不能接受需要考虑。而且如果操作数据和查询存在波动的峰谷，是不是要引入动态<code>TTL</code>的机制，以达到缓存使用和直接访问数据库的一种平衡，这就需要权衡业务需求和技术方案。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过上边的这些问题问答，再来看看上面提出的微服务架构下静态数据通用缓存处理机制。</p>
<ul>
<li><strong>通过业务服务来包装对数据的操作</strong>，不管是操作关系数据库还是缓存数据库，数据消费者其实不需要关心，它只关心业务服务能不能提供高并发实时数据的查询能力。</li>
<li>利用分布式系统中经常<strong>使用队列进行解耦</strong>的方式，业务服务不干写入缓存的事，增加一个队列订阅数据变更，然后从队列取数据写入缓存数据库。</li>
<li>对于绝大部分正常的情况，通过队列更新缓存数据和业务服务中更新缓存数据，其实时性是差不多的，同时实现了业务操作和写缓存的解耦。</li>
<li><strong>在极端崩溃导致数据不一致的情况下，通过数据一致检查程序进行补救，尽快更新缓存数据</strong>。</li>
<li>现在业务服务可以通过访问<code>Redis</code>缓存来提供对静态数据的高并发准实时查询能力，缓存中不存在的数据就是不存在，没有缓存穿透。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于微服务架构而言，这个机制借助队列这种通用的解耦方式，独立了缓存更新处理，通过准实时更新和定时检查，保证了缓存的实时性和极端情况下较短时间内达到最终一致，通过缓存的持久化机制消除了缓存穿透和雪崩，在缓存的数据较大或读取并发较高时支持水平扩容，可以认为对业务静态数据提供了一种广泛适用的缓存处理机制。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方案在某些情况下可能是没有必要的，比如你要缓存一个全国限行的城市列表，使用一个进程内缓存就够了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后剩下的就是工作量的问题了，这个会给开发和维护带来复杂性，队列有没有用的顺手的，人手是不是够，业务需求是什么样的，需要考虑清楚。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Redis耦合问题：</strong>图中业务服务直接访问了<code>Redis</code>，如果要实现业务服务对<code>Redis</code>的完全透明，这个还比较复杂，可以考虑采用<code>AOP</code>的方式，对关系数据库和<code>Redis</code>保持相同的类型定义，分别采用<code>ORM</code>和反序列化的方式标准化输出，这是个想法我也没有实现；同时缓存数据是准实时的，如果要求完全一致，还是应该提供从关系数据库查询的版本。另外如果要摆脱对<code>Redis</code>的直接依赖，还可以通过<code>OpenResty</code>来实现对资源的透明访问，这个不是本文的重点。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>服务可用性问题：</strong>这篇文章没有关注服务可用性问题，为了保证服务的高可用，每个服务或者程序都应该有多份部署的，无论是负载均衡的方案，或者传统的主备方案，在部分部署不可用时仍能够继续提供服务。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/08/17/Kafka原理了解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/17/Kafka原理了解/" itemprop="url">Kafka原理了解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-17T12:12:57+08:00">
                2019-08-17
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/消息队列/" itemprop="url" rel="index">
                    <span itemprop="name">消息队列</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/消息队列/Kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Kafka原理了解"><a href="#Kafka原理了解" class="headerlink" title="Kafka原理了解"></a>Kafka原理了解</h1><h2 id="一、Kafka-简介"><a href="#一、Kafka-简介" class="headerlink" title="一、Kafka 简介"></a>一、Kafka 简介</h2><h3 id="Kafka-创建背景"><a href="#Kafka-创建背景" class="headerlink" title="Kafka 创建背景"></a>Kafka 创建背景</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Kafka</strong> 是一个消息系统，原本开发自 LinkedIn，用作 LinkedIn 的活动流（<code>Activity Stream</code>）和运营数据处理管道（<code>Pipeline</code>）的基础。现在它已被<a href="https://cwiki.apache.org/confluence/display/KAFKA/Powered+By" target="_blank" rel="noopener">多家不同类型的公司</a> 作为多种类型的数据管道和消息系统使用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>活动流数据</strong>是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量（<code>Page View</code>）、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。<strong>运营数据</strong>指的是服务器的性能数据（CPU、IO 使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。</p>
<h3 id="Kafka-简介"><a href="#Kafka-简介" class="headerlink" title="Kafka 简介"></a>Kafka 简介</h3><p><code>Kafka</code> 是一种分布式的，基于发布 / 订阅的消息系统。主要设计目标如下：</p>
<ul>
<li>以时间复杂度为 <code>O(1)</code>的方式提供消息持久化能力，即使对 <code>TB</code>级以上数据也能保证常数时间复杂度的访问性能。</li>
<li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 <code>100K</code> 条以上消息的传输。</li>
<li>支持<code>Kafka Server</code>间的消息分区，及分布式消费，同时保证每个 <code>Partition</code> 内的消息顺序传输。</li>
<li>同时支持离线数据处理和实时数据处理。</li>
<li><code>Scale out</code>：支持在线水平扩展。</li>
</ul>
<h3 id="Kafka-基础概念"><a href="#Kafka-基础概念" class="headerlink" title="Kafka 基础概念"></a>Kafka 基础概念</h3><h4 id="概念一：生产者与消费者"><a href="#概念一：生产者与消费者" class="headerlink" title="概念一：生产者与消费者"></a>概念一：生产者与消费者</h4><p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210611.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于 <code>Kafka</code> 来说客户端有两种基本类型：<strong>生产者（Producer）</strong>和<strong>消费者（Consumer）</strong>。除此之外，还有用来做数据集成的 <code>Kafka Connect API</code> 和流式处理的 <code>Kafka Streams</code> 等高阶客户端，但这些高阶客户端底层仍然是生产者和消费者<code>API</code>，它们只不过是在上层做了封装。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这很容易理解，生产者（也称为发布者）创建消息，而消费者（也称为订阅者）负责消费or读取消息。</p>
<h4 id="概念二：主题（Topic）与分区（Partition）"><a href="#概念二：主题（Topic）与分区（Partition）" class="headerlink" title="概念二：主题（Topic）与分区（Partition）"></a>概念二：主题（Topic）与分区（Partition）</h4><p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210616.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在<code>Kafka</code>中，消息以<strong>主题（Topic）</strong>来分类，每一个主题都对应一个「消息队列」，这有点儿类似于数据库中的表。但是如果我们把所有同类的消息都塞入到一个“中心”队列中，势必缺少可伸缩性，无论是生产者/消费者数目的增加，还是消息数量的增加，都可能耗尽系统的性能或存储。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们使用一个生活中的例子来说明：现在 A 城市生产的某商品需要运输到 B 城市，走的是公路，那么单通道的高速公路不论是在「A 城市商品增多」还是「现在 C 城市也要往 B 城市运输东西」这样的情况下都会出现「吞吐量不足」的问题。所以我们现在引入<strong>分区（Partition）</strong>的概念，类似“允许多修几条道”的方式对我们的主题完成了水平扩展。</p>
<h4 id="概念三：Broker-和集群（Cluster）"><a href="#概念三：Broker-和集群（Cluster）" class="headerlink" title="概念三：Broker 和集群（Cluster）"></a>概念三：Broker 和集群（Cluster）</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个 <code>Kafka</code>服务器也称为 <code>Broker</code>，它接受生产者发送的消息并存入磁盘；<code>Broker</code> 同时服务消费者拉取分区消息的请求，返回目前已经提交的消息。使用特定的机器硬件，一个 <code>Broker</code> 每秒可以处理成千上万的分区和百万量级的消息。（现在动不动就百万量级..我特地去查了一把，好像确实集群的情况下吞吐量挺高的..摁..）</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;若干个 <code>Broker</code> 组成一个集群（<code>Cluster</code>），其中集群内某个 <code>Broker</code> 会成为集群控制器（<code>Cluster Controller</code>），它负责管理集群，包括分配分区到 <code>Broker</code>、监控 <code>Broker</code> 故障等。在集群内，一个分区由一个 <code>Broker</code> 负责，这个 <code>Broker</code> 也称为这个分区的 <code>Leader</code>；当然一个分区可以被复制到多个 <code>Broker</code>上来实现冗余，这样当存在<code>Broker</code> 故障时可以将其分区重新分配到其他 <code>Broker</code>来负责。下图是一个样例：</p>
<p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210624.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Kafka</code> 的一个关键性质是<strong>日志保留</strong>（<code>retention</code>），我们可以配置主题的消息保留策略，譬如只保留一段时间的日志或者只保留特定大小的日志。当超过这些限制时，老的消息会被删除。我们也可以针对某个主题单独设置消息过期策略，这样对于不同应用可以实现个性化。</p>
<h4 id="概念四：多集群"><a href="#概念四：多集群" class="headerlink" title="概念四：多集群"></a>概念四：多集群</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随着业务发展，我们往往需要多集群，通常处于下面几个原因：</p>
<ul>
<li>基于数据的隔离；</li>
<li>基于安全的隔离；</li>
<li>多数据中心（容灾）</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当构建多个数据中心时，往往需要实现消息互通。举个例子，假如用户修改了个人资料，那么后续的请求无论被哪个数据中心处理，这个更新需要反映出来。又或者，多个数据中心的数据需要汇总到一个总控中心来做数据分析。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上面说的分区复制冗余机制只适用于同一个 <code>Kafka</code> 集群内部，对于多个<code>Kafka</code>集群消息同步可以使用 <code>Kafka</code> 提供的 <code>MirrorMaker</code> 工具。本质上来说，<code>MirrorMaker</code> 只是一个<code>Kafka</code> 消费者和生产者，并使用一个队列连接起来而已。它从一个集群中消费消息，然后往另一个集群生产消息。</p>
<h2 id="二、Kafka-的设计与实现"><a href="#二、Kafka-的设计与实现" class="headerlink" title="二、Kafka 的设计与实现"></a>二、Kafka 的设计与实现</h2><h3 id="讨论一：Kafka-存储在文件系统上"><a href="#讨论一：Kafka-存储在文件系统上" class="headerlink" title="讨论一：Kafka 存储在文件系统上"></a>讨论一：Kafka 存储在文件系统上</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;是的，<strong>您首先应该知道 Kafka 的消息是存在于文件系统之上的</strong>。<code>Kafka</code> 高度依赖文件系统来存储和缓存消息，一般的人认为 “磁盘是缓慢的”，所以对这样的设计持有怀疑态度。实际上，磁盘比人们预想的快很多也慢很多，这取决于它们如何被使用；一个好的磁盘结构设计可以使之跟网络速度一样快。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现代的操作系统针对磁盘的读写已经做了一些优化方案来加快磁盘的访问速度。比如，<strong>预读</strong>会提前将一个比较大的磁盘快读入内存。<strong>后写</strong>会将很多小的逻辑写操作合并起来组合成一个大的物理写操作。并且，操作系统还会将主内存剩余的所有空闲内存空间都用作<strong>磁盘缓存</strong>，所有的磁盘读写操作都会经过统一的磁盘缓存（除了直接 I/O 会绕过磁盘缓存）。综合这几点优化特点，<strong>如果是针对磁盘的顺序访问，某些情况下它可能比随机的内存访问都要快，甚至可以和网络的速度相差无几。</strong></p>
<p><strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述的 Topic 其实是逻辑上的概念，面相消费者和生产者，物理上存储的其实是 Partition</strong>，每一个 <code>Partition</code> 最终对应一个目录，里面存储所有的消息和索引文件。默认情况下，每一个 <code>Topic</code> 在创建时如果不指定<code>Partition</code> 数量时只会创建 1 个 <code>Partition</code>。比如，我创建了一个 <code>Topic</code> 名字为<code>test</code> ，没有指定 <code>Partition</code> 的数量，那么会默认创建一个<code>test-0</code> 的文件夹，这里的命名规则是：<code>&lt;topic_name&gt;-&lt;partition_id&gt;</code>。</p>
<p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210631.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;任何发布到<code>Partition</code> 的消息都会被追加到<code>Partition</code>数据文件的尾部，这样的<strong>顺序写磁盘</strong>操作让 <code>Kafka</code> 的效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是 Kafka 高吞吐率的一个很重要的保证）。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每一条消息被发送到<code>Broker</code>中，会根据 <code>Partition</code>规则选择被存储到哪一个 <code>Partition</code>。如果 <code>Partition</code>规则设置的合理，所有消息可以均匀分布到不同的 <code>Partition</code>中。</p>
<h3 id="讨论二：Kafka-中的底层存储设计"><a href="#讨论二：Kafka-中的底层存储设计" class="headerlink" title="讨论二：Kafka 中的底层存储设计"></a>讨论二：Kafka 中的底层存储设计</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设我们现在 <code>Kafka</code> 集群只有一个 <code>Broker</code>，我们创建 2 个<code>Topic</code> 名称分别为：「topic1」和「topic2」，<code>Partition</code> 数量分别为 1、2，那么我们的根目录下就会创建如下三个文件夹：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">| --topic1-0</span><br><span class="line">| --topic2-0</span><br><span class="line">| --topic2-1</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在 <code>Kafka</code> 的文件存储中，<strong>同一个 <code>Topic</code>下有多个不同的 <code>Partition</code>，每个 <code>Partition</code> 都为一个目录，而每一个目录又被平均分配成多个大小相等的 <code>Segment File</code></strong> 中，<code>Segment File</code> 又由<code>index file</code> 和 <code>data file</code> 组成，他们总是成对出现，<strong>后缀 <code>“.index”</code> 和<code>“.log”</code> 分表表示<code>Segment</code>索引文件和数据文件</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在假设我们设置每个<code>Segment</code>大小为 500 MB，并启动生产者向 <code>topic1</code> 中写入大量数据，<code>topic1-0</code>文件夹中就会产生类似如下的一些文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">| --topic1-0</span><br><span class="line">    | --00000000000000000000.index</span><br><span class="line">    | --00000000000000000000.log</span><br><span class="line">    | --00000000000000368769.index</span><br><span class="line">    | --00000000000000368769.log</span><br><span class="line">    | --00000000000000737337.index</span><br><span class="line">    | --00000000000000737337.log</span><br><span class="line">    | --00000000000001105814.index</span><br><span class="line">    | --00000000000001105814.log</span><br><span class="line">| --topic2-0</span><br><span class="line">| --topic2-1</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Segment 是 Kafka 文件存储的最小单位。</strong><code>Segment</code> 文件命名规则：<code>Partition</code> 全局的第一个 <code>Segment</code>从 0 开始，后续每个<code>Segment</code> 文件名为上一个 <code>Segment</code>文件最后一条消息的<code>offset</code>值。数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用0填充。如<code>00000000000000368769.index</code> 和<code>00000000000000368769.log</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上面的一对 <code>Segment File</code> 为例，说明一下索引文件和数据文件对应关系：</p>
<p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210640.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中以索引文件中元数据 <code>&lt;3, 497&gt;</code> 为例，依次在数据文件中表示第 3 个 <code>message</code>（在全局<code>Partition</code> 表示第 <code>368769 + 3 = 368772</code>个<code>message</code>）以及该消息的物理偏移地址为<code>497</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意该<code>index</code> 文件并不是从0开始，也不是每次递增1的，这是因为<code>Kafka</code>采取<strong>稀疏索引</strong>存储的方式，每隔一定字节的数据建立一条索引，它减少了索引文件大小，使得能够把<code>index</code> 映射到内存，降低了查询时的磁盘 <code>IO</code>开销，同时也并没有给查询带来太多的时间消耗。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为其文件名为上一个 <code>Segment</code>最后一条消息的<code>offset</code> ，所以当需要查找一个指定<code>offset</code> 的 <code>message</code>时，通过在所有 <code>segment</code>的文件名中进行<strong>二分查找</strong>就能找到它归属的 <code>segment</code> ，再在其 <code>index</code> 文件中找到其对应到文件上的物理位置，就能拿出该 <code>message</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于消息在 <code>Partition</code> 的<code>Segment</code>数据文件中是顺序读写的，且<strong>消息消费后不会删除（删除策略是针对过期的<code>Segment</code> 文件）</strong>，这种顺序磁盘<code>IO</code> 存储设计师<code>Kafka</code> 高性能很重要的原因。</p>
<blockquote>
<p>Kafka 是如何准确的知道 message 的偏移的呢？这是因为在 Kafka 定义了标准的数据存储结构，在 Partition 中的每一条 message 都包含了以下三个属性：</p>
<ul>
<li>offset：表示 message 在当前 Partition 中的偏移量，是一个逻辑上的值，唯一确定了 Partition 中的一条 message，可以简单的认为是一个 id；</li>
<li>MessageSize：表示 message 内容 data 的大小；</li>
<li>data：message 的具体内容</li>
</ul>
</blockquote>
<h3 id="讨论三：生产者设计概要"><a href="#讨论三：生产者设计概要" class="headerlink" title="讨论三：生产者设计概要"></a>讨论三：生产者设计概要</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当我们发送消息之前，先问几个问题：每条消息都是很关键且不能容忍丢失么？偶尔重复消息可以么？我们关注的是消息延迟还是写入消息的吞吐量？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;举个例子，有一个信用卡交易处理系统，当交易发生时会发送一条消息到 <code>Kafka</code>，另一个服务来读取消息并根据规则引擎来检查交易是否通过，将结果通过<code>Kafka</code>返回。对于这样的业务，消息既不能丢失也不能重复，由于交易量大因此吞吐量需要尽可能大，延迟可以稍微高一点。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;再举个例子，假如我们需要收集用户在网页上的点击数据，对于这样的场景，少量消息丢失或者重复是可以容忍的，延迟多大都不重要只要不影响用户体验，吞吐则根据实时用户数来决定。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不同的业务需要使用不同的写入方式和配置。具体的方式我们在这里不做讨论，现在先看下生产者写消息的基本流程：</p>
<p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210649.png" alt="img"></p>
<p>流程如下：</p>
<ol>
<li>首先，我们需要创建一个<code>ProducerRecord</code>，这个对象需要包含消息的主题（<code>topic</code>）和值（<code>value</code>），可以选择性指定一个键值（<code>key</code>）或者分区（<code>partition</code>）。</li>
<li>发送消息时，生产者会对键值和值序列化成字节数组，然后发送到分配器（<code>partitioner</code>）。</li>
<li>如果我们指定了分区，那么分配器返回该分区即可；否则，分配器将会基于键值来选择一个分区并返回。</li>
<li>选择完分区后，生产者知道了消息所属的主题和分区，它将这条记录添加到相同主题和分区的批量消息中，另一个线程负责发送这些批量消息到对应的<code>Kafka broker</code>。</li>
<li>当<code>broker</code>接收到消息后，如果成功写入则返回一个包含消息的主题、分区及位移的<code>RecordMetadata</code>对象，否则返回异常。</li>
<li>生产者接收到结果后，对于异常可能会进行重试。</li>
</ol>
<h3 id="讨论四：消费者设计概要"><a href="#讨论四：消费者设计概要" class="headerlink" title="讨论四：消费者设计概要"></a>讨论四：消费者设计概要</h3><h4 id="消费者与消费组"><a href="#消费者与消费组" class="headerlink" title="消费者与消费组"></a>消费者与消费组</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设这么个场景：我们从<code>Kafka</code>中读取消息，并且进行检查，最后产生结果数据。我们可以创建一个消费者实例去做这件事情，但如果生产者写入消息的速度比消费者读取的速度快怎么办呢？这样随着时间增长，消息堆积越来越严重。对于这种场景，我们需要增加多个消费者来进行水平扩展。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Kafka</code>消费者是<strong>消费组</strong>的一部分，<strong>当多个消费者形成一个消费组来消费主题时，每个消费者会收到不同分区的消息</strong>。假设有一个<code>T1</code>主题，该主题有4个分区；同时我们有一个消费组<code>G1</code>，这个消费组只有一个消费者<code>C1</code>。那么消费者<code>C1</code>将会收到这4个分区的消息，如下所示：</p>
<p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210656.png" alt="img"></p>
<p>如果增加到4个消费者，那么每个消费者将会分别收到一个分区的消息，如下所示：</p>
<p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210704.png" alt="img"></p>
<p>但如果我们继续增加消费者到这个消费组，剩余的消费者将会空闲，不会收到任何消息：</p>
<p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210731.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总而言之，我们<strong>可以通过增加消费组的消费者来进行水平扩展提升消费能力</strong>。这也是为什么建议创建主题时使用比较多的分区数，这样可以在消费负载高的情况下增加消费者来提升性能。另外，消费者的数量不应该比分区数多，因为多出来的消费者是空闲的，没有任何帮助。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Kafka一个很重要的特性就是，只需写入一次消息，可以支持任意多的应用读取这个消息。</strong>换句话说，每个应用都可以读到全量的消息。为了使得每个应用都能读到全量消息，应用需要有不同的消费组。对于上面的例子，假如我们新增了一个新的消费组G2，而这个消费组有两个消费者，那么会是这样的：</p>
<p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210739.png" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个场景中，消费组G1和消费组G2都能收到T1主题的全量消息，在逻辑意义上来说它们属于不同的应用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，总结起来就是：<strong>如果应用需要读取全量消息，那么请为该应用设置一个消费组；如果该应用消费能力不足，那么可以考虑在这个消费组里增加消费者</strong>。</p>
<h4 id="消费组与分区重平衡"><a href="#消费组与分区重平衡" class="headerlink" title="消费组与分区重平衡"></a>消费组与分区重平衡</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到，当新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其他消费者负责的；另外，当消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区。这种现象称为<strong>重平衡（rebalance）</strong>。重平衡是 <code>Kafka</code> 一个很重要的性质，这个性质保证了高可用和水平扩展。<strong>不过也需要注意到，在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。</strong>而且，将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，这段期间也会降低消费性能。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;消费者通过定期发送心跳（<code>hearbeat</code>）到一个作为组协调者（<code>group coordinator</code>）的 <code>broker</code> 来保持在消费组内存活。这个 <code>broker</code> 不是固定的，每个消费组都可能不同。当消费者拉取消息或者提交时，便会发送心跳。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>如果消费者超过一定时间没有发送心跳，那么它的会话（<code>session</code>）就会过期，组协调者会认为该消费者已经宕机，然后触发重平衡</strong>。可以看到，<strong>从消费者宕机到会话过期是有一定时间的，这段时间内该消费者的分区都不能进行消息消费</strong>；通常情况下，我们可以进行优雅关闭，这样消费者会发送离开的消息到组协调者，这样组协调者可以立即进行重平衡而不需要等待会话过期。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在 <code>0.10.1</code>版本，<code>Kafka</code> 对心跳机制进行了修改，将发送心跳与拉取消息进行分离，这样使得发送心跳的频率不受拉取的频率影响。另外更高版本的 <code>Kafka</code> 支持配置一个消费者多长时间不拉取消息但仍然保持存活，这个配置可以避免活锁（<code>livelock</code>）。活锁，是指应用没有故障但是由于某些原因不能进一步消费。</p>
<h4 id="Partition-与消费模型"><a href="#Partition-与消费模型" class="headerlink" title="Partition 与消费模型"></a>Partition 与消费模型</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Kafka</code> 中一个 <code>topic</code>中的消息是被打散分配在多个 <code>Partition</code>(分区) 中存储的， <code>Consumer Group</code>在消费时需要从不同的 <code>Partition</code> 获取消息，那最终如何重建出 <code>Topic</code>中消息的顺序呢？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答案是：没有办法。<strong><code>Kafka</code> 只会保证在 <code>Partition</code>内消息是有序的，而不管全局的情况</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下一个问题是：<code>Partition</code>中的消息可以被（不同的 <code>Consumer Group</code>）多次消费，那 <code>Partition</code>中被消费的消息是何时删除的？ <code>Partition</code> 又是如何知道一个<code>Consumer Group</code> 当前消费的位置呢？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>无论消息是否被消费，除非消息到期 <code>Partition</code>从不删除消息</strong>。例如设置保留时间为 2 天，则消息发布 2 天内任何<code>Group</code>都可以消费，2 天后，消息自动被删除。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Partition</code>会为每个<code>Consumer Group</code> 保存一个偏移量，记录<code>Group</code> 消费到的位置。 如下图：</p>
<p><img src="//blog.com/2019/08/17/Kafka原理了解/20190717210747.png" alt="img"></p>
<h4 id="为什么-Kafka-是-pull-模型"><a href="#为什么-Kafka-是-pull-模型" class="headerlink" title="为什么 Kafka 是 pull 模型"></a>为什么 Kafka 是 pull 模型</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;消费者应该向 <code>Broker</code> 要数据（<code>pull</code>）还是<code>Broker</code> 向消费者推送数据（<code>push</code>）？作为一个消息系统，<code>Kafka</code> 遵循了传统的方式，选择由<code>Producer</code> 向<code>broker push</code>消息并由<code>Consumer</code> 从 <code>broker pull</code>消息。一些 <code>logging-centric system</code>，比如 <code>Facebook</code> 的<a href="https://github.com/facebookarchive/scribe" target="_blank" rel="noopener">Scribe</a>和<code>Cloudera</code>的<a href="http://flume.apache.org/" target="_blank" rel="noopener">Flume</a>，采用<code>push</code>模式。事实上，<code>push</code> 模式和<code>pull</code> 模式各有优劣。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>push 模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。</strong><code>push</code>模式的目标是尽可能以最快速度传递消息，但是这样很容易造成<code>Consumer</code> 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>而 pull 模式则可以根据 Consumer 的消费能力以适当的速率消费消息。</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>对于 Kafka 而言，pull 模式更合适。</strong></p>
<ol>
<li><code>pull</code> 模式可简化<code>broker</code> 的设计</li>
<li><code>Consumer</code>可自主控制消费消息的速率</li>
<li><code>Consumer</code> 可以自己控制消费方式——即可批量消费也可逐条消费</li>
<li><code>Consumer</code>能选择不同的提交方式从而实现不同的传输语义</li>
</ol>
<h3 id="讨论五：Kafka-如何保证可靠性"><a href="#讨论五：Kafka-如何保证可靠性" class="headerlink" title="讨论五：Kafka 如何保证可靠性"></a>讨论五：Kafka 如何保证可靠性</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当我们讨论<strong>可靠性</strong>的时候，我们总会提到保证这个词语。可靠性保证是基础，我们基于这些基础之上构建我们的应用。比如关系型数据库的可靠性保证是<code>ACID</code>，也就是原子性（<code>Atomicity</code>）、一致性（<code>Consistency</code>）、隔离性（<code>Isolation</code>）和持久性（<code>Durability</code>）。</p>
<p><code>Kafka</code> 中的可靠性保证有如下四点：</p>
<ul>
<li><strong>对于一个分区来说，它的消息是有序的</strong>。如果一个生产者向一个分区先写入消息A，然后写入消息B，那么消费者会先读取消息A再读取消息B。</li>
<li>当消息写入所有<code>in-sync</code>状态的<strong>副本</strong>后，消息才会认为<strong>已提交（committed）</strong>。这里的写入有可能只是写入到文件系统的缓存，不一定刷新到磁盘。生产者可以等待不同时机的确认，比如等待分区主副本写入即返回，后者等待所有<code>in-sync</code>状态副本写入才返回。</li>
<li><strong>一旦消息已提交，那么只要有一个副本存活，数据不会丢失</strong>。</li>
<li><strong>消费者只能读取到已提交的消息</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用这些基础保证，我们构建一个可靠的系统，这时候需要考虑一个问题：究竟我们的应用需要多大程度的可靠性？可靠性不是无偿的，它与系统可用性、吞吐量、延迟和硬件价格息息相关，得此失彼。因此，我们往往需要做权衡，一味的追求可靠性并不实际。</p>
<blockquote>
<p>想了解更多戳这里：<a href="http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/21/kafka-data-delivery.html" target="_blank" rel="noopener">http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/21/kafka-data-delivery.html</a></p>
</blockquote>
<h2 id="三、参考资料"><a href="#三、参考资料" class="headerlink" title="三、参考资料"></a>三、参考资料</h2><ol>
<li><a href="https://www.infoq.cn/article/kafka-analysis-part-1" target="_blank" rel="noopener">https://www.infoq.cn/article/kafka-analysis-part-1</a> - Kafka 设计解析（一）：Kafka 背景及架构介绍</li>
<li><a href="http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/06/kafka-Meet-Kafka.html" target="_blank" rel="noopener">http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/06/kafka-Meet-Kafka.html</a> - Kafka系列（一）初识Kafka</li>
<li><a href="https://lotabout.me/2018/kafka-introduction/" target="_blank" rel="noopener">https://lotabout.me/2018/kafka-introduction/</a> - Kafka原理了解介绍</li>
<li><a href="https://www.zhihu.com/question/28925721" target="_blank" rel="noopener">https://www.zhihu.com/question/28925721</a> - Kafka 中的 Topic 为什么要进行分区? - 知乎</li>
<li><a href="https://blog.joway.io/posts/kafka-design-practice/" target="_blank" rel="noopener">https://blog.joway.io/posts/kafka-design-practice/</a> - Kafka 的设计与实践</li>
<li><a href="http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/21/kafka-data-delivery.html" target="_blank" rel="noopener">http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/21/kafka-data-delivery.html</a> - Kafka系列（六）可靠的数据传输</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/19/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><span class="page-number current">20</span><a class="page-number" href="/page/21/">21</a><span class="space">&hellip;</span><a class="page-number" href="/page/147/">147</a><a class="extend next" rel="next" href="/page/21/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">刘泽明</p>
              <p class="site-description motion-element" itemprop="description">做一个懂业务的程序员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">731</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">394</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">237</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘泽明</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
