<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="搬运工 + 践行者" type="application/atom+xml">






<meta name="description" content="做一个懂业务的程序员">
<meta property="og:type" content="website">
<meta property="og:title" content="搬运工 + 践行者">
<meta property="og:url" content="http://blog.com/page/26/index.html">
<meta property="og:site_name" content="搬运工 + 践行者">
<meta property="og:description" content="做一个懂业务的程序员">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="搬运工 + 践行者">
<meta name="twitter:description" content="做一个懂业务的程序员">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.com/page/26/">





  <title>搬运工 + 践行者</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">搬运工 + 践行者</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">记录学习的技能和遇到的问题</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/13/Redis的Linux系统优化/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/13/Redis的Linux系统优化/" itemprop="url">Redis的Linux系统优化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-13T12:12:57+08:00">
                2019-07-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Redis的Linux系统优化"><a href="#Redis的Linux系统优化" class="headerlink" title="Redis的Linux系统优化"></a>Redis的Linux系统优化</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="https://cachecloud.github.io/2017/02/16/Redis%E7%9A%84Linux%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/" target="_blank" rel="noopener">https://cachecloud.github.io/2017/02/16/Redis%E7%9A%84Linux%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/</a></p>
</blockquote>
<p><br></p>
<h2 id="一-内存分配控制"><a href="#一-内存分配控制" class="headerlink" title="一. 内存分配控制"></a>一. 内存分配控制</h2><h3 id="1-vm-overcommit-memory"><a href="#1-vm-overcommit-memory" class="headerlink" title="1. vm.overcommit_memory"></a>1. vm.overcommit_memory</h3><p><code>Redis</code>在启动时可能会出现这样的日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &apos;vm.overcommit_memory = 1&apos; to /etc/sysctl.conf and then reboot or run the </span><br><span class="line">command &apos;sysctl vm.overcommit_memory=1&apos; for this to take effect.</span><br></pre></td></tr></table></figure>
<p>在分析这个问题之前，首先要弄清楚什么是<code>overcommit</code>？Linux操作系统对大部分申请内存的请求都回复yes，以便能运行更多的程序。因为申请内存后，并不会马上使用内存，这种技术叫做<code>overcommit</code>。如果Redis在启动时有上面的日志，说明<code>vm.overcommit_memory=0</code>，Redis提示把它设置为1。</p>
<p><code>vm.overcommit_memory</code>用来设置内存分配策略，它有三个可选值，如下表所示。</p>
<table>
<thead>
<tr>
<th style="text-align:left">vm.overcommit_memory</th>
<th style="text-align:left">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">表示内核将检查是否有足够的可用内存。如果有足够的可用内存，内存申请通过，否则内存申请失败，并把错误返回给应用进程</td>
</tr>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left">表示内核允许超量使用内存直到用完为止</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left">表示内核决不过量的(“never overcommit”)使用内存，即系统整个内存地址空间不能超过swap+50%的RAM值，50%是overcommit_ratio默认值，此参数同样支持修改</td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：本文的可用内存代表物理内存与swap之和。</span><br></pre></td></tr></table></figure>
<p>日志中的<code>Background save</code>代表的是<code>bgsave</code>和<code>bgrewriteaof</code>，如果当前可用内存不足，操作系统应该如何处理<code>fork</code>。如果<code>vm.overcommit_memory=0</code>，代表如果没有可用内存，就申请内存失败，对应到Redis就是<code>fork</code>执行失败，在Redis的日志会出现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cannot allocate memory</span><br></pre></td></tr></table></figure>
<p>Redis建议把这个值设置为1，是为了让<code>fork</code>能够在低内存下也执行成功。</p>
<h3 id="2-获取和设置"><a href="#2-获取和设置" class="headerlink" title="2. 获取和设置"></a>2. 获取和设置</h3><h4 id="获取："><a href="#获取：" class="headerlink" title="获取："></a>获取：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/sys/vm/overcommit_memory</span><br><span class="line">0</span><br></pre></td></tr></table></figure>
<h4 id="设置："><a href="#设置：" class="headerlink" title="设置："></a>设置：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;vm.overcommit_memory=1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line">sysctl vm.overcommit_memory=1</span><br></pre></td></tr></table></figure>
<h3 id="3-最佳实践"><a href="#3-最佳实践" class="headerlink" title="3. 最佳实践"></a>3. 最佳实践</h3><ul>
<li>Redis设置合理的<code>maxmemory</code>，保证机器有20%~30%的闲置内存。</li>
<li>集中化管理<code>aof</code>重写和<code>rdb</code>的<code>bgsave</code>。</li>
<li>设置<code>vm.overcommit_memory=1</code>，防止极端情况下，会造成<code>fork</code>失败。</li>
</ul>
<h2 id="二-swappiness"><a href="#二-swappiness" class="headerlink" title="二. swappiness"></a>二. swappiness</h2><h3 id="1-参数说明"><a href="#1-参数说明" class="headerlink" title="1. 参数说明"></a>1. 参数说明</h3><p><code>swap</code>对于操作系统来比较重要，当物理内存不足时，可以<code>swap out</code>一部分内存页，已解燃眉之急。但世界上没有免费午餐，<code>swap</code>空间由硬盘提供，对于需要高并发、高吞吐的应用来说，磁盘IO通常会成为系统瓶颈。<strong>在Linux中，并不是要等到所有物理内存都使用完才会使用到<code>swap</code>，系统参数<code>swppiness</code>会决定操作系统使用<code>swap</code>的倾向程度</strong>。<code>swappiness</code>的取值范围是<code>0~100</code>，<code>swappiness</code>的值越大，说明操作系统可能使用<code>swap</code>的概率越高，<code>swappiness</code>值越低，表示操作系统更加倾向于使用物理内存。<code>swap</code>的默认值是60，了解这个值的含义后，有利于Redis的性能优化。下表对<code>swappiness</code>的重要值进行了说明。</p>
<table>
<thead>
<tr>
<th style="text-align:left">swapniess</th>
<th style="text-align:left">策略</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">Linux3.5以及以上：宁愿OOM killer也不用swap<br> Linux3.4以及更早：宁愿swap也不要OOM killer</td>
</tr>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left">Linux3.5以及以上：宁愿swap也不要OOM killer</td>
</tr>
<tr>
<td style="text-align:left">60</td>
<td style="text-align:left">默认值</td>
</tr>
<tr>
<td style="text-align:left">100</td>
<td style="text-align:left">操作系统会主动地使用swap</td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">运维提示：OOM(Out Of Memory) killer机制是指Linux操作系统发现可用内存不足时，强制杀死一些用户进程（非内核进程），来保证系统有足够的可用内存进行分配。</span><br></pre></td></tr></table></figure>
<p>从下表中可以看出，<code>swappiness</code>参数在Linux 3.5版本前后的表现并不完全相同，Redis运维人员在设置这个值需要关注当前操作系统的内核版本。</p>
<h3 id="2-设置方法"><a href="#2-设置方法" class="headerlink" title="2. 设置方法"></a>2. 设置方法</h3><p><code>swappiness</code>设置方法如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &#123;bestvalue&#125; &gt; /proc/sys/vm/swappiness</span><br></pre></td></tr></table></figure>
<p>但是上述方法在系统重启后就会失效，为了让配置在重启Linux操作系统后立即生效，只需要在<code>/etc/sysctl.conf</code>追加 <code>vm.swappiness={bestvalue}</code>即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo vm.swappiness=&#123;bestvalue&#125; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure>
<p>需要注意<code>/proc/sys/vm/swappiness</code>是设置操作，<code>/etc/sysctl.conf</code>是追加操作。</p>
<h3 id="3-如何监控swap"><a href="#3-如何监控swap" class="headerlink" title="3. 如何监控swap"></a>3. 如何监控swap</h3><h4 id="1-查看swap的总体情况"><a href="#1-查看swap的总体情况" class="headerlink" title="(1) 查看swap的总体情况"></a>(1) 查看swap的总体情况</h4><p>Linux提供了<code>free</code>命令来查询操作系统的内存使用情况，其中也包含了<code>swap</code>的相关使用情况。下面是某台Linux服务器执行<code>free –m</code>(以兆为到位)的结果，其中需要重点关注的是最后一行的<code>swap</code>统计，从执行结果看，<code>swap</code>一共有4095M，使用了0M，空闲了4095M。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">             total       used       free     shared    buffers     cached</span><br><span class="line">Mem:         64385      31573      32812          0        505      10026</span><br><span class="line">-/+ buffers/cache:      21040      43344</span><br><span class="line">Swap:         4095          0       4095</span><br></pre></td></tr></table></figure>
<p>在另一台Linux服务器同样执行free -m，这台服务器开启了8189M <code>swap</code>，其中使用了5241M。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">             total       used       free     shared    buffers     cached</span><br><span class="line">Mem:         24096       8237      15859          0        136       2483</span><br><span class="line">-/+ buffers/cache:       5617      18479</span><br><span class="line">Swap:         8189       5241       2947</span><br></pre></td></tr></table></figure>
<h4 id="2-实时查看swap的使用"><a href="#2-实时查看swap的使用" class="headerlink" title="(2) 实时查看swap的使用"></a>(2) 实时查看swap的使用</h4><p>Linux提供了<code>vmstat</code>命令查询系统的相关性能指标，其中包含负载、CPU、内存、swap、IO的相关属性。但其中和<strong>swap有关的指标是si和so，它们分别代表了操作系统的swap in和swap out</strong>。下面是执行<code>vmstat 1</code>（每隔一秒输出）的效果，可以看到<code>si</code>和<code>so</code>都为0，代表当前没有使用<code>swap</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># vmstat  1</span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line"> 1  0      0 33593468 517656 10271928    0    0     0     1    0    0  8  0 91  0  0	</span><br><span class="line"> 4  0      0 33594516 517656 10271928    0    0     0     0 10606 9647 10  1 90  0  0	</span><br><span class="line"> 1  0      0 33594392 517656 10271928    0    0     0     0 11490 10244 11  1 89  0  0	</span><br><span class="line"> 6  0      0 33594292 517656 10271928    0    0     0    36 12406 10681 13  1 87  0  0</span><br></pre></td></tr></table></figure>
<h4 id="3-查看指定进程的swap使用情况"><a href="#3-查看指定进程的swap使用情况" class="headerlink" title="(3) 查看指定进程的swap使用情况"></a>(3) 查看指定进程的swap使用情况</h4><p>Linux操作系统中，<code>/proc/{pid}</code>目录是存储指定进程的相关信息，其中<strong><code>/proc/{pid}/smaps</code>是记录了当前进程所对应的内存映像信息</strong>，这个信息对于查询指定进程的<code>swap</code>使用情况很有帮助。下面以一个Redis实例进行说明</p>
<p>通过<code>info server</code>获取Redis的进程号<code>process_id</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h ip -p port info server | grep process_id</span><br><span class="line">process_id:986</span><br></pre></td></tr></table></figure>
<p>通过<code>cat /proc/986/smaps</code>查询Redis的<code>smaps</code>信息，由于有多个内存块信息，这里只输出一个内存块镜像信息进行观察。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">2aab0a400000-2aab35c00000 rw-p 2aab0a400000 00:00 0 </span><br><span class="line">Size:            712704 kB</span><br><span class="line">Rss:             617872 kB</span><br><span class="line">Shared_Clean:         0 kB</span><br><span class="line">Shared_Dirty:         0 kB</span><br><span class="line">Private_Clean:    15476 kB</span><br><span class="line">Private_Dirty:   602396 kB</span><br><span class="line">Swap:             58056 kB</span><br><span class="line">Pss:             617872 kB</span><br></pre></td></tr></table></figure>
<p>其中<strong><code>Swap</code>字段代表该内存块存在<code>swap</code>分区的数据大小</strong>。通过执行如下命令，就可以找到每个内存块镜像信息中，这个进程使用到的<code>swap</code>量，通过求和就可以算出总的<code>swap</code>用量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/986/smaps | grep Swap</span><br><span class="line">Swap:                 0 kB</span><br><span class="line">Swap:                 0 kB</span><br><span class="line">…</span><br><span class="line">Swap:                 0 kB</span><br><span class="line">Swap:            478320 kB</span><br><span class="line">…</span><br><span class="line">Swap:               624 kB</span><br><span class="line">Swap:                 0 kB</span><br></pre></td></tr></table></figure>
<h3 id="4-最佳实践"><a href="#4-最佳实践" class="headerlink" title="4. 最佳实践"></a>4. 最佳实践</h3><p>如果<code>Linux&gt;3.5，vm.swapniess=1</code>，否则<code>vm.swapniess=0</code>，从而实现如下两个目标：</p>
<ul>
<li>物理内存充足时候，使Redis足够快。</li>
<li>物理内存不足时候，避免<code>Redis</code>死掉(如果当前<code>Redis</code>为高可用，死掉比阻塞更好)。</li>
</ul>
<h2 id="三-Transparent-Huge-Pages"><a href="#三-Transparent-Huge-Pages" class="headerlink" title="三. Transparent Huge Pages"></a>三. Transparent Huge Pages</h2><p>Redis在启动时可能会看到如下日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &apos;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&apos; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.</span><br></pre></td></tr></table></figure>
<p>从提示看Redis建议修改<code>Transparent Huge Pages (THP)</code>的相关配置，Linux kernel在2.6.38内核增加了<code>Transparent Huge Pages (THP)</code>特性 ，<strong>支持大内存页(2MB)分配，默认开启</strong>。当开启时可以降低<code>fork</code>子进程的速度，但<code>fork</code>之后，每个内存页从原来4KB变为2MB，会<strong>大幅增加重写期间父进程内存消耗。同时每次写命令引起的复制内存页单位放大了512倍，会拖慢写操作的执行时间，导致大量写操作慢查询</strong>。例如简单的<code>incr</code>命令也会出现在慢查询中。因此Redis日志中建议将此特性进行禁用，禁用方法如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo never &gt;  /sys/kernel/mm/transparent_hugepage/enabled</span><br></pre></td></tr></table></figure>
<p>而且为了使机器重启后THP配置依然生效，可以在<code>/etc/rc.local</code>中追加<code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code>。</p>
<p>在设置THP配置时需要注意：有些Linux的发行版本没有将THP放到<code>/sys/kernel/mm/transparent_hugepage/enabled</code>中，例如Red Hat 6以上的THP配置放到<code>/sys/kernel/mm/redhat_transparent_hugepage/enabled</code>中。而Redis源码中检查<code>THP</code>时，把THP位置写死。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FILE *fp = fopen(&quot;/sys/kernel/mm/transparent_hugepage/enabled&quot;,&quot;r&quot;);</span><br><span class="line">if (!fp) return 0;</span><br></pre></td></tr></table></figure>
<p>所以在发行版中，虽然没有<code>THP</code>的日志提示，但是依然存在<code>THP</code>所带来的问题。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo never &gt;  /sys/kernel/mm/redhat_transparent_hugepage/enabled</span><br></pre></td></tr></table></figure>
<h2 id="四-OOM-killer"><a href="#四-OOM-killer" class="headerlink" title="四. OOM killer"></a>四. OOM killer</h2><p><code>OOM killer</code>会在可用内存不足时<strong>选择性的杀掉用户进程</strong>，它的运行规则是怎样的，会选择哪些用户进程“下手”呢？<code>OOM killer</code>进程会<strong>为每个用户进程设置一个权值，这个权值越高，被“下手”的概率就越高，反之概率越低</strong>。每个进程的权值存放在<code>/proc/{progress_id}/oom_score</code>中，这个值是受<code>/proc/{progress_id}/oom_adj</code>的控制，<code>oom_adj</code>在不同的Linux版本的最小值不同，可以参考Linux源码中oom.h(从-15到-17)。当<code>oom_adj</code>设置为最小值时，该进程将不会被<code>OOM killer</code>杀掉，设置方法如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &#123;value&#125; &gt; /proc/$&#123;process_id&#125;/oom_adj</span><br></pre></td></tr></table></figure>
<p>对于Redis所在的服务器来说，可以将所有<code>Redis</code>的<code>oom_adj</code>设置为最低值或者稍小的值，降低被<code>OOM killer</code>杀掉的概率。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for redis_pid in $(pgrep -f &quot;redis-server&quot;)</span><br><span class="line">do</span><br><span class="line">  echo -17 &gt; /proc/$&#123;redis_pid&#125;/oom_adj</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h3 id="运维提示："><a href="#运维提示：" class="headerlink" title="运维提示："></a>运维提示：</h3><ul>
<li>有关<code>OOM killer</code>的详细细节，可以参考Linux源码<code>mm/oom_kill.c</code>中<code>oom_badness</code>函数。</li>
<li>笔者认为<code>oom_adj</code>参数只能起到辅助作用，合理的规划内存更为重要。</li>
<li>通常在高可用情况下，被杀掉比僵死更好，因此不要过多依赖<code>oom_adj</code>配置</li>
</ul>
<h2 id="五-使用NTP"><a href="#五-使用NTP" class="headerlink" title="五. 使用NTP"></a>五. 使用NTP</h2><p><strong><code>NTP(Network Time Protocol)</code>网络时间协议，一种保证不同机器时钟一致性的服务</strong>。我们知道像<code>Redis Sentinel</code>和<code>Redis Cluster</code>这两种需要多个<code>Redis</code>实例的类型，可能会涉及多台服务器。虽然<code>Redis</code>并没有对多个服务器的时钟有严格的要求，但是假如多个<code>Redis</code>实例所在的服务器时钟不一致，对于一些异常情况的日志排查是非常困难的，例如<code>Redis Cluster</code>的故障转移，如果日志时间不一致，对于我们排查问题带来很大的困扰(注：但不会影响集群功能，集群节点依赖各自时钟)。一般公司里都会有<code>NT</code>P服务用来提供标准时间服务，从而达到纠正时钟的效果(如下图所示)，为此我们<strong>可以每天定时去同步一次系统时间，从而使得集群中的时间是统一</strong>。</p>
<p><img src="//blog.com/2019/07/13/Redis的Linux系统优化/3084_3bb93b70_695d_bfa8_69d4_6acce0e01f40_1.png" alt="img"></p>
<p>例如每小时的同步1次NTP服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 * * * * /usr/sbin/ntpdate ntp.xx.com &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
<h2 id="六-ulimit"><a href="#六-ulimit" class="headerlink" title="六. ulimit"></a>六. ulimit</h2><p>在Linux中，可以通过<code>ulimit</code>查看和设置系统的当前用户进程的<strong>资源数</strong>。其中<code>ulimit -a</code>命令包含的<code>open files</code>参数，是单个用户同时打开的最大文件个数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># ulimit –a</span><br><span class="line">…</span><br><span class="line">max locked memory       (kbytes, -l) 64</span><br><span class="line">max memory size         (kbytes, -m) unlimited</span><br><span class="line">open files                      (-n) 1024</span><br><span class="line">pipe size            (512 bytes, -p) 8</span><br><span class="line">…</span><br></pre></td></tr></table></figure>
<p>Redis允许同时有多个客户端通过网络进行连接，可以通过配置<code>maxclients</code>来限制最大客户端连接数。对Linux操作系统来说这些网络连接都是文件句柄。假设当前<code>open files</code>是4096，那么启动Redis时会看到如下日志。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># You requested maxclients of 10000 requiring at least 10032 max file descriptors.</span><br><span class="line"># Redis can’t set maximum open files to 10032 because of OS error: Operation not permitted.</span><br><span class="line"># Current maximum open files is 4096. Maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase ‘ulimit –n’.</span><br></pre></td></tr></table></figure>
<p>上面的日志解释如下：</p>
<ul>
<li><p>第一行：Redis建议把<code>open files</code>至少设置成10032，那么这个10032是如何来的呢？因为<code>maxclients</code>的默认是10000，这些是用来处理客户端连接的，除此之外，Redis内部会使用最多32个文件描述符，所以这里的10032 = 10000 + 32。</p>
</li>
<li><p>第二行：Redis不能将<code>open files</code>设置成10032，因为它没有权限设置。</p>
</li>
<li><p>第三行：当前系统的<code>open files</code>是4096，所以<code>maxclients</code>被设置成4096-32=4064个，如果你想设置更高的<code>maxclients</code>，请使用<code>ulimit -n</code>来设置。<br>从上面的三行日志分析可以看出<strong><code>open files</code>的限制优先级比<code>maxclients</code>大</strong>。</p>
</li>
</ul>
<p>  <code>open files</code>的设置方法如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ulimit –Sn &#123;max-open-files&#125;</span><br></pre></td></tr></table></figure>
<h2 id="七-TCP-backlog"><a href="#七-TCP-backlog" class="headerlink" title="七. TCP backlog"></a>七. TCP backlog</h2><p>Redis默认的<code>tcp-backlog</code>为511，可以通过修改配置<code>tcp-backlog</code>进行调整，如果Linux的<code>tcp-backlog</code>小于Redis设置的<code>tcp-backlog</code>，那么在Redis启动时会看到如下日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.</span><br></pre></td></tr></table></figure>
<p>查看方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/sys/net/core/somaxconn</span><br><span class="line">128</span><br></pre></td></tr></table></figure>
<p>修改方法：.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 511 &gt; /proc/sys/net/core/somaxconn</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/13/磁盘IO那些事/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/13/磁盘IO那些事/" itemprop="url">磁盘IO那些事</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-13T12:12:57+08:00">
                2019-07-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/磁盘IO/" itemprop="url" rel="index">
                    <span itemprop="name">磁盘IO</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="磁盘IO那些事"><a href="#磁盘IO那些事" class="headerlink" title="磁盘IO那些事"></a>磁盘IO那些事</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="https://mp.weixin.qq.com/s/HCaR5esmDIpRROVdPcESvQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/HCaR5esmDIpRROVdPcESvQ</a></p>
</blockquote>
<p><br></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;计算机硬件性能在过去十年间的发展普遍遵循摩尔定律，通用计算机的<code>CPU</code>主频早已超过<code>3GHz</code>，内存也进入了普及<code>DDR4</code>的时代。然而传统硬盘虽然在存储容量上增长迅速，但是在读写性能上并无明显提升，同时<code>SSD</code>硬盘价格高昂，不能在短时间内完全替代传统硬盘。传统磁盘的I/O读写速度成为了计算机系统性能提高的瓶颈，制约了计算机整体性能的发展。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;硬盘性能的制约因素是什么？如何根据磁盘<code>I/O</code>特性来进行系统设计？针对这些问题，本文将介绍硬盘的物理结构和性能指标，以及操作系统针对磁盘性能所做的优化，最后讨论下基于磁盘<code>I/O</code>特性设计的技巧。</p>
<h2 id="硬盘的物理结构"><a href="#硬盘的物理结构" class="headerlink" title="硬盘的物理结构"></a>硬盘的物理结构</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：</p>
<p><img src="//blog.com/2019/07/13/磁盘IO那些事/1.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区，硬盘中每个扇区的大小固定为512字节。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示：</p>
<p><img src="//blog.com/2019/07/13/磁盘IO那些事/2.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;早期的硬盘每磁道扇区数相同，此时由磁盘基本参数可以计算出硬盘的容量：存储容量=磁头数*磁道（柱面）数*每道扇区数*每扇区字节数。<strong>由于每磁道扇区数相同，外圈磁道半径大，里圈磁道半径小，外圈和里圈扇区面积自然会不一样。同时，为了更好的读取数据，即使外圈扇区面积再大也只能和内圈扇区一样存放相同的字节数（512字节）</strong>。这样一来，外圈的记录密度就要比内圈小，会浪费大量的存储空间。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如今的硬盘都使用<code>ZBR</code>（<code>Zoned Bit Recording</code>，区位记录）技术，<strong>盘片表面由里向外划分为数个区域，不同区域的磁道扇区数目不同，同一区域内各磁道扇区数相同，盘片外圈区域磁道长扇区数目较多，内圈区域磁道短扇区数目较少，大体实现了等密度，从而获得了更多的存储空间</strong>。此时，由于每磁道扇区数各不相同，所以传统的容量计算公式就不再适用。实际上如今的硬盘大多使用<code>LBA</code>（<code>Logical Block Addressing</code>）<strong>逻辑块寻址模式</strong>，知道<code>LBA</code>后即可计算出硬盘容量。</p>
<h2 id="影响硬盘性能的因素"><a href="#影响硬盘性能的因素" class="headerlink" title="影响硬盘性能的因素"></a>影响硬盘性能的因素</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个<code>I/O</code>请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。</p>
<h3 id="1-寻道时间"><a href="#1-寻道时间" class="headerlink" title="1. 寻道时间"></a>1. 寻道时间</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Tseek</code>是指<strong>将读写磁头移动至正确的磁道上所需要的时间</strong>。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在<code>3-15ms</code>。</p>
<h3 id="2-旋转延迟"><a href="#2-旋转延迟" class="headerlink" title="2. 旋转延迟"></a>2. 旋转延迟</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Trotation</code>是指<strong>盘片旋转将请求数据所在的扇区移动到读写磁盘下方所需要的时间</strong>。<strong>旋转延迟取决于磁盘转速</strong>，通常用磁盘旋转一周所需时间的1/2表示。比如：<code>7200rpm</code>的磁盘平均旋转延迟大约为<code>60*1000/7200/2 = 4.17ms</code>，而转速为<code>15000rpm</code>的磁盘其平均旋转延迟为2ms。</p>
<h3 id="3-数据传输时间"><a href="#3-数据传输时间" class="headerlink" title="3. 数据传输时间"></a>3. 数据传输时间</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Ttransfer</code>是指<strong>完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率</strong>。目前<code>IDE/ATA</code>能达到<code>133MB/s</code>，<code>SATA II</code>可达到<code>300MB/s</code>的接口数据传输率，<strong>数据传输时间通常远小于前两部分消耗时间</strong>。简单计算时可忽略。</p>
<h2 id="衡量性能的指标"><a href="#衡量性能的指标" class="headerlink" title="衡量性能的指标"></a>衡量性能的指标</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;机械硬盘的连续读写性能很好，但<strong>随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高</strong>。衡量磁盘的重要主要指标是<code>IOPS</code>和吞吐量。</p>
<h3 id="1-IOPS"><a href="#1-IOPS" class="headerlink" title="1. IOPS"></a>1. IOPS</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>IOPS（Input/Output Per Second）</code>即<strong>每秒的输入输出量（或读写次数），即指每秒内系统能处理的<code>I/O</code>请求数量</strong>。<strong>随机读写频繁的应用，如小文件存储等，关注随机读写性能，<code>IOPS</code>是关键衡量指标</strong>。可以推算出磁盘的<code>IOPS = 1000ms / (Tseek + Trotation + Transfer)</code>，如果忽略数据传输时间，理论上可以计算出随机读写最大的<code>IOPS</code>。常见磁盘的随机读写最大<code>IOPS</code>为：</p>
<ul>
<li><code>7200rpm</code>的磁盘 <code>IOPS = 76 IOPS</code></li>
<li><code>10000rpm</code>的磁盘<code>IOPS = 111 IOPS</code></li>
<li><code>15000rpm</code>的磁盘<code>IOPS = 166 IOPS</code></li>
</ul>
<h3 id="2-吞吐量"><a href="#2-吞吐量" class="headerlink" title="2. 吞吐量"></a>2. 吞吐量</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;吞吐量（<code>Throughput</code>），指<strong>单位时间内可以成功传输的数据数量</strong>。顺序读写频繁的应用，如视频点播，关注连续读写性能、数据吞吐量是关键衡量指标。它主要<strong>取决于磁盘阵列的架构，通道的大小以及磁盘的个数</strong>。不同的磁盘阵列存在不同的架构，但他们都有自己的内部带宽，一般情况下，内部带宽都设计足够充足，不会存在瓶颈。<strong>磁盘阵列与服务器之间的数据通道对吞吐量影响很大</strong>，比如一个<code>2Gbps</code>的光纤通道，其所能支撑的最大流量仅为<code>250MB/s</code>。最后，当前面的瓶颈都不再存在时，硬盘越多的情况下吞吐量越大。</p>
<h2 id="操作系统层的优化"><a href="#操作系统层的优化" class="headerlink" title="操作系统层的优化"></a>操作系统层的优化</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然<code>15000rpm</code>的磁盘计算出的理论最大<code>IOPS</code>仅为<code>166</code>，但在实际运行环境中，实际磁盘的<code>IOPS</code>往往能够突破200甚至更高。这其实就是在系统调用过程中，操作系统进行了一系列的优化。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么操作系统是如何操作硬盘的呢？类似于网络的分层结构，下图显示了Linux系统中对于磁盘的一次读请求在核心空间中所要经历的层次模型。从图中看出：对于磁盘的一次读请求，首先经过虚拟文件系统层（<code>VFS Layer</code>），其次是具体的文件系统层（例如<code>Ext2</code>），接下来是<code>Cache</code>层（<code>Page Cache Layer</code>）、通用块层（<code>Generic Block Layer</code>）、<code>I/O</code>调度层（<code>I/O Scheduler Layer</code>）、块设备驱动层（<code>Block Device Driver Layer</code>），最后是物理块设备层（<code>Block Device Layer</code>）。</p>
<p><img src="//blog.com/2019/07/13/磁盘IO那些事/3.webp" alt="img"></p>
<h3 id="虚拟文件系统层（VFS-Layer）"><a href="#虚拟文件系统层（VFS-Layer）" class="headerlink" title="虚拟文件系统层（VFS Layer）"></a>虚拟文件系统层（VFS Layer）</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>VFS（Virtual File System）</code>虚拟文件系统是一种软件机制，更<strong>确切的说扮演着文件系统管理者的角色，与它相关的数据结构只存在于物理内存当中</strong>。它的作用是：屏蔽下层具体文件系统操作的差异，为上层的操作提供一个统一的接口。正是因为有了这个层次，<code>Linux</code>中允许众多不同的文件系统共存并且对文件的操作可以跨文件系统而执行。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>VFS</code>中包含着向物理文件系统转换的一系列数据结构，如<code>VFS</code>超级块、<code>VFS</code>的<code>Inode</code>、各种操作函数的转换入口等。<code>Linux</code>中<code>VFS</code>依靠四个主要的数据结构来描述其结构信息，分别为超级块、索引结点、目录项和文件对象。</p>
<h4 id="超级块"><a href="#超级块" class="headerlink" title="超级块"></a>超级块</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;超级块（<code>Super Block</code>）：<strong>超级块对象表示一个文件系统，它存储一个已安装的文件系统的控制信息</strong>，包括文件系统名称（比如<code>Ext2</code>）、文件系统的大小和状态、块设备的引用和元数据信息（比如空闲列表等等）。<code>VFS</code>超级块存在于内存中，它在文件系统安装时建立，并且在文件系统卸载时自动删除。同时需要注意的是<strong>对于每个具体的文件系统来说，也有各自的超级块，它们存放于磁盘</strong>。</p>
<h4 id="索引节点"><a href="#索引节点" class="headerlink" title="索引节点"></a>索引节点</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;索引结点（<code>Inode</code>）：<strong>索引结点对象存储了文件的相关元数据信息</strong>，例如：文件大小、设备标识符、用户标识符、用户组标识符等等。<code>Inode</code>分为两种：一种是<code>VFS</code>的<code>Inode</code>，一种是具体文件系统的<code>Inode</code>。前者在内存中，后者在磁盘中。所以每次其实是将磁盘中的<code>Inode</code>调进填充内存中的<code>Inode</code>，这样才是算使用了磁盘文件<code>Inode</code>。当创建一个文件的时候，就给文件分配了一个<code>Inode</code>。一个<code>Inode</code>只对应一个实际文件，一个文件也会只有一个<code>Inode</code>。</p>
<h4 id="目录项"><a href="#目录项" class="headerlink" title="目录项"></a>目录项</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目录项（<code>Dentry</code>）：<strong>引入目录项对象的概念主要是出于方便查找文件的目的</strong>。不同于前面的两个对象，<strong>目录项对象没有对应的磁盘数据结构，只存在于内存中</strong>。一个路径的各个组成部分，不管是目录还是普通的文件，都是一个目录项对象。如，在路径<code>/home/source/test.java</code>中，目录<code>/</code>, <code>home</code>, <code>source</code>和文件 <code>test.java</code>都对应一个目录项对象。<strong><code>VFS</code>在查找的时候，根据一层一层的目录项找到对应的每个目录项的<code>Inode</code>，那么沿着目录项进行操作就可以找到最终的文件</strong>。</p>
<h4 id="文件对象"><a href="#文件对象" class="headerlink" title="文件对象"></a>文件对象</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;文件对象（<code>File</code>）：<strong>文件对象描述的是进程已经打开的文件</strong>。因为<strong>一个文件可以被多个进程打开，所以一个文件可以存在多个文件对象</strong>。<strong>一个文件对应的文件对象可能不是惟一的，但是其对应的索引节点和目录项对象肯定是惟一的</strong>。</p>
<h3 id="Ext2文件系统"><a href="#Ext2文件系统" class="headerlink" title="Ext2文件系统"></a>Ext2文件系统</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>VFS</code>的下一层即是具体的文件系统，本节简要介绍下Linux的<code>Ext2</code>文件系统。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个文件系统一般使用块设备上一个独立的逻辑分区。对于<code>Ext2</code>文件系统来说，硬盘分区首先被划分为一个个的<code>Block</code>，一个<code>Ext2</code>文件系统上的每个<code>Block</code>都是一样大小的。但是不同<code>Ext2</code>文件系统，<code>Block</code>大小可能不同，这是在创建<code>Ext2</code>系统决定的，一般为<code>1k</code>或者<code>4k</code>。由于<code>Block</code>数量很多，为了方便管理，<strong><code>Ext2</code>将这些<code>Block</code>聚集在一起分为几个大的块组（<code>Block Group</code>），每个块组包含的等量的物理块，在块组的数据块中存储文件或目录</strong>。<code>Ext2</code>文件系统存储结构如下图所示：</p>
<p><img src="//blog.com/2019/07/13/磁盘IO那些事/4.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Ext2</code>中的<code>Super Block</code>和<code>Inode Table</code>分别对应<code>VFS</code>中的超级块和索引结点，存放在磁盘。每个块组都有一个块组描述符<code>GDT（Group Descriptor Table）</code>，存储一个块组的描述信息，例如在这个块组中从哪里开始是<code>Inode</code>表，从哪里开始是数据块等等。<code>Block Bitmap</code>和<code>Inode Bitmap</code>分别表示<code>Block</code>和<code>Inode</code>是否空闲可用。<code>Data Block</code>数据块是用来真正存储文件内容数据的地方，下面我们看一下具体的存储规则。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在<code>Ext2</code>文件系统中所支持的<code>Block</code>大小有<code>1K、2K、4K</code>三种。在格式化时<code>Block</code>的大小就固定了，且<strong>每个<code>Block</code>都有编号，方便<code>Inode</code>的记录</strong>。<strong>每个<code>Block</code>内最多只能够放置一个文件的数据，如果文件大于<code>Block</code>的大小，则一个文件会占用多个<code>Block</code>；如果文件小于<code>Block</code>，则该<code>Block</code>的剩余容量就不能够再被使用了，即磁盘空间会浪费</strong>。下面看看<code>Inode</code>和<code>Block</code>的对应关系。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Inode</code>要记录的数据非常多，但<strong>大小仅为固定的128字节</strong>，同时记录一个<code>Block</code>号码就需要4字节，假设一个文件有<code>400MB</code>且每个<code>Block</code>为<code>4K</code>时，那么至少也要十万笔<code>Block</code>号码的记录。<code>Inode</code>不可能有这么多的记录信息，因此<code>Ext2</code>将Inode记录<code>Block</code>号码的区域定义为12个直接、一个间接、一个双间接与一个三间接记录区。<code>Inode</code>存储结构如下图所示：</p>
<p><img src="//blog.com/2019/07/13/磁盘IO那些事/5.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最左边为<code>Inode</code>本身（128 bytes），里面有12个直接指向<code>Block</code>号码的对照，这12笔记录能够直接取得Block号码。至于所谓的间接就是再拿一个<code>Block</code>来当作记录<code>Block</code>号码的记录区，如果文件太大时，就会使用间接的<code>Block</code>来记录编号。如上图当中间接只是拿一个<code>Block</code>来记录额外的号码而已。 同理，如果文件持续长大，那么就会利用所谓的双间接，第一个<code>Block</code>仅再指出下一个记录编号的<code>Block</code>在哪里，实际记录的在第二个<code>Block</code>当中。依此类推，三间接就是利用第三层<code>Block</code>来记录编号。</p>
<h3 id="Page-Cache层"><a href="#Page-Cache层" class="headerlink" title="Page Cache层"></a>Page Cache层</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>引入<code>Cache</code>层的目的是为了提高Linux操作系统对磁盘访问的性能</strong>。<strong>Cache层在内存中缓存了磁盘上的部分数据</strong>。当数据的请求到达时，如果在<code>Cache</code>中存在该数据且是最新的，则直接将数据传递给用户程序，免除了对底层磁盘的操作，提高了性能。<code>Cache</code>层也正是磁盘<code>IOPS</code>为什么能突破200的主要原因之一。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Linux的实现中，文件<code>Cache</code>分为两个层面，一是<code>Page Cache</code>，另一个<code>Buffer Cache</code>，<strong>每一个<code>Page Cache</code>包含若干<code>Buffer Cache</code></strong>。<strong><code>Page Cache</code>主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有<code>read/write</code>操作的时候</strong>。<strong><code>Buffer Cache</code>则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;磁盘<code>Cache</code>有两大功能：预读和回写。</p>
<h4 id="预读"><a href="#预读" class="headerlink" title="预读"></a>预读</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;预读其实就是利用了<strong>局部性原理</strong>，具体过程是：对于每个文件的第一个读请求，<strong>系统读入所请求的页面并读入紧随其后的少数几个页面（通常是三个页面），这时的预读称为同步预读</strong>。</p>
<p>对于第二次读请求：</p>
<ol>
<li>如果所读页面不在<code>Cache</code>中，即不在前次预读的页中，则表明文件访问不是顺序访问，系统继续采用同步预读；</li>
<li>如果所读页面在<code>Cache</code>中，则表明前次预读命中，<strong>操作系统把预读页的大小扩大一倍，此时预读过程是异步的，应用程序可以不等预读完成即可返回，只要后台慢慢读页面即可，这时的预读称为异步预读</strong>。</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;任何接下来的读请求都会处于两种情况之一：第一种情况是所请求的页面处于预读的页面中，这时继续进行异步预读；第二种情况是所请求的页面处于预读页面之外，这时系统就要进行同步预读。</p>
<h4 id="回写"><a href="#回写" class="headerlink" title="回写"></a>回写</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;回写是通过暂时将数据存在<code>Cache</code>里，然后<strong>统一异步写到磁盘中</strong>。通过这种<strong>异步的数据I/O模式解决了程序中的计算速度和数据存储速度不匹配的鸿沟，减少了访问底层存储介质的次数，使存储系统的性能大大提高</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Linux 2.6.32内核之前，采用<code>pdflush</code>机制来将脏页真正写到磁盘中，什么时候开始回写呢？下面两种情况下，脏页会被写回到磁盘：</p>
<ol>
<li>在空闲<strong>内存低于一个特定的阈值</strong>时，内核必须将脏页写回磁盘，以便释放内存。</li>
<li>当<strong>脏页在内存中驻留超过一定的阈值</strong>时，内核必须将超时的脏页写会磁盘，以确保脏页不会无限期地驻留在内存中。</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;回写开始后，<code>pdflush</code>会持续写数据，直到满足以下两个条件：</p>
<ol>
<li>已经有指定的最小数目的页被写回到磁盘。</li>
<li>空闲内存页已经回升，超过了阈值。</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Linux 2.6.32内核之后，放弃了原有的<code>pdflush</code>机制，改成了<code>bdi_writeback</code>机制。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>bdi_writeback</code>机制主要解决了原有<code>fdflush</code>机制存在的一个问题：<strong>在多磁盘的系统中，<code>pdflush</code>管理了所有磁盘的<code>Cache</code>，从而导致一定程度的<code>I/O</code>瓶颈</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>bdi_writeback</code>机制为每个磁盘都创建了一个线程，专门负责这个磁盘的<code>Page Cache</code>的刷新工作，从而实现了每个磁盘的数据刷新在线程级的分离，提高了<code>I/O</code>性能</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;回写机制存在的问题是<strong>回写不及时引发数据丢失</strong>（可由<code>sync|fsync</code>解决），回写期间读<code>I/O</code>性能很差。</p>
<h3 id="通用块层"><a href="#通用块层" class="headerlink" title="通用块层"></a>通用块层</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通用块层的主要工作是：<strong>接收上层发出的磁盘请求，并最终发出<code>I/O</code>请求</strong>。该层隐藏了底层硬件块设备的特性，为块设备提供了一个通用的抽象视图。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于<code>VFS</code>和具体的文件系统来说，块（<code>Block</code>）是基本的数据传输单元，当内核访问文件的数据时，它首先从磁盘上读取一个块。但是对于磁盘来说，扇区是最小的可寻址单元，块设备无法对比它还小的单元进行寻址和操作。由于<strong>扇区是磁盘的最小可寻址单元，所以块不能比扇区还小，只能整数倍于扇区大小，即一个块对应磁盘上的一个或多个扇区</strong>。一般来说，块大小是2的整数倍，而且由于<strong><code>Page Cache</code>层的最小单元是页（<code>Page</code>）</strong>，所以<strong>块大小不能超过一页的长度</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大多情况下，数据的传输通过<code>DMA</code>方式。旧的磁盘控制器，仅仅支持简单的<code>DMA</code>操作：每次数据传输，只能传输磁盘上相邻的扇区，即数据在内存中也是连续的。这是因为如果传输非连续的扇区，会导致磁盘花费更多的时间在寻址操作上。而现在的磁盘控制器支持“分散/聚合”<code>DMA</code>操作，这种模式下，数据传输可以在多个非连续的内存区域中进行。为了利用“分散/聚合”<code>DMA</code>操作，<strong>块设备驱动必须能处理被称为段（segments）的数据单元</strong>。<strong>一个段就是一个内存页面或一个页面的部分，它包含磁盘上相邻扇区的数据</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通用块层是粘合所有上层和底层的部分，一个<strong>页的磁盘数据布局</strong>如下图所示：</p>
<p><img src="//blog.com/2019/07/13/磁盘IO那些事/6.webp" alt="img"></p>
<h3 id="I-O调度层"><a href="#I-O调度层" class="headerlink" title="I/O调度层"></a><strong>I/O调度层</strong></h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>I/O</code>调度层的功能是管理块设备的请求队列。即接收通用块层发出的<code>I/O</code>请求，缓存请求并试图合并相邻的请求。并<strong>根据设置好的调度算法，回调驱动层提供的请求处理函数，以处理具体的<code>I/O</code>请求</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果简单地以内核产生请求的次序直接将请求发给块设备的话，那么块设备性能肯定让人难以接受，因为<strong>磁盘寻址是整个计算机中最慢的操作之一</strong>。为了优化寻址操作，内核不会一旦接收到<code>I/O</code>请求后，就按照请求的次序发起块<code>I/O</code>请求。为此<code>Linux</code>实现了几种<code>I/O</code>调度算法，算法基本思想就是<strong>通过合并和排序<code>I/O</code>请求队列中的请求，以此大大降低所需的磁盘寻道时间，从而提高整体<code>I/O</code>性能</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;常见的I/O调度算法包括<code>Noop</code>调度算法（<code>No Operation</code>）、<code>CFQ</code>（完全公正排队I/O调度算法）、<code>DeadLine</code>（截止时间调度算法）、<code>AS</code>预测调度算法等。</p>
<ul>
<li><code>Noop</code>算法：最简单的<code>I/O</code>调度算法。该算法仅适当合并用户请求，并不排序请求。新的请求通常被插在调度队列的开头或末尾，下一个要处理的请求总是队列中的第一个请求。这种算法是为不需要寻道的块设备设计的，如<code>SSD</code>。因为其他三个算法的优化是基于缩短寻道时间的，而<code>SSD</code>硬盘没有所谓的寻道时间且<code>I/O</code>响应时间非常短。</li>
<li><code>CFQ</code>算法：算法的主要目标是在触发<code>I/O</code>请求的所有进程中确保磁盘<code>I/O</code>带宽的公平分配。算法使用许多个排序队列，存放了不同进程发出的请求。<strong>通过散列将同一个进程发出的请求插入同一个队列中</strong>。采用轮询方式扫描队列，从第一个非空队列开始，依次调度不同队列中特定个数（公平）的请求，然后将这些请求移动到调度队列的末尾。</li>
<li><code>Deadline</code>算法：算法引入了两个排队队列分别包含读请求和写请求，两个最后期限队列包含相同的读和写请求。本质就是一个超时定时器，当请求被传给电梯算法时开始计时。一旦最后期限队列中的超时时间已到，就想请求移至调度队列末尾。<code>Deadline</code>算法避免了电梯调度策略（为了减少寻道时间，会优先处理与上一个请求相近的请求）带来的对某个请求忽略很长一段时间的可能。</li>
<li><code>AS</code>算法：<code>AS</code>算法本质上依据局部性原理，预测进程发出的读请求与刚被调度的请求在磁盘上可能是“近邻”。算法统计每个进程<code>I/O</code>操作信息，当刚刚调度了由某个进程的一个读请求之后，算法马上检查排序队列中的下一个请求是否来自同一个进程。如果是，立即调度下一个请求。否则，查看关于该进程的统计信息，如果确定进程p可能很快发出另一个读请求，那么就延迟一小段时间。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前文中计算出的<code>IOPS</code>是理论上的随机读写的最大<code>IOPS</code>，在随机读写中，每次<code>I/O</code>操作的寻址和旋转延时都不能忽略不计，有了这两个时间的存在也就限制了<code>IOPS</code>的大小。现在如果我们考虑在读取一个很大的存储连续分布在磁盘的文件，因为文件的存储的分布是连续的，磁头在完成一个读<code>I/O</code>操作之后，不需要重新寻址，也不需要旋转延时，在这种情况下我们能到一个很大的<code>IOPS</code>值。这时由于不再考虑寻址和旋转延时，则性能瓶颈仅是数据传输时延，假设数据传输时延为<code>0.4ms</code>，那么<code>IOPS=1000 / 0.4 = 2500 IOPS</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在许多的开源框架如<code>Kafka</code>、<code>HBase</code>中，都<strong>通过追加写的方式来尽可能的将随机I/O转换为顺序I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高<code>IOPS</code></strong>。</p>
<h3 id="块设备驱动层"><a href="#块设备驱动层" class="headerlink" title="块设备驱动层"></a>块设备驱动层</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;驱动层中的驱动程序对应具体的物理块设备。它从上层中取出<code>I/O</code>请求，并根据该<code>I/O</code>请求中指定的信息，通过向具体块设备的设备控制器发送命令的方式，来操纵设备传输数据。</p>
<h2 id="基于磁盘I-O特性设计的技巧"><a href="#基于磁盘I-O特性设计的技巧" class="headerlink" title="基于磁盘I/O特性设计的技巧"></a>基于磁盘I/O特性设计的技巧</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在上一节中我们了解了<code>Linux</code>系统中请求到达磁盘的一次完整过程，期间<code>Linux</code>通过<code>Cache</code>以及排序合并<code>I/O</code>请求来提高系统的性能。其本质就是由于<strong>磁盘随机读写慢、顺序读写快</strong>。本节针对常见开源系统阐述一些基于磁盘<code>I/O</code>特性的设计技巧。</p>
<h3 id="采用追加写"><a href="#采用追加写" class="headerlink" title="采用追加写"></a>采用追加写</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在进行系统设计时，良好的读性能和写性能往往不可兼得。在许多常见的开源系统中都是<strong>优先在保证写性能的前提下来优化读性能</strong>。那么如何设计能让一个系统拥有良好的写性能呢？一个好的办法就是<strong>采用追加写，每次将数据添加到文件</strong>。<strong>由于完全是顺序的，所以可以具有非常好的写操作性能</strong>。但是这种方式也存在一些缺点：<strong>从文件中读一些数据时将会需要更多的时间</strong>：需要倒序扫描，直到找到所需要的内容。</p>
<p>当然在一些简单的场景下也能够保证读操作的性能：</p>
<ul>
<li><p><strong>数据是被整体访问</strong>，比如<code>HDFS</code></p>
</li>
<li><ul>
<li><code>HDFS</code>建立在一次写多次读的模型之上。在<code>HDFS</code>中就是采用了追加写并且设计为高数据吞吐量；高吞吐量必然以高延迟为代价，所以<code>HDFS</code>并不适用于对数据访问要求低延迟的场景；由于采用是的追加写，也并不适用于任意修改文件的场景。<code>HDFS</code>设计为流式访问大文件，使用大数据块并且采用流式数据访问来保证数据被整体访问，同时最小化硬盘的寻址开销，只需要一次寻址即可，这时寻址时间相比于传输时延可忽略，从而也拥有良好的读性能。<code>HDFS</code>不适合存储小文件，原因之一是由于<code>NameNode</code>内存不足问题，还有就是因为访问大量小文件需要执行大量的寻址操作，并且需要不断的从一个<code>datanode</code>跳到另一个<code>datanode</code>，这样会大大降低数据访问性能。</li>
</ul>
</li>
<li><p><strong>知道文件明确的偏移量</strong>，比如<code>Kafka</code></p>
</li>
<li><ul>
<li>在<code>Kafka</code>中，采用消息追加的方式来写入每个消息，每个消息读写时都会利用<code>Page Cache</code>的预读和后写特性，同时<strong><code>partition</code>中都使用顺序读写</strong>，以此来提高<code>I/O</code>性能。虽然<code>Kafka</code>能够根据偏移量查找到具体的某个消息，但是查找过程是顺序查找，因此如果数据很大的话，查找效率就很低。所以<strong><code>Kafka</code>中采用了分段和索引的方式来解决查找效率问题</strong>。<strong><code>Kafka</code>把一个<code>patition</code>大文件又分成了多个小文件段，每个小文件段以偏移量命名，通过多个小文件段，不仅可以使用二分搜索法很快定位消息，同时也容易定期清除或删除已经消费完的文件，减少磁盘占用</strong>。为了进一步提高查找效率，<code>Kafka</code><strong>为每个分段后的数据建立了索引文件，并通过索引文件稀疏存储来降低元数据占用大小</strong>。一个段中数据对应结构如下图所示：</li>
</ul>
</li>
</ul>
<p><img src="//blog.com/2019/07/13/磁盘IO那些事/7.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在面对更复杂的读场景（比如按<code>key</code>）时，如何来保证读操作的性能呢？简单的方式是像<code>Kafka</code>那样，将文件数据有序保存，使用二分查找来优化效率；或者通过建索引的方式来进行优化；也可以采用<code>hash</code>的方式将数据分割为不同的桶。以上的方法都能增加读操作的性能，但是由于在数据上强加了数据结构，又会降低写操作的性能。比如如果采用索引的方式来优化读操作，那么在更新索引时就需要更新<code>B-tree</code>中的特定部分，这时候的写操作就是随机写。那么有没有一种办法在保证写性能不损失的同时也提供较好的读性能呢？一个好的选择就是使用    <code>LSM-tree</code>。<code>LSM-tree</code>与<code>B-tree</code>相比，<code>LSM-tree</code>牺牲了部分读操作，以此大幅提高写性能。</p>
<ul>
<li>日志结构的合并树<code>LSM（The Log-Structured Merge-Tree）</code>是<code>HBase，LevelDB</code>等<code>NoSQL</code>数据库的存储引擎。<code>Log-Structured</code>的思想是将整个磁盘看做一个日志，在日志中存放永久性数据及其索引，每次都添加到日志的末尾。并且通过将很多小文件的存取转换为连续的大批量传输，使得对于文件系统的大多数存取都是顺序的，从而提高磁盘I/O。<strong><code>LSM-tree</code>就是这样一种采用追加写、数据有序以及将随机I/O转换为顺序I/O的延迟更新，批量写入硬盘的数据结构</strong>。<code>LSM-tree</code>将数据的修改增量先保存在内存中，达到指定的大小限制后再将这些修改操作批量写入磁盘。因此比较旧的文件不会被更新，重复的纪录只会通过创建新的纪录来覆盖，这也就产生了一些冗余的数据。所以系统会周期性的合并一些数据，移除重复的更新或者删除纪录，同时也会删除上述的冗余。在进行读操作时，如果内存中没有找到相应的<code>key</code>，那么就是倒序从一个个磁盘文件中查找。如果文件越来越多那么读性能就会越来越低，目前的解决方案是采用页缓存来减少查询次数，周期合并文件也有助于提高读性能。在文件越来越多时，可通过布隆过滤器来避免大量的读文件操作。<code>LSM-tree</code>牺牲了部分读性能，以此来换取写入的最大化性能，特别适用于读需求低，会产生大量插入操作的应用环境。</li>
</ul>
<h3 id="文件合并和元数据优化"><a href="#文件合并和元数据优化" class="headerlink" title="文件合并和元数据优化"></a>文件合并和元数据优化</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前的大多数文件系统，如<code>XFS/Ext4、GFS、HDFS</code>，在元数据管理、缓存管理等实现策略上都侧重大文件。上述基于磁盘I/O特性设计的系统都有一个共性特点就是都运行在这些文件系统之上。这些文件系统在面临海量时在性能和存储效率方面都大幅降低，本节来探讨下海量小文件下的系统设计。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;常见<strong>文件系统在海量小文件应用下性能表现不佳的根本原因是磁盘最适合顺序的大文件I/O读写模式，而非常不适合随机的小文件I/O读写模式</strong>。主要原因体现在元数据管理低效和数据布局低效：</p>
<ul>
<li><strong>元数据管理低效</strong>：由于小文件数据内容较少，因此元数据的访问性能对小文件访问性能影响巨大。<code>Ext2</code>文件系统中<code>Inode</code>和<code>Data Block</code>分别保存在不同的物理位置上，一次读操作需要至少经过两次的独立访问。在海量小文件应用下，<code>Inode</code>的频繁访问，使得原本的并发访问转变为了海量的随机访问，大大降低了性能。另外，大量的小文件会快速耗尽<code>Inode</code>资源，导致磁盘尽管有大量<code>Data Block</code>剩余也无法存储文件，会浪费磁盘空间。</li>
<li><strong>数据布局低效</strong>：<code>Ext2</code>在<code>Inode</code>中使用多级指针来索引数据块。对于大文件，数据块的分配会尽量连续，这样会具有比较好的空间局部性。但是对于小文件，数据块可能零散分布在磁盘上的不同位置，并且会造成大量的磁盘碎片，不仅造成访问性能下降，还大量浪费了磁盘空间。数据块一般为<code>1KB、2KB或4KB</code>，对于小于<code>4KB</code>的小文件，<code>Inod</code>e与数据的分开存储破坏了空间局部性，同时也造成了大量的随机<code>I/O</code>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于海量小文件应用，常见的I/O流程复杂也是造成磁盘性能不佳的原因。对于小文件，磁盘的读写所占用的时间较少，而用于文件的open()操作占用了绝大部分系统时间，导致磁盘有效服务时间非常低，磁盘性能低下。针对于问题的根源，优化的思路大体上分为：</p>
<ol>
<li><p><strong>针对数据布局低效，采用小文件合并策略，将小文件合并为大文件</strong>。</p>
</li>
<li><p><strong>针对元数据管理低效，优化元数据的存储和管理</strong>。</p>
</li>
</ol>
<p>   针对这两种优化方式，业内也出现了许多优秀的开源软件。</p>
<h4 id="小文件合并"><a href="#小文件合并" class="headerlink" title="小文件合并"></a>小文件合并</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;小文件合并为大文件后，首先减少了大量元数据，提高了元数据的检索和查询效率，降低了文件读写的I/O操作延时。其次将可能连续访问的小文件一同合并存储，增加了文件之间的局部性，将原本小文件间的随机访问变为了顺序访问，大大提高了性能。同时，合并存储能够有效的减少小文件存储时所产生的磁盘碎片问题，提高了磁盘的利用率。最后，合并之后小文件的访问流程也有了很大的变化，由原来许多的<code>open</code>操作转变为了<code>seek</code>操作，定位到大文件具体的位置即可。如何寻址这个大文件中的小文件呢？其实就是<strong>利用一个旁路数据库来记录每个小文件在这个大文件中的偏移量和长度等信息</strong>。其实小文件合并的策略本质上就是通过分层的思想来存储元数据。中控节点存储一级元数据，也就是大文件与底层块的对应关系；数据节点存放二级元数据，也就是最终的用户文件在这些一级大块中的存储位置对应关系，经过两级寻址来读写数据。</p>
<ul>
<li>淘宝的<code>TFS</code>就采用了小文件合并存储的策略。<code>TFS</code>中默认<code>Block</code>大小为64M，每个块中会存储许多不同的小文件，但是这个块只占用一个<code>Inode</code>。假设一个<code>Block</code>为<code>64M</code>，数量级为<code>1PB</code>。那么<code>NameServer</code>上会有<code>1 *1024* 1024 * 1024 / 64 = 16.7M</code>个Block。假设每个<code>Block</code>的元数据大小为<code>0.1K</code>，则占用内存不到<code>2G</code>。在<code>TFS</code>中，文件名中包含了<code>Block ID</code>和<code>File ID</code>，通过<code>Block ID</code>定位到具体的<code>DataServer</code>上，然后<code>DataServer</code>会根据本地记录的信息来得到<code>File ID</code>所在<code>Block</code>的偏移量，从而读取到正确的文件内容。<code>TFS</code>一次读过程如下图所示：</li>
</ul>
<p><img src="//blog.com/2019/07/13/磁盘IO那些事/8.webp" alt="img"></p>
<h4 id="元数据管理优化"><a href="#元数据管理优化" class="headerlink" title="元数据管理优化"></a>元数据管理优化</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一般来说元数据信息包括名称、文件大小、设备标识符、用户标识符、用户组标识符等等，在小文件系统中可以对元数据信息进行精简，仅保存足够的信息即可。元数据精简可以减少元数据通信延时，同时相同容量的<code>Cache</code>能存储更多的元数据，从而提高元数据使用效率。另外可以在文件名中就包含元数据信息，从而减少一个元数据的查询操作。最后针对特别小的一些文件，可以采取元数据和数据并存的策略，将数据直接存储在元数据之中，通过减少一次寻址操作从而大大提高性能。</p>
<ul>
<li><code>TFS</code>中文件命名就隐含了位置信息等部分元数据，从而减少了一个元数据的查询操作。在<code>Rerserfs</code>中，对于小于<code>1KB</code>的小文件，<code>Rerserfs</code>可以将数据直接存储在<code>Inode</code>中。</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文从磁盘性能指标出发，探究了操作系统与磁盘的交互以及对磁盘读写的优化，最后列举了一些常用开源系统中基于磁盘<code>I/O</code>特性的设计特点。期望通过展现磁盘<code>I/O</code>的特性，为存储系统设计和解决一些系统性能问题提供一种新思路。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/13/Redis RDB 持久化详解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/13/Redis RDB 持久化详解/" itemprop="url">Redis RDB 持久化详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-13T12:12:57+08:00">
                2019-07-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Redis-RDB-持久化详解"><a href="#Redis-RDB-持久化详解" class="headerlink" title="Redis RDB 持久化详解"></a>Redis RDB 持久化详解</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="https://mp.weixin.qq.com/s/NpUV-7bvXTD3iu0_2aRssQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/NpUV-7bvXTD3iu0_2aRssQ</a></p>
</blockquote>
<p><br></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Redis</code> 是一种内存数据库，将数据保存在内存中，读写效率要比传统的将数据保存在磁盘上的数据库要快很多。但是一旦进程退出，<code>Redis</code> 的数据就会丢失。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了解决这个问题，<code>Redis</code> 提供了 <code>RDB</code>和 <code>AOF</code>两种持久化方案，将内存中的数据保存到磁盘中，避免数据丢失。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;antirez 在《<code>Redis</code> 持久化解密》一文中说，一般来说有三种常见的策略来进行持久化操作，防止数据损坏：</p>
<ul>
<li>方法1 是<strong>数据库不关心发生故障，在数据文件损坏后通过数据备份或者快照来进行恢复</strong>。<code>Redis</code> 的 <code>RDB</code> 持久化就是这种方式。</li>
<li>方法2 是<strong>数据库使用操作日志，每次操作时记录操作行为，以便在故障后通过日志恢复到一致性的状态</strong>。因为操作日志是顺序追加的方式写的，所以不会出现操作日志也无法恢复的情况。类似于 <code>Mysql</code> 的 <code>redo</code>和 <code>undo</code> 日志，具体可以看这篇<a href="https://mp.weixin.qq.com/s?__biz=Mzg2NjE5NDQyOA==&amp;mid=2247483785&amp;idx=1&amp;sn=e40537c048f0880daf441350c695ffc6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">《InnoDB的磁盘文件及落盘机制》</a>文章。</li>
<li>方法3 是<strong>数据库不进行老数据的修改，只是以追加方式去完成写操作，这样数据本身就是一份日志，这样就永远不会出现数据无法恢复的情况了</strong>。<code>CouchDB</code>就是此做法的优秀范例。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>RDB</code> 就是第一种方法，它就是把当前 <code>Redis</code> 进程的数据生成<strong>时间点快照</strong>( <code>point-in-time snapshot</code> ) 保存到存储设备的过程。</p>
<h2 id="RDB-的使用"><a href="#RDB-的使用" class="headerlink" title="RDB 的使用"></a>RDB 的使用</h2><p><code>RDB</code> 触发机制分为使用指令手动触发和 <code>redis.conf</code>配置自动触发。</p>
<h3 id="手动触发"><a href="#手动触发" class="headerlink" title="手动触发"></a>手动触发</h3><p>手动触发 <code>Redis</code>进行 <code>RDB</code>持久化的指令的为:</p>
<ul>
<li><p><code>save</code> ，该指令会<strong>阻塞当前<code>Redis</code> 服务器，执行<code>save</code>指令期间，<code>Redis</code>不能处理其他命令</strong>，直到 <code>RDB</code>过程完成为止。</p>
</li>
<li><p><code>bgsave</code>，执行该命令时，<strong><code>Redis</code> 会在后台异步执行快照操作，此时 <code>Redis</code> 仍然可以相应客户端请求</strong>。</p>
<p>具体操作是 <code>Redis</code> 进程执行 <code>fork</code> 操作创建子进程，<strong><code>RDB</code> 持久化过程由子进程负责</strong>，完成后自动结束。<strong><code>Redis</code> 只会在 <code>fork</code> 期间发生阻塞</strong>，但是一般时间都很短。但是如果 Redis 数据量特别大， <code>fork</code> 时间就会变长，而且占用内存会加倍，这一点需要特别注意。</p>
</li>
</ul>
<h3 id="自动触发"><a href="#自动触发" class="headerlink" title="自动触发"></a>自动触发</h3><p>自动触发 <code>RDB</code> 的默认配置如下所示:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1            # 表示900 秒内如果至少有 1 个 key 的值变化，则触发RDB</span><br><span class="line">save 300 10           # 表示300 秒内如果至少有 10 个 key 的值变化，则触发RDB</span><br><span class="line">save 60 10000         # 表示60 秒内如果至少有 10000 个 key 的值变化，则触发RDB</span><br></pre></td></tr></table></figure>
<p>如果不需要 <code>Redis</code>进行持久化，那么可以注释掉所有的 <code>save</code>行来停用保存功能，也可以直接一个空字符串来停用持久化：<code>save &quot;&quot;</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>Redis</code> 服务器周期操作函数 <code>serverCron</code> 默认每个 100 毫秒就会执行一次，该函数用于正在运行的服务器进行维护，它的一项工作就是检查 <code>save</code> 选项所设置的条件是否有一项被满足，如果满足的话，就执行 <code>bgsave</code> 指令</strong>。</p>
<h2 id="RDB-整体流程"><a href="#RDB-整体流程" class="headerlink" title="RDB 整体流程"></a>RDB 整体流程</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;了解了 <code>RDB</code> 的基础使用后，我们要继续深入对 <code>RDB</code>持久化的学习。在此之前，我们可以先思考一下如何实现一个持久化机制，毕竟这是很多中间件所需的一个模块。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先，<strong>持久化保存的文件内容结构必须是紧凑的</strong>，特别对于数据库来说，需要持久化的数据量十分大，需要保证持久化文件不至于占用太多存储。其次，进行持久化时，<strong>中间件应该还可以快速地响应用户请求，持久化的操作应该尽量少影响中间件的其他功能</strong>。最后，毕竟<strong>持久化会消耗性能，如何在性能和数据安全性之间做出平衡，如何灵活配置触发持久化操作</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接下来我们将带着这些问题，到源码中寻求答案。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文中的源码来自 <code>Redis 4.0</code> ，<code>RDB</code>持久化过程的相关源码都在 <code>rdb.c</code>文件中。其中大概的流程如下图所示。</p>
<p><img src="//blog.com/2019/07/13/Redis RDB 持久化详解/1.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图表明了三种触发<code>RDB</code> 持久化的手段之间的整体关系。通过 <code>serverCron</code> 自动触发的<code>RDB</code>相当于直接调用了 <code>bgsave</code> 指令的流程进行处理。而 <code>bgsave</code> 的处理流程启动子进程后，调用了 <code>save</code>指令的处理流程。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面我们从 <code>serverCron</code> 自动触发逻辑开始研究。</p>
<h3 id="自动触发-RDB-持久化"><a href="#自动触发-RDB-持久化" class="headerlink" title="自动触发 RDB 持久化"></a>自动触发 RDB 持久化</h3><p><img src="//blog.com/2019/07/13/Redis RDB 持久化详解/2.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示， <code>redisServer</code> 结构体的 <code>save_params</code>指向拥有三个值的数组，该数组的值与 <code>redis.conf</code> 文件中 <code>save</code> 配置项一一对应。分别是 <code>save9001</code>、 <code>save30010</code> 和 <code>save6010000</code>。<code>dirty</code> 记录着有多少键值发生变化， <code>lastsave</code>记录着上次 <code>RDB</code> 持久化的时间。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;而 <code>serverCron</code> 函数就是遍历该数组的值，检查当前<code>Redis</code>状态是否符合触发 <code>RDB</code> 持久化的条件，比如说距离上次 <code>RDB</code>持久化过去了 900 秒并且有至少一条数据发生变更。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">serverCron</span><span class="params">(struct aeEventLoop *eventLoop, <span class="keyword">long</span> <span class="keyword">long</span> id, <span class="keyword">void</span> *clientData)</span> </span>&#123;</span><br><span class="line">    ....</span><br><span class="line">    <span class="comment">/* Check if a background saving or AOF rewrite in progress terminated. */</span></span><br><span class="line">    <span class="comment">/* 判断后台是否正在进行 rdb 或者 aof 操作 */</span></span><br><span class="line">    <span class="keyword">if</span> (server.rdb_child_pid != <span class="number">-1</span> || server.aof_child_pid != <span class="number">-1</span> ||</span><br><span class="line">        ldbPendingChildren())</span><br><span class="line">    &#123;</span><br><span class="line">        ....</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 到这儿就能确定 当前木有进行 rdb 或者 aof 操作</span></span><br><span class="line">        <span class="comment">// 遍历每一个 rdb 保存条件</span></span><br><span class="line">         <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; server.saveparamslen; j++) &#123;</span><br><span class="line">            struct saveparam *sp = server.saveparams+j;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//如果数据保存记录 大于规定的修改次数 且距离 上一次保存的时间大于规定时间或者上次BGSAVE命令执行成功，才执行 BGSAVE 操作</span></span><br><span class="line">            <span class="keyword">if</span> (server.dirty &gt;= sp-&gt;changes &amp;&amp;</span><br><span class="line">                server.unixtime-server.lastsave &gt; sp-&gt;seconds &amp;&amp;</span><br><span class="line">                (server.unixtime-server.lastbgsave_try &gt;</span><br><span class="line">                 CONFIG_BGSAVE_RETRY_DELAY ||</span><br><span class="line">                 server.lastbgsave_status == C_OK))</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">//记录日志</span></span><br><span class="line">                serverLog(LL_NOTICE,<span class="string">"%d changes in %d seconds. Saving..."</span>,</span><br><span class="line">                    sp-&gt;changes, (<span class="keyword">int</span>)sp-&gt;seconds);</span><br><span class="line">                rdbSaveInfo rsi, *rsiptr;</span><br><span class="line">                rsiptr = rdbPopulateSaveInfo(&amp;rsi);</span><br><span class="line">                <span class="comment">// 异步保存操作</span></span><br><span class="line">                rdbSaveBackground(server.rdb_filename,rsiptr);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ....</span><br><span class="line">    server.cronloops++;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1000</span>/server.hz;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果符合触发 <code>RDB</code>持久化的条件， <code>serverCron</code>会调用 <code>rdbSaveBackground</code>函数，也就是 <code>bgsave</code>指令会触发的函数。</p>
<h3 id="子进程后台执行-RDB-持久化"><a href="#子进程后台执行-RDB-持久化" class="headerlink" title="子进程后台执行 RDB 持久化"></a>子进程后台执行 RDB 持久化</h3><p>执行 <code>bgsave</code> 指令时，<code>Redis</code> 会先触发 <code>bgsaveCommand</code> 进行当前状态检查，然后才会调用 <code>rdbSaveBackground</code>，其中的逻辑如下图所示。</p>
<p><img src="//blog.com/2019/07/13/Redis RDB 持久化详解/3.webp" alt="img"></p>
<p><code>rdbSaveBackground</code> 函数中最主要的工作就是调用 <code>fork</code> 命令生成子流程，然后在子流程中执行 <code>rdbSave</code>函数，也就是 <code>save</code>指令最终会触发的函数。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">rdbSaveBackground</span><span class="params">(<span class="keyword">char</span> *filename, rdbSaveInfo *rsi)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">pid_t</span> childpid;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> start;</span><br><span class="line">    <span class="comment">// 检查后台是否正在执行 aof 或者 rdb 操作</span></span><br><span class="line">    <span class="keyword">if</span> (server.aof_child_pid != <span class="number">-1</span> || server.rdb_child_pid != <span class="number">-1</span>) <span class="keyword">return</span> C_ERR;</span><br><span class="line">    <span class="comment">// 拿出 数据保存记录，保存为 上次记录</span></span><br><span class="line">    server.dirty_before_bgsave = server.dirty;</span><br><span class="line">    <span class="comment">// bgsave 时间</span></span><br><span class="line">    server.lastbgsave_try = time(<span class="literal">NULL</span>);</span><br><span class="line">    start = ustime();</span><br><span class="line">    <span class="comment">// fork 子进程</span></span><br><span class="line">    <span class="keyword">if</span> ((childpid = fork()) == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> retval;</span><br><span class="line">        <span class="comment">/* 关闭子进程继承的 socket 监听 */</span></span><br><span class="line">        closeListeningSockets(<span class="number">0</span>);</span><br><span class="line">        <span class="comment">// 子进程 title 修改</span></span><br><span class="line">        redisSetProcTitle(<span class="string">"redis-rdb-bgsave"</span>);</span><br><span class="line">        <span class="comment">// 执行rdb 写入操作</span></span><br><span class="line">        retval = rdbSave(filename,rsi);</span><br><span class="line">        <span class="comment">// 执行完毕以后</span></span><br><span class="line">        ....</span><br><span class="line">        <span class="comment">// 退出子进程</span></span><br><span class="line">        exitFromChild((retval == C_OK) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/* 父进程，进行fork时间的统计和信息记录，比如说rdb_save_time_start、rdb_child_pid、和rdb_child_type */</span></span><br><span class="line">        ....</span><br><span class="line">        <span class="comment">// rdb 保存开始时间 bgsave 子进程</span></span><br><span class="line">        server.rdb_save_time_start = time(<span class="literal">NULL</span>);</span><br><span class="line">        server.rdb_child_pid = childpid;</span><br><span class="line">        server.rdb_child_type = RDB_CHILD_TYPE_DISK;</span><br><span class="line">        updateDictResizePolicy();</span><br><span class="line">        <span class="keyword">return</span> C_OK;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> C_OK; <span class="comment">/* unreached */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为什么 <code>Redis</code> 使用子进程而不是线程来进行后台 <code>RDB</code>持久化呢？主要是出于<code>Redis</code>性能的考虑，我们知道<strong><code>Redis</code>对客户端响应请求的工作模型是单进程和单线程的，如果在主进程内启动一个线程，这样会造成对数据的竞争条件</strong>。所以<strong>为了避免使用锁降低性能，<code>Redis</code>选择启动新的子进程，独立拥有一份父进程的内存拷贝，以此为基础执行<code>RDB</code>持久化</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是需要注意的是，<code>fork</code> 会消耗一定时间，并且父子进程所占据的内存是相同的，当 <code>Redis</code>键值较大时，<code>fork</code> 的时间会很长，这段时间内 <code>Redis</code> 是无法响应其他命令的。除此之外，<code>Redis</code>占据的内存空间会翻倍。</p>
<h3 id="生成-RDB-文件，并且持久化到硬盘"><a href="#生成-RDB-文件，并且持久化到硬盘" class="headerlink" title="生成 RDB 文件，并且持久化到硬盘"></a>生成 RDB 文件，并且持久化到硬盘</h3><p><code>Redis</code> 的 <code>rdbSave</code> 函数是真正进行 <code>RDB</code> 持久化的函数，它的大致流程如下：</p>
<ul>
<li>首先打开一个临时文件，</li>
<li>调用 <code>rdbSaveRio</code>函数，将当前 <code>Redis</code> 的内存信息写入到这个临时文件中，</li>
<li>接着调用 <code>fflush</code>、 <code>fsync</code> 和 <code>fclose</code> 接口将文件写入磁盘中，</li>
<li>使用 <code>rename</code> 将临时文件改名为 正式的 <code>RDB</code> 文件，</li>
<li>最后记录 <code>dirty</code> 和 <code>lastsave</code>等状态信息。这些状态信息在 <code>serverCron</code>时会使用到。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">rdbSave</span><span class="params">(<span class="keyword">char</span> *filename, rdbSaveInfo *rsi)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> tmpfile[<span class="number">256</span>];</span><br><span class="line">    <span class="comment">// 当前工作目录</span></span><br><span class="line">    <span class="keyword">char</span> cwd[MAXPATHLEN];</span><br><span class="line">    FILE *fp;</span><br><span class="line">    rio rdb;</span><br><span class="line">    <span class="keyword">int</span> error = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 生成tmpfile文件名 temp-[pid].rdb */</span></span><br><span class="line">    <span class="built_in">snprintf</span>(tmpfile,<span class="number">256</span>,<span class="string">"temp-%d.rdb"</span>, (<span class="keyword">int</span>) getpid());</span><br><span class="line">    <span class="comment">/* 打开文件 */</span></span><br><span class="line">    fp = fopen(tmpfile,<span class="string">"w"</span>);</span><br><span class="line">    .....</span><br><span class="line">    <span class="comment">/* 初始化rio结构 */</span></span><br><span class="line">    rioInitWithFile(&amp;rdb,fp);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (rdbSaveRio(&amp;rdb,&amp;error,RDB_SAVE_NONE,rsi) == C_ERR) &#123;</span><br><span class="line">        errno = error;</span><br><span class="line">        <span class="keyword">goto</span> werr;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (fflush(fp) == EOF) <span class="keyword">goto</span> werr;</span><br><span class="line">    <span class="keyword">if</span> (fsync(fileno(fp)) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">    <span class="keyword">if</span> (fclose(fp) == EOF) <span class="keyword">goto</span> werr;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 重新命名 rdb 文件，把之前临时的名称修改为正式的 rdb 文件名称 */</span></span><br><span class="line">    <span class="keyword">if</span> (rename(tmpfile,filename) == <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="comment">// 异常处理</span></span><br><span class="line">        ....</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 写入完成，打印日志</span></span><br><span class="line">    serverLog(LL_NOTICE,<span class="string">"DB saved on disk"</span>);</span><br><span class="line">    <span class="comment">// 清理数据保存记录</span></span><br><span class="line">    server.dirty = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 最后一次完成 SAVE 命令的时间</span></span><br><span class="line">    server.lastsave = time(<span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">// 最后一次 bgsave 的状态置位 成功</span></span><br><span class="line">    server.lastbgsave_status = C_OK;</span><br><span class="line">    <span class="keyword">return</span> C_OK;</span><br><span class="line">    ....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里要简单说一下 <code>fflush</code>和 <code>fsync</code>的区别。它们俩都是用于刷缓存，但是所属的层次不同。<code>fflush</code>函数用于 <code>FILE*</code> 指针上，将缓存数据从应用层缓存刷新到内核中，而 <code>fsync</code> 函数则更加底层，作用于文件描述符，用于将内核缓存刷新到物理设备上。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关于 Linux IO 的具体原理可以参考<a href="https://mp.weixin.qq.com/s?__biz=Mzg2NjE5NDQyOA==&amp;mid=2247483824&amp;idx=1&amp;sn=48d3fd8374c035361a9df4e67b6528df&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">《聊聊Linux IO》</a></p>
<h3 id="内存数据到-RDB-文件"><a href="#内存数据到-RDB-文件" class="headerlink" title="内存数据到 RDB 文件"></a>内存数据到 RDB 文件</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>rdbSaveRio</code> 会将 <code>Redis</code> 内存中的数据以相对紧凑的格式写入到文件中，其文件格式的示意图如下所示。</p>
<p><img src="//blog.com/2019/07/13/Redis RDB 持久化详解/4.webp" alt="img"></p>
<p><code>rdbSaveRio</code>函数的写入大致流程如下：</p>
<ul>
<li>先写入 <code>REDIS</code>魔法值，然后是 <code>RDB</code>文件的版本( <code>rdb_version</code> )，额外辅助信息 ( <code>aux</code>)。辅助信息中包含了 <code>Redis</code> 的版本，内存占用和复制库( <code>repl-id</code> )和偏移量(<code>repl-offset</code> )等。</li>
<li>然后 <code>rdbSaveRio</code> 会遍历当前 <code>Redis</code> 的所有数据库，将数据库的信息依次写入。先写入 <code>RDB_OPCODE_SELECTDB</code>识别码和数据库编号，接着写入 <code>RDB_OPCODE_RESIZEDB</code>识别码和数据库键值数量和待失效键值数量，最后会遍历所有的键值，依次写入。</li>
<li>在写入键值时，当该键值有失效时间时，会先写入 <code>RDB_OPCODE_EXPIRETIME_MS</code>识别码和失效时间，然后写入键值类型的识别码，最后再写入键和值。</li>
<li>写完数据库信息后，还会把<code>Lua</code> 相关的信息写入，最后再写入 <code>RDB_OPCODE_EOF</code>结束符识别码和校验值。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">rdbSaveRio</span><span class="params">(rio *rdb, <span class="keyword">int</span> *error, <span class="keyword">int</span> flags, rdbSaveInfo *rsi)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">snprintf</span>(magic,<span class="keyword">sizeof</span>(magic),<span class="string">"REDIS%04d"</span>,RDB_VERSION);</span><br><span class="line">    <span class="comment">/* 1 写入 magic字符'REDIS' 和 RDB 版本 */</span></span><br><span class="line">    <span class="keyword">if</span> (rdbWriteRaw(rdb,magic,<span class="number">9</span>) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">    <span class="comment">/* 2 写入辅助信息  REDIS版本,服务器操作系统位数,当前时间,复制信息比如repl-stream-db,repl-id和repl-offset等等数据*/</span></span><br><span class="line">    <span class="keyword">if</span> (rdbSaveInfoAuxFields(rdb,flags,rsi) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">    <span class="comment">/* 3 遍历每一个数据库，逐个数据库数据保存 */</span></span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; server.dbnum; j++) &#123;</span><br><span class="line">        <span class="comment">/* 获取数据库指针地址和数据库字典 */</span></span><br><span class="line">        redisDb *db = server.db+j;</span><br><span class="line">        dict *d = db-&gt;dict;</span><br><span class="line">        <span class="comment">/* 3.1 写入数据库部分的开始标识 */</span></span><br><span class="line">        <span class="keyword">if</span> (rdbSaveType(rdb,RDB_OPCODE_SELECTDB) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">        <span class="comment">/* 3.2 写入当前数据库号 */</span></span><br><span class="line">        <span class="keyword">if</span> (rdbSaveLen(rdb,j) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">uint32_t</span> db_size, expires_size;</span><br><span class="line">        <span class="comment">/* 获取数据库字典大小和过期键字典大小 */</span></span><br><span class="line">        db_size = (dictSize(db-&gt;dict) &lt;= UINT32_MAX) ?</span><br><span class="line">                                dictSize(db-&gt;dict) :</span><br><span class="line">                                UINT32_MAX;</span><br><span class="line">        expires_size = (dictSize(db-&gt;expires) &lt;= UINT32_MAX) ?</span><br><span class="line">                                dictSize(db-&gt;expires) :</span><br><span class="line">                                UINT32_MAX;</span><br><span class="line">        <span class="comment">/* 3.3 写入当前待写入数据的类型，此处为 RDB_OPCODE_RESIZEDB，表示数据库大小 */</span></span><br><span class="line">        <span class="keyword">if</span> (rdbSaveType(rdb,RDB_OPCODE_RESIZEDB) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">        <span class="comment">/* 3.4 写入获取数据库字典大小和过期键字典大小 */</span></span><br><span class="line">        <span class="keyword">if</span> (rdbSaveLen(rdb,db_size) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">        <span class="keyword">if</span> (rdbSaveLen(rdb,expires_size) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">        <span class="comment">/* 4 遍历当前数据库的键值对 */</span></span><br><span class="line">        <span class="keyword">while</span>((de = dictNext(di)) != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            sds keystr = dictGetKey(de);</span><br><span class="line">            robj key, *o = dictGetVal(de);</span><br><span class="line">            <span class="keyword">long</span> <span class="keyword">long</span> expire;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* 初始化 key，因为操作的是 key 字符串对象，而不是直接操作 键的字符串内容 */</span></span><br><span class="line">            initStaticStringObject(key,keystr);</span><br><span class="line">            <span class="comment">/* 获取键的过期数据 */</span></span><br><span class="line">            expire = getExpire(db,&amp;key);</span><br><span class="line">            <span class="comment">/* 4.1 保存键值对数据 */</span></span><br><span class="line">            <span class="keyword">if</span> (rdbSaveKeyValuePair(rdb,&amp;key,o,expire) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 5 保存 Lua 脚本*/</span></span><br><span class="line">    <span class="keyword">if</span> (rsi &amp;&amp; dictSize(server.lua_scripts)) &#123;</span><br><span class="line">        di = dictGetIterator(server.lua_scripts);</span><br><span class="line">        <span class="keyword">while</span>((de = dictNext(di)) != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            robj *body = dictGetVal(de);</span><br><span class="line">            <span class="keyword">if</span> (rdbSaveAuxField(rdb,<span class="string">"lua"</span>,<span class="number">3</span>,body-&gt;ptr,sdslen(body-&gt;ptr)) == <span class="number">-1</span>)</span><br><span class="line">                <span class="keyword">goto</span> werr;</span><br><span class="line">        &#125;</span><br><span class="line">        dictReleaseIterator(di);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 6 写入结束符 */</span></span><br><span class="line">    <span class="keyword">if</span> (rdbSaveType(rdb,RDB_OPCODE_EOF) == <span class="number">-1</span>) <span class="keyword">goto</span> werr;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 7 写入CRC64校验和 */</span></span><br><span class="line">    cksum = rdb-&gt;cksum;</span><br><span class="line">    memrev64ifbe(&amp;cksum);</span><br><span class="line">    <span class="keyword">if</span> (rioWrite(rdb,&amp;cksum,<span class="number">8</span>) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">    <span class="keyword">return</span> C_OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>rdbSaveRio</code>在写键值时，会调用 <code>rdbSaveKeyValuePair</code> 函数。该函数会依次写入键值的过期时间，键的类型，键和值。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">rdbSaveKeyValuePair</span><span class="params">(rio *rdb, robj *key, robj *val, <span class="keyword">long</span> <span class="keyword">long</span> expiretime)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">/* 如果有过期信息 */</span></span><br><span class="line">    <span class="keyword">if</span> (expiretime != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="comment">/* 保存过期信息标识 */</span></span><br><span class="line">        <span class="keyword">if</span> (rdbSaveType(rdb,RDB_OPCODE_EXPIRETIME_MS) == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        <span class="comment">/* 保存过期具体数据内容 */</span></span><br><span class="line">        <span class="keyword">if</span> (rdbSaveMillisecondTime(rdb,expiretime) == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Save type, key, value */</span></span><br><span class="line">    <span class="comment">/* 保存键值对 类型的标识 */</span></span><br><span class="line">    <span class="keyword">if</span> (rdbSaveObjectType(rdb,val) == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="comment">/* 保存键值对 键的内容 */</span></span><br><span class="line">    <span class="keyword">if</span> (rdbSaveStringObject(rdb,key) == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="comment">/* 保存键值对 值的内容 */</span></span><br><span class="line">    <span class="keyword">if</span> (rdbSaveObject(rdb,val) == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>根据键的不同类型写入不同格式，各种键值的类型和格式如下所示。</p>
<p><img src="//blog.com/2019/07/13/Redis RDB 持久化详解/5.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Redis</code>有庞大的对象和数据结构体系，它使用六种底层数据结构构建了包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象的对象系统。感兴趣的同学可以参考 <a href="https://mp.weixin.qq.com/s?__biz=Mzg2NjE5NDQyOA==&amp;mid=2247483760&amp;idx=1&amp;sn=a601a4425e6316a4bba8d7936ce7c988&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">《十二张图带你了解 Redis 的数据结构和对象系统》</a>一文。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不同的数据结构进行<code>RDB</code>持久化的格式都不同。我们今天只看一下集合对象是如何持久化的。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ssize_t</span> rdbSaveObject(rio *rdb, robj *o) &#123;</span><br><span class="line">    <span class="keyword">ssize_t</span> n = <span class="number">0</span>, nwritten = <span class="number">0</span>;</span><br><span class="line">    ....</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (o-&gt;type == OBJ_SET) &#123;</span><br><span class="line">        <span class="comment">/* Save a set value */</span></span><br><span class="line">        <span class="keyword">if</span> (o-&gt;encoding == OBJ_ENCODING_HT) &#123;</span><br><span class="line">            dict *<span class="built_in">set</span> = o-&gt;ptr;</span><br><span class="line">            <span class="comment">// 集合迭代器</span></span><br><span class="line">            dictIterator *di = dictGetIterator(<span class="built_in">set</span>);</span><br><span class="line">            dictEntry *de;</span><br><span class="line">            <span class="comment">// 写入集合长度</span></span><br><span class="line">            <span class="keyword">if</span> ((n = rdbSaveLen(rdb,dictSize(<span class="built_in">set</span>))) == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">            nwritten += n;</span><br><span class="line">            <span class="comment">// 遍历集合元素</span></span><br><span class="line">            <span class="keyword">while</span>((de = dictNext(di)) != <span class="literal">NULL</span>) &#123;</span><br><span class="line">                sds ele = dictGetKey(de);</span><br><span class="line">                <span class="comment">// 以字符串的形式写入，因为是SET 所以只写入 Key 即可</span></span><br><span class="line">                <span class="keyword">if</span> ((n = rdbSaveRawString(rdb,(<span class="keyword">unsigned</span> <span class="keyword">char</span>*)ele,sdslen(ele)))</span><br><span class="line">                    == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">                nwritten += n;</span><br><span class="line">            &#125;</span><br><span class="line">            dictReleaseIterator(di);</span><br><span class="line">        &#125; </span><br><span class="line">    .....</span><br><span class="line">    <span class="keyword">return</span> nwritten;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/" itemprop="url">PHP使用nginx+sendfile机制实现大文件的下载</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-12T12:12:57+08:00">
                2019-07-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/PHP/" itemprop="url" rel="index">
                    <span itemprop="name">PHP</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/PHP/NGINX/" itemprop="url" rel="index">
                    <span itemprop="name">NGINX</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/PHP/NGINX/文件下载/" itemprop="url" rel="index">
                    <span itemprop="name">文件下载</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/PHP/NGINX/文件下载/sendfile/" itemprop="url" rel="index">
                    <span itemprop="name">sendfile</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/PHP/NGINX/文件下载/sendfile/zero-copy/" itemprop="url" rel="index">
                    <span itemprop="name">zero copy</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="PHP使用nginx-sendfile机制实现大文件的下载"><a href="#PHP使用nginx-sendfile机制实现大文件的下载" class="headerlink" title="PHP使用nginx+sendfile机制实现大文件的下载"></a>PHP使用nginx+sendfile机制实现大文件的下载</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用<code>PHP</code>来实现一个简单的文件下载功能时我们可能会直接使用<code>readfile</code>来读取文件的内容，然后输出到浏览器。就像下面这样：</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">download_v1</span><span class="params">($filename, $filePath)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        ini_set(<span class="string">'memory_limit'</span>, <span class="string">'1000M'</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// $filename = "Sphinx.zip";</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// $filePath = "/mnt/hgfs/www/37_project".DIRECTORY_SEPARATOR.$filename;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 校验通过后</span></span><br><span class="line">        header(<span class="string">'Content-Type: application/octet-stream'</span>);</span><br><span class="line"></span><br><span class="line">        ob_start();</span><br><span class="line">        readfile($filePath);</span><br><span class="line"></span><br><span class="line">        sleep(<span class="number">30</span>);</span><br><span class="line"></span><br><span class="line">        $data = ob_get_contents();</span><br><span class="line">        ob_end_clean();</span><br><span class="line"></span><br><span class="line">        header(<span class="string">'Accept-Length: '</span>.strlen($data));</span><br><span class="line">        $ua = $_SERVER[<span class="string">"HTTP_USER_AGENT"</span>];  <span class="comment">// 处理不同浏览器的兼容性</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (preg_match(<span class="string">"/MSIE/"</span>, $ua) || preg_match(<span class="string">"/rv:/"</span>, $ua)) &#123;</span><br><span class="line">            $encoded_filename = rawurlencode($filename);</span><br><span class="line">            header(<span class="string">'Content-Disposition: attachment; filename="'</span> . $encoded_filename . <span class="string">'"'</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (preg_match(<span class="string">"/Firefox/"</span>, $ua)) &#123;</span><br><span class="line">            header(<span class="string">"Content-Disposition: attachment; filename*=\"utf8''"</span> . $filename . <span class="string">'"'</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            header(<span class="string">'Content-Disposition: attachment; filename="'</span> . $filename . <span class="string">'"'</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">echo</span> $data;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当我们下载的是一些小文件，可能还能正常工作，但当我们下载一个较大的文件时，比如当我下载一个370M的文件时，可能就会直接出错了：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PHP message: PHP Fatal error:  Allowed memory size of <span class="number">134217728</span> bytes exhausted (tried to allocate <span class="number">129499136</span> bytes)</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然这是由于<code>PHP</code>对每一个脚本所能申请到的最大内存做了限制，默认最大能申请到128M，我们可以通过修改 <code>memory_limit</code> 的值来增大每个脚本所能申请到的最大内存，例如我们将它调整到1024M。再来执行我们的程序，发现又能正常下载了。当然这是一个治标不治本的办法，因为我们的内存是有限的，当有多个人同时在下载时，我们的服务器立马就会挂掉，我们可以通过监视器来查看一下我们的<code>PHP</code>及<code>nginx</code>的内存及<code>IO</code>的情况：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在我们下载文件前，无论是<code>nginx</code>还是<code>PHP</code>它们的内存，以及磁盘的读写都是很小的</p>
<p><img src="//blog.com/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/v2-faea42963d429df229092db356a47157_b.jpg" alt="img"></p>
<p><img src="//blog.com/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/v2-382025e9421ee6f8a1e371c9e89998c2_b.jpg" alt="img"></p>
<p><img src="//blog.com/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/v2-31eb672050bc72dbeecddce8572c89fc_b.jpg" alt="img"></p>
<p><img src="//blog.com/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/v2-d25b1622492c7bec289b683fb709bbb2_b.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当我们开始下载后，我们发现<code>PHP</code>的内存迅速飙升，<code>nginx</code>的<code>IO</code>也迅速飙升：</p>
<p><img src="//blog.com/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/v2-20acc734dc55109a6525a2f2e46ad811_b.jpg" alt="img"></p>
<p><img src="//blog.com/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/v2-17276e17fb2dba4f4c22fd3efb67fa0f_b.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这也很好理解，我们调用<code>readfile</code>将文件读入<code>buffer</code>中，所以<code>PHP</code>的内存飙升，当我调用<code>ob_end_clean</code>时，关闭了<code>buffer</code>并将数据输送到<code>nginx</code>中，<code>nginx</code>的<code>buffer</code>存放不了这么大的数据就会，就会将数据写入零时文件中，这就使得<code>nginx</code>的磁盘写入字节飙升，最后我们通过<code>echo</code>将数据输出到客户端时，<code>nginx</code>再将数据一段一段从零时文件中读取出来，发送到客户端。所以我们发现这种方式不仅会有内存问题，还有一次<code>copy</code>文件的过程，所以性能自然是比较低的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面我们使用<code>sendfile</code>机制来实现下载的功能，那么什么是<code>sendfile</code>呢？<code>sendfile</code>是现代操作系统提供的一个系统调用，每个<code>web</code>服务器可以通过配置文件设置是否开启该功能。它可以在两个文件描述符之间直接传递数据，从而避免了内核缓冲区数据和用户缓冲区数据之间的拷贝，也被称之为“零拷贝”模式。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先我们需要确保我们的<code>nginx</code>开启了<code>sendfile</code>:</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">sendfile</span> <span class="literal">on</span>;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后我们还要在<code>nginx</code>配置文件中加上以下这段：</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置 sendfile</span></span><br><span class="line"><span class="attribute">location</span> /assets/uploads/ &#123;</span><br><span class="line">     internal; # 表示这个路径只能在 Nginx 内部访问, 提高了安全性</span><br><span class="line">     <span class="attribute">root</span> /phpProjects/mphf/mph-backend;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个时候如果我们<code>PHP</code>代码中给的文件下载路径为<code>/assets/uploads/a.pdf</code>，则表示我们的下载文件为 <code>/phpProjects/mphf/mph-backend/assets/uploads/a.pdf</code> 。这时我们的<code>PHP</code>端只需要做一些校验，兼容性处理的工作，处理完后通过<code>X-Accel-Redirect</code>将下载的事交给<code>nginx</code>处理就行了。</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">download_v2</span><span class="params">($filename, $filePath)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 校验通过后</span></span><br><span class="line">        header(<span class="string">'Content-Type: application/octet-stream'</span>);</span><br><span class="line"></span><br><span class="line">        $ua = $_SERVER[<span class="string">"HTTP_USER_AGENT"</span>]; <span class="comment">// 处理不同浏览器的兼容性</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (preg_match(<span class="string">"/MSIE/"</span>, $ua) || preg_match(<span class="string">"/rv:/"</span>, $ua)) &#123;</span><br><span class="line">            $encoded_filename = rawurlencode($filename);</span><br><span class="line">            header(<span class="string">'Content-Disposition: attachment; filename="'</span> . $encoded_filename . <span class="string">'"'</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (preg_match(<span class="string">"/Firefox/"</span>, $ua)) &#123;</span><br><span class="line">            header(<span class="string">"Content-Disposition: attachment; filename*=\"utf8''"</span> . $filename . <span class="string">'"'</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            header(<span class="string">'Content-Disposition: attachment; filename="'</span> . $filename . <span class="string">'"'</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        header(<span class="string">'X-Accel-Redirect: '</span>.$filePath);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用<code>sendfile</code>机制后我们下载时我们再次通过活动监视器来查看，<code>nginx</code>及<code>PHP</code>的内存和<code>IO</code>的情况（再次测试时，最好将活动监视器，<code>nginx</code>和 <code>php-fpm</code> 关闭，然后再启动）：</p>
<p><img src="//blog.com/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/v2-31eb672050bc72dbeecddce8572c89fc_b.jpg" alt="img"></p>
<p><img src="//blog.com/2019/07/12/PHP使用nginx+sendfile机制实现大文件的下载/v2-bbbe49707dd90732f516a695afbe676d_b.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过监控我们发现<code>php</code>的内存不会在飙升了，<code>nginx</code>也不会有磁盘的写入了。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="attribute">limit_conn_zone</span> <span class="variable">$binary_remote_addr</span> zone=perip:<span class="number">10m</span>;</span><br><span class="line"><span class="attribute">limit_conn_zone</span> <span class="variable">$server_name</span> zone=perserver:<span class="number">10m</span>;</span><br><span class="line"></span><br><span class="line"><span class="attribute">sendfile</span>        <span class="literal">on</span>;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="attribute">limit_conn</span> perip <span class="number">10</span>;</span><br><span class="line"><span class="attribute">limit_rate_after</span> <span class="number">20m</span>;</span><br><span class="line"><span class="attribute">limit_rate</span> <span class="number">100k</span>;</span><br><span class="line"></span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后我们在通过<code>nginx</code>的限速来限制下载的速度，基本这个下载功能就OK啦！</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/11/如何设计编写业务代码/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/11/如何设计编写业务代码/" itemprop="url">如何设计编写业务代码</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-11T12:12:57+08:00">
                2019-07-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/代码规范与技巧/" itemprop="url" rel="index">
                    <span itemprop="name">代码规范与技巧</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/代码规范与技巧/代码技巧/" itemprop="url" rel="index">
                    <span itemprop="name">代码技巧</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/代码规范与技巧/代码技巧/Code-Review/" itemprop="url" rel="index">
                    <span itemprop="name">Code Review</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="如何设计编写业务代码"><a href="#如何设计编写业务代码" class="headerlink" title="如何设计编写业务代码"></a>如何设计编写业务代码</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="https://juejin.im/post/5c306528518825262058105a" target="_blank" rel="noopener">https://juejin.im/post/5c306528518825262058105a</a></p>
</blockquote>
<p><br></p>
<p>最近我一直在思考几个问题：</p>
<ul>
<li>业务代码究竟难不难写？</li>
<li>一直开发业务代码是不是完全学不到东西？</li>
<li>5年+开发经验的老程序员的价值在哪里？</li>
<li>如何通过面试来区分业务代码开发的水平？</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其实，这几个问题或多或少是相互关联的。有的时候大家也会自嘲说，“程序员接手的代码永远是烂摊子，然后自己继续在这个烂摊子上产出代码，留给又一波后人接手”。十几年来经历过十来个公司，我看了不少差的代码，也看了不少好的代码，自己产出过垃圾代码，也带领团队实现过一些自认为不错的代码。你可能会说，业务代码就是增删改查，和框架代码的难度不能比，完全是机械劳动，其实我觉得不完全是这样，甚至完全不是这样，我个人认为写出能跑的业务代码不难，但要写出好的业务代码其实是挺难的，更重要的是如果系统设计的足够好，在很长一段时间内系统的可维护性是可控的，只需要简单扩展即可，如果基础打的不够好，那么项目可能就是一次性项目，下面我列出业务系统我关注的一些点，你想想是不是有道理。</p>
<h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h2><h3 id="标准的项目结构"><a href="#标准的项目结构" class="headerlink" title="标准的项目结构"></a>标准的项目结构</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我自己非常注重搭建项目结构的起步过程，<strong>模块的划分、目录（包）的命名</strong>，我觉得非常重要，如果做的足够好，别人导入项目后可能只需要10分钟就可以大概了解结构了。</p>
<p>1、有些名词是约定俗成的，大家一眼就能看出是啥东西的，比如：</p>
<ul>
<li><code>controllers</code></li>
<li><code>services</code></li>
<li><code>configs</code></li>
<li><code>utils</code></li>
<li><code>commons</code></li>
<li><code>jobs</code></li>
</ul>
<p>比较重要的是<strong>确定先进行分类再分业务，还是先分业务再分类</strong>，在代码里混用这两种风格的结构就会很混乱：</p>
<ul>
<li><p><code>controllers</code></p>
<ul>
<li><code>order</code></li>
<li><code>user</code></li>
</ul>
</li>
<li><p><code>jobs</code></p>
<ul>
<li><code>order</code></li>
<li><code>user</code></li>
</ul>
</li>
<li><p><code>order</code></p>
<ul>
<li><code>services</code></li>
<li><code>mappers</code></li>
</ul>
</li>
<li><p><code>user</code></p>
<ul>
<li><code>services</code></li>
<li><code>mappers</code></li>
</ul>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>对于直筒的三层架构的纯数据表驱动的代码我建议第一层是分类，第二层是业务功能</strong>：</p>
<ul>
<li>看一眼<code>controllers</code>目录我们知道项目对外的<code>Api</code>能力</li>
<li>看一眼<code>services</code>目录我们知道项目的逻辑复杂度</li>
<li>看一眼<code>mappers</code>目录我们知道项目的表结构</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于<strong>有一些项目，不一定每一个逻辑都涉及到三层架构，数据流量比较复杂，我建议是按照业务功能先来分，下一层视情况也不一定完全是需要按照组件类型分二级目录，也可以是按功能来分</strong>：</p>
<ul>
<li><code>core</code><ul>
<li><code>storage</code></li>
<li><code>service</code></li>
</ul>
</li>
<li><code>dispatcher</code><ul>
<li><code>engine</code></li>
<li><code>context</code></li>
</ul>
</li>
<li><code>callback</code> <ul>
<li><code>gateway</code></li>
<li><code>handler</code></li>
</ul>
</li>
<li><code>notification</code><ul>
<li><code>sms</code></li>
<li><code>push</code></li>
</ul>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于这种目录结构一眼望去就能知道大概项目数据流和架构了，<code>core</code>对内，<code>dispatcher</code>做分发的感觉，<code>callback</code>是外部来的回调数据，<code>notification</code>是通知外部的数据流。这种数据流向复杂的项目，使用这种结构会比前一种合理的多，因为我们<strong>需要先关注数据流，而不是三层结构的层次</strong>，甚至对于<code>core</code>、<code>dispatcher</code>、<code>notification</code>我们知道其实是没有<code>controller</code>的。</p>
<p>2、有些名词可能就需要内部有一个统一，比如不同的层次面向数据库，面向业务，面向<code>UI</code>，面向<code>RPC</code>需要有不同的<code>POJO</code>，我们需要明确一套对应的命名，能明确就好，比如下面的这些<code>POJO</code>我们其实挺难分辨其用途的，需要进行规范，并且放置于匹配的目录结构中：</p>
<ul>
<li><code>CreateOrderRequest</code>/ <code>CreateOrderResponse</code></li>
<li><code>CreateOrderParam</code> / <code>CreateOrderDto</code></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以约定第一组用于服务本身访问外部（<code>Rpc</code>服务也好，<code>REST</code>服务也好），第二组用于服务本身对外提供的<code>Web Api</code>，比如：</p>
<ul>
<li><p><code>controllers</code></p>
<ul>
<li><code>OrderController</code><ul>
<li><code>queryOrder()</code></li>
<li><code>createOrder()</code></li>
</ul>
</li>
<li><code>QueryOrderParam</code></li>
<li><code>QueryOrderDto</code></li>
<li><code>CreateOrderParam</code></li>
<li><code>CreateOrderDto</code></li>
</ul>
</li>
</ul>
<ul>
<li><p><code>rpcs</code></p>
<ul>
<li><code>UserService</code><ul>
<li><code>login()</code></li>
<li><code>register()</code></li>
</ul>
</li>
<li><code>LoginRequest</code></li>
<li><code>LoginResponse</code></li>
<li><code>RegisterRequest</code></li>
<li><code>RegisterResponse</code></li>
</ul>
</li>
</ul>
<ul>
<li><p><code>services</code></p>
<ul>
<li><code>OrderService</code></li>
<li><code>OrderServiceImpl</code></li>
<li><code>OrderEntity</code></li>
</ul>
</li>
</ul>
<ul>
<li><p><code>storages</code></p>
<ul>
<li><code>OrderMapper</code></li>
<li><code>OrderModel</code></li>
</ul>
</li>
</ul>
<p>总之，虽然可能10+人在维护相同的项目，<strong>目录结构的风格、命名、专用名词的使用一定要统一</strong>。</p>
<h3 id="统一的框架"><a href="#统一的框架" class="headerlink" title="统一的框架"></a>统一的框架</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个需要在开展项目之前明确下来，我见过有项目中同时使用了<code>Spring MVC</code>和<code>Jersey</code>做<code>Web API</code>，同时使用了<code>Spring Scheduler</code>和<code>Quartz</code>做任务调度。最好是<strong>项目开展前明确框架的版本并且搭建好项目脚手架</strong>，大概涉及：</p>
<ul>
<li><code>Web API / Web MVC</code></li>
<li><code>Job Scheduler</code></li>
<li><code>Micro Service</code></li>
<li><code>Config Center</code></li>
<li><code>Redis Client</code></li>
<li><code>Data Access</code></li>
<li><code>Entity Mapper</code></li>
<li><code>MQ Client</code></li>
</ul>
<p>当然，我们也可以独立出依赖管理的项目，专门由独立模块进行依赖版本管理。最差也要在<code>Wiki</code>上进行明确。</p>
<h3 id="统一的API"><a href="#统一的API" class="headerlink" title="统一的API"></a>统一的API</h3><p>如果项目涉及到对外提供<code>API</code>，那么非常有必要在初期就规范<code>API</code>的框架定义，涉及到：</p>
<ul>
<li>包装类 <code>Result&lt;T&gt;</code>的定义（见过一个项目用了三种包装类的）以及遇到错误的情况下，<code>Http</code>状态码的体现 比如这样的包装类格式：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ApiResult</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> success;</span><br><span class="line">    String code;</span><br><span class="line">    String message;</span><br><span class="line">    String path;</span><br><span class="line">    <span class="keyword">long</span> time;</span><br><span class="line">    T data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以这么和客户端的开发来明确：</p>
<p>1、即使遇到错误，<code>Http</code>状态码还是200，<code>Http</code>状态码如果是500或是404的话那一定是网关层面的错误了，这个错误不是后端服务返回的</p>
<p>2、在<code>Http</code>状态码还是200的时候代表收到了后端的返回，前端去按照<code>ApiResult</code>以<code>Json</code>格式反序列化<code>Http Body</code>的报文</p>
<p>3、然后查看<code>success</code>（如果没<code>success</code>也行，我们可以约定<code>code</code>是200就是成功），如果是<code>success</code>代表后端服务成功处理了请求，如果不成功，则根据后端给的错误代码映射表根据<code>code</code>进行处理或直接提示<code>message</code>中的内容。注意，<strong>这里的success只代表后端是否成功处理了请求，不代表请求代表的业务逻辑是否成功处理</strong>。</p>
<blockquote>
<p>举一个例子，如果这个请求是异步支付请求，那么<code>success==true</code>代表前端给的参数都正确，后端正确接受了支付申请，不代表支付成功</p>
</blockquote>
<p>4、<strong>在<code>success==true</code>的情况下再去解析<code>data</code>中的内容，拿取客户端需要的信息</strong>，还是前面的例子，<code>data</code>里可以是<code>{&quot;orderStatus&quot;:&quot;PROCESSING&quot;, &quot;orderId&quot;:&quot;1234&quot;}</code>，这个才是真正业务逻辑的数据和状态，<code>success</code>并不代表订单支付操作就是成功的，也可能是处理中的状态</p>
<p>所以这是几个层次的事情，<code>Http Status-&gt;ApiResult.status-&gt;ApiResult.data.orderStatus</code></p>
<ul>
<li><strong>加解密规范和签名规范 Api的加密解密以及签名</strong>最好在设计的时候就考虑进去，而且要仔细斟酌，否则以后很难变更，特别<code>Api</code>的使用方是客户端的情况，客户端很难轻易强更。如果做<code>SAAS</code>服务，建议参考大厂的规范，比如亚马逊<code>AWS</code>的<code></code>API<code>规范或阿里云</code>API<code>的规范，不建议自己造轮子，大厂做的</code>API`规范都是经过安全方面的专家深度思考的。</li>
<li><strong>版本管理规范</strong>（比如<code>Url path</code>路由还是<code>Http header</code>路由） 如果使用了老版本的话，是否需要在返回内容中提示新版本的<code>Url</code>、版本号、老版本最后维护时间呢？这个就不展开了</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以统一<code>Api</code>这个事情不仅仅是<code>Api</code>的格式还涉及到<strong>安全处理、版本处理、客户端操作方式</strong>等等。对于一些需要服务端驱动客户端的业务（<code>UI</code>逻辑动态）来说，我们可以定义一套更复杂的<code>ApiResult</code>，让服务端告知客户端这个时候应该是提示还是跳转还是返回等等。</p>
<h3 id="统一的源码工作模式"><a href="#统一的源码工作模式" class="headerlink" title="统一的源码工作模式"></a>统一的源码工作模式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在大家都使用<code>Git</code>，分支如何管理每一个公司（在<code>Gitflow</code>的基础上）都会略有不同，也需要和大家明确：</p>
<ul>
<li><strong>分支的定义</strong>（<code>master</code>、<code>develop</code>、<code>release</code>、<code>hotfix</code>、<code>feature</code>）</li>
<li><strong>分支命名规范</strong></li>
<li><strong><code>checkout</code>、<code>merge request</code>流程</strong></li>
<li><strong>提测流程</strong></li>
<li><strong>上线流程</strong></li>
<li><strong><code>Hotfix</code>流程</strong></li>
</ul>
<p>别小这个，虽然这个和代码质量和架构无关，但是梳理清楚可以：</p>
<ul>
<li>提高开发和测试的工作效率，人多也乱</li>
<li>减少甚至杜绝代码管理导致的线上事故</li>
<li>让项目管理者和架构师可以明确什么代码现在在哪里</li>
<li>方便运维处理发布和回滚</li>
<li>让项目的开发可以灵活适应多变的需求</li>
</ul>
<h2 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;见过一些项目在实现业务代码的时候是不考虑任何<strong>异常处理、事务处理、锁处理</strong>的，在流量小无并发的情况下，这些项目不容易爆发出严重的问题，基本能用。但是对于高并发的项目或将来可能会高速发展的项目，如果不考虑这些问题会死的很难看。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们来想一下，如果现在在设计一个订单服务，如果因为网络问题、并发问题导致数据错乱、服务中断的可能在千分之一，如果一个业务一天只有1000次请求，1天才遇到这样1次问题，即使遇到了问题用户也不一定会来反馈，即使来反馈往往客服也能通过后台取消订单等操作来处理，这个问题不会爆发出来，如果一天的单量是1000万，那么每天可能就会有10000单异常的订单，这个可能就超过了客服的处理能力了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很少有项目真正100%完全做好了所有细节，只不过往往是因为量小得不到大家的重视罢了。但我们想一下，如果遇到数据库或中间件级别大规模故障的情况下，如果一致性处理的不好，那么数据库恢复后可能会留下一大堆异常数据需要修复，如果处理的好，业务数据不会错乱，数据库恢复后业务马上可以恢复。在遇到事故的时候，系统这方面的设计功力就体现出来了。</p>
<h3 id="一致性处理"><a href="#一致性处理" class="headerlink" title="一致性处理"></a>一致性处理</h3><p>在实现代码的时候需要考虑如下事情：</p>
<h4 id="本地事务处理"><a href="#本地事务处理" class="headerlink" title="本地事务处理"></a>本地事务处理</h4><p>本地事务处理：见过一些代码完全不考虑事务，或者是只是知其然使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@Transactional</span><br></pre></td></tr></table></figure>
<p>，但是方法内部完全<code>catch</code>了所有异常的情况 </p>
<ul>
<li>事务包含的方法块</li>
<li>嵌套事务、事务传播</li>
<li>什么时候遇到什么异常应该回滚</li>
<li><code>@Transactional</code>是否真正生效了？</li>
</ul>
<h4 id="外部服务调用的事务问题"><a href="#外部服务调用的事务问题" class="headerlink" title="外部服务调用的事务问题"></a>外部服务调用的事务问题</h4><ul>
<li>调用外部服务出现异常的时候，本地事务怎么处理</li>
<li>调用的外部服务是否允许重试（幂等调用）</li>
<li>调用外部服务出现未知结果后，怎么进行补偿</li>
<li>补偿是否有上限，是否存在死信数据卡死补偿的情况？</li>
<li>如果有2+外部服务连同本地数据库存储都需要有事务性，怎么实现</li>
</ul>
<h4 id="数据重复和顺序问题"><a href="#数据重复和顺序问题" class="headerlink" title="数据重复和顺序问题"></a>数据重复和顺序问题</h4><ul>
<li>先本地事务提交还是先调用外部接口（如果先调用外部接口，可能会遇到外部回调的时候本地事务还没提交找不到数据的情况）</li>
<li>从<code>MQ</code>收到的消息顺序问题怎么解决？</li>
<li>重新入<code>MQ</code>的延迟消息或重试消息乱序是否会有问题？</li>
<li>对外提供的<code>Api</code>或回调方法是否支持幂等？</li>
</ul>
<h4 id="锁的问题"><a href="#锁的问题" class="headerlink" title="锁的问题"></a>锁的问题</h4><ul>
<li><p>哪个层面做锁？服务层分布式锁还是数据库层面锁？</p>
</li>
<li><p>乐观锁还是悲观锁？</p>
</li>
<li><p>你确信你的<code>Redis</code>锁方案是可靠的吗？</p>
</li>
<li><p>你是否知道多少请求在排队等待，又是为什么？</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这些要做好真的很难，每一步都需要认证考虑，但是很遗憾见过的很多具有复杂业务的代码，在<code>Service</code>中一连串调用了N个外部服务进行写操作，方法内也实现了N个表的写操作，即不考虑外部服务的事务和补偿问题，本地也没有事务控制，出了错只是打印了堆栈然后客户端看到的是一个服务器忙。</p>
<h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;异常处理不仅仅是狭义上遇到了<code>Exception</code>怎么去处理，还有各种业务逻辑遇到错误的时候我们怎么去处理。 就拿记日志这一件事情来说：</p>
<ul>
<li><code>WARN</code>和<code>ERROR</code>的选择需要好好考虑，<code>WARN</code>一般我倾向于记录可自恢复但值得关注的错误，<code>ERROR</code>代表了不能自己恢复的错误。对于业务处理遇到问题用<code>ERROR</code>不合理，对于<code>catch</code>到了异常也不是全用<code>ERROR</code>。</li>
<li>记录哪些信息，最好打印一定的上下文（用户Id、订单Id、外部传来的关键数据）而不仅仅是打印线程栈。</li>
<li>记录了上下问信息，是否要考虑日志脱敏问题？可以在框架层面实现，比如自定义实现<code>logback</code>的<code>ClassicConverter</code></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们知道<code>catch</code>到了异常或遇到了业务错误，我们除了记录日志还有很多选择，也需要认真考虑什么时候应该做什么：</p>
<ul>
<li>直接返回</li>
<li>抛出异常</li>
<li>重试处理</li>
<li>恢复处理</li>
<li>熔断处理</li>
<li>降级处理</li>
<li>甚至关闭业务</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这又涉及到了弹力设计的话题，我们的系统往往会对接各种外部服务、<code>Api</code>，大部分服务都不会有<code>SLA</code>，即使有在大并发下我们也需要考虑外部服务不可用对自己的影响，会不会把自己拖死。我们总是希望：</p>
<ul>
<li>尽可能以小的代价通过尝试让业务可以完成</li>
<li>如果外部服务基本不可用，而我们又同步调用外部服务的话，我们需要进行自我保护直接熔断，否则在持续的并发的情况下自己就会垮了</li>
<li>如果外部服务特别重要，我们往往会考虑引入多个同类型的服务，根据价格、服务标准做路由，在出现问题的时候自动降级</li>
</ul>
<h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><h3 id="表"><a href="#表" class="headerlink" title="表"></a>表</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;表的设计和<code>Api</code>的定义类似，属于那种开头没有开好，以后改变需要花<code>10x</code>代价的，我知道，一开始在业务不明确的情况下，设计出良好的一步到位的表结构很困难，但是至少我们可以做的是有一个好的标准：</p>
<ul>
<li><strong>统一的附加字段</strong>，<code>create_time</code>，<code>update_time</code>，<code>version</code>等</li>
<li><strong>表的命名标准</strong>，比如<code>[domain]_[tablename]_[tabletype]</code></li>
<li><strong>字段类型、长度标准</strong></li>
<li>虽没有外键，但是<strong>外表关联字段和主表字段的命名标准</strong></li>
<li>_id还是_no等字段命名的区别</li>
</ul>
<p>除了标准，尽可能需要结合业务以及业务可能的扩展思考一下：</p>
<ul>
<li><strong><code>1:N</code>的可能性</strong>，是有1就足够了，还是一开始就要设计<code>1:N</code>的层次关系</li>
<li>如果表字段可能会很多，业务变化多，是否考虑<code>1:1</code>甚至<code>1:N</code>的扩展表，<strong>把扩展字段从主表分开</strong></li>
<li><strong>表的领域职责</strong>，表可能也会分上游、中游、下游，什么字段应该在哪里太重要了（我觉得表的领域相当于之前提到的项目结构中的包的分类，这个最好一开始定义清楚）</li>
<li><strong>关联表字段冗余冗余到什么程度，冗余字段的同步</strong></li>
<li><strong>枚举的维护方式，是否考虑字典表</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于表结构文档，我觉得列出字段类型、长度、说明是不够的，如果能结合业务代码梳理清楚下面这些，那这个文档就是真正有价值的<em>表结构文档</em>：</p>
<ul>
<li><strong>记录由哪个业务模块创建</strong></li>
<li><strong>数据重要程度</strong></li>
<li><strong>数据归档方案</strong></li>
<li><strong>字段数据源头</strong></li>
<li><strong>字段会由谁更改</strong></li>
<li><strong>字段可能会在哪里缓存</strong></li>
</ul>
<h3 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我想90%的业务项目都是所谓的三层结构，<code>Web</code>层处理参数调用<code>Service</code>层做<code>Db</code>层的聚合，<code>Db</code>层基本就是代码生成或<code>Orm</code>框架补充少量的手写<code>SQL</code>。对于这样的项目，大部分人认为是没有设计的，也不需要设计。我认为那是因为没有好好思考：</p>
<ul>
<li><strong>在我们写下<code>if-else</code>的时候，我们就可以考虑使用抽象类+具体实现类的方式来替代</strong></li>
<li><strong>在实现层次化业务处理的时候，就可以考虑使用Filter或职责链模式来实现</strong></li>
<li><strong>在封装外部Api的时候与其每次都写一套解析逻辑，我们是否考虑进行动态封装呢</strong></li>
<li><strong>在数据改变后我们要记录改版轨迹，与其复制粘贴是否考虑过发布订阅模式</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;说白了就是利用各种设计模式和<code>OO</code>思想，来尽可能在业务变化需要扩展的时候：</p>
<ul>
<li><strong>只是新增代码而不是修改代码</strong></li>
<li><strong>尽可能减少重复代码复制粘贴</strong></li>
<li><strong>尽可能让同类代码都呆在一起</strong></li>
<li><strong>尽可能让直筒式的代码有层次</strong></li>
</ul>
<h2 id="往大了说"><a href="#往大了说" class="headerlink" title="往大了说"></a>往大了说</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一个公司层面，如果有几十个，几百个业务项目，我们看这个公司的技术水平到了什么程度，我个人认为不仅仅是用了什么新技术，而是是否：</p>
<ul>
<li>具有统一的开发、服务框架</li>
<li>具有统一的运维、监控、中间件、测试平台</li>
<li>具有清晰的纵向领域划分</li>
<li>具有清晰的横向基础平台服务和基础业务服务</li>
<li>具有统一的代码工作模式</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最简单的一个例子，一个业务从前到后跨10个事业部，100个服务，实现灰度测试，想想这件事情有多难？整个公司层面要实现步调一致的这些东西还确实很难，不仅仅是技术能力的体现，没有良好的组织架构，人心不齐，恐怕这些无法实现，实现了也无法推广，推广了也无法持续……当然，这些已经超出个人能做的了，作为程序员的我们应该从我做起，认真考虑前面提到的这些问题，至少在项目内部做良好的设计。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;再来看看文首的问题，你看，虽然只是写业务代码，如果要写的足够好，必须要了解设计模式、理解各种弹力设计、理解事务、熟悉框架、了解中间件原理，怎么可能学不到东西，要实现健壮的业务代码，其实很难，要考虑的东西太多了，如果说写框架我们需要考虑不同的使用方和使用环境，这很难，写业务代码我们要考虑到千奇百怪的使用行为，要考虑到层次不起的对接方，这不比写框架简单。对于5年+经验丰富的程序员应当有能力开一个好头，或者说愿意在老代码上去做一些改变，否则你的价值在哪里呢？</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/25/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/25/">25</a><span class="page-number current">26</span><a class="page-number" href="/page/27/">27</a><span class="space">&hellip;</span><a class="page-number" href="/page/147/">147</a><a class="extend next" rel="next" href="/page/27/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">刘泽明</p>
              <p class="site-description motion-element" itemprop="description">做一个懂业务的程序员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">731</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">394</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">237</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘泽明</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
