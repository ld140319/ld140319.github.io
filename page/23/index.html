<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="搬运工 + 践行者" type="application/atom+xml">






<meta name="description" content="做一个懂业务的程序员">
<meta property="og:type" content="website">
<meta property="og:title" content="搬运工 + 践行者">
<meta property="og:url" content="http://blog.com/page/23/index.html">
<meta property="og:site_name" content="搬运工 + 践行者">
<meta property="og:description" content="做一个懂业务的程序员">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="搬运工 + 践行者">
<meta name="twitter:description" content="做一个懂业务的程序员">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.com/page/23/">





  <title>搬运工 + 践行者</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">搬运工 + 践行者</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">记录学习的技能和遇到的问题</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/28/如何做一个靠谱的发号器/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/28/如何做一个靠谱的发号器/" itemprop="url">如何做一个靠谱的发号器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-28T12:12:57+08:00">
                2019-07-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/分布式ID生成/" itemprop="url" rel="index">
                    <span itemprop="name">分布式ID生成</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="如何做一个靠谱的发号器"><a href="#如何做一个靠谱的发号器" class="headerlink" title="如何做一个靠谱的发号器"></a>如何做一个靠谱的发号器</h1><p><br></p>
<blockquote>
<p>原文地址：<a href="https://mp.weixin.qq.com/s/VI6boay48QSWhEj5jtjGcw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/VI6boay48QSWhEj5jtjGcw</a></p>
</blockquote>
<p><br></p>
<h2 id="为什么需要一个发号器"><a href="#为什么需要一个发号器" class="headerlink" title="为什么需要一个发号器"></a>为什么需要一个发号器</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在使用数据库时，表的主键经常会使用数据库的自增（<code>auto_increment</code>）来产生。这当然很方便也很高效。但是使用自增也会带来一些麻烦。如果从一个数据库以外的地方，也就是发号器来产生全局唯一 ID，这些问题就可以得到解决，生活就可以更美好。</p>
<ul>
<li><p><strong>难以适应分片场景</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在采用数据库分片时，如果使用数据库自增 ID，不同分片上会产生相同的 ID。单靠 ID 无法唯一标示一个对象，还需要额外加上分片字段才行。如果需要将 ID 用于其他对象的关联时，会麻烦很多。而采用发号器生成的是全局唯一的 ID，单靠 ID 就能实现关联。同时，这也使得采用 ID 作为分片字段成为可能。</p>
</li>
<li><p><strong>主备切换时数据冲突</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在 MySQL 集群发生主备切换时，异步复制无法确保主从完全同步。在备库开放写入后，备库上产生的自增 ID 会和尚未同步的主库上的数据冲突。这样一来，即使原来的主库恢复了，也无法重新加入集群。数据修复也变成了一件非常困难的事情。引入发号器以后，备库上插入的 ID 和原来主库上的 ID 是不会重复的。因此，未复制的新增数据和对这些新增数据的修改就不会在备库发生冲突。</p>
</li>
<li><p><strong>网络异常时无法判断插入是否成功</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当插入记录时，如果使用数据库自增 ID，在完成插入后，才能得到产生的 ID。如果在执行语句时发生网络中断，客户端无法知道事务是否成功，即使成功，也无法再获得产生的 ID。如果使用发号器，就可以在插入之前预先产生 ID。如果碰到网络中断，可以用已经获得的 ID 去尝试查询来判断之前的插入是否成功。</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此外，一些业务 ID 会需要一个全局唯一的整数作为它的组成部分。其他的分布式系统可以用全局单调的唯一 ID 作为事务号。有一个现成的服务就不用各自实现了。</p>
<h2 id="发号器的必要特性"><a href="#发号器的必要特性" class="headerlink" title="发号器的必要特性"></a>发号器的必要特性</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;既然叫发号器，首先就得保证 ID 的全局唯一。就是说保证无论什么情况下都不会发出重复的 ID。这看起来很简单，但是事实上，很多实现却上并没有做到这点。要真正做到全局唯一，发号器必须要实现 <code>crash safe</code>，并不受外部环境变化影响。</p>
<ul>
<li><p><strong><code>crash safe</code></strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先是 <code>crash safe</code>。即得保证在服务崩溃重新恢复后，不会产生已经发过的 ID。在服务彻底完蛋时，也要能够在其他地方恢复出一个一定能用的。有的实现定期保存或者异步保存已经发过的 ID。如果发生崩溃，如果直接用保存过的 ID 继续发，就会发出已经发过的号。有的实现采用 <code>MySQL</code> 或 <code>Redis</code>来产生 ID。由于 <code>MySQL</code> 和<code>Redis</code>的复制本身难以保证强一致，在发生主备切换时，备机尚未完全同步的话，还是会发出重复的 ID 来。有的实现没有使用副本，单纯靠分片来实现负载均衡和高可用，这时如果某个实例完蛋了，想要重新恢复一个就没法了。</p>
</li>
<li><p><strong>不受外部环境变化影响</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很多发号器实现是基于时间戳的。但是有些实现直接采用了机器上的时间戳作为 ID 的一部分。如果机器时间发生回跳（不要认为这不可能），就会造成 ID 重复。使用时间戳同时也对机器时间的精度有了依赖。</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;要让发号器能真正有用，还得实现高可用，并能支撑足够大的吞吐量。不然发号器本身也会成为一个单点或瓶颈。</p>
<h2 id="如何设计发号器"><a href="#如何设计发号器" class="headerlink" title="如何设计发号器"></a>如何设计发号器</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有赞同样有对发号器的需求。经过对现有实现的考察后，我们还是打算实现一个自己的发号器，我给它起了个名字：<code>March</code>。我们的发号器同样要解决这些问题。</p>
<h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;要满足真正的全局唯一，持久化是必须的。而且持久化还必须是不会丢失的，强一致的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果发号器实现是分散在各个应用服务器上的，由于应用服务器的持久化能力是难以保证的，可靠性就会受影响。而且这样一来，每个应用服务器也要有一个终身及死后也全局唯一的 ID 作为产生的 ID 的一部分，来满足全局唯一，这就大大提高了部署和运维的门槛。所以，我们认为<strong>发号器最好还是集中式</strong>的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在采用集中式的前提下，持久化的副本也是不可少的。要自己实现这样的一个持久化系统是很难的。所以，在持久化方案上，我们选择了现成的 <code>etcd</code>。<code>etcd</code> 能满足<strong>不会丢失的，多副本，强一致</strong>的全部需求。<strong>持久化就可以全部放到<code>etcd</code> 中，发号器本身就可以是无状态的，这样一来，高可用的实现也会容易一些</strong>。</p>
<h3 id="是否全局单调"><a href="#是否全局单调" class="headerlink" title="是否全局单调"></a>是否全局单调</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;是否全局单调其实是个权衡。在确定要高可用的前提下，全局单调和负载均衡是不可兼得的（可以想想为什么）。我们最终还是选择实现全局单调。全局单调的 ID 有额外的好处。作为主键时，可以直接代替时间字段排序。由于 <code>MySQL</code>二级索引是指向主键的，使用主键排序通常可以避免排序操作，直接利用索引就能完成。另外，如果要实现一些分布式一致性系统，一个全局单调的 ID 生成器也是一个必备的组件。</p>
<h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>由于采用了全局单调，高可用方案就只能是主备的</strong>。<strong>一个集群内，同时只能有一个实例对外提供服务</strong>。这时候就要考虑怎么实现选主和故障切换。既然我们用了<code>etcd</code>，实现高可用的时候也正好可以用上它的 <code>TTL</code>、<code>Watch</code>这些特性。然后也要能让客户端知道哪个实例才是主实例，可以自动切换访问路径。</p>
<h3 id="ID-的形式"><a href="#ID-的形式" class="headerlink" title="ID 的形式"></a>ID 的形式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;发号器产生的 ID 一般都是 64 位整数，这样对数据库比较友好，容量也能满足业务需求，不会哪天爆了。通常产生的 ID 可以分成两大类。一类是单纯的<code>Sequence</code>，即一个不断递增的整数。另一类是基于 <code>Timestamp</code>的，由于机器时间的精度限制，通常都会额外再加一段 <code>Sequence</code>。为了分布式，还经常会加上各种不同的标示实例的位。不同的实现无非就是这些东西的组合以及各段的长短的变化。有赞之前已经有了几个实现。新的发号器要落地，也得兼容现有的。所以不同的 ID 的形式还是都得支持。但是具体实现细节上，可以比原有的更进一步。</p>
<h3 id="认证和权限控制"><a href="#认证和权限控制" class="headerlink" title="认证和权限控制"></a>认证和权限控制</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用发号器的业务方会有很多。为了信息安全，和避免相互干扰，认证和权限控制功能也有了需求。<code>March</code> 可以设置多个用户，为每个用户分配访问不同的发号器的权限，以及其他的创建，管理类权限。用户信息同样不能丢，所以也持久化在<code>etcd</code>中。</p>
<h3 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;作为一个服务，就会有和客户端交互。有交互，就要有一个协议。我们希望尽量能采用一个现成的协议。这样对实现不同语言的客户端会方便很多。同时这个协议要足够轻量高效，也能具备扩展性。我们最后选择了 <code>Redis</code>协议。<code>Redis</code> 协议很简单，协议本身的负担小。由于是个广泛使用的东西，各种语言都有它的库。这样在实现客户端 <code>SDK</code> 的时候，就有了个很好的起点。现成的一些命令，如 <code>INCR</code>，<code>INCRBY</code>，<code>GET</code> 等本身也很适合用于发号器。在需要一些特殊的功能时，也可以自己添加新命令。高可用方面，<code>Redis Cluster</code>的协议也可以用上。这样客户端的自动切换就不用自己实现了。对于服务端，好几个语言也都有现成的库。</p>
<h2 id="发号器的实现"><a href="#发号器的实现" class="headerlink" title="发号器的实现"></a>发号器的实现</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有赞的发号器 <code>March</code>是用 <code>Go</code> 语言实现的。语言选择上其实没太大讲究。不过对于这类项目，<code>Go</code>在开发效率，部署简便，和倾向低延迟的 <code>gc</code> 优化还是有一些优势。</p>
<h3 id="ID生成"><a href="#ID生成" class="headerlink" title="ID生成"></a>ID生成</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面说过，发号器产生的 ID 可以分成两大类。一类是 <code>Sequence，</code>一类是基于<code>Timestamp</code> 的。这两类有各自的实现。</p>
<ul>
<li><p><code>Sequence</code></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>March</code>在启动时会从<code>etcd</code>中载入之前持久化的已经发过的 id 作为起点。然后执行一次持久化，将起始<code>id + batch</code>保存下来。 <code>[ id, id + batch )</code> 的区间就是缓存。客户端请求时，下发的 id 都是从这个缓存中取的。同时启动一个<code>goroutine</code>来做持久化。在这个缓存的容量低于水位线（默认是 50%）时，会异步通知这个持久化<code>goroutine</code> 进行持久化，将<code>id + batch * 2</code> 保存下来。此时，缓存的上界就扩容到了<code>id + batch * 2</code>，以此类推。由于持久化是异步的，所以一般情况下，并不会阻塞请求，造成请求延迟增大。但是有突发的并发时，在持久化没进行完，缓存就已经耗尽的情况下，为了保证正确性，才会发生阻塞，等待持久化完成。所以，对于高并发的应用，配置一个大的缓存区间可以获取更高的性能。比如将 <code>batch</code>设为 10000，平均发出 10000 个号才需要持久化一次。备机平时是不提供服务的，在发生主备切换时，备机才会从持久化中重新载入配置。所以备机提升为主机以后，也可以保证不会发重，只是从客户端看来，会跳空一段 id。不过这也算不上什么问题。</p>
</li>
<li><p><code>Timestamp</code></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Timestamp</code>类型的 ID 分成 3 段：<code>node</code>，<code>timestamp</code>，<code>sequence</code>。通过配置各个段的长度和偏移，以及时间戳的精度，就可以兼容各种已有的基于时间戳的发号器实现。多个请求到来时，如果<code>timestamp</code> 相同，会增长 <code>sequence</code>。<code>timestamp</code> 改变时，就清零<code>sequence</code>。有一点特别的地方是，我们允许<code>sequence</code> 段溢出。 溢出的部分会加到<code>timestamp</code> 段上去。这样即使在时间戳精度范围内<code>sequence</code>耗尽了，也不用阻塞请求。<code>Timestamp</code>类型持久化的是时间，保存的是当前的 <code>timestamp</code> + 提前量。这里的 <code>timestamp</code>是包含 <code>sequence</code> 溢出的部分。<code>Timestamp</code>类型的持久化是定时进行的。由于已持久化的时间戳总是大于当前时间的，因此等待持久化而造成的阻塞基本上是不会发生的。<code>March</code> 启动时，如果获取的当前时间大于保存的时间，就使用当前时间作为起点，否则就使用已保存的时间作为起点。每次请求获取时间时也是类似。如果发现获取的时间小于已经发过的 <code>timestamp</code>，就继续使用当前 <code>timestamp</code>。这样就确保了即使机器时间跳变时，发出的 id 也是单调增长的，绝对不会重复。同时由于允许溢出，也不会因为时间回跳而阻塞。当然这种方式带来的一个影响是，如果从获取的 id 里解析出时间，可能并不是准确的时间。由于切换或溢出，看到的时间可能会提前。不过本来也不应该依赖这些细节不是么。</p>
</li>
</ul>
<h3 id="高可用-1"><a href="#高可用-1" class="headerlink" title="高可用"></a>高可用</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>March</code> 的高可用是利用<code>etcd</code>的 <code>ttl</code> 和 <code>watch</code> 实现的</strong>。<strong>启动时，先尝试创建一个新的带<code>ttl</code>的 <code>Node</code></strong>。<strong>如果成功，就成为了主节点；如果由于已存在而失败，就成为了备节点</strong>。</p>
<ul>
<li><p>主节点</p>
<p>定时用前一次请求返回的<code>index</code> 刷新<code>Node</code>的 <code>ttl</code>，保持自己的主节点角色。发现刷新失败时，说明主节点角色已经被抢走，从抢主节点过程重新开始。与此同时，还会等待<code>demote</code>请求。收到 <code>demote</code>请求时，会等待新的主节点信息，然后将自己置为备节点。</p>
</li>
<li><p>备节点</p>
<p>先查询主节点的信息。在备节点收到发号请求时，会按<code>Redis Cluster</code>协议重定向到主节点。之后就开始 <code>Watch Node</code>的变化。检测到变化后，也开始抢主节点过程。</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样，可以做到在主节点发生故障时，最多等待一个 <code>ttl</code>就能检测到，并完成切换。而在主动切换时，结合客户端，可以做到完全无损，只有毫秒级的阻塞。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此外，每个节点都会存保存各自的带<code>ttl</code>的节点信息，同时定时刷新，用于返回给客户端集群信息。每个发号器在每次持久化时，也会携带上上一次持久化获得的 <code>index</code>。一旦不匹配出错，也会将自身重置为备节点。这可以避免网络堵塞或进程僵死造成原主失效而自身却不知道。在发生非预期错误时，<code>HA goroutine</code>会等待 <code>2 * ttl</code>，以免不断出错造成死循环。此外，备节点也需要能够完成用户认证。但因为认证是不能重定向的，所以还需要检测 <code>etcd</code> 上的用户信息变化，重新同步用户数据。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;发号器看起来简单，但是要实现一个靠谱的，易用的，要考虑到的地方还是很多的。其实很多东西都是这样。我们还做了更多。为了更容易接入落地，我们在数据库中间件中也做了集成。配置后，执行 <code>insert</code> 时，会自动代入配置的自增字段和 id 值，让业务方完全无痛。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/27/可扩展性设计/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/27/可扩展性设计/" itemprop="url">可扩展性设计</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-27T12:12:57+08:00">
                2019-07-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/" itemprop="url" rel="index">
                    <span itemprop="name">微服务</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/分布式系统/高可用/" itemprop="url" rel="index">
                    <span itemprop="name">高可用</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/分布式系统/高可用/扩展性/" itemprop="url" rel="index">
                    <span itemprop="name">扩展性</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="可扩展性设计"><a href="#可扩展性设计" class="headerlink" title="可扩展性设计"></a>可扩展性设计</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可扩展性的重要程度在很多系统中往往被低估，扩展性是衡量系统架构优劣的一个非常重要的判断指标，但是也不能盲目追求扩展性，还要兼顾成本，以下的示例将会告诉我们可扩展性设计的重要程度。</p>
<blockquote>
<p>Facebook在2009年每天产生3千万张照片；2013年每天产生3.5亿张照片；2015年产生20亿张照片。</p>
<p>阿里巴巴2009年首个双十一一天内销售额为5000万；2012年双十一一天内销售额为191亿；2017年双十一一天内销售额为1682亿元，11秒内即破亿。</p>
</blockquote>
<h2 id="加机器能解决问题吗"><a href="#加机器能解决问题吗" class="headerlink" title="加机器能解决问题吗"></a>加机器能解决问题吗</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;任何一个系统，随着业务的快速发展，都需要考虑或解决扩展性的问题。系统是否可以做到流量来临的时候通过扩展避免宕机，甚至不降低用户体验，很多互联网公司在用户规模增长速度比较快，技术积累不足的阶段都发生过宕机事件。比较典型的例子是聚美优品为了庆祝三周年，做了大量宣传、广告，受到了大量关注。为了应对流量的爆发聚美方面多次为服务器扩容，并制定了详细的技术应对方案，老板陈欧在微博中写道：“我们的后台已经准备好了宕机出现，如果真的出现宕机就给技术人员每人发一把刀切腹”。 但是当促销真正开始的时候，出现了大量宕机事故，网页无法打开、永远都在排队中，用户戏称：“我终于明白了聚美优品三周年，打破低价你想不到的折扣这句广告词的真谛，就是价格多低我也进不去看不见”，甚至有的用户认为宕机是阴谋，为了“少赔点儿”，对于用户来说宕机是难以理解的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外一个例子，京东初期，和当当网、苏宁、国美频频发生“价格战”，京东商城CEO刘强东通过微博宣称：“京东商城所有大家电将在未来三年内保持零毛利，并保证比国美、苏宁连锁店便宜至少10%以上。”苏宁易购立即开始进行反击，苏宁易购执行副总裁李斌通过微博宣称：“包括家电在内的所有产品价格必然低于京东。”活动开始不到10分钟，由于服务器瞬间流量暴增，苏宁官网和苏宁易购就出现访问困难和无法登录的情况，整个促销伴随的是服务器频频宕机、网站打不开。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上面的两个例子能够看出，扩展性是多么重要。到了关键时刻绝不仅仅是加机器这么简单。</p>
<h2 id="横向扩展与纵向扩展介绍"><a href="#横向扩展与纵向扩展介绍" class="headerlink" title="横向扩展与纵向扩展介绍"></a>横向扩展与纵向扩展介绍</h2><p>我们也可以<strong>把加机器得到的性能提升叫做横向扩展</strong>。</p>
<p><strong>横向扩展（scale out）</strong>也叫水平扩展，指用更多的节点支撑更大量的请求。例如1台机器支撑<code>10000TPS</code>，两台机器是否能支撑<code>20000TPS</code>？</p>
<p><strong>纵向扩展（scale up）</strong>也叫垂直扩展，扩展一个点的能力支撑更大的请求。通常通过提升硬件实现，例如把磁盘升级为<code>SSD</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>横向扩展通常是为了提升吞吐量，响应时间一般要求不受吞吐量影响即可</strong>。因为本身在访问量比较小的时候，响应时间就是可接受的范围，例如去分布式缓存<code>get</code>一条数据的响应时间在毫秒级，理想情况如图所示，只要在吞吐量不断提升的情况下保持这个响应时间就可以。当然，<strong>响应时间和吞吐量在资源一定的情况下，通常是互斥关系，如果要降低响应时间，可以通过纵向扩展，提升单机能力，或者改变数据存储结构，压缩等方式</strong>。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/1.webp" alt="img"></p>
<p><em>响应时间和吞吐量随节点数变化关系图</em></p>
<h2 id="AKF扩展立方体"><a href="#AKF扩展立方体" class="headerlink" title="AKF扩展立方体"></a>AKF扩展立方体</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提到可扩展性，就不得不提著名的<code>AKF</code>扩展立方体（<code>Scalability Cube</code>），<code>AKF</code>是<code>ebay</code>前副总裁<code>Martin Abbott</code>在<code>《The Art of Scalability》</code>一书中的经典理论，作者把系统在架构上的扩展性按照三个维度进行说明，如图所示。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/2.webp" alt="img"></p>
<p><em>AKF扩展立方体</em></p>
<p>下面我们通过表格简单说明一下三个轴适用的场景、优势及挑战。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/3.webp" alt="img"></p>
<p><em>AKF扩展立方体</em></p>
<p>下面我们可以用一个例子来说明，系统是如何从初期一步步扩展的。假设，我们现在要开发一个微博系统。</p>
<p><strong>第一阶段。</strong>产品初期，可能我们只有十人左右的团队，还没有用户，需求也不确定。如图所示，此时我们只需要通过单体架构实现，为了容灾，我们可以在前端放置一个负载均衡服务，后端采用两个服务。数据库为了容灾也可以采用<code>Master-Slave</code>的架构。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/4.webp" alt="img"></p>
<p><em>单体架构，按X轴扩展</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随着用户访问的快速增长，当系统出现性能瓶颈的时候，我们此时采用的是X轴的扩展方式，通过不断的克隆<code>service</code>，增加<code>service</code>的数量来应对。当数据库出现瓶颈的时候，我们可以做读写分离。这就是按照X轴扩展的思路。</p>
<p><strong>第二阶段。</strong>用户快速增长，产品需求快速增加，研发团队可能会接近百人，沟通效率越来越低，数据库主从延迟问题开始暴漏，磁盘压力逐步加大。为了缓解这些问题，首先，作为过渡阶段，可以再增加业务服务实例的数量，数据库可以通过提升硬件的性能暂时抵抗压力。另一方面，我们开始按照业务领域拆分服务，如图所示，每个服务独享一个数据库，接口是服务与外部联系的唯一通道。这样既降低了耦合度，提升了沟通效率，又可以缓解数据库的压力，实现分库操作。但是，在数据库中，单表的数据量持续增长，假设我们用<code>MySQL</code>，随着数据量的增加，响应时间变长，吞吐量下降，此时我们首先会进行垂直分表，例如用户表有100个字段，但是我们常用的可能是10个字段，我们会按照一对一的方式拆分为两张表。可以参考微服务架构拆分的相关内容。这就是按照Y轴扩展的思路。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/5.webp" alt="img"></p>
<p><em>微服务架构，按Y轴扩展</em></p>
<p><strong>第三阶段。</strong>随着用户规模的快速增长，数据库成为了性能瓶颈，如图所示，我们会通过<code>MQ</code>削峰填谷，解决写的性能瓶颈，通过分布式缓存解决读的性能瓶颈。在数据库一侧，我们会对表进行水平拆分，例如，我们有3千万用户数据，可以根据用户ID拆分为4张表，每张表750万条数据。为了解决拆分带来的复杂性，可以通过数据库中间件屏蔽底层分表细节。当然，这时候很可能会遇到数据中心的容量瓶颈，促使我们去建立多数据中心，按照用户的地域去切分数据，让数据离用户更近一些。这就是按照Z轴扩展的思路。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/6.webp" alt="img"></p>
<p><em>Z轴扩展</em></p>
<h2 id="如何扩展长连接"><a href="#如何扩展长连接" class="headerlink" title="如何扩展长连接"></a>如何扩展长连接</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先，应该尽量减少长连接，实际上并不是每个应用都需要那么及时。大部分都可以通过短连接搞定。例如电商的App，所有的浏览、下单都可以基于短连接实现，极少需要长连接。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，我们假设要设计一个微博App客户端和服务端的交互。当我关注的人发了一条微博，此时如果我不在线，并不需要马上收到，完全可以当我上线的时候通过短连接去拉取消息。但是，如果我正在看微博，应该提醒我有几条新消息，这个通知是需要及时性的。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/7.webp" alt="img"></p>
<p><em>微博App客户端和服务端的交互</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，及时性消息也不一定非得是长连接，也可以采用定时轮询的方式。实际上，在真实的生产环境，为了保证到达率，通常需要长连接和短连接配合，因为长连接在网络条件不好的情况下，经常会出现各种各样的问题，导致不能及时到达，通过轮询心跳的方式可以定时拉取消息，缓解长连接推送失败的问题。</p>
<h3 id="当其中一个push服务挂掉的时候，客户端应该作何反应"><a href="#当其中一个push服务挂掉的时候，客户端应该作何反应" class="headerlink" title="当其中一个push服务挂掉的时候，客户端应该作何反应"></a>当其中一个<code>push</code>服务挂掉的时候，客户端应该作何反应</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么，问题来了，当其中一个<code>push</code>服务挂掉的时候，客户端应该作何反应？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;常用的方案有两种：反向代理和注册中心。</p>
<h4 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，可以在<code>client</code>和<code>push</code>之间增加一层反向代理服务，<code>client</code>并不知道具体的<code>push</code>服务，通过反向代理服务转发，另外反向代理也兼具负载均衡的作用。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/8.png" alt="img"></p>
<p><em>反向代理</em></p>
<h4 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a>注册中心</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，如果现在存在一个注册中心，就可以<code>client</code>在连接<code>push</code>服务的时候，先到注册中心获取可以连接的列表，然后再根据<code>push</code>服务的地址去连接<code>push</code>服务，这样，如果一个<code>push</code>服务挂掉，就可以让<code>client</code>连到另外一个<code>push</code>服务了。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/9.webp" alt="img"></p>
<p><em>注册中心</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果需要推送的消息量太大，可能会导致雪崩，我们需要限流，业界普遍会在推送服务前增加<code>MQ</code>以削峰填谷。</p>
<h3 id="如何记录client和push的对应关系"><a href="#如何记录client和push的对应关系" class="headerlink" title="如何记录client和push的对应关系"></a>如何记录client和push的对应关系</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;还有另外一个问题，当推送消息的时候，肯定要知道通过哪个<code>push</code>服务去推送，因为<code>client</code>不可能和所有的<code>push</code>服务建立长连接，单机的连接数是有限的，如何记录<code>client</code>和<code>push</code>的对应关系呢？</p>
<h4 id="将映射关系数据放入缓存"><a href="#将映射关系数据放入缓存" class="headerlink" title="将映射关系数据放入缓存"></a>将映射关系数据放入缓存</h4><p><strong>方法一、</strong>记录<code>client</code>和<code>pushserver</code>的映射关系。如图所示，将关系数据放入缓存。</p>
<p>优势：扩容可以不用影响现有节点连接。假设现在有两个节点，扛不住压力了，扩容到3个节点，此时我们只需要把新的连接连到新的节点，已经存在的连接可以不用断开重连。</p>
<p>劣势：需要维护<code>client</code>和<code>pushserver</code>的映射关系。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/10.webp" alt="img"></p>
<p><em>消息推送映射关系</em></p>
<h4 id="根据节点总数计算映射关系"><a href="#根据节点总数计算映射关系" class="headerlink" title="根据节点总数计算映射关系"></a>根据节点总数计算映射关系</h4><p><strong>方法二、</strong>根据节点总数计算映射关系。</p>
<p>优势：简单。只需要知道现在一共有几个<code>pushserver</code>，根据<code>ClientID</code>对总节点求余、一致性哈希或者根据用户ID的范围，就应该知道应该推送到哪个节点。</p>
<p>劣势：首先，<strong>如果扩容需要断开一批连接，重新连到新的<code>pushserver</code>节点，有中断的可能</strong>。其次，如果根据范围计算，有可能存在热点，某个<code>pushserver</code>压力很大，而其他节点比较轻松。最后，如果一旦<code>push</code>节点挂掉，就要重新建立连接。有时成本是比较高的，假设我们一共有4个节点，监控到一个节点故障，此时要把这个节点的连接转移到其他三个节点，一旦故障节点恢复，因为三个节点压力较大，我们又要再让客户断开连接，连到新的节点。如图所示，如果我们建立几个冗余节点，一旦发生故障，迅速把<code>back</code>节点顶上来，后面故障节点恢复后可以作为<code>back</code>节点。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/11.webp" alt="img"></p>
<p><em>备份节点</em></p>
<h2 id="如何扩展数据库"><a href="#如何扩展数据库" class="headerlink" title="如何扩展数据库"></a>如何扩展数据库</h2><h3 id="X轴扩展—主从复制集群"><a href="#X轴扩展—主从复制集群" class="headerlink" title="X轴扩展—主从复制集群"></a>X轴扩展—主从复制集群</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设我们的<code>service</code>访问数据库的吞吐量在4500TPS，其中写为500TPS，这种典型的读多写少的场景，我们通常会采用读写分离，如图所示，将所有的读请求分发到<code>Slave</code>上，<code>Master</code>只负责写，<code>Master</code>和<code>Slave</code>之间通过数据库自带同步机制复制数据。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/12.webp" alt="img"></p>
<p><em>Master-Slave结构</em></p>
<p>在这种方案中，多个<code>Slave</code>服务器异步的复制<code>Master</code>的数据，复制步骤如下。</p>
<ol>
<li><p><code>Master</code>将更新记录到二进制日志(<code>binary log</code>)中。</p>
</li>
<li><p><code>Slave</code>将<code>Master</code>的日志(<code>binary log</code>)拷贝到它的中继日志(<code>relay log</code>)。</p>
</li>
<li><p><code>Slave</code>重做中继日志中的事件。</p>
</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于很多业务都符合读多写少的特点，使得这种扩展方式简单有效，可以很容易的缓解读负载。采用主从复制还可以将服务进行隔离，例如，终端用户访问<code>Slave-01</code>，系统内部统计工具访问<code>Slave-02</code>，当运营人员做系统内部统计的时候会使<code>Slave-02</code>压力骤增，这种隔离方式将起到保护<code>Slave-01</code>不受影响。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方案的问题在于当<code>Slave</code>增加到一定数量时，<code>Slave</code>对<code>Master</code>的负载以及网络带宽都会成为严重的问题。本身单库承受不了可能是因为磁盘<code>IO</code>达到上限，而同步数据同样需要消耗<code>Master</code>服务器的性能。</p>
<p>使用新版本有助于解决部分问题，如MySQL5.7在主从复制方面提供了几个比较实用的功能。</p>
<ol>
<li><p>多源复制（多主一从）。</p>
</li>
<li><p>半同步复制改进。</p>
</li>
<li><p>基于组提交（<code>LOGICAL_CLOCK</code>）的并行复制。</p>
</li>
</ol>
<h3 id="Y轴扩展—分库、垂直分表"><a href="#Y轴扩展—分库、垂直分表" class="headerlink" title="Y轴扩展—分库、垂直分表"></a>Y轴扩展—分库、垂直分表</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Master-Slave</code>集群适合读多写少的场景，只能通过不断增加<code>Slave</code>的实例个数解决读的性能问题，但是毕竟<strong>只能通过<code>Master</code>写入，单节点的写入能力有限</strong>，况且，如果要满足写后读一致性，就需要让读也访问<code>Master</code>，当系统规模不断增大时，如果写成为了瓶颈点，就需要考虑Y轴的扩展了。首先要考虑的是分库，分库是指把原来一个数据库中的多张表根据数据量、访问量、关联程度分解到多个数据库中。通常<strong>分库操作是和微服务拆分同步进行的，可以根据微服务划分的原则进行划分，划分后每个服务独享一个数据库</strong>。<strong>分库的最大特点就是相对简单，尤其适合各业务之间的耦合度比较低，业务逻辑非常清晰的系统</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分库相对于<code>Master-Slave</code>集群付出的成本更高，<strong>需要处理分布式事务问题、关联查询问题</strong>。但是相对于下面的方案更简单一些。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;垂直分表是分库的一种特殊形式。有的业务中，单表字段数非常多，一些电商中的用户表可能超过200个字段。虽然表内的字段确实是一对一的关系，但是实际上，并不是所有的字段都是常用的，通常这200个字段可能只有十几个字段是常用的。如果我们已经进行了分库，将用户表独立出来了，仍然存在性能问题，此时我们可以尝试进行垂直分表。也就是把单表的字段垂直拆分为多张表。初期可以放到一个数据库中，查询的时候更简单。如果仍然存在性能问题，可以分到不同的数据库，放到不同的物理机上。</p>
<h3 id="Z轴扩展—分片（sharding）"><a href="#Z轴扩展—分片（sharding）" class="headerlink" title="Z轴扩展—分片（sharding）"></a>Z轴扩展—分片（sharding）</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果采用分库、垂直分表还是不能解决问题，此时只能通过Z轴的扩展方式，进行分片了。什么时候开始考虑分片呢？由于采用分片会导致架构的复杂度大幅上升，所以如果能避免应该尽量避免。一般按照经验值，<code>MySQL</code>在单表十个字段以下，<strong>数据量达到1千万左右</strong>时，如果采用<code>SATA</code>磁盘，性能会遇到比较大的瓶颈。如果此时数据量还是大幅增长，就应该考虑分片了。</p>
<h4 id="分片目标"><a href="#分片目标" class="headerlink" title="分片目标"></a>分片目标</h4><p>数据库分片的目标如下：</p>
<ol>
<li><p><strong>数据量尽可能分布均匀</strong>。因为数据量会对数据库造成压力，影响性能指标。在100条数据里搜索一条数据和在一亿条数据里搜索一条数据完全不一样。</p>
</li>
<li><p><strong>访问量尽可能分布均匀</strong>。例如微博某大V，如果发布一条“介绍女朋友”的信息，可能会有几千万的的转发评论。最好不要存在某个点特别热，因为扩缩容通常是整体架构的行为，当然也可以通过缓存的方式，让热点数据尽量命中缓存，缓解热点问题。</p>
</li>
<li><p><strong>一次访问尽可能落到一个分片</strong>。在分片的时候，按照哪个<code>key</code>进行切分可以决定一次请求会访问几个分片。例如，如果订单表按照订单ID进行切分，以买家维度进行查询时，势必造成要遍历所有的表，这样通过分片提升的性能就大打折扣。系统的扩展性受到挑战。</p>
</li>
<li><p><strong>数据迁移量尽可能少</strong>。当需要扩容的时候，为了不中断服务，数据迁移的过程是比较复杂的，需要迁移的数据量越少，对系统整体的压力就会越小。</p>
</li>
</ol>
<h4 id="分片算法"><a href="#分片算法" class="headerlink" title="分片算法"></a>分片算法</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据库分片对原有的架构破坏性很大，需要考虑的地方很多，因此分片的算法至关重要，以下我们就来了解一下几种常用的分片算法。</p>
<h5 id="区间法（Range-Based）"><a href="#区间法（Range-Based）" class="headerlink" title="区间法（Range-Based）"></a>区间法（Range-Based）</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，假设现在一共有2000万条记录，此时，我们可以按照ID的范围分成四张表，每张表独占一个数据库。当然也可以根据时间、地域、组织进行切分，例如一个月一张表、一个省一张表、一个租户一张表等等。电信级的应用很多是基于省份分片，这样做的另一个好处是隔离性。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/13.webp" alt="img"></p>
<p><em>区间法</em></p>
<p>区间法的优势：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;利于排序，这几种分区算法中，只有区间法可以配合分区算法更容易排序。</p>
<p>区间法的缺点：</p>
<ol>
<li><p><strong>容易导致热点问题</strong>。假设上图中<code>500w-1000w</code>压力较大，此时如何分裂？如何迁移数据？</p>
</li>
<li><p><strong>需要额外的元数据记录</strong>。</p>
</li>
</ol>
<p>适用场景如下：</p>
<ol>
<li><p><strong>历史数据严重低于最近的数据访问，历史数据可以归档</strong>。例如电商中订单的物流信息，可能保留三个月就可以了。</p>
</li>
<li><p><strong>数据分布相对比较均匀的场景</strong>。</p>
</li>
<li><p><strong>数据按照区域需要隔离的场景</strong>。</p>
</li>
</ol>
<h5 id="轮流法（Round-Robin）"><a href="#轮流法（Round-Robin）" class="headerlink" title="轮流法（Round-Robin）"></a>轮流法（Round-Robin）</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;轮流法是<strong>根据关键字对分片总量求余以实现均匀分布</strong>。给定一个数据K，应该放到哪个分区？可以按照这个公式<code>n= K mod N</code>，N代表分片总数，K代表分片关键字，n就是我们要放的节点位置。如图所示，如果把用户ID作为key，userID=1的数据对4求余等于1，应该放到第二个数据库。如果key是自增长的int或long，数据分布均匀，不容易出现热点问题。如果key是规律的字母或数字组成，则很容易出现问题，此时我们可以对key计算hash值缓解。公式变为<code>n= Hash(K)mod N</code>。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/14.webp" alt="img"></p>
<p><em>轮流法</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>采用轮询法，当进行扩容的时候，最好是成倍扩容，迁移的数据量少</strong>。例如从两个节点扩容为四个节点，需要迁移一半的数据。我们举例说明一下，如果现在有两个库，采用轮询法分库，现在由两个库扩展为三个库，发生移动的数据量为三分之二。但是如果是从两个分片变为四个分片，只有一半的数据发生了移动，迁移的数据量更少，并且达成了扩容的效果。</p>
<p>轮询法的优势如下：</p>
<ol>
<li><p>简单，开发运维人员看到<code>Key</code>的时候，很容易知道这条数据应该在哪个分片。</p>
</li>
<li><p>不需要维护元数据。</p>
</li>
</ol>
<p>轮询法的缺点如下：</p>
<ol>
<li><p><strong>当进行扩缩容的时候，迁移的数据量较大</strong>。</p>
</li>
<li><p>不容易排序。</p>
</li>
</ol>
<p>轮询法的适用场景如下：</p>
<ol>
<li><p><strong>不经常扩缩容的场景</strong>。</p>
</li>
<li><p>不需要排序或者可以用其他方式代替的场景。</p>
</li>
</ol>
<h5 id="一致性哈希法（Consistent-Hashing）"><a href="#一致性哈希法（Consistent-Hashing）" class="headerlink" title="一致性哈希法（Consistent Hashing）"></a>一致性哈希法（Consistent Hashing）</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设现在我们有一张用户表，水平切分为两张表。用户ID是自增长的。现在我们计算一下用户ID是<code>1、2、3、4、5、6、7、8、9</code>的数据应该如何分布？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;按照轮流法进行<code>MOD</code>，结果应该如图所示，<code>DB-0</code>储<code>2/4/6/8</code>，<code>DB-1</code>存储<code>1/3/5/7/9</code>。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/15.webp" alt="img"></p>
<p><em>一致性哈希法</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果现在进行扩容，扩展到3个数据库。如图所示，DB-0中的2要迁移到DB-2，4要迁移到DB-1，DB-1中的3要迁移到DB-0，DB-1中的5要迁移到DB-2。只剩下框内的数据没有发生移动。实际上，DB-2只是存储了3条数据，却移动了5条数据（所以，<strong>一般基于<code>MOD</code>算法的数据扩容，通常是基于倍数进行，原因就是为了减少数据迁移量</strong>）。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/16.webp" alt="img"></p>
<p><em>数据迁移</em></p>
<p>那么，有没有办法只移动3条数据呢？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一致性哈希就是为了解决这个问题而生的。一致性哈希算法（<code>Consistent Hashing</code>）是在1997年由麻省理工学院提出的一种分布式哈希（<code>DHT</code>）实现算法，设计目标是为了解决因特网中的热点(<code>Hot Spot</code>)问题，一致性哈希相比其他算法可以减少数据的迁移量。一致性哈希的架构如图所示：</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/17.webp" alt="img"></p>
<p><em>一致性哈希</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先将<code>key</code>按照常用的<code>hash</code>算法对应到一个具有<code>2^32</code>次方个桶的空间中，即<code>0~(2^32)-1</code>的数字空间中。我们可以将这些数字头尾相连，想象成一个闭合的环形，如图所示，2的32次方是42亿，这相当于有了42亿个节点，当然这些节点不必真的对应一个数据库，可以认为是一个虚拟节点。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/18.webp" alt="img"></p>
<p><em>哈希环（一）</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在假设将两个数据库的IP、HostName加上端口计算出一个<code>hash code</code>值，如果DB-0是1201（虚拟的），DB-1是13465456，将这两个节点分布在这个环上，那么所有的数据如果通过<code>hash code</code>后取模计算出的结果落在0-1201范围，就放到<code>DB-0</code>上，如果在<code>1201-13465456</code>或者大于<code>13465456</code>就放到DB-1上。如图所示，<strong>一致性哈希是按照顺时针分布数据的</strong>。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/19.webp" alt="img"></p>
<p><em>哈希环（二）</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;继续用上面的例子，将用户ID（1-9）也用同样的方法算出<code>hashcode</code>并对42亿取模将其存放到环形节点上。假设（1/4/6/7）落在了DB-0，（2/3/5/8/9）落在了DB-1，如果现在新增一个节点，假设按照IP、HostName加上端口计算出一个<code>hash code</code>值是23123，只有落在DB-1的数据（2/3/5/8/9）涉及到迁移，DB-0可以保持不变，可能3/8迁移到了新的节点。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们简单介绍了一致性哈希大致原理，到这里大家应该大致明白<strong>一致性哈希为什么迁移的数据量比较小，因为一致性哈希最终是基于范围迁移的</strong>。相对于直接通过范围分片，一致性哈希做了一次哈希值计算，分散了热点。当然，这里存在一个比较大的问题，<strong>当节点比较少的时候，数据分布不均匀。会导致热点的存在，为了解决这个问题。又引入了虚拟节点（<code>virtual node</code>）的机制</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，可以针对每个节点虚拟出N个节点，因为虚拟出的节点是按照<code>hash code</code>并对42亿取模结果放到哈希环上的，所以，不会像很多初学者认为的那样排好序的，结果是散落在环上的，也就是说DB-0对应的是DB-0-1和DB-0-2。他们在环上并不是一定会挨在一起的，<strong>当虚拟节点足够多的时候，是平均散落在环上的</strong>。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/20.webp" alt="img"></p>
<p><em>哈希环（三）</em></p>
<p>假设现在<code>DB-0</code>发生故障，按照顺时针，<code>DB-0-1</code>的数据会落到<code>DB-2-0</code>上，<code>DB-0-2</code>的数据会落在<code>DB-1-1</code>上。</p>
<p>一致性哈希的优势：</p>
<ol>
<li><strong>扩缩容数据迁移量较少</strong>。【增加节点只影响顺时针前一个节点，减少节点只影响顺时针后一个节点】</li>
</ol>
<p>一致性哈希的缺点：</p>
<ol>
<li>算法复杂，不容易调试。</li>
<li>不容易排序。</li>
</ol>
<p>一致性哈希的适用场景：</p>
<ol>
<li>不需要排序或者可以用其他方式代替的场景。</li>
</ol>
<h4 id="如何避免重新均衡数据"><a href="#如何避免重新均衡数据" class="headerlink" title="如何避免重新均衡数据"></a>如何避免重新均衡数据</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为重新均衡是昂贵的。<strong>需要重新均衡的原因是分片是静态的，但是数据是动态的，业务是动态的，也就是说，可能现在是均衡的，过了一段时间，变成不均衡的了</strong>。也有可能某段时间是均衡的，另外一段时间是不均衡的。如很多<code>SNS</code>类的网站，初始阶段，活跃用户可能集中在1千万以下的区间，过了几年，活跃用户可能会集中在1亿到2亿之间，这是一个动态变化的过程。所以，在分片的时候，要用发展的眼光看问题。</p>
<h4 id="管理分片"><a href="#管理分片" class="headerlink" title="管理分片"></a>管理分片</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;管理分片是一个复杂的问题。我们很难实现数据的强一致性，如果采用分布式事务，会使性能、扩展性受到很大影响。如何进行<strong>分页、排序</strong>等查询？以前一条<code>SQL</code>就搞定了，如果使用了分片，当进行分页、排序的时候，就会变的非常复杂了。如为了避免热点，根据哈希分了64张表，查询出按时间排序后的第10000条到100010条数据，这就需要去所有分片取数据，在内存中进行计算。当然，也可以建立另一维度的数据去解决。但是这增加了架构的复杂度，有可能还要为此引入其他的服务。因此，水平分表应该作为最后一个选择。</p>
<h4 id="为什么要带拆分键"><a href="#为什么要带拆分键" class="headerlink" title="为什么要带拆分键"></a>为什么要带拆分键</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们都知道当数据库进行水平分表的时候，需要通过拆分键路由进行查询。这是为什么呢？<strong>因为如果你不带拆分键，就要到所有的表去查询，数据库中间件不知道去哪查。虽然可以通过并行的方式查询所有表，但是这会导致数据库的压力提升</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，如果带上拆分键<code>uid</code>，则很容易定位到<code>DB2</code>，如果不带拆分键<code>uid</code>，数据库中间件不知道去哪查，只能查询所有的数据库。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/21.webp" alt="img"></p>
<p><em>是否带拆分键对比</em></p>
<h4 id="分片后的关联查询问题"><a href="#分片后的关联查询问题" class="headerlink" title="分片后的关联查询问题"></a>分片后的关联查询问题</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们通过一个例子来了解这个问题。例如，一个库中包含两张表，一个用户表，一个订单表，如果查询“北京的订单金额大于100的数量”，在一个库中可以通过关联查询完成。如果用户和订单被划分到了不同的服务，再进行关联查询，就非常麻烦了。</p>
<h5 id="方案一：建立多维度数据库"><a href="#方案一：建立多维度数据库" class="headerlink" title="方案一：建立多维度数据库"></a>方案一：建立多维度数据库</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以尝试建立另外一个综合数据库，相当于为了进行关联查询多冗余了一份数据。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，电商中比较典型的例子。实施微服务架构后，商品、价格、库存垂直划分为多个独立的数据库。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/22.webp" alt="img"></p>
<p><em>建立多维度数据库</em></p>
<p>更新时，通过消息中间件异步更新到综合数据库内。</p>
<p>查询时，直接从综合数据库查询。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然综合表有可能变得臃肿，但是综合表的查询一般是后台管理人员使用，查询频率较低。当然，综合表可以替换为<code>Mongodb</code>，因为<code>Mongodb</code>可以自动伸缩。运维的工作量要更简单。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个类似的做法是在大数据平台建立综合数据查询系统，问题是有可能存在延迟。需要根据具体业务场景决定。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;建立多维度数据库方案的优势是架构简单，问题主要包含如下两方面：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. 可能存在不一致的风险。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.  综合表有可能变的庞大无比，如果查询量比较大，可能会成为性能瓶颈。</p>
<h5 id="方案二：建立外部搜索引擎"><a href="#方案二：建立外部搜索引擎" class="headerlink" title="方案二：建立外部搜索引擎"></a>方案二：建立外部搜索引擎</h5><p>如图所示，可以通过分布式的搜索引擎，建立倒排索引，进行全文检索。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/23.webp" alt="img"></p>
<p><em>建立外部搜索引擎</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;全文检索目前有很多开源的方案，最为流行的莫过于<code>apache solr</code>和<code>elasticsearch</code>。很多互联网公司的全文检索解决方案都是用这两个框架或者基于这两个框架进行开发。他们的共同点是底层都采用了<code>lucene</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种方案目前应用比较广泛，在电商场景中比较常见。</p>
<h5 id="方案三：通过分布式缓存"><a href="#方案三：通过分布式缓存" class="headerlink" title="方案三：通过分布式缓存"></a>方案三：通过分布式缓存</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过分布式缓存，冗余数据。如果存在一份数据相对比较小，占用空间并不是特别大，可以用这种方案存储结果性数据。特别适合于多对多的场景。这种方案常用在<code>SNS</code>类系统的综合查询。</p>
<h4 id="分片扩容（re-sharding）"><a href="#分片扩容（re-sharding）" class="headerlink" title="分片扩容（re-sharding）"></a>分片扩容（re-sharding）</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分片的时候，应该从长期考虑，避免频繁的进行重新分片（<code>re-sharding</code>），因为重新分片会导致大量的数据迁移。可以根据未来数据量的增长速度、架构调整的可能性进行规划，如果预留太多会导致成本增加，预留太少会导致频繁迁移，根据经验值，可以预留未来1-2年的空间，<strong>如果害怕资源浪费，可以把多个实例部署到一台服务器</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设现在有两个分片，采用<code>MOD</code>的分片算法，如果存在（0-9）的用户ID，进行<code>MOD</code>后的分布情况是DB-0（0/2/4/6/8）, DB-1（1/3/5/7/9）。按照前面我们的建议，最好是<strong>按照倍数扩容，此时迁移的比例最少</strong>，因为当数据量较大的时候，迁移会对系统压力造成很大的影响，应该尽量减少迁移。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以<code>MySQL</code>为例，应该选择流量较小的时段进行扩容。禁止在高峰期扩容。</p>
<h5 id="停服扩容"><a href="#停服扩容" class="headerlink" title="停服扩容"></a>停服扩容</h5><p>如图所示，停服扩容步骤如下。</p>
<ol>
<li><p>选择好升级的时间段，评估升级所需时长，对外沟通，挂出公告。</p>
</li>
<li><p>到时间后，所有流量在前端负载均衡处转发到停服公告页面，观察数据库状态，没有流量后先对数据库进行备份，然后开始升级。</p>
</li>
<li><p>新建两个数据库，分别命名为DB-2、DB-3。可以通过一些开源的迁移工具，也可以自己开发一个迁移服务，或者利用存储过程进行迁移数据。</p>
</li>
<li><p>迁移完成后，删除DB-0、DB-1冗余的数据。验证数据完整性、一致性。</p>
</li>
<li><p>如果有数据库中间件，修改中间件分片策略；如果没有数据库中间件，修改<code>service</code>的分片策略。</p>
</li>
<li><p>验证。如果没有问题流量切回。如果发现问题，再挂出公告利用前面的备份进行回滚。</p>
</li>
</ol>
<p><img src="//blog.com/2019/07/27/可扩展性设计/24.webp" alt="img"></p>
<p><em>停服扩容</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种做法比较简单，容易操作。但是需要停止服务，要求一次性作对，否则回滚比较麻烦。这在产品初期，访问量不是特别高，技术实力较差时可以选择停服扩容。但是通常需要扩容的情况，一般数据量都比较大了。技术人员的水平、熟练程度、前期的准备工作对于这种方案的成败起到了决定性的作用，包括中断的时长也会受到以上因素影响。</p>
<h5 id="基于数据库的0中断扩容"><a href="#基于数据库的0中断扩容" class="headerlink" title="基于数据库的0中断扩容"></a>基于数据库的0中断扩容</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先需要说的是，0中断并非不能有中断，而是<strong>中断的时间足够短，可以忽略，不需要通知用户，或者对用户体验影响不大</strong>。以下案例假设存在数据库中间件，如果没有，则需要基于业务服务进行操作。</p>
<ol>
<li><p>选择好升级的时间段，先对数据库备份。</p>
</li>
<li><p>通常为了容灾，提升读性能，此时应该已经有了<code>Slave</code>节点。如果没有<code>Slave</code>，如图所示，需要先分别为两个数据库建立<code>Slave</code>实例DB-2、DB-3。</p>
</li>
</ol>
<p><img src="//blog.com/2019/07/27/可扩展性设计/25.webp" alt="img"></p>
<p><em>建立Slave</em></p>
<ol start="3">
<li>当<code>Master</code>和<code>Slave</code>之间延迟较小时，修改数据库中间件配置，停止写入，只能读取。如图所示，将<code>Slave</code>提升为<code>Master</code>。</li>
</ol>
<p><img src="//blog.com/2019/07/27/可扩展性设计/26.webp" alt="img"></p>
<p><em>将Slave提升为Master</em></p>
<ol start="4">
<li>如图所示，修改数据库中间件配置，分片规则改为四个库。</li>
</ol>
<p><img src="//blog.com/2019/07/27/可扩展性设计/27.webp" alt="img"></p>
<p><em>修改数据库中间件配置</em></p>
<ol start="5">
<li><p>修改数据库中间件配置，允许正常读写。注意，<strong>此时存在冗余数据，必须要求数据库中间件具备排重功能</strong>。</p>
</li>
<li><p><strong>删除冗余数据</strong>。</p>
</li>
</ol>
<p>注意，从3到5，读取不受影响。写入是中断的，中断的时长取决于前期的准备工作和操作的熟练程度，一般可以控制到分钟级。如果希望中断时间更短，可以把主从同步修改为主主同步或者半同步复制，会缩短中断时间。但是，这需要提前做好准备。</p>
<p>另外，也可以把所有的写入数据暂时记录日志或者写入<code>MQ</code>，等到主从完全一致之后，先写入日志或者<code>MQ</code>的数据。</p>
<h5 id="基于数据库中间件的0中断扩容"><a href="#基于数据库中间件的0中断扩容" class="headerlink" title="基于数据库中间件的0中断扩容"></a>基于数据库中间件的0中断扩容</h5><p>还有一种方案和上一种方案类似，只不过是通过数据库中间件完成的。大致步骤如下。</p>
<ol>
<li><p>备份数据。</p>
</li>
<li><p>建立另外两个数据库实例DB-2、DB-3，分别作为DB-0、DB-1的副本。可以通过迁移工具（基于状态机模式读取<code>binlog</code>）让数据尽量接近。</p>
</li>
<li><p>修改数据库中间件配置，停止<code>update</code>和<code>delete</code>，只能<code>insert</code>和读取，<code>insert</code>的时候需要通过数据库中间件进行双写，将DB-0的数据同步写入到DB-2，将DB-1的数据同步写入到DB-3。</p>
</li>
<li><p>比对数据，当DB-0和DB-2的数据完全一致，DB-1和DB-3的数据完全一致的时候，修改数据库中间件配置，开始<code>update</code>和<code>delete</code>。</p>
</li>
<li><p>修改数据库中间件配置，修改分片规则，切换为4个库进行读写。</p>
</li>
<li><p>删除冗余数据。如图所示，扩容结束。</p>
</li>
</ol>
<p><img src="//blog.com/2019/07/27/可扩展性设计/28.webp" alt="img"></p>
<p><em>基于数据库中间件的0中断扩容</em></p>
<p>这个方案中断的只有<code>update</code>和<code>delete</code>，如果业务场景这两个操作比较少，比较适合这个方案。</p>
<p>在实际的业务中，如果复杂度较高，会混合使用以上的分片算法，例如微信红包的规则为<code>db_xx.t_y_dd</code>，<code>xx/y</code>代表红包ID的<code>hash</code>值后三位，<code>dd的</code>代表天数，实际上混用了一致性哈希和区间法，通过这种混合的分片算法，既避免了区间法导致的热点数据的问题，又利于迁移数据，可以按照天为单位整张表进行迁移。</p>
<h4 id="精选案例"><a href="#精选案例" class="headerlink" title="精选案例"></a>精选案例</h4><h5 id="活动平台数据表水平切分"><a href="#活动平台数据表水平切分" class="headerlink" title="活动平台数据表水平切分"></a>活动平台数据表水平切分</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，假设现在有一个活动平台，管理员可以创建活动，为活动添加用户，针对一个活动给用户发送促销短信或邮件提醒。按照场景，正常的操作逻辑是，查询关注某活动的所有用户，并且发送消息。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/29.webp" alt="img"></p>
<p><em>活动平台需求关系</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这是一个典型的多对多，通常当用户数据量比较大的时候，会先选择分库，也就是把用户表独立到一个数据库，活动和活动关系表放到一个数据库。活动一般不会特别多，或者说活跃的活动不会特别多，但是活动用户关系表会非常大。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果活动库变的非常大，此时该如何切分？一般不会选择直接把活动用户关系表独立到一个库，由于活动的数据量不是特别大，分库的效果不好，避免不了水平分表。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果按照活动进行分片，当查询关注活动的所有用户时，可以在一个分片内查出所有数据，但是按照活动进行分片会产生热点数据，因为有的活动可能用户比较多，而有的活动用户比较少。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果按照用户进行切分，虽然不会有热点数据问题。但是当查询关注活动的所有用户时，需要遍历所有分片。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实际上，关系数据只是两个id而已，数据条数可能比较多，但是占用的存储空间并不会特别大，可以优先考虑通过缓存缓解数据库的压力，不做分区。活动有明显的时效性，一旦活动结束，数据就可以归档到历史数据库了。因为关系数据一般不会更新，可以将缓存的过期时间设置的长一点。</p>
<h5 id="SNS数据表水平切分"><a href="#SNS数据表水平切分" class="headerlink" title="SNS数据表水平切分"></a>SNS数据表水平切分</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很多人用过微博或者微信，主要的表结构包括用户表、用户关系表（谁关注了谁）、消息表（发的微博、朋友圈），关系如图所示。用户之间是有关系的，通常发布出去的内容按照用户的查询方式有多个维度。例如在微博中，首页通常是<code>timeline[1]</code>，是自己看的比较多的页面，还有一个页面是<code>profile[2]</code>，关注者会经常访问。当消息的量比较大时，需要进行水平分表，如何切分保证不去遍历所有的分片呢？</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/30.webp" alt="img"></p>
<p><em>SNS需求关系</em></p>
<blockquote>
<p>[1]Timeline是指你可以看到的你关注的所有人发布的消息流，通常按照时间排序形成。</p>
<p>[2]Profile是指自己或者单个人发布的所有信息的流，通常按照时间排序形成。</p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果按照发布消息的用户ID去切分数据，在查询<code>profile</code>的时候，可以在一个分片取到所有数据，但是，在查看<code>timeline</code>的时候，就面临着遍历所有的分片数据。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如以下表格所示，根据需求有两张表，分别是消息表和用户关注表，如果消息表被分为8张表，根据求余的算法，用户ID为1的消息会落入第一个分片，用户ID为2的消息会落入第二个分片，如果查询用户ID为1的<code>profile</code>页面，可以直接在第一个分片取到所有数据，但是在用户关注表中我们不难发现，用户ID为10001的用户关注了用户ID为1和2的两个用户，如果用户10001查询自己的<code>timeline</code>页面，需要遍历所有分片。而<code>timeline</code>才是读取量比较大的页面，这样性能会非常低。</p>
<p>表格 5‑1 消息表分片1</p>
<table>
<thead>
<tr>
<th><strong>消息ID</strong></th>
<th><strong>发布消息的用户ID</strong></th>
<th><strong>消息内容</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1000</td>
<td>1</td>
<td>……</td>
</tr>
<tr>
<td>1001</td>
<td>1</td>
<td>……</td>
</tr>
</tbody>
</table>
<p>表格 5‑2 消息表分片2</p>
<table>
<thead>
<tr>
<th><strong>消息ID</strong></th>
<th><strong>发布消息的用户ID</strong></th>
<th><strong>消息内容</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1005</td>
<td>2</td>
<td>……</td>
</tr>
<tr>
<td>1006</td>
<td>2</td>
<td>……</td>
</tr>
</tbody>
</table>
<p>表格 5‑3 用户关注表</p>
<table>
<thead>
<tr>
<th><strong>用户ID</strong></th>
<th><strong>关注的用户ID</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>10001</td>
<td>1</td>
</tr>
<tr>
<td>10001</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>提升读性能的关键方案之一就是冗余，除了上面的消息内容表，可以再增加一张表，让<code>timeline</code>数据可以在一个分片内取到，一次来兼顾两个维度的查询性能，带来的问题是可能会比较浪费资源</strong>。这也是目前<code>Twitter</code>的方案，由于国内的<code>SNS</code>存在大量僵尸用户，一般都采用推拉结合的方式兼顾。</p>
<h5 id="电商数据表水平切分"><a href="#电商数据表水平切分" class="headerlink" title="电商数据表水平切分"></a>电商数据表水平切分</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;电商中以订单为典型，一个订单包含订单id，买家id，卖家id，三个比较重要的查询关键字。为了简化，我们先不考虑订单和子订单相关的内容。</p>
<p>那么，该如何选择水平切分键呢？</p>
<p><strong>如果按照订单id切分，则按照卖家id和买家id查询会遍历所有的表</strong>；</p>
<p><strong>如果按照买家id切分，则按照订单id和卖家id查询会遍历所有的表</strong>；</p>
<p><strong>如果按照卖家id切分，则按照订单id和买家id查询会遍历所有的表</strong>；</p>
<p>现在我们先来分析一下业务场景。</p>
<ol>
<li><p>80%以上的查询是通过订单id进行查询。</p>
</li>
<li><p>15%左右通过买家id查询已购买商品列表。</p>
</li>
<li><p>5%左右通过卖家id查询已卖出商品列表。</p>
</li>
</ol>
<p>以上数据各个电商平台业务场景不一，比例会有浮动。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很明显，根据业务场景，如果只能选一个，我们最好是选择订单id进行切分。那么，如果按照卖家id和买家id查询如何解决？</p>
<p>一种方法，我们可以为<strong>卖家和买家分别存储一个维度的冗余数据，以供查询</strong>。但是这样就是三倍冗余，比较浪费。</p>
<blockquote>
<p>订单id=》卖家id</p>
<p>订单id=》买家id</p>
</blockquote>
<p>另外一种方法是<strong>通过外置搜索引擎建立索引进行查询</strong>。相比上一种更好。因为用户买家id或者卖家id进行查询的时候，通常还有其他过滤条件。</p>
<p>还有一种比较讨巧的做法，就是<strong>让订单id和买家id建立联系</strong>。<strong>我们在水平切分表的时候，可以截取买家id的后几位，生成订单id时在末尾加上截取出来的买家id</strong>。如果在生成订单id的时候能够保持后几位和买家id一致，那订单id和买家id就相当于建立了联系。通过订单id和买家id查询都不用遍历所有表了。</p>
<h2 id="如何扩展数据中心"><a href="#如何扩展数据中心" class="headerlink" title="如何扩展数据中心"></a>如何扩展数据中心</h2><h3 id="两地三中心和同城多活"><a href="#两地三中心和同城多活" class="headerlink" title="两地三中心和同城多活"></a>两地三中心和同城多活</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常，为了容灾，大型企业系统会采用灾备的部署方式，也就是说，一个主机房，一个备份机房，主机房承载所有的流量，而备份机房平时处于休眠状态，没有流量，只有当发生灾难，主机房不可用的时候才会启用备份机房。而通常主备之间的延迟比较大，只能采用异步复制数据的方式。但是这仅仅作为灾备，如果一个机房的容量达到瓶颈，是无法扩展的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了解决这个问题，通常会采用两地三中心的方案，这也是很多银行系统在使用的方案。如图所示，<strong>其中两个机房需要离的比较近，延迟非常小，某些场景下可以看成一个机房，所以，需要专线连接，所有的流量都由这两个机房承载，另外一个则作为灾备，平时处于休眠状态</strong>。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/31.webp" alt="img"></p>
<p><em>两地三中心</em></p>
<p>对于两地三中心，问题如下：</p>
<ul>
<li><p>由于需要低延迟，专线比较贵，“两地”通常离的比较近，真正的灾难来临，例如地震，还是跟主备一样。</p>
</li>
<li><p>备份节点处于休眠状态，比较浪费资源。</p>
</li>
<li><p>备份节点处于休眠状态，真正切换的时候，需要的时间较长。</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们需要明确的是，在两地三中心这种数据中心架构中，首先需要梳理出核心业务流程，对服务进行分级，规划哪些业务需要部署到多个数据中心，并不是所有的应用都需要做到那么高的可用性。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其次，<strong>往备份节点同步数据一定是异步的复制方式，否则性能会受到非常大的影响，异步意味着可能会丢失部分数据，这是不可避免的，如果真的发生地震，只要磁盘不坏，还是可以恢复的，尽管恢复的时间比较长</strong>。</p>
<h3 id="同城多活"><a href="#同城多活" class="headerlink" title="同城多活"></a>同城多活</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;微信采用的是一地三园区的部署方式，三个园区是对等并且物理隔离的，也就是说，无论是服务层，还是存储层，都部署在三个园区，流量被负载均衡到三个园区，不存在资源浪费。当其中一个园区发生故障时，流量会被均分到另外两个园区，另外两个园区流量上升百分之五十。这是由微信的底层存储决定的，微信底层存储采用的是<code>KVSvr</code>，可以实现强一致性、高可用、高性能，实际上，是利用W+R&gt;N原理，只要写数据时写两份成功才返回，就能保证，如果一个节点挂掉，读取两个节点一定能读到一份最新的数据。当然，一地决定了时延较低，但是也无法做到跨城区的容灾。</p>
<p>我们来总结一下上面的方案。</p>
<ul>
<li><strong>如果跨城区，能跨城市容灾，但是成本高，利用率低，一致性低</strong>。</li>
<li><strong>如果同城，成本低，利用率高，可以保证核心业务强一致，但不能跨城市容灾，且扩展性受限</strong>。</li>
</ul>
<p>那么有没有其他的方案呢？当然是有，不过，系统架构将变的越来越复杂，成本越来越高。</p>
<h3 id="异地多活"><a href="#异地多活" class="headerlink" title="异地多活"></a>异地多活</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;异地多活是指在两个以上的城市建立机房，流量被平均分配，当一个城市出现故障的时候，可以将发生故障的城市的流量快速切换到其他城市。异地多活就像以城市为单位的分片，如，IP为北京的访问北京机房，IP为上海的访问上海机房。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果做到异地多活，首先要分析业务，实际上，有的业务要实现多活是比较容易的，而有的业务是很难实现多活的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如手机通讯录，用户之间是没有关系的，也就是说A的通讯录里面存的数据不需要和其他人有任何关系。这种数据结构非常简单，可以以用户所在城市为切分键，这样就不存在一行数据在多个数据中心同时修改的情况。假设将中国分为三个数据中心，分别为北京、上海、广州，当用户属于北京数据中心时，所有请求都访问北京。新增数据时，只要北京写入成功就返回，然后同步组件订阅数据库<code>binlog</code>信息，同步到其他机房汇总、备份。如图所示。</p>
<p><img src="//blog.com/2019/07/27/可扩展性设计/32.webp" alt="img"></p>
<p><em>异地多活</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果是微博、电商这种数据，选择切分键就比较麻烦。在电商中，有买家和卖家两个维度读写数据，当买家下订单后，卖家维度要及时扣减库存，生成订单。而买家和卖家很可能不在一个城市。由于一般电商都是微服务架构，一次下单操作，在后台可能是几百次请求调用，如果这些请求要在多个数据中心来回传递10次，假设每次跨数据中心要延迟50毫秒，那一次下单操作在采用异地多活架构之后就要比以前响应时间降低500毫秒，这是不能接受的。所以，我们最好能保证一次请求可以在一个机房内完成。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于异地多活的成本比较高，不只是物理成本，还有设计、开发、维护的成本，因此，应该尽量让核心业务实现异地多活，而不是所有业务一视同仁。这个思路和数据库的扩展是一致的，<strong>如果能将一个独立的业务拆分到另外一个机房，应该优先选择这种方案，如果依赖太多，解决不了，再选择异地多活</strong>。另外一个原因是有些业务很难实现拆分，特别是一些对一致性要求特别高的服务，比如库存，异步将是致命的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>在考虑异地多活的时候，还要考虑一致性问题</strong>，前面我提到了一行数据的一致性问题，如果是整张表的一致性呢？如注册手机号，需要唯一键约束，如果分布到多张表中，无法实现一致性约束，虽然前端在写入前做了很充分的校验，但是如果一个用户进入多个注册页面，填写了校验信息，瞬间提交所有注册请求，由于异步的问题，可能导致全部成功。这时候有两种解决方案，一种是从业务的角度，这种毕竟是少数，如果前端已经做了防重复提交，那就可能存在恶意行为，应该由另外的定时任务去补偿处理。另外一种从技术角度，<strong>如果认为业务不允许出现任何不一致，此业务可以不做异地多活，可以做到多个数据中心读取，一个数据中心写入</strong>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/27/RPC 框架的可靠性设计/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/27/RPC 框架的可靠性设计/" itemprop="url">RPC 框架的可靠性设计</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-27T12:12:57+08:00">
                2019-07-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/" itemprop="url" rel="index">
                    <span itemprop="name">微服务</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/分布式系统/RPC/" itemprop="url" rel="index">
                    <span itemprop="name">RPC</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="RPC-框架的可靠性设计"><a href="#RPC-框架的可靠性设计" class="headerlink" title="RPC 框架的可靠性设计"></a>RPC 框架的可靠性设计</h1><h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h2><h3 id="1-1-分布式调用引入的故障"><a href="#1-1-分布式调用引入的故障" class="headerlink" title="1.1 分布式调用引入的故障"></a>1.1 分布式调用引入的故障</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在传统的单体架构中，业务服务调用都是本地方法调用，不会涉及到网络通信、协议栈、消息序列化和反序列化等，当使用 <code>RPC</code>框架将业务由单体架构改造成分布式系统之后，本地方法调用将演变成跨进程的远程调用，会引入一些新的故障点，如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/1.webp" alt="img"></p>
<p><em>RPC 调用引入的潜在故障点</em></p>
<p>新引入的潜在故障点包括：</p>
<p>1．<strong>消息的序列化和反序列化故障</strong>，例如，不支持的数据类型。</p>
<p>2．<strong>路由故障</strong>：包括服务的订阅、发布故障，服务实例故障之后没有及时刷新路由表，导致 <code>RPC</code> 调用仍然路由到故障节点。</p>
<p>3．<strong>网络通信故障</strong>，包括网络闪断、网络单通、丢包、客户端浪涌接入等。</p>
<h3 id="1-2-第三方服务依赖"><a href="#1-2-第三方服务依赖" class="headerlink" title="1.2 第三方服务依赖"></a>1.2 第三方服务依赖</h3><p><code>RPC</code>服务通常会依赖第三方服务，包括数据库服务、文件存储服务、缓存服务、消息队列服务等</p>
<p>这种第三方依赖同时也引入了潜在的故障：</p>
<p>1．<strong>网络通信类故障</strong>, 如果采用 <code>BIO</code>调用第三方服务，很有可能被阻塞。</p>
<p>2．<strong>“雪崩效用”导致的级联故障</strong>，例如服务端处理慢导致客户端线程被阻塞。</p>
<p>3．<strong>第三方不可用导致 <code>RPC</code> 调用失败</strong>。</p>
<p><strong>典型的第三方依赖示例如下：</strong></p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/2.webp" alt="img"></p>
<p><em>RPC 服务端的第三方依赖</em></p>
<h2 id="2-通信层的可靠性设计"><a href="#2-通信层的可靠性设计" class="headerlink" title="2. 通信层的可靠性设计"></a>2. 通信层的可靠性设计</h2><h3 id="2-1-链路有效性检测"><a href="#2-1-链路有效性检测" class="headerlink" title="2.1  链路有效性检测"></a>2.1  链路有效性检测</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当网络发生单通、连接被防火墙 <code>Hang</code> 住、长时间 <code>GC</code> 或者通信线程发生非预期异常时，会导致链路不可用且不易被及时发现。特别是异常发生在凌晨业务低谷期间，当早晨业务高峰期到来时，由于链路不可用会导致瞬间的大批量业务失败或者超时，这将对系统的可靠性产生重大的威胁。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从技术层面看，<strong>要解决链路的可靠性问题，必须周期性的对链路进行有效性检测</strong>。<strong>目前最流行和通用的做法就是心跳检测</strong>。</p>
<p>心跳检测机制分为三个层面：</p>
<ol>
<li><p><strong><code>TCP</code> 层面的心跳检测，即 <code>TCP</code> 的<code>Keep-Alive</code>机制，它的作用域是整个 <code>TCP</code>协议栈</strong>。</p>
</li>
<li><p><strong>协议层的心跳检测，主要存在于长连接协议中</strong>。例如 <code>MQTT</code>协议。</p>
</li>
<li><p><strong>应用层的心跳检测，它主要由各业务产品通过约定方式定时给对方发送心跳消息实现</strong>。</p>
</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>心跳检测的目的就是确认当前链路可用，对方活着并且能够正常接收和发送消息</strong>。做为高可靠的 <code>NIO</code>框架，<code>Netty</code>也提供了心跳检测机制，下面我们一起熟悉下心跳的检测原理。</p>
<p><strong>心跳检测的原理示意图如下：</strong></p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/3.webp" alt="img"></p>
<p><em>链路心跳检测</em></p>
<p>不同的协议，心跳检测机制也存在差异，归纳起来主要分为两类：</p>
<p>1．<strong><code>Ping-Pong</code>型心跳</strong>：由通信一方定时发送 <code>Ping</code>消息，对方接收到 <code>Ping</code> 消息之后，立即返回<code>Pong</code>应答消息给对方，属于请求 - 响应型心跳。</p>
<p>2．<strong><code>Ping-Ping</code> 型心跳</strong>：不区分心跳请求和应答，由通信双方按照约定定时向对方发送心跳 <code>Ping</code> 消息，它属于双向心跳。</p>
<p>心跳检测策略如下：</p>
<p>1．<strong>连续 N 次心跳检测都没有收到对方的 <code>Pong</code>应答消息或者<code>Ping</code>请求消息，则认为链路已经发生逻辑失效，这被称作心跳超时</strong>。</p>
<p>2．读取和发送心跳消息的时候如何直接发生了 <code>IO</code>异常，说明链路已经失效，这被称为心跳失败。</p>
<p>无论发生心跳超时还是心跳失败，都需要<strong>关闭链路，由客户端发起重连操作，保证链路能够恢复正常</strong>。</p>
<p><code>Netty</code> 的心跳检测实际上是利用了链路空闲检测机制实现的，它的空闲检测机制分为三种：</p>
<p>1．<strong>读空闲</strong>，链路持续时间 t 没有读取到任何消息。</p>
<p>2．<strong>写空闲</strong>，链路持续时间 t 没有发送任何消息。</p>
<p>3．<strong>读写空闲</strong>，链路持续时间 t 没有接收或者发送任何消息。</p>
<p><code>Netty</code> 的<strong>默认读写空闲机制是发生超时异常，关闭连接</strong>，但是，我们可以定制它的超时实现机制，以便支持不同的用户场景，链路空闲接口定义如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">channelIdle</span><span class="params">(ChannelHandlerContext ctx, IdleStateEvent evt)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">	ctx.fireUserEventTriggered(evt);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;链路空闲的时候并没有关闭链路，而是触发 <code>IdleStateEvent</code> 事件，<strong>用户订阅 <code>IdleStateEvent</code> 事件，用于自定义逻辑处理，例如关闭链路、客户端发起重新连接、告警和打印日志等</strong>。利用 <code>Netty</code> 提供的链路空闲检测机制，可以非常灵活的实现链路空闲时的有效性检测。</p>
<h3 id="2-2-客户端断连重连"><a href="#2-2-客户端断连重连" class="headerlink" title="2.2 客户端断连重连"></a>2.2 客户端断连重连</h3><p>当发生如下异常时，客户端需要释放资源，重新发起连接：</p>
<p>1．<strong>服务端因为某种原因，主动关闭连接，客户端检测到链路被正常关闭</strong>。</p>
<p>2．<strong>服务端因为宕机等故障，强制关闭连接，客户端检测到链路被 <code>Rest</code> 掉</strong>。</p>
<p>3．<strong>心跳检测超时，客户端主动关闭连接</strong>。</p>
<p>4．<strong>客户端因为其它原因（例如解码失败），强制关闭连接</strong>。</p>
<p>5．<strong>网络类故障，例如网络丢包、超时、单通等，导致链路中断</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端检测到链路中断后，等待 <code>INTERVAL</code>时间，由客户端发起重连操作，如果重连失败，间隔周期 <code>INTERVAL</code> 后再次发起重连，直到重连成功。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>为了保证服务端能够有充足的时间释放句柄资源，在首次断连时客户端需要等待<code>INTERVAL</code> 时间之后再发起重连，而不是失败后就立即重连</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了保证句柄资源能够及时释放，无论什么场景下的重连失败，客户端都必须保证自身的资源被及时释放，包括但不限于 <code>SocketChannel</code>、<code>Socket</code> 等。重连失败后，需要打印异常堆栈信息，方便后续的问题定位。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;利用 <code>Netty Channel</code> 提供的 <code>CloseFuture</code>，可以非常方便的检测链路状态，一旦链路关闭，相关事件即被触发，可以重新发起连接操作，代码示例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	future.channel().closeFuture().sync();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">	<span class="comment">// 所有资源释放完成之后，清空资源，再次发起重连操作</span></span><br><span class="line">	executor.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">                TimeUnit.SECONDS.sleep(<span class="number">3</span>);<span class="comment">//3 秒之后发起重连，等待句柄释放</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 发起重连操作</span></span><br><span class="line">                    connect(NettyConstant.PORT, NettyConstant.REMOTEIP);         </span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    ...... 异常处理相关代码省略</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-3-缓存重发"><a href="#2-3-缓存重发" class="headerlink" title="2.3 缓存重发"></a>2.3 缓存重发</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当我们调用消息发送接口的时候，消息并没有真正被写入到<code>Socket</code>中，而是<strong>先放入<code>NIO</code>通信框架的消息发送队列中，由 <code>Reactor</code>线程扫描待发送的消息队列，异步的发送给通信对端</strong>。假如很不幸，消息队列中积压了部分消息，此时链路中断，这会导致部分消息并没有真正发送给通信对端，示例如下：</p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/4.webp" alt="img"></p>
<p><em>链路中断导致积压消息没有发送</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;发生此故障时，我们希望 <code>NIO</code> 框架能够自动实现消息缓存和重新发送，遗憾的是作为基础的 <code>NIO</code>通信框架，无论是 <code>Mina</code> 还是 <code>Netty</code>，都没有提供该功能，需要通信框架自己封装实现.</p>
<p>基于 <code>Netty</code> 的实现策略如下：</p>
<p>1．调用 <code>Netty ChannelHandlerContext</code> 的 <code>write</code> 方法时，返回<code>ChannelFuture</code>对象，我们在 <code>ChannelFuture</code> 中注册发送结果监听 <code>Listener</code>。</p>
<p>2．在 <code>Listener</code> 的 <code>operationComplete</code> 方法中判断操作结果，如果操作不成功，将之前发送的消息对象添加到重发队列中。</p>
<p>3．链路重连成功之后，根据策略，将缓存队列中的消息重新发送给通信对端。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要指出的是，<strong>并非所有场景都需要通信框架做重发</strong>，例如服务框架的客户端，如果某个服务提供者不可用，会自动切换到下一个可用的服务提供者之上。假定是链路中断导致的服务提供者不可用，即便链路重新恢复，也没有必要将之前积压的消息重新发送，因为消息已经通过<code>FailOver</code> 机制切换到另一个服务提供者处理。所以，<strong>消息缓存重发只是一种策略，通信框架应该支持链路级重发策略</strong>。</p>
<h3 id="2-4-客户端超时保护"><a href="#2-4-客户端超时保护" class="headerlink" title="2.4 客户端超时保护"></a>2.4 客户端超时保护</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在传统的同步阻塞编程模式下，客户端 <code>Socket</code> 发起网络连接，往往需要<strong>指定连接超时时间</strong>，这样做的目的主要有两个：</p>
<p>1．在同步阻塞<code>I/O</code>模型中，连接操作是同步阻塞的，如果不设置超时时间，客户端<code>I/O</code> 线程可能会被长时间阻塞，这会导致系统可用 <code>I/O</code>线程数的减少。</p>
<p>2．业务层需要：大多数系统都会对业务流程执行时间有限制，例如 <code>WEB</code> 交互类的响应时间要小于 3S。客户端设置连接超时时间是为了实现业务层的超时。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于 <code>NIO</code>的 <code>SocketChannel</code>，在非阻塞模式下，它会直接返回连接结果，如果没有连接成功，也没有发生 <code>I/O</code>异常，则需要将<code>SocketChannel</code>注册到<code>Selector</code> 上监听连接结果。所以，<strong>异步连接的超时无法在<code>API</code>层面直接设置，而是需要通过用户自定义定时器来主动监测</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Netty</code> 在创建 <code>NIO</code> 客户端时，支持设置连接超时参数。<code>Netty</code> 的客户端连接超时参数与其它常用的 <code>TCP</code> 参数一起配置，使用起来非常方便，上层用户不用关心底层的超时实现机制。这既满足了用户的个性化需求，又实现了故障的分层隔离。</p>
<h3 id="2-5-针对客户端的并发连接数流控"><a href="#2-5-针对客户端的并发连接数流控" class="headerlink" title="2.5 针对客户端的并发连接数流控"></a>2.5 针对客户端的并发连接数流控</h3><p>以 <code>Netty</code> 的 <code>HTTPS</code>服务端为例，针对客户端的并发连接数流控原理如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/5.webp" alt="img"></p>
<p><em>服务端 HTTS 连接数流控</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于 <code>Netty</code> 的 <code>Pipeline</code>机制，可以对 <code>SSL</code>握手成功、<code>SSL</code>连接关闭做切面拦截（类似于 <code>Spring</code> 的 <code>AOP</code> 机制，但是没采用反射机制，性能更高），通过流控切面接口，对 <code>HTTPS</code>连接做计数，根据计数器做流控↓↓↓</p>
<p>服务端的流控算法如下：</p>
<p>1．获取流控阈值。</p>
<p>2．从全局上下文中获取当前的并发连接数，与流控阈值对比，如果小于流控阈值，则对当前的计数器做原子自增，允许客户端连接接入。</p>
<p>3．如果等于或者大于流控阈值，则抛出流控异常给客户端。</p>
<p>4．<code>SSL</code> 连接关闭时，获取上下文中的并发连接数，做原子自减。</p>
<p><strong>在实现服务端流控时，需要注意如下几点：</strong></p>
<p>1．流控的 <code>ChannelHandler</code> 声明为 <a href="mailto:`@ChannelHandler.Sharable" target="_blank" rel="noopener">`@ChannelHandler.Sharable</a><code>，这样全局创建一个流控实例，就可以在所有的</code>SSL` 连接中共享。</p>
<p>2．通过 <code>userEventTriggered</code>方法拦截 <code>SslHandshakeCompletionEvent</code> 和 <code>SslCloseCompletionEvent</code>事件，在 <code>SSL</code>握手成功和 <code>SSL</code>连接关闭时更新流控计数器。</p>
<p>3．流控并不是单针对 <code>ESTABLISHED</code> 状态的 <code>HTTP</code> 连接，而是针对所有状态的连接，因为客户端关闭连接，并不意味着服务端也同时关闭了连接，只有 <code>SslCloseCompletionEvent</code>事件触发时，服务端才真正的关闭了 <code>NioSocketChannel</code>，<code>GC</code>才会回收连接关联的内存。</p>
<p>4．流控 <code>ChannelHandler</code> 会被多个<code>NioEventLoop</code> 线程调用，因此对于相关的计数器更新等操作，要保证并发安全性，避免使用全局锁，可以通过原子类等提升性能。</p>
<h3 id="2-6-内存保护"><a href="#2-6-内存保护" class="headerlink" title="2.6 内存保护"></a><strong>2.6 内存保护</strong></h3><p><code>NIO</code>通信的内存保护主要集中在如下几点：</p>
<ol>
<li><p><strong>链路总数的控制</strong>：每条链路都包含接收和发送缓冲区，链路个数太多容易导致内存溢出。</p>
</li>
<li><p><strong>单个缓冲区的上限控制</strong>：防止非法长度或者消息过大导致内存溢出。</p>
</li>
<li><p><strong>缓冲区内存释放</strong>：防止因为缓冲区使用不当导致的内存泄露。</p>
</li>
<li><p><strong><code>NIO</code> 消息发送队列的长度上限控制</strong>。</p>
</li>
</ol>
<p>当我们对消息进行解码的时候，需要创建缓冲区。缓冲区的创建方式通常有两种：</p>
<ol>
<li><p><strong>容量预分配，在实际读写过程中如果不够再扩展</strong>。</p>
</li>
<li><p><strong>根据协议消息长度创建缓冲区</strong>。</p>
</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在实际的商用环境中，如果遇到畸形码流攻击、协议消息编码异常、消息丢包等问题时，可能会解析到一个超长的长度字段。笔者曾经遇到过类似问题，报文长度字段值竟然是 2G 多，由于代码的一个分支没有对长度上限做有效保护，结果导致内存溢出。系统重启后几秒内再次内存溢出，幸好及时定位出问题根因，险些酿成严重的事故。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Netty</code> 提供了编解码框架，因此对于解码缓冲区的上限保护就显得非常重要。下面，我们看下 <code>Netty</code>是如何对缓冲区进行上限保护的：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先，在内存分配的时候指定缓冲区长度上限：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">* Allocate a &#123;<span class="doctag">@link</span> ByteBuf&#125; with the given initial capacity and the given</span></span><br><span class="line"><span class="comment">* maximal capacity. If it is a direct or heap buffer depends on the actual</span></span><br><span class="line"><span class="comment">* implementation.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">ByteBuf <span class="title">buffer</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">int</span> maxCapacity)</span></span>;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其次，在对缓冲区进行写入操作的时候，如果缓冲区容量不足需要扩展，首先对最大容量进行判断，如果扩展后的容量超过上限，则拒绝扩展：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ByteBuf <span class="title">capacity</span><span class="params">(<span class="keyword">int</span> newCapacity)</span> </span>&#123;</span><br><span class="line">	ensureAccessible();</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (newCapacity &lt; <span class="number">0</span> || newCapacity &gt; maxCapacity()) &#123;</span><br><span class="line">		<span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"newCapacity: "</span> + newCapacity);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在消息解码的时候，对消息长度进行判断，如果超过最大容量上限，则抛出解码异常，拒绝分配内存，以<code>LengthFieldBasedFrameDecoder</code>的<code>decode</code>方法为例进行说明：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (frameLength &gt; maxFrameLength) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> discard = frameLength - in.readableBytes();</span><br><span class="line">    tooLongFrameLength = frameLength;</span><br><span class="line">    <span class="keyword">if</span> (discard &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    	in.skipBytes((<span class="keyword">int</span>) frameLength);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	discardingTooLongFrame = <span class="keyword">true</span>;</span><br><span class="line">	bytesToDiscard = discard;</span><br><span class="line">	in.skipBytes(in.readableBytes());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">failIfNecessary(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br></pre></td></tr></table></figure>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="img"></p>
<h2 id="3-RPC-调用层的可靠性设计"><a href="#3-RPC-调用层的可靠性设计" class="headerlink" title="3. RPC 调用层的可靠性设计"></a>3. RPC 调用层的可靠性设计</h2><h3 id="3-1-RPC-调用异常场景"><a href="#3-1-RPC-调用异常场景" class="headerlink" title="3.1 RPC 调用异常场景"></a>3.1 RPC 调用异常场景</h3><p><code>RPC</code> 调用过程中除了通信层的异常，通常也会遇到如下几种故障：</p>
<ol>
<li><p><strong>服务路由失败</strong></p>
</li>
<li><p><strong>服务端超时</strong></p>
</li>
<li><p><strong>服务端调用失败</strong></p>
</li>
</ol>
<p><code>RPC</code> 框架需要能够针对上述常见的异常做容错处理，以提升业务调用的可靠性。</p>
<h4 id="3-1-1-服务路由失败"><a href="#3-1-1-服务路由失败" class="headerlink" title="3.1.1 服务路由失败"></a>3.1.1 服务路由失败</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>RPC</code>客户端通常会<strong>基于订阅 / 发布的机制获取服务端的地址列表，并将其缓存到本地</strong>，<code>RPC</code>调用时，根据负载均衡策略从本地缓存的路由表中获取到一个唯一的服务端节点发起调用，原理如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/6.webp" alt="img"></p>
<p><em>基于订阅发布机制的 RPC 调用</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过缓存的机制能够提升 <code>RPC</code> 调用的性能，<code>RPC</code>客户端不需要每次调用都向注册中心查询目标服务的地址信息，但是也可能会发生如下两类潜在故障：</p>
<p>1．<strong>某个 <code>RPC</code> 服务端发生故障，或者下线，客户端没有及时刷新本地缓存的服务地址列表，就会导致<code>RPC</code> 调用失败</strong>。</p>
<p>2．<strong><code>RPC</code>客户端和服务端都工作正常，但是 <code>RPC</code>客户端和服务端的连接或者网络发生了故障，如果没有链路的可靠性检测机制，就会导致 <code>RPC</code>调用失败</strong>。</p>
<h4 id="3-1-2-服务端超时"><a href="#3-1-2-服务端超时" class="headerlink" title="3.1.2 服务端超时"></a><strong>3.1.2 服务端超时</strong></h4><p>当<strong>服务端无法在指定的时间内返回应答给客户端，就会发生超时</strong>，导致超时的原因主要有：</p>
<p>1．<strong>服务端的<code>I/O</code>线程没有及时从网络中读取客户端请求消息</strong>，导致该问题的原因通常是 <code>I/O</code>线程被意外阻塞或者执行长周期操作。</p>
<p>2．<strong>服务端业务处理缓慢，或者被长时间阻塞</strong>，例如查询数据库，由于没有索引导致全表查询，耗时较长。</p>
<p>3．<strong>服务端发生长时间 <code>Full GC</code></strong>，导致所有业务线程暂停运行，无法及时返回应答给客户端。</p>
<h4 id="3-1-3-服务端调用失败"><a href="#3-1-3-服务端调用失败" class="headerlink" title="3.1.3 服务端调用失败"></a>3.1.3 服务端调用失败</h4><p>有时会发生服务端调用失败，导致服务端调用失败的原因主要有如下几种：</p>
<p>1．<strong>服务端解码失败</strong>，会返回消息解码失败异常。</p>
<p>2．<strong>服务端发生动态流控</strong>，返回流控异常。</p>
<p>3．<strong>服务端消息队列积压率超过最大阈值</strong>，返回系统拥塞异常。</p>
<p>4．<strong>访问权限校验失败</strong>，返回权限相关异常。</p>
<p>5．<strong>违反 SLA 策略</strong>，返回 SLA 控制相关异常。</p>
<p>6．<strong>其他系统异常</strong>。</p>
<p>需要指出的是，服务调用异常<strong>不包括业务层面的处理异常</strong>，例如数据库操作异常、用户记录不存在异常等。</p>
<h3 id="3-2-RPC-调用可靠性方案"><a href="#3-2-RPC-调用可靠性方案" class="headerlink" title="3.2 RPC 调用可靠性方案"></a>3.2 RPC 调用可靠性方案</h3><h4 id="3-2-1-注册中心与链路检测双保险机制"><a href="#3-2-1-注册中心与链路检测双保险机制" class="headerlink" title="3.2.1 注册中心与链路检测双保险机制"></a>3.2.1 注册中心与链路检测双保险机制</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为注册中心有集群内所有 <code>RPC</code> 客户端和服务端的实例信息，因此<strong>通过注册中心向每个服务端和客户端发送心跳消息，检测对方是否在线，如果连续 N 次心跳超时，或者心跳发送失败，则判断对方已经发生故障或者下线（下线可以通过优雅停机的方式主动告知注册中心，实时性会更好）</strong>。注册中心将故障节点的服务实例信息通过心跳消息发送给客户端，<strong>由客户端将故障的服务实例信息从本地缓存的路由表中删除，后续消息调用不再路由到该节点</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一些特殊场景下，尽管注册中心与服务端、客户端的连接都没有问题，但是服务端和客户端之间的链路发生了异常，由于发生链路异常的服务端仍然在缓存表中，因此消息还会继续调度到故障节点上，所以，<strong>利用 <code>RPC</code>客户端和服务端之间的双向心跳检测，可以及时发现双方之间的链路问题，利用重连等机制可以快速的恢复连接，如果重连 N 次都失败，则服务路由时不再将消息发送到连接故障的服务节点上</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;利用注册中心对服务端的心跳检测和通知机制、以及服务端和客户端针对链路层的双向心跳检测机制，可以有效检测出故障节点，提升<code>RPC</code>调用的可靠性，它的原理如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/7.webp" alt="img"></p>
<p><em>注册中心与链路双向心跳检测机制原理</em></p>
<h4 id="3-2-2-集群容错策略"><a href="#3-2-2-集群容错策略" class="headerlink" title="3.2.2 集群容错策略"></a><strong>3.2.2 集群容错策略</strong></h4><p>常用的集群容错策略包括：</p>
<p>1．失败自动切换 (<code>Failover</code>)</p>
<p>2．失败通知（<code>Failback</code>）</p>
<p>3．失败缓存（<code>Failcache</code>）</p>
<p>4．快速失败（<code>Failfast</code>）</p>
<h5 id="失败自动切换"><a href="#失败自动切换" class="headerlink" title="失败自动切换"></a>失败自动切换</h5><p><strong>失败自动切换策略：</strong>服务调用失败自动切换策略指的是当发生 <code>RPC</code> 调用异常时，重新选路，查找下一个可用的服务提供者。</p>
<p>服务发布的时候，可以指定服务的集群容错策略。消费者可以覆盖服务提供者的通用配置，实现个性化的容错策略。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Failover</code>策略的设计思路如下：消费者路由操作完成之后，获得目标地址，调用通信框架的消息发送接口发送请求，监听服务端应答。<strong>如果返回的结果是 <code>RPC</code> 调用异常（超时、流控、解码失败等系统异常），根据消费者集群容错的策略进行容错路由，如果是 <code>Failover</code>，则重新返回到路由 <code>Handler</code> 的入口，从路由节点继续执行</strong>。选路完成之后，对目标地址进行比对，防止重新路由到故障服务节点，过滤掉上次的故障服务提供者之后，调用通信框架的消息发送接口发送请求消息。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>RPC</code> 框架提供 <code>Failover</code> 容错策略，但是用户在使用时需要自己保证用对地方，下面对<code>Failover</code>策略的应用场景进行总结：</p>
<p>1．读操作，因为通常它是幂等的。</p>
<p>2．<strong>幂等性服务，保证调用 1 次与 N 次效果相同</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要特别指出的是，失败重试会增加服务调用时延，因此<strong>框架必须对失败重试的最大次数做限制，通常默认为 3，防止无限制重试导致服务调用时延不可控</strong>。</p>
<h5 id="失败通知"><a href="#失败通知" class="headerlink" title="失败通知"></a>失败通知</h5><p><strong>失败通知（Failback）：</strong>在很多业务场景中，客户端需要能够获取到服务调用失败的具体信息，通过对失败错误码等异常信息的判断，决定后续的执行策略，例如非幂等性的服务调用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Failback</code>的设计方案如下：<code>RPC</code>框架获取到服务提供者返回的 <code>RPC</code> 异常响应之后，根据策略进行容错。如果是 <code>Failback</code> 模式，则不再重试其它服务提供者，而是<strong>将 <code>RPC</code> 异常通知给客户端，由客户端捕获异常进行后续处理</strong>。</p>
<h5 id="失败缓存"><a href="#失败缓存" class="headerlink" title="失败缓存"></a>失败缓存</h5><p><strong>失败缓存（Failcache）：</strong><code>Failcache</code> 策略是失败自动恢复的一种，在实际项目中它的应用场景如下：</p>
<p>1．<strong>服务有状态路由，必须定点发送到指定的服务提供者</strong>。当发生链路中断、流控等服务暂时不可用时，<strong><code>RPC</code>框架将消息临时缓存起来，等待周期 T，重新发送，直到服务提供者能够正常处理该消息</strong>。</p>
<p>2．<strong>对时延要求不敏感的服务</strong>。系统服务调用失败，通常是链路暂时不可用、服务流控、<code>GC</code>挂住服务提供者进程等，这种失败不是永久性的失败，它的恢复是可预期的。<strong>如果客户端对服务调用时延不敏感，可以考虑采用自动恢复模式，即先缓存，再等待，最后重试</strong>。</p>
<p>3．<strong>通知类服务</strong>。例如通知粉丝积分增长、记录接口日志等，对服务调用的实时性要求不高，可以容忍自动恢复带来的时延增加。</p>
<p>为了保证可靠性，<code>Failcache</code>策略在设计的时候需要考虑如下几个要素：</p>
<p>1．<strong>缓存时间、缓存对象上限数等需要做出限制，防止内存溢出</strong>。</p>
<p>2．<strong>缓存淘汰算法的选择，是否支持用户配置</strong>。</p>
<p>3．<strong>定时重试的周期 T、重试的最大次数等需要做出限制并支持用户指定</strong>。</p>
<p>4．<strong>重试达到最大上限仍失败，需要丢弃消息，记录异常日志</strong>。</p>
<h5 id="快速失败"><a href="#快速失败" class="headerlink" title="快速失败"></a>快速失败</h5><p><strong>快速失败（Failfast）：在业务高峰期，对于一些非核心的服务，希望只调用一次，失败也不再重试，为重要的核心服务节约宝贵的运行资源</strong>。此时，快速失败是个不错的选择。快速失败策略的设计比较简单，<strong>获取到服务调用异常之后，直接忽略异常，记录异常日志</strong>。</p>
<h2 id="4-第三方服务依赖故障隔离"><a href="#4-第三方服务依赖故障隔离" class="headerlink" title="4. 第三方服务依赖故障隔离"></a>4. 第三方服务依赖故障隔离</h2><h3 id="4-1-总体策略"><a href="#4-1-总体策略" class="headerlink" title="4.1 总体策略"></a>4.1 总体策略</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;尽管很多第三方服务会提供 <code>SLA</code>，但是 <code>RPC</code>服务本身并不能完全依赖第三方服务自身的可靠性来保障自己的高可靠，第三方服务依赖隔离的总体策略如下：</p>
<p>1．第三方依赖隔离可以采用线程池 + 响应式编程（例如 <code>RxJava</code>）的方式实现。</p>
<p>2．对第三方依赖进行分类，每种依赖对应一个独立的线程 / 线程池。</p>
<p>3．服务不直接调用第三方依赖的 <code>API</code>，而是使用异步封装之后的 <code>API</code>接口。</p>
<p>4．异步调用第三方依赖 <code>API</code> 之后，获取 <code>Future</code>对象。利用响应式编程框架，</p>
<p>可以订阅后续的事件，接收响应，针对响应进行编程。</p>
<h3 id="4-2-异步化"><a href="#4-2-异步化" class="headerlink" title="4.2 异步化"></a>4.2 异步化</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果第三方服务提供的是标准的 <code>HTTP/Restful</code>服务，则利用异步 <code>HTTP</code>客户端，例如 <code>Netty</code>、<code>Vert.x</code>、异步 <code>RestTemplate</code> 等发起异步服务调用，这样无论是服务端自身处理慢还是网络慢，都不会导致调用方被阻塞。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果对方是私有或者定制化的协议，<code>SDK</code> 没有提供异步接口，则需要采用线程池或者利用一些开源框架实现故障隔离。</p>
<p>异步化示例图如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/8.webp" alt="img"></p>
<p><em>异步化原理示意图</em></p>
<p>异步化的几个关键技术点：</p>
<p>1．<strong>异步具有依赖和传递性，如果想在某个业务流程的某个过程中做异步化，则入口处就需要做异步</strong>。例如如果想把 <code>Redis</code>服务调用改造成异步，则调用 <code>Redis</code>服务之前的流程也需要同时做异步化，否则意义不大（<strong>除非调用方不需要返回值</strong>）。</p>
<p>2．通常而言，全栈异步对于业务性能和可靠性提升的意义更大，全栈异步会涉及到内部服务调用、第三方服务调用、数据库、缓存等平台中间件服务的调用，异步化改造成本比较高，但是收益也比较明显。</p>
<p>3．<strong>不同框架、服务的异步编程模型尽量保持一致</strong>，例如统一采取 <code>RxJava</code> 风格的接口、或者 <code>JDK8</code> 的 <code>CompletableFuture</code>。如果不同服务<code>SDK</code>的异步 <code>API</code>接口风格差异过大，会增加业务的开发成本，也不利用线程模型的归并和整合。</p>
<h3 id="4-3-基于-Hystrix-的第三方依赖故障隔离"><a href="#4-3-基于-Hystrix-的第三方依赖故障隔离" class="headerlink" title="4.3 基于 Hystrix 的第三方依赖故障隔离"></a>4.3 基于 Hystrix 的第三方依赖故障隔离</h3><p>集成 <code>Netflix</code>开源的<code>Hystrix</code>框架，可以非常方便的实现第三方服务依赖故障隔离，它提供的主要功能包括:</p>
<p>1．依赖隔离</p>
<p>2．熔断器</p>
<p>3．优雅降级</p>
<p>4．<code>Reactive</code>编程</p>
<p>5．信号量隔离</p>
<p>建议的集成策略如下：</p>
<p>1．第三方依赖隔离：使用 <code>HystrixCommand</code>做一层异步封装，实现业务的 <code>RPC</code>服务调用线程和第三方依赖的线程隔离。</p>
<p>2．依赖分类管理：对第三方依赖进行分类、分组管理，根据依赖的特点设置熔断策略、优雅降级策略、超时策略等，以实现差异化的处理。</p>
<p><strong>总体集成视图如下所示：</strong></p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/9.webp" alt="img"></p>
<p><em>基于 Hystrix 的第三方故障隔离框架</em></p>
<p>基于 <code>Hystrix</code>可以非常方便的实现第三方依赖服务的熔断降级，它的工作原理如下：</p>
<p>1．熔断判断：服务调用时，对熔断开关状态进行判断，当熔断器开关关闭时, 请求被允许通过熔断器。</p>
<p>2．熔断执行：当熔断器开关打开时，服务调用请求被禁止通过，执行失败回调接口。</p>
<p>3．自动恢复：熔断之后，周期 T 之后允许一条消息通过，如果成功，则取消熔断状态，否则继续处于熔断状态。</p>
<p>流程如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC 框架的可靠性设计/10.webp" alt="img"></p>
<p><em>基于 Hystrix 的熔断降级</em></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/27/RPC协议之争和选型要点/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/27/RPC协议之争和选型要点/" itemprop="url">RPC协议之争和选型要点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-27T12:12:57+08:00">
                2019-07-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/" itemprop="url" rel="index">
                    <span itemprop="name">微服务</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/分布式系统/RPC/" itemprop="url" rel="index">
                    <span itemprop="name">RPC</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="RPC协议之争和选型要点"><a href="#RPC协议之争和选型要点" class="headerlink" title="RPC协议之争和选型要点"></a>RPC协议之争和选型要点</h1><h2 id="1-协议之争背景"><a href="#1-协议之争背景" class="headerlink" title="1. 协议之争背景"></a>1. 协议之争背景</h2><h3 id="1-1-RPC-调用的协议选择"><a href="#1-1-RPC-调用的协议选择" class="headerlink" title="1.1 RPC 调用的协议选择"></a>1.1 RPC 调用的协议选择</h3><p><code>RPC</code> 调用的协议选择包含两部分：</p>
<p><strong>1．协议栈：</strong>广义上协议栈可以分为公有协议和私有协议，例如 <code>HTTP</code>、<code>SMPP</code>、<code>WebService</code> 等都是公有协议；如果是某个公司或者组织内部自定义、自己使用的协议，没有被国际标准化组织接纳和认可的，往往划为私有协议，例如 <code>Thrift</code> 协议。</p>
<p><strong>2．序列化方式：</strong>同一种协议也可以承载多种序列化方式，以<code>HTTP</code>协议为例，它可以承载文本类序列化方式，例如：<code>XML</code>、<code>JSON</code> 等，也可以承载二进制序列化方式，例如谷歌的<code>Protobuf</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不同的协议选择，对 <code>RPC</code> 调用的性能、开发难度和问题定位效率都有影响，因此，选择哪种协议，对 <code>RPC</code>框架而言至关重要。由于各个协议都有自己的优缺点，因此很多框架在技术选型时都非常纠结。各种观点存在激烈交锋，<strong>有的看重性能和时延、有的更看重跨语言和可维护性</strong>。协议的选择是 <code>RPC</code> 框架构建的一个技术难点。</p>
<h3 id="1-2-私有协议流行的原因"><a href="#1-2-私有协议流行的原因" class="headerlink" title="1.2 私有协议流行的原因"></a>1.2 私有协议流行的原因</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;私有协议本质上是厂商内部发展和采用的标准，除非授权，其他厂商一般无权使用该协议。私有协议也称非标准协议，就是未经国际或国家标准化组织采纳或批准，由某个企业自己制订，协议实现细节不愿公开，只在企业自己生产的设备之间使用的协议。私有协议具有封闭性、垄断性、排他性等特点。如果网上大量存在私有（非标准）协议，现行网络或用户一旦使用了它，后进入的厂家设备就必须跟着使用这种非标准协议，才能够互连互通，否则根本不可能进入现行网络。这样，使用非标准协议的厂家就实现了垄断市场的愿望。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;尽管私有协议具有垄断性的特征，但并非所有的私有协议设计者的初衷就是为了垄断。由于现代软件系统的复杂性，一个大型软件系统往往会被人为地拆分成多个模块，另外随着移动互联网的兴起，网站的规模也越来越大，业务的功能越来越多，为了能够支撑业务的发展，往往需要集群和分布式部署，这样，各个模块之间就要进行跨节点通信。</p>
<p>在传统的 <code>Java</code> 应用中，通常使用以下 4 种方式进行跨节点通信。</p>
<p>1．通过<code>RMI</code> 进行远程服务调用。</p>
<p>2．通过 <code>Java</code>的<code>Socket+Java</code>序列化的方式进行跨节点调用。</p>
<p>3．利用一些开源的<code>RPC</code> 框架进行远程服务调用，例如<code>Facebook</code>的<code>Thrift</code>，<code>Google</code> 的<code>gRPC</code>等。</p>
<p>4．利用标准的公有协议进行跨节点服务调用，例如 <code>HTTP+XML</code>、<code>Restful+JSON</code> 或者 <code>WebService</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;跨节点的远程服务调用，除了链路层的物理连接外，还需要对请求和响应消息进行编解码。在请求和应答消息本身以外，也需要携带一些其他控制和管理类指令，例如链路建立的握手请求和响应消息、链路检测的心跳消息等。当这些功能组合到一起之后，就会形成私有协议。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;私有协议的优点：<strong>灵活性高，可以按照业务的使用场景来设计和优化，在某个公司或者组织内部使用时也可以按需定制和演进</strong>，所以大部分<code>RPC</code>框架都支持私有二进制协议，例如阿里的<code>Dubbo</code>、华为的 <code>ServiceComb</code>、<code>Apache</code> 的 <code>Thrift</code> 等。</p>
<h3 id="1-3-序列化方式"><a href="#1-3-序列化方式" class="headerlink" title="1.3 序列化方式"></a>1.3 序列化方式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>当进行远程跨进程服务调用时，需要把被传输的数据结构 / 对象序列化为字节数组或者 <code>ByteBuffer</code>。而当远程服务读取到 <code>ByteBuffer</code> 对象或者字节数组时，需要将其反序列化为原始的数据结构 / 对象</strong>。利用序列化框架可以实现上述转换工作。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Java</code> 序列化从<code>JDK 1.1</code> 版本就已经提供，它不需要添加额外的类库，只需实现<code>java.io.Serializable</code>并生成序列 ID 即可，因此，它从诞生之初就得到了广泛的应用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是在远程服务调用（<code>RPC</code>）时，很少直接使用<code>Java</code>序列化进行消息的编解码和传输，这又是什么原因呢？下面通过分析<code>Java</code>序列化的缺点来找出答案:</p>
<p><strong>缺点 1：无法跨语言</strong>，是 <code>Java</code> 序列化最致命的问题。对于跨进程的服务调用，服务提供者可能会使用 <code>C++</code>或者其他语言开发，当我们需要和异构语言进程交互时，<code>Java</code> 序列化就难以胜任。由于<code>Java</code>序列化技术是<code>Java</code>语言内部的私有协议，其它语言并不支持，对于用户来说它完全是黑盒。对于<code>Java</code>序列化后的字节数组，别的语言无法进行反序列化，这就严重阻碍了它的应用。事实上，目前几乎所有流行的<code>Java RPC</code>通信框架，都没有使用<code>Java</code> 序列化作为编解码框架，原因就在于它无法跨语言，而这些 <code>RPC</code> 框架往往需要支持跨语言调用。</p>
<p><strong>缺点 2：</strong>相比于业界的一些序列化框架，<code>Java</code>默认的<strong>序列化效能较低，主要体现在：序列化之后的字节数组体积较大，性能较低</strong>。在同等情况下，编码后的字节数组越大，存储的时候就越占空间，存储的硬件成本就越高，并且在网络传输时更占带宽，导致系统的吞吐量降低。<code>Java</code> 序列化后的码流偏大也一直被业界所诟病，导致它的应用范围受到了很大限制。</p>
<p>当前比较流行的序列化方式可以分为两大类:</p>
<p><strong>1．文本类序列化方式：</strong>主要包括 <code>JSON</code>和<code>XML</code>，它们的优点是：支持跨语言、可读性好、配套的支持工具比较全。缺点就是：<strong>序列化之后的码流比较大、冗余内容多，性能相对比较差</strong>。</p>
<p><strong>2．私有的二进制类序列化方式：</strong>比较流行的有 <code>Thrift</code>序列化框架、<code>MessagePack</code> 和谷歌的 <code>Protobuf</code>框架。它的优点是性能高，缺点就是<strong>可读性差，支撑的工具链不健全</strong>。</p>
<h2 id="2-RPC-协议选型要点"><a href="#2-RPC-协议选型要点" class="headerlink" title="2. RPC 协议选型要点"></a>2. RPC 协议选型要点</h2><h3 id="2-1-协议栈的选择"><a href="#2-1-协议栈的选择" class="headerlink" title="2.1 协议栈的选择"></a>2.1 协议栈的选择</h3><h4 id="2-1-1-公有协议"><a href="#2-1-1-公有协议" class="headerlink" title="2.1.1 公有协议"></a>2.1.1 公有协议</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;尽管公有协议种类繁多例如之前非常流行的 <code>WebService</code>、<code>WADL</code> 等，但目前来看，<strong>如果选择公有协议，<code>HTTP</code> 协议还是首选，具有 <code>Rest</code> 风格的<code>Restful + JSON</code>接口是当前最流行的方式</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>RPC</code>协议如果选择 <code>Restful + JSON</code>，会带来如下几个优点：</p>
<p><strong>1．践行 API First 理念：</strong>通过使用<code>Swagger YAML</code>定义 <code>API</code>，服务端和客户端都基于 <code>API</code> 定义，通过 <code>Swagger</code>代码生成工具生成不同语言的接口和模型定义类库，客户端不需要从服务端导入接口定义类库，也不需要配置 <code>Maven</code> 依赖，这样就实现了双方依赖的解耦：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/1.webp" alt="img"></p>
<p><em>Swagger 代码工具生成服务端和客户端代码</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了代码生成，利用 <code>swagger editor</code> 和 <code>swagger ui</code>工具，可以在线定义和维护 <code>API</code>接口的契约，实现接口 <code>API</code>的在线化管理，更好的管控<code>API</code>变更，示例如下：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/2.webp" alt="img"></p>
<p><em>基于 Swagger UI 在线管理 Restful API</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于 <code>RPC</code>接口的测试，由于是 <code>Restful</code> 风格的，利用一些开源的契约测试框架，可以方便的进行契约化测试：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/3.webp" alt="img"></p>
<p><em>对 Restful 风格的 RPC API 做契约化测试</em></p>
<p><strong>2．天生语言中立：</strong><code>HTTP</code> 协议和 <code>JSON</code> 序列化天生就是语言中立的，对于 <code>RPC</code> 框架，在架构上能够支持多语言非常重要。不同的业务场景，适合不同的语言，例如后端复杂业务逻辑使用 <code>Java</code>开发效率更高，对于 <code>API</code>网关或者边缘服务，适合 <code>GO</code> 语言。对于一些序列化框架，由于使用了一些特定语言的特性，例如<code>Exception</code>、泛型等，这对于跨语言演进是个灾难，像<code>protostuff</code> 就绑定了<code>Java</code>语言。</p>
<p><strong>3．内部和外部 API 接口的统一：</strong><code>RPC</code>服务通常只开放给内部的客户端做调用，如果需要开放给外部的端侧、其它渠道调用，往往需要前置一个 <code>API</code>网关或者 <code>Edge Service</code>，用来做安全接入、权限管理、统一流控、灰度发布等。组网示例如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/4.webp" alt="img"></p>
<p><em>对 RPC 服务对外开放组网图</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果 <code>RPC</code> 调用选择 <code>Restful API</code>，则对外开放时，<code>API</code>网关 <code>Edge Service</code> 只要做安全等相关功能即可，消息可以透传转发给后端 <code>RPC</code> 服务。如果后端<code>RPC</code> 服务选择私有协议，将私有协议直接开放给合作伙伴显然是不合适的，这就需要在 <code>API</code>网关上为后端<code>RPC</code> 服务定义 <code>API</code>接口，同时做消息映射和转换，最终形成对外开放一套 <code>API</code>接口，内部使用又一套<code>API</code>接口，但是功能却相同或者类似，这增加了接口的开发和维护工作量。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前主流的<code>API Gateway</code>都支持直接导入 <code>Swagger</code> 定义的<code>API</code>，自动生成并发布<code>API</code>接口，以<code>AWS</code>的 <code>API Gateway</code>为例，如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/5.webp" alt="img"></p>
<p><em>AWS 基于 Swagger 接口定义生成 API</em></p>
<p>当 <code>RPC</code> 服务开放给内部和外部是同一套<code>API</code>接口时，接口的开发和维护工作量都会减少很多。</p>
<p><strong>4．问题定位更简单：</strong><code>HTTP</code> 协议 +<code>JSON</code>文本序列化方式，更容易调试，抓包的码流解读也更容易，相反如果是二进制私有协议，码流需要人工解读，难度较高。</p>
<h4 id="2-1-2-私有协议"><a href="#2-1-2-私有协议" class="headerlink" title="2.1.2 私有协议"></a>2.1.2 私有协议</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;绝大多数的私有协议传输层都基于<code>TCP/IP</code>，对于<code>Java</code>语言，可以利用 <code>Netty</code> 的 <code>NIO TCP</code> 协议栈进行私有协议的定制和开发。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;私有协议的格式往往存在较大差异，但是对于大多数 <code>RPC</code> 框架的私有协议，往往会包含如下几个字段：</p>
<p><strong>1．消息头：</strong>消息头中通常会包含<strong>校验码、消息长度、消息类型、消息 / 会话 ID、需要调用的 RPC 接口名、方法名，以及扩展的消息头</strong>，通常是个类似 <code>Map</code> 的结构，用于隐式传参。</p>
<p><strong>2．消息体：</strong>对于请求消息，主要就是<strong>请求参数</strong>，对于响应，就是<strong>响应对象以及结果码</strong>。</p>
<p>下面以基于 <code>Netty</code> 开发的 <code>Netty</code>协议栈为例进行说明，它的协议栈模型如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/6.webp" alt="img"></p>
<p><em>Netty 协议栈通信交互图</em></p>
<p><code>Netty</code> 协议栈承载了业务内部各模块之间的消息交互和 <code>RPC</code> 调用，它的主要功能包括：</p>
<p>1．基于 <code>Netty</code> 的 <code>NIO</code> 通信框架，提供高性能的异步通信能力。</p>
<p>2．提供消息的编解码框架，可以实现 <code>POJO</code> 的序列化和反序列化。</p>
<p>3．提供基于 IP 地址的白名单接入认证机制。</p>
<p>4．链路的有效性校验机制。</p>
<p>5．链路的断连重连机制。</p>
<p><code>RPC</code> 协议栈交互的流程说明如下：</p>
<p>1．<code>Netty</code> 协议栈客户端发送握手请求消息，携带节点 ID 等有效身份认证信息。</p>
<p>2．<code>Netty</code>协议栈服务端对握手请求消息进行合法性校验，包括节点 ID 有效性校验、节点重复登录校验和 IP 地址合法性校验，校验通过后，返回登录成功的握手应答消息。</p>
<p>3．链路建立成功之后，客户端发送业务消息。</p>
<p>4．链路成功之后，服务端发送心跳消息。</p>
<p>5．链路建立成功之后，客户端发送心跳消息。</p>
<p>6．链路建立成功之后，服务端发送业务消息。</p>
<p>7．服务端退出时，服务端关闭连接，客户端感知对方关闭连接后，被动关闭客户端连接。</p>
<p><code>Netty</code> 协议栈的消息定义如下：</p>
<p>消息包含消息头和消息体：</p>
<table>
<thead>
<tr>
<th style="text-align:left">名 称</th>
<th style="text-align:left">类 型</th>
<th style="text-align:left">长 度</th>
<th style="text-align:left">描 述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">header</td>
<td style="text-align:left">Header</td>
<td style="text-align:left">变长</td>
<td style="text-align:left">消息头定义</td>
</tr>
<tr>
<td style="text-align:left">body</td>
<td style="text-align:left">Object</td>
<td style="text-align:left">变长</td>
<td style="text-align:left">对于请求消息，它是方法的参数（作为示例，只支持携带一个参数）；对于响应消息，它是返回值</td>
</tr>
</tbody>
</table>
<p>其中，消息头定义如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left">名 称</th>
<th style="text-align:left">类 型</th>
<th style="text-align:left">长 度</th>
<th style="text-align:left">描 述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">crcCode</td>
<td style="text-align:left">整型 int</td>
<td style="text-align:left">32</td>
<td style="text-align:left">Netty 消息的校验码，它由三部分组成：1）0xABEF：固定值，表明该消息是 Netty 协议消息，2 个字节；2）主版本号：1～255，1 个字节；3）次版本号：1～255，1 个字节。crcCode = 0xABEF + 主版本号 + 次版本号</td>
</tr>
</tbody>
</table>
<p>续表</p>
<table>
<thead>
<tr>
<th style="text-align:left">名 称</th>
<th style="text-align:left">类 型</th>
<th style="text-align:left">长 度</th>
<th style="text-align:left">描 述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">length</td>
<td style="text-align:left">整型 int</td>
<td style="text-align:left">32</td>
<td style="text-align:left">消息长度，整个消息，包括消息头和消息体</td>
</tr>
<tr>
<td style="text-align:left">sessionID</td>
<td style="text-align:left">长整型 long</td>
<td style="text-align:left">64</td>
<td style="text-align:left">集群节点内全局唯一，由会话 ID 生成器生成</td>
</tr>
<tr>
<td style="text-align:left">type</td>
<td style="text-align:left">Byte</td>
<td style="text-align:left">8</td>
<td style="text-align:left">0：业务请求消息；1：业务响应消息；2：业务 ONE WAY 消息（既是请求又是响应消息）；3：握手请求消息；4：握手应答消息；5：心跳请求消息；6：心跳应答消息。</td>
</tr>
<tr>
<td style="text-align:left">priority</td>
<td style="text-align:left">Byte</td>
<td style="text-align:left">8</td>
<td style="text-align:left">消息优先级：0～255</td>
</tr>
<tr>
<td style="text-align:left">interfaceName</td>
<td style="text-align:left">String</td>
<td style="text-align:left">变长</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">methodName</td>
<td style="text-align:left">String</td>
<td style="text-align:left">变长</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">attachment</td>
<td style="text-align:left">Map&lt;String, Object&gt;</td>
<td style="text-align:left">变长</td>
<td style="text-align:left">可选字段，用于扩展消息头</td>
</tr>
</tbody>
</table>
<p>对于私有协议栈的构建，需要考虑到如下几点，整体成本较高：</p>
<p>1．支持的数据结构类型，以及采用的序列化方式。</p>
<p>2．握手和接入认证。</p>
<p>3．心跳检测机制。</p>
<p>4．断连和重连机制。</p>
<p>5．并发连接数的控制。</p>
<p>6．异常、畸形码流的检测和保护。</p>
<p>7．流量限制和整形。</p>
<p>8．连接池。</p>
<p>9．网络闪断、宕机保护、消息缓存和重发机制等。</p>
<p>尽管私有协议栈构建成本较高，但是它的优势也很明显：</p>
<p>1．灵活性、可定制性更好，可以针对业务特定场景做优化。</p>
<p>2．可以实现更高的性能。</p>
<h3 id="2-2-序列化框架"><a href="#2-2-序列化框架" class="headerlink" title="2.2 序列化框架"></a>2.2 序列化框架</h3><h4 id="2-2-1-选型的原则"><a href="#2-2-1-选型的原则" class="headerlink" title="2.2.1 选型的原则"></a>2.2.1 选型的原则</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果对性能要求不高，则建议选用 <code>JSON</code>，否则可以选择一些业界主流的序列化框架，需要注意的是，对于序列化框架的选择，<strong>一定要考虑跨语言性</strong>，如果绑定特定语言，会对未来 <code>RPC</code> 框架支持多语言带来极大的困难。</p>
<h4 id="2-2-2-Google-的-Protobuf"><a href="#2-2-2-Google-的-Protobuf" class="headerlink" title="2.2.2 Google 的 Protobuf"></a>2.2.2 Google 的 Protobuf</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Protobuf</code> 全称<code>Google Protocol Buffers</code>，它由谷歌开源而来，在谷歌内部久经考验。它将数据结构以<code>.proto</code>文件进行描述，通过代码生成工具可以生成对应数据结构的<code>POJO</code> 对象和 <code>Protobuf</code> 相关的方法和属性。</p>
<p>它的特点如下:</p>
<p>1．结构化数据存储格式（<code>XML</code>，<code>JSON</code> 等）。</p>
<p>2．高效的编解码性能。</p>
<p>3．语言无关、平台无关、扩展性好。</p>
<p>4．官方支持<code>Java</code>、<code>C++</code>和 <code>Python</code> 三种语言（社区会支持更多中语言）。</p>
<p><code>Protobuf</code>的优点主要有两个：</p>
<p><strong>1．IDL 契约：</strong>利用数据描述文件对数据结构进行说明，可以实现语言和平台无关，通过标识字段的顺序，可以实现协议的前向兼容，同时提供代码生成工具，可以生成各种语言的服务端和客户端代码。</p>
<p><strong>2．性能：</strong>相比于其它序列化框架，它的性能更优，数据对比如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/7.webp" alt="img"></p>
<p><em>Protobuf 编解码和其他几种序列化框架的响应时间对比</em></p>
<h4 id="2-2-3-Apache-Thrift"><a href="#2-2-3-Apache-Thrift" class="headerlink" title="2.2.3 Apache Thrift"></a>2.2.3 Apache Thrift</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Thrift</code> 源于<code>Facebook</code>，在 2007 年<code>Facebook</code> 将<code>Thrift</code>作为一个开源项目提交给 Apache 基金会。对于当时的<code>Facebook</code> 来说，创造 <code>Thrift</code>是为了解决<code>Facebook</code> 各系统间大数据量的传输通信以及系统之间语言环境不同需要跨平台的特性，因此 <code>Thrift</code>可以支持多种程序语言，如 <code>C++、Cocoa、Erlang、Haskell、Java、Ocami、Perl、PHP、Python、Ruby</code>和<code>Smalltalk</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在多种不同的语言之间通信，<code>Thrift</code> 可以作为高性能的通信中间件使用，它支持数据（对象）序列化和多种类型的 <code>RPC</code> 服务。<code>Thrift</code> 适用于静态的数据交换，需要先确定好它的数据结构，当数据结构发生变化时，必须重新编辑<code>IDL</code>文件，生成代码和编译，这一点跟其他 <code>IDL</code>工具相比可以视为是<code>Thrift</code>的弱项。<code>Thrift</code> 适用于搭建大型数据交换及存储的通用工具，对于大型系统中的内部数据传输，相对于<code>JSON</code>和<code>XML</code> 在性能和传输大小上都有明显的优势。</p>
<p><code>Thrift</code> 主要由 5 部分组成:</p>
<ol>
<li><strong>语言系统以及 IDL 编译器：</strong>负责由用户给定的 <code>IDL</code>文件生成相应语言的接口代码；</li>
<li><strong>TProtocol：</strong><code>RPC</code> 的协议层，可以选择多种不同的对象序列化方式，如 <code>JSON</code> 和 <code>Binary</code>；</li>
<li><strong>TTransport：</strong><code>RPC</code> 的传输层，同样可以选择不同的传输层实现，如 <code>socket、NIO、MemoryBuffer</code> 等；</li>
<li><strong>TProcessor：</strong>作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口；</li>
<li><strong>TServer：</strong>聚合 <code>TProtocol</code>、<code>TTransport</code> 和 <code>TProcessor</code>等对象。</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要重点关注的是编解码框架，与之对应的就是 <code>TProtocol</code>。由于 <code>Thrift</code>的 <code>RPC</code>服务调用和编解码框架绑定在一起，所以，通常我们使用<code>Thrift</code>的时候会采取 <code>RPC</code> 框架的方式。但是，它的 <code>TProtocol</code>编解码框架还是可以以类库的方式独立使用的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与 <code>Protobuf</code>比较类似的是，<code>Thrift</code> 通过<code>IDL</code>描述接口和数据结构定义，它支持 8 种 <code>Java</code> 基本类型、<code>Map</code>、<code>Set</code>和 <code>List</code>，支持可选和必选定义，功能非常强大。因为可以定义数据结构中字段的顺序，所以它也可以支持协议的前向兼容。</p>
<p><code>Thrift</code> 支持三种比较典型的编解码方式。</p>
<ul>
<li>通用的二进制编解码</li>
<li>压缩二进制编解码</li>
<li>优化的可选字段压缩编解码</li>
</ul>
<p>由于支持二进制压缩编解码，<code>Thrift</code>的编解码性能表现也相当优异，远远超过<code>Java</code> 序列化和 <code>RMI</code> 等。</p>
<h4 id="2-2-4-MessagePack-序列化框架"><a href="#2-2-4-MessagePack-序列化框架" class="headerlink" title="2.2.4 MessagePack 序列化框架"></a>2.2.4 MessagePack 序列化框架</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>MessagePack</code> 是一个高效的二进制序列化框架，它像<code>JSON</code>一样支持不同语言间的数据交换，但是它的性能更快，序列化之后的码流也更小。<code>MessagePack</code>提供了对多语言的支持，官方支持的语言如下：<code>Java、Python、Ruby、Haskell、C#、OCaml、Lua、Go、C、C++</code> 等。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>MessagePack</code> 的 <code>Java API</code>非常简单，如果使用<code>MessagePack</code>进行开发，只需要导入<code>MessagePack maven</code>依赖：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;groupId&gt;org.msgpack&lt;/groupId&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;artifactId&gt;msgpack&lt;/artifactId&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;version&gt;$&#123;msgpack.version&#125;&lt;/version&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<p>它的<code>API</code>使用示例如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; src = new ArrayList&lt;String&gt;();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">src.add(&quot;msgpack&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">src.add(&quot;kumofs&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">src.add(&quot;viver&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">MessagePack msgpack = new MessagePack();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">byte[] raw = msgpack.write(src);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">List&lt;String&gt; dst1 =</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">msgpack.read(raw, Templates.tList(Templates.TString));</span><br></pre></td></tr></table></figure>
<h4 id="2-2-5-选型建议"><a href="#2-2-5-选型建议" class="headerlink" title="2.2.5. 选型建议"></a>2.2.5. 选型建议</h4><p>上面列举的几种序列化框架各有优缺点，如果选用，则建议从如下几个维度做对比：</p>
<p>1．支持数据类型的丰富度。</p>
<p>2．性能对比测试，主要包括 序列化和反序列化的耗时、CPU 和内存占用，以及序列化之后的码流大小。</p>
<p>3．尽管都支持跨语言，但是由于支持的语言丰富度不同，业务需要根据自己 <code>RPC</code> 框架未来可能支持的语言做选择。</p>
<h2 id="3-RPC-协议栈实践"><a href="#3-RPC-协议栈实践" class="headerlink" title="3. RPC 协议栈实践"></a>3. RPC 协议栈实践</h2><h3 id="3-1-Restful-API-的优化"><a href="#3-1-Restful-API-的优化" class="headerlink" title="3.1 Restful API 的优化"></a>3.1 Restful API 的优化</h3><p>使用 <code>Restful API</code>可以带来很多收益：</p>
<ul>
<li><code>API</code> 接口更加规范和标准，可以通过 <code>Swagger API</code> 规范来描述服务接口，并生成客户端和服务端代码。</li>
<li><code>Restful API</code>可读性更好，也更容易维护。</li>
<li>服务提供者和消费者基于<code>API</code>契约，双方可以解耦，不需要在客户端引入 <code>SDK</code>和类库的直接依赖，未来的独立升级也更方便。</li>
<li>内外可以使用同一套<code>API</code>，非常容易开放给外部或者合作伙伴使用，而不是对内和对外维护两套不同协议的 <code>API</code>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常，对外开放的<code>API</code>使用 <code>Restful</code> 是通用的做法，但是在系统内部，例如商品中心和订单中心，<code>RPC</code> 调用使用 <code>Restful</code> 风格的 <code>API</code>作为微服务的<code>API</code>，却可能存在性能风险。</p>
<h4 id="3-1-1-HTTP1-X-的性能问题"><a href="#3-1-1-HTTP1-X-的性能问题" class="headerlink" title="3.1.1 HTTP1.X 的性能问题"></a>3.1.1 HTTP1.X 的性能问题</h4><p>如果采用的 <code>Restful API</code> 底层使用的 <code>HTTP</code>协议栈是同步阻塞<code>I/O</code>，则服务端的处理性能将大打折扣：</p>
<p><strong>1．性能问题：</strong>一连接一线程模型导致服务端的并发接入数和系统吞吐量受到极大限制。</p>
<p><strong>2．可靠性问题：</strong>由于 <code>I/O</code> 操作采用同步阻塞模式，当网络拥塞或者通信对端处理缓慢会导致<code>I/O</code> 线程被挂住，阻塞时间无法预测。</p>
<p><strong>3．可维护性问题：</strong><code>I/O</code>线程数无法有效控制、资源无法有效共享（多线程并发问题），系统可维护性差。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果 <code>HTTP</code> 协议栈采用了异步非阻塞 <code>I/O</code>模型（例如 <code>Netty</code>、<code>Servlet3.X</code>版本），则可以解决同步阻塞 <code>I/O</code>的问题，带来如下收益：</p>
<p>1．同一个<code>I/O</code>线程可以并行处理多个客户端链接，有效降低了<code>I/O</code>线程数量，提升了资源调度利用率</p>
<p>2．读写操作都是非阻塞的，不会因为对端处理慢、网络时延大等导致的<code>I/O</code> 线程被阻塞</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相比于 <code>TCP</code> 类协议，例如<code>Thrift</code>, 采用了非阻塞 <code>I/O</code>的 <code>HTTP/1.X</code>协议仍然存在性能问题，原因如下所示：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果 <code>HTTP</code> 协议栈采用了异步非阻塞 <code>I/O</code>模型（例如<code>Netty</code>、<code>Servlet3.X</code> 版本），则可以解决同步阻塞<code>I/O</code>的问题，带来如下收益：</p>
<ul>
<li><p>同一个<code>I/O</code>线程可以并行处理多个客户端链接，有效降低了 <code>I/O</code>线程数量，提升了资源调度利用率。</p>
</li>
<li><p>读写操作都是非阻塞的，不会因为对端处理慢、网络时延大等导致的<code>I/O</code> 线程被阻塞。</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相比于 <code>TCP</code> 类协议，例如 <code>Thrift</code>, 采用了非阻塞 <code>I/O</code> 的 <code>HTTP/1.X</code> 协议仍然存在性能问题，原因如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/8.webp" alt="img"></p>
<p><em>HTTP/1.X 请求 - 响应模式</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于 <code>HTTP</code> 协议是无状态的，客户端发送请求之后，必须等待接收到服务端响应之后，才能继续发送请求（非 <code>websocket</code>、<code>pipeline</code> 等模式）。<strong>在某一个时刻，链路上只存在单向的消息流，实际上把 <code>TCP</code>的双工变成了单工模式</strong>。<strong>如果服务端响应耗时较大，则单个<code>HTTP</code>链路的通信性能严重下降，只能通过不断的新建连接来提升 <code>I/O</code>性能</strong>。但这也会带来很多副作用，例如<strong>句柄数的增加、<code>I/O</code> 线程的负载加重</strong>等。显而易见，修 8 条单向车道的成本远远高于修一条双向 8 车道的成本。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了无状态导致的链路传输性能差之外，<code>HTTP/1.X</code> 还存在如下几个影响性能的问题：</p>
<ul>
<li><code>HTTP</code>客户端超时之后，由于协议是无状态的，客户端无法对请求和响应进行关联，只能关闭链路重连，<strong>反复的建链会增加成本开销和时延</strong>（如果客户端选择不关闭链路，继续发送新的请求，服务端可能会把上一条客户端认为超时的响应返回回去，也可能按照 HTTP 协议规范直接关闭链路，无路哪种处理，都会导致链路被关闭）。如果采用传统的 <code>RPC</code> 私有协议，请求和响应可以通过消息 ID 或者会话 ID 做关联，某条消息的超时并不需要关闭链路，只需要丢弃该消息重发即可。</li>
<li><strong><code>HTTP</code> 本身包含文本类型的协议消息头，占用一些字节</strong>。另外，采用<code>JSON</code>类文本的序列化方式，报文相比于传统的私有 <code>RPC</code> 协议也大很多，降低了传输性能。</li>
<li><strong>服务端无法主动推送响应</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果业务对性能和资源成本要求非常苛刻，在选择使用基于 <code>HTTP/1.X</code> 的 <code>Restful API</code>代替私有 <code>RPC API</code>（通常是基于 <code>TCP</code>的二进制私有协议）时就要三思；反之，如果业务对性能要求较低，或者在硬件成本和开放性、规范性上更看重后者，则使用 <code>Restful API</code>也无妨。</p>
<h4 id="3-1-2-优化方案"><a href="#3-1-2-优化方案" class="headerlink" title="3.1.2 优化方案"></a>3.1.2 优化方案</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果选择 <code>Restful API</code>作为内部<code>RPC</code> 或者微服务的接口协议，则建议使用<code>HTTP/2.0</code>协议来承载，它的优点如下：支持双向流、消息头压缩、单 <code>TCP</code>的多路复用、服务端推送等特性, 某个 <code>RPC</code>调用超时也不需要关闭 <code>HTTP</code>连接，只需要关闭对应的<code>Stream</code> 流即可，这样可以避免大量超时时频繁的 <code>HTTP</code>连接重建，有效解决传统 <code>HTTP/1.X</code>协议遇到的问题，效果与 <code>RPC</code>的 <code>TCP</code> 私有协议接近，采用<code>HTTP/2</code> 的 <code>gRPC Steaming</code> 通信模式示例如下：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/9.webp" alt="img"></p>
<p><em>gRPC 基于 HTTP/2 的服务端 streaming 调用</em></p>
<h3 id="3-2-Apache-ServiceComb-的多协议实践"><a href="#3-2-Apache-ServiceComb-的多协议实践" class="headerlink" title="3.2 Apache ServiceComb 的多协议实践"></a>3.2 Apache ServiceComb 的多协议实践</h3><h4 id="3-2-1-标准化的服务契约"><a href="#3-2-1-标准化的服务契约" class="headerlink" title="3.2.1 标准化的服务契约"></a>3.2.1 标准化的服务契约</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>ServiceComb</code>使用 <code>yaml</code>文件格式定义服务契约，推荐使用 <code>Swagger Editor</code>工具来编写契约，可检查语法格式及自动生成 <code>API</code> 文档。服务契约与具体协议无关系，无论使用 <code>RPC</code> 二进制协议通信还是使用标准的 <code>Restful + JSON</code>，都可以使用 <code>Swagger API</code> 来描述和定义微服务接口。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接口定义完成之后，将契约文件放到 <code>&quot;resources/microservices&quot;</code>或者<code>&quot;resources/application&quot;</code> 目录下即可，目录结构如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/10.webp" alt="img"></p>
<p><em>微服务接口契约定义</em></p>
<h4 id="3-2-2-通信协议"><a href="#3-2-2-通信协议" class="headerlink" title="3.2.2 通信协议"></a>3.2.2 通信协议</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>ServiceComb</code> 实现了两种网络通道，包括 <code>Rest</code> 和 <code>Highway</code>，均支持 <code>TLS</code>加密传输。其中，<code>REST</code> 网络通道将服务以标准 <code>Restful</code> 形式发布，调用端兼容直接使用 <code>Http client</code> 使用标准 <code>Restful</code>形式进行调用。</p>
<p><code>Rest</code>协议栈支持两种实现方式：</p>
<p>1．<code>REST over Servlet</code> 对应使用 <code>web</code> 容器部署运行，需要新建一个 <code>servlet</code>工程将微服务包装起来，打成 <code>war</code> 包，加载到 <code>web</code> 容器中启动运行。</p>
<p>2．<code>REST over Vertx</code> 通信通道对应使用 <code>standalone</code>部署运行模式，可直接通过 <code>main</code> 函数拉起。使用 <code>REST over Vertx</code> 网络通道需要在 <code>maven pom</code> 文件中添加如下依赖：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/11.webp" alt="img"></p>
<p><em>REST over Vertx 通信方式</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了对 <code>Rest</code>的支持，在一些需要高性能、低时延的场景，使用私有二进制性能会更高一些。<code>Highway</code> 是 <code>ServiceComb</code>的高性能私有协议，用户可在有特殊性能需求的场景下选用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用 <code>Highway</code>网络通道需要在 <code>maven pom</code> 文件中添加如下依赖：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/12.webp" alt="img"></p>
<p><em>Highway 通信方式</em></p>
<p><code>ServiceComb</code> 的通信协议有如下几个特点：</p>
<p>1．协议与服务接口契约定义没关系，使用 <code>Swagger</code> 定义的 <code>API</code>接口，仍然可以使用二进制 <code>Highway</code>私有协议进行 <code>RPC</code> 调用。</p>
<p>2．协议与业务代码无耦合关系，一套业务接口，可以选择发布成哪种协议。支持同一个服务接口发布成多种协议，客户端可以根据自己的需要选择哪种协议方式调用。</p>
<h4 id="3-2-3-对-HTTP-2-协议的支持"><a href="#3-2-3-对-HTTP-2-协议的支持" class="headerlink" title="3.2.3 对 HTTP/2 协议的支持"></a>3.2.3 对 HTTP/2 协议的支持</h4><p><code>ServiceComb</code> 提供了对 <code>HTTP/2</code>的支持，用于解决传统 <code>HTTP/1.1</code> 的性能问题，它支持 2 种 <code>HTTP/2</code>通信方式：</p>
<p><strong>1．h2(Http2 + TLS)：</strong>服务端在配置服务监听地址时，可以通过在地址后面追加<code>?sslEnabled=true</code> 开启 <code>TLS</code>通信，示例如下：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/13.webp" alt="img"></p>
<p><em>h2 通信方式配置</em></p>
<p><strong>2．h2c(Http2 without TLS)：</strong>服务端在配置服务监听地址时，可以通过在地址后面追加<code>?protocol=http2</code> 启用 h2c 通信：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/14.webp" alt="img"></p>
<p><em>h2c 通信方式配置</em></p>
<h4 id="3-2-4-性能对比数据"><a href="#3-2-4-性能对比数据" class="headerlink" title="3.2.4. 性能对比数据"></a>3.2.4. 性能对比数据</h4><p><code>Restful</code>和 <code>Highway</code>（私有二进制协议）两种协议在不同模式的性能对比数据如下所示：</p>
<p><img src="//blog.com/2019/07/27/RPC协议之争和选型要点/15.webp" alt="img"></p>
<p><em>性能对比数据</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上述性能测试数据对比可以发现，私有的二进制协议 <code>Highway（TCP + Protobuf）</code>比 <code>Restful+JSON</code> 协议整体性能高 2 倍 + 左右。如果 <code>Restful+JSON</code>采用 <code>HTTP/1.1</code> 承载，无法实现链路的多路复用，一旦 <code>RPC</code>调用超时就会频繁重建链路，可靠性相比于<code>TCP</code>私有协议会差很多。</p>
<h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><h3 id="4-1-协议与接口的解耦"><a href="#4-1-协议与接口的解耦" class="headerlink" title="4.1. 协议与接口的解耦"></a>4.1. 协议与接口的解耦</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无论是选择 <code>Restful</code>（<code>HTTP</code> 协议）还是私有二进制协议，总是存在各自的优缺点，对于比较复杂的业务场景，可能多种协议都需要支持，这就要求 <code>RPC</code> 框架必须实现接口定义与协议本身的解耦，即业务可以平滑的切换协议，上层应用不需要感知。</p>
<h3 id="4-2-RPC-协议的定制和扩展"><a href="#4-2-RPC-协议的定制和扩展" class="headerlink" title="4.2 RPC 协议的定制和扩展"></a>4.2 RPC 协议的定制和扩展</h3><p>一个比较好的协议往往具备较强的扩展性，协议的扩展主要体现在两点：</p>
<p>1．协议栈本身的扩展，例如基于协议框架扩展出另一种协议。</p>
<p>2．协议栈采用的序列化框架的扩展。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于 <code>RPC</code>框架而言，更有价值的是序列化框架的扩展，可以在协议头中增加一个标识协议类型的字段，RPC 框架根据协议类型来调用对应的序列化框架，实现业务自定义的序列化和反序列化。</p>
<h3 id="4-3-一些技术难点"><a href="#4-3-一些技术难点" class="headerlink" title="4.3 一些技术难点"></a>4.3 一些技术难点</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不同的序列化框架，对数据类型的支持不同，对字段是否支持乱序也存在差异，所以，从某种程度看，协议和序列化方式完全与业务接口解耦也是很困难的，会有很多约束和限制，所以需要辨证的看待接口和协议的解耦，尽量做到对业务的影响最小、以及约束和限制的规范化。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/27/深入剖析通信层和 RPC 调用的异步化/" itemprop="url">深入剖析通信层和 RPC 调用的异步化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-27T12:12:57+08:00">
                2019-07-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/" itemprop="url" rel="index">
                    <span itemprop="name">微服务</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/微服务/分布式系统/RPC/" itemprop="url" rel="index">
                    <span itemprop="name">RPC</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="深入剖析通信层和-RPC-调用的异步化"><a href="#深入剖析通信层和-RPC-调用的异步化" class="headerlink" title="深入剖析通信层和 RPC 调用的异步化"></a>深入剖析通信层和 RPC 调用的异步化</h1><blockquote>
<p>原文地址：<a href="https://www.infoq.cn/article/q3iPeYQv-uF5YsISq62c" target="_blank" rel="noopener">https://www.infoq.cn/article/q3iPeYQv-uF5YsISq62c</a></p>
</blockquote>
<h2 id="1-异步的一些常见误区"><a href="#1-异步的一些常见误区" class="headerlink" title="1. 异步的一些常见误区"></a>1. 异步的一些常见误区</h2><h3 id="1-1-常见的理解误区"><a href="#1-1-常见的理解误区" class="headerlink" title="1.1. 常见的理解误区"></a>1.1. 常见的理解误区</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在将近 10 年的平台中间件研发历程中，我们的平台和业务经历了从 <code>C++</code> 到<code>Java</code>，从同步的<code>BIO</code>到非阻塞的 <code>NIO</code>，以及纯异步的事件驱动 <code>I/O(AIO)</code>。服务器也从 <code>Web</code>容器逐步迁移到了内部更轻量、更高性能的微容器。服务之间的<code>RPC</code>调用从最初的同步阻塞式调用逐步升级到了全栈异步非阻塞调用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每次的技术演进都会涉及到大量底层平台技术以及上层编程模型的切换，在实际工作中，我发现很多同学对通信框架的异步和 <code>RPC</code>调用的异步理解有误，比较<strong>典型的错误理解</strong>包括：</p>
<p>1．我使用的是 <code>Tomcat8</code>，因为 <code>Tomcat8</code> 支持 <code>NIO</code>，所以我基于 <code>Tomcat</code> 开发的 <code>HTTP</code> 调用都是异步的。</p>
<p>2．因为我们的<code>RPC</code> 框架底层使用的是<code>Netty</code>、<code>Vert.X</code> 等异步框架，所以我们的 <code>RPC</code> 调用天生就是异步的。</p>
<p>3．因为我们底层的通信框架不支持异步，所以 <code>RPC</code>调用也无法异步化。</p>
<h3 id="1-2-混淆-Tomcat-NIO-与-HTTP-服务的异步化"><a href="#1-2-混淆-Tomcat-NIO-与-HTTP-服务的异步化" class="headerlink" title="1.2. 混淆 Tomcat NIO 与 HTTP 服务的异步化"></a>1.2. 混淆 Tomcat NIO 与 HTTP 服务的异步化</h3><h4 id="1-2-1-Tomcat-的-BIO-和-NIO"><a href="#1-2-1-Tomcat-的-BIO-和-NIO" class="headerlink" title="1.2.1. Tomcat 的 BIO 和 NIO"></a>1.2.1. Tomcat 的 BIO 和 NIO</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在 <code>Tomcat6.X</code>版本对 <code>NIO</code>提供比较完善的支持之前，作为 <code>Web</code> 服务器，<code>Tomcat</code>以 <code>BIO</code> 的方式接收并处理客户端的 <code>HTTP</code>请求，当并发访问量比较大时，就容易发生拥塞等性能问题，它的工作原理示意如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/5f26869e4853a31488aa7fb1da9dfb53.jpg" alt="img"></p>
<p><em>采用 BIO 做 HTTP 服务器的 Web 容器</em></p>
<p>传统同步阻塞通信（<code>BIO</code>）面临的主要问题如下：</p>
<p>1．<strong>性能问题：一连接一线程模型导致服务端的并发接入数和系统吞吐量受到极大限制</strong>。</p>
<p>2．<strong>可靠性问题：由于<code>I/O</code> 操作采用同步阻塞模式，当网络拥塞或者通信对端处理缓慢会导致<code>I/O</code> 线程被挂住，阻塞时间无法预测</strong>。</p>
<p>3．<strong>可维护性问题：<code>I/O</code> 线程数无法有效控制、资源无法有效共享（多线程并发问题），系统可维护性差</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上图我们可以看出，每当有一个新的客户端接入，服务端就需要创建一个新的线程（或者重用线程池中的可用线程），每个客户端链路对应一个线程。当客户端处理缓慢或者网络有拥塞时，服务端的链路线程就会被同步阻塞，也就是说所有的<code>I/</code>O 操作都可能被挂住，这会导致线程利用率非常低，同时随着客户端接入数的不断增加，服务端的<code>I/O</code> 线程不断膨胀，直到无法创建新的线程。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>同步阻塞<code>I/O</code>导致的问题无法在业务层规避，必须改变<code>I/O</code>模型，才能从根本上解决这个问题</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Tomcat 6.X</code>提供了对<code>NIO</code> 的支持，通过指定<code>Connector protocol=“org.apache.coyote.http11.Http11NioProtocol”</code>，就可以开启 <code>NIO</code>模式，采用 <code>NIO</code>之后，利用 <code>Selector</code>的轮询以及 <code>I/O</code>操作的非阻塞特性，可以实现使用更少的<code>I/O</code>线程处理更多的客户端连接，提升吞吐量和主机的资源利用率。<code>Tomcat 8.X</code>之后提供了对 <code>NIO2.0</code> 的支持，默认也开启了 <code>NIO</code> 通信模式。</p>
<h4 id="1-2-2-Tomcat-NIO-与-Servlet-异步"><a href="#1-2-2-Tomcat-NIO-与-Servlet-异步" class="headerlink" title="1.2.2. Tomcat NIO 与 Servlet 异步"></a>1.2.2. Tomcat NIO 与 Servlet 异步</h4><p>事实上，<code>Tomcat</code> 支持 <code>NIO</code>，与 <code>Tomcat</code> 的 <code>HTTP</code>服务是否是异步的，没有必然关系，这个可以从两个层面理解：</p>
<p>1．<code>HTTP</code>消息的读写：<strong>即便采用了<code>NIO</code>，<code>HTTP</code>请求和响应的消息处理仍然可能是同步阻塞的，这与协议栈的具体策略有关系</strong>。从 <code>Tomcat</code> 官方文档可以看到，<code>Tomcat 6.X</code>版本即便采用 <code>Http11NioProtocol</code>，<code>HTTP</code> 请求消息和响应消息的读写仍然是<code>Blocking</code> 的。</p>
<p>2．<code>HTTP</code> 请求和响应的生命周期管理：<strong>本质上就是<code>Servlet</code>是否支持异步</strong>，如果 <code>Servlet</code> 是 <code>3.X</code> 之前的版本，则 <code>HTTP</code> 协议的处理仍然是同步的，这就意味着 <code>Tomcat</code>的 <code>Connector</code>线程需要同时处理<code>HTTP</code> 请求消息、执行 <code>Servlet Filter</code>、以及业务逻辑，然后将业务构造的<code>HTTP</code> 响应消息发送给客户端，整个 <code>HTTP</code>消息的生命周期都采用了同步处理方式。</p>
<p><code>Tomcat</code>与 <code>Servlet</code>的版本配套关系如下所示：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Servlet\</strong>** 规范版本**</th>
<th style="text-align:left"><strong>Tomcat\</strong>** 版本**</th>
<th style="text-align:left"><strong>JDK\</strong>** 版本**</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">4.0</td>
<td style="text-align:left">9.0.X</td>
<td style="text-align:left">8+</td>
</tr>
<tr>
<td style="text-align:left">3.1</td>
<td style="text-align:left">8.0.X</td>
<td style="text-align:left">7+</td>
</tr>
<tr>
<td style="text-align:left">3.0</td>
<td style="text-align:left">7.0.X</td>
<td style="text-align:left">6+</td>
</tr>
<tr>
<td style="text-align:left">2.5</td>
<td style="text-align:left">6.0.X</td>
<td style="text-align:left">5+</td>
</tr>
<tr>
<td style="text-align:left">2.4</td>
<td style="text-align:left">5.5.X</td>
<td style="text-align:left">1.4+</td>
</tr>
<tr>
<td style="text-align:left">2.3</td>
<td style="text-align:left">4.1.X</td>
<td style="text-align:left">1.3+</td>
</tr>
</tbody>
</table>
<p><em>Tomcat 与 Servlet 的版本配套关系</em></p>
<h4 id="1-2-3-Tomcat-NIO-与-HTTP-服务调用"><a href="#1-2-3-Tomcat-NIO-与-HTTP-服务调用" class="headerlink" title="1.2.3. Tomcat NIO 与 HTTP 服务调用"></a>1.2.3. Tomcat NIO 与 HTTP 服务调用</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以 <code>Tomcat 6.X</code>版本为例，<code>Tomcat HTTP</code> 协议消息和后续的业务逻辑处理如下所示（<code>Tomcat HTTP</code> 协议处理非常复杂，为了便于理解，图示做了简化）：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/3a4e9cba12532f413f6fd27cf48eac59.jpg" alt="img"></p>
<p><em>Tomcat 6.X 的 HTTP 消息接入和处理原理</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上图可以看出，<code>HTTP</code> 请求消息的读取、<code>Servlet Filter</code>的执行、业务 <code>Servlet</code>的逻辑处理，以及 <code>HTTP</code> 响应都是由 <code>Tomcat</code> 的 <code>NIO</code>线程（<code>Processor</code>，实际更复杂些，这里做了简化处理）做处理，即<strong><code>HTTP</code> 消息的处理周期中都是串行同步执行的</strong>，尽管<code>Tomcat</code> 使用 <code>NIO</code>做接入，<code>HTTP</code>服务端的处理仍然是同步的。它的弊端很明显，<strong>如果 <code>Servlet</code>中的业务逻辑处理比较复杂，则会导致 <code>Tomcat</code> 的 <code>NIO</code> 线程被阻塞，无法读取其它 <code>HTTP</code> 客户端发送的<code>HTTP</code> 请求消息，导致客户端读响应超时</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可能有读者会有疑问，为什么不能创建一个业务线程池，由业务线程池异步处理业务逻辑，处理完成之后再填充 <code>HttpServletResponse</code>，发送响应。实际上在<code>Servlet</code>支持异步之前是无法实现的，原因是每个响应对象只有在 <code>Servlet</code>的<code>service</code>方法或 <code>Filter</code> 的 <code>doFilter</code>方法范围内有效，该方法一旦调用完成，<code>Tomcat</code> 就认为本次<code>HTTP</code>消息处理完成，它会回收 <code>HttpServletRequest</code> 和<code>HttpServletResponse</code> 对象再利用，<strong>如果业务异步化之后再处理 <code>HttpServletResponse</code>，拿到的实际就不是之前请求消息对应的响应，会发生各种非预期问题，因此，业务逻辑必须在 <code>service</code>方法结束前执行，无法做异步化处理</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果使用的是支持<code>Servlet3.0+</code> 版本的<code>Tomcat</code>，通过开启异步处理模式，就能解决同步调用面临的各种问题。</p>
<h4 id="1-2-4-总结"><a href="#1-2-4-总结" class="headerlink" title="1.2.4. 总结"></a>1.2.4. 总结</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过以上分析我们可以看出，除了将 <code>Tomcat</code> 的 <code>Connector</code> 配置成 <code>NIO</code> 模式之外，还需要 <code>Tomcat</code> 配套的 <code>Servlet</code>版本支持异步化（<code>3.0+</code>），同时还需要在业务<code>Servlet</code>的代码中开启异步模式，<code>HTTP</code> 服务端才能够实现真正的异步化：<code>I/O</code> 异步以及业务逻辑处理的异步化。</p>
<h3 id="1-3-混淆-RPC-异步与-I-O-异步"><a href="#1-3-混淆-RPC-异步与-I-O-异步" class="headerlink" title="1.3. 混淆 RPC 异步与 I/O 异步"></a>1.3. 混淆 RPC 异步与 I/O 异步</h3><h4 id="1-3-1-Java-的各种-I-O-模型"><a href="#1-3-1-Java-的各种-I-O-模型" class="headerlink" title="1.3.1. Java 的各种 I/O 模型"></a>1.3.1. Java 的各种 I/O 模型</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很多人喜欢将<code>JDK 1.4</code>提供的 <code>NIO</code>框架称为异步非阻塞 <code>I/O</code>，但是，如果严格按照 <code>UNIX</code>网络编程模型和 <code>JDK</code>的实现进行区分，实际上它只能被称为非阻塞 <code>I/O</code>，不能叫异步非阻塞 <code>I/O</code>。在早期的<code>JDK 1.4</code>和 <code>1.5 update10</code>版本之前，<code>JDK</code> 的 <code>Selector</code>基于<code>select/poll</code> 模型实现，它是基于<code>I/O</code>复用技术的非阻塞<code>I/O</code>，不是异步 <code>I/O</code>。在 <code>JDK 1.5 update10</code> 和<code>Linux core2.6</code>以上版本，<code>Sun</code>优化了 <code>Selctor</code>的实现，它在底层使用 <code>epoll</code>替换了 <code>select/poll</code>，上层的<code>API</code>并没有变化，可以认为是<code>JDK NIO</code> 的一次性能优化，但是它仍旧没有改变 <code>I/O</code> 的模型。相关优化的官方说明如下图所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/b29a9693beb7f2bd3b1b2f3b80276bd2.jpg" alt="img"></p>
<p><em>JDK1.5_update10 支持 epoll</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由<code>JDK1.7</code> 提供的 <code>NIO 2.0</code> 新增了异步的套接字通道，它是真正的异步 <code>I/O</code>，<strong>在异步<code>I/O</code> 操作的时候可以传递信号变量，当操作完成之后会回调相关的方法，异步<code>I/O</code>也被称为 <code>AIO</code></strong>。<code>NIO</code>类库支持非阻塞读和写操作，相比于之前的同步阻塞读和写，它是异步的，因此很多人仍然习惯于称<code>NIO</code> 为异步非阻塞<code>I/O</code>，在此不需要太咬文嚼字。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不同的 <code>I/O</code> 模型由于线程模型、<code>API</code>等差别很大，所以用法的差异也非常大。各种<code>I/O</code>模型的优缺点对比如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"><strong>同步阻塞 I/O（BIO）</strong></th>
<th style="text-align:left"><strong>非阻塞 I/O（NIO）</strong></th>
<th style="text-align:left"><strong>异步 I/O（AIO）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">客户端个数：I/O 线程</td>
<td style="text-align:left">1：1</td>
<td style="text-align:left"><em>M</em>：1（1 个 I/O 线程处理多个客户端连接）</td>
<td style="text-align:left"><em>M</em>：0（不需要用户启动额外的 I/O 线程，被动回调）</td>
</tr>
<tr>
<td style="text-align:left">I/O 类型（阻塞）</td>
<td style="text-align:left">阻塞 I/O</td>
<td style="text-align:left">非阻塞 I/O</td>
<td style="text-align:left">非阻塞 I/O</td>
</tr>
<tr>
<td style="text-align:left">I/O 类型（同步）</td>
<td style="text-align:left">同步 I/O</td>
<td style="text-align:left">同步 I/O（I/O 多路复用）</td>
<td style="text-align:left">异步 I/O</td>
</tr>
<tr>
<td style="text-align:left">API 使用难度</td>
<td style="text-align:left">简单</td>
<td style="text-align:left">非常复杂</td>
<td style="text-align:left">复杂</td>
</tr>
<tr>
<td style="text-align:left">调试难度</td>
<td style="text-align:left">简单</td>
<td style="text-align:left">复杂</td>
<td style="text-align:left">复杂</td>
</tr>
<tr>
<td style="text-align:left">可靠性</td>
<td style="text-align:left">非常差</td>
<td style="text-align:left">高</td>
<td style="text-align:left">高</td>
</tr>
<tr>
<td style="text-align:left">吞吐量</td>
<td style="text-align:left">低</td>
<td style="text-align:left">高</td>
<td style="text-align:left">高</td>
</tr>
</tbody>
</table>
<p><em>Java 各种 I/O 模型优缺点对比</em></p>
<h4 id="1-3-2-RPC-工作原理"><a href="#1-3-2-RPC-工作原理" class="headerlink" title="1.3.2. RPC 工作原理"></a>1.3.2. RPC 工作原理</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>RPC</code> 的全称是 <code>Remote Procedure Call</code>，它是一种进程间通信方式。允许像调用本地服务一样调用远程服务，它的具体实现方式可以不同，例如 <code>Spring</code> 的 <code>HTTP Invoker</code>，<code>Facebook</code> 的 <code>Thrift</code> 二进制私有协议通信。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>RPC</code> 框架的目标就是让远程过程（服务）调用更加简单、透明，<code>RPC</code> 框架负责屏蔽底层的传输方式（<code>TCP</code> 或者 <code>UDP</code>）、序列化方式（<code>XML</code>/<code>Json</code>/ 二进制）和通信细节。框架使用者只需要了解谁在什么位置提供了什么样的远程服务接口即可，开发者不需要关心底层通信细节和调用过程。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>RPC</code> 框架的调用原理图如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/b64ce2ee1e7a6a39e3820a33bf91e721.jpg" alt="img"></p>
<p><em>RPC 框架原理图</em></p>
<p><code>RPC</code> 框架实现的几个核心技术点总结如下：</p>
<p>1．<strong>远程服务提供者需要以某种形式提供服务调用相关的信息，包括但不限于服务接口定义、数据结构，或者中间态的服务定义文件</strong>，例如 <code>Thrift</code>的<code>IDL</code> 文件，<code>WS-RPC</code> 的 <code>WSDL</code> 文件定义，甚至也可以是服务端的接口说明文档；服务调用者需要通过一定的途径获取远程服务调用相关信息，例如服务端接口定义 <code>Jar</code> 包导入，获取服务端 <code>IDL</code>文件等。</p>
<p>2．<strong>远程代理对象</strong>：服务调用者调用的服务实际是远程服务的本地代理，对于 <code>Java</code>语言，它的实现就是<code>JDK</code> 的动态代理，通过动态代理的拦截机制，将本地调用封装成远程服务调用。</p>
<p>3．<strong>通信</strong>：<code>RPC</code> 框架与具体的协议无关，例如 <code>Spring</code>的远程调用支持<code>HTTP Invoke</code>、<code>RMI Invoke</code>，<code>MessagePack</code> 使用的是私有的二进制压缩协议。</p>
<p>4．<strong>序列化</strong>：远程通信，需要将对象转换成二进制码流进行网络传输，不同的序列化框架，支持的数据类型、数据包大小、异常类型以及性能等都不同。不同的 <code>RPC</code> 框架应用场景不同，因此技术选择也会存在很大差异。一些做的比较好的 <code>RPC</code> 框架，可以支持多种序列化方式，有的甚至支持用户自定义序列化框架（<code>Hadoop Avro</code>）。</p>
<h4 id="1-3-3-RPC-异步与-I-O-的异步"><a href="#1-3-3-RPC-异步与-I-O-的异步" class="headerlink" title="1.3.3. RPC 异步与 I/O 的异步"></a>1.3.3. RPC 异步与 I/O 的异步</h4><p><code>RPC</code> 异步与<code>I/O</code>的异步没有必然关系，当然，在大多数场景下，<code>RPC</code>框架底层会使用异步<code>I/O</code>，实现全栈异步。</p>
<p><code>RPC</code> 框架异步调度模型如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/26dfc69b3b55b9b6c2404219cb82dbb4.jpg" alt="img"></p>
<p><em>异步 RPC 调用原理</em></p>
<p>异步<code>RPC</code>调用的关键点有 2 个：</p>
<p>1．<strong>不能阻塞调用方线程</strong>：接口调用通常会返回 <code>Future</code> 或者 <code>Promise</code>对象，代表异步操作的一个回调对象，当异步操作完成之后，由 <code>I/O</code>线程回调业务注册的<code>Listener</code>，继续执行业务逻辑。</p>
<p>2．<strong>请求和响应的上下文关联</strong>：除了 <code>HTTP/1.X</code> 协议，大部分二进制协议的 <code>TCP</code> 链路都是多路复用的，请求和响应消息的发送和接收顺序是无序的。所以，<strong>异步<code>RPC</code> 调用需要缓存请求和响应的上下文关联关系，以及响应需要使用到的消息上下文</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;正如上图所示，当 <code>RPC</code>调用请求消息发送到<code>I/O</code>线程的消息队列之后，业务线程就可以返回，至于<code>I/O</code>线程采用同步还是异步的方式读写消息，与 <code>RPC</code>调用的同步和异步没必然的关联关系，当然，采用异步<code>I/O,</code> 整体性能和可靠性会更好一些，所以现在大部分的 <code>RPC</code>框架底层采用的都是异步 / 非阻塞<code>I/O</code>。以<code>Netty</code>为例，无论 <code>RPC</code> 调用是同步还是异步，只要调用消息发送接口，<code>Netty</code> 都会将发送请求封装成 Task，加入到 <code>I/O</code>线程的消息队列中统一处理，相关代码如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/7d6845ca87ed511de0c7bf778e490631.jpg" alt="img"></p>
<p>异步回调的一些实现策略：</p>
<p>1．<code>Future/Promise</code>：比较常用的有 <code>JDK8</code> 之前的 <code>Future</code>，通过添加 <code>Listener</code> 来做异步回调，<code>JDK8</code>之后通常使用 <code>CompletableFuture</code>，它支持各种复杂的异步处理策略，例如自定义线程池、多个异步操作的编排、有返回值和无返回值异步、多个异步操作的级联操作等。</p>
<p>2．<code>线程池 +RxJava</code>: 最经典的实现就是 <code>Netflix</code> 开源的 <code>Hystrix</code> 框架，使用 <code>HystrixCommand</code>（创建线程池）做一层异步封装，将同步调用封装成异步调用，利用 <code>RxJava API</code>，通过订阅的方式对结果做异步处理，它的工作原理如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/d7aad590d68c5eaf4b7a79bac68cf74f.jpg" alt="img"></p>
<p><em>利用 Hystix 做异步化封装</em></p>
<h4 id="1-3-4-总结"><a href="#1-3-4-总结" class="headerlink" title="1.3.4. 总结"></a>1.3.4. 总结</h4><p>通过以上分析可以得出如下结论：</p>
<p>1．<strong><code>RPC</code>异步指的是业务线程发起 <code>RPC</code> 调用之后，不用同步等待服务端返回应答，而是立即返回，当接收到响应之后，回调执行业务的后续逻辑</strong>。</p>
<p>2．<strong><code>I/O</code>的异步是通信层的具体实现策略，使用异步<code>I/O</code> 会带来性能和可靠性提升，但是与 <code>RPC</code> 调用是同步还是异步没必然关系</strong>。</p>
<h2 id="2-RPC-同步与异步调用"><a href="#2-RPC-同步与异步调用" class="headerlink" title="2. RPC 同步与异步调用"></a>2. RPC 同步与异步调用</h2><p>很多 <code>RPC</code> 框架同时支持同步和异步调用，下面对同步和异步 <code>RPC</code>调用的工作原理以及优缺点进行分析。</p>
<h3 id="2-1-同步-RPC-调用"><a href="#2-1-同步-RPC-调用" class="headerlink" title="2.1. 同步 RPC 调用"></a>2.1. 同步 RPC 调用</h3><h4 id="2-1-1-同步-RPC-调用流行的原因"><a href="#2-1-1-同步-RPC-调用流行的原因" class="headerlink" title="2.1.1. 同步 RPC 调用流行的原因"></a>2.1.1. 同步 RPC 调用流行的原因</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在传统的单体架构中，以<code>Spring + Struts + MyBatis + Tomcat</code>为例，业务逻辑通常由各种 <code>Controller（Spring Bean）</code>来实现，它的逻辑架构如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/434e420b8d2b3cdbcc817585ef48bbc8.jpg" alt="img"></p>
<p><em>基于 MVC 的传统单体架构</em></p>
<p>在单体架构中，本地方法调用都是同步方式，而且定义形式往往都是如下形式（请求参数 + 方法返回值）：</p>
<p><code>String sayHello(String hello);</code></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;切换到 <code>RPC</code> 框架之后，很多都支持通过 <code>XML</code>引用或者代码注解的方式引用远端的<code>RPC</code>服务，可以像使用本地接口一样调用远程的服务，这种<strong>开发模式与传统单体应用开发模式相似，编程简单，学习和切换成本低，调试也比较方便，因此，同步 <code>RPC</code>调用成为大部分项目的首选</strong>。</p>
<p>以 <code>XML</code> 方式导入远端服务提供者的 <code>API</code>接口示例如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;xxx:reference id=&quot;echoService&quot; interface=&quot;edu.neu.EchoService&quot; /&gt;</span><br><span class="line"> </span><br><span class="line">&lt;bean class=&quot;edu.neu.xxxAction&quot; init-method=&quot;start&quot;&gt;</span><br><span class="line"> </span><br><span class="line">      &lt;property name=&quot;echoService&quot; ref=&quot;echoService&quot; /&gt;</span><br><span class="line"> </span><br><span class="line">&lt;/bean&gt;</span><br></pre></td></tr></table></figure>
<p>导入之后业务就可以直接在代码中调用 <code>echoService</code> 接口，与传统单体应用调用本地 <code>Spring Bean</code>一样，无需感知远端服务接口的具体部署位置信息。</p>
<h4 id="2-1-2-同步-RPC-调用工作原理"><a href="#2-1-2-同步-RPC-调用工作原理" class="headerlink" title="2.1.2. 同步 RPC 调用工作原理"></a>2.1.2. 同步 RPC 调用工作原理</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同步 <code>RPC</code>调用是最常用的一种服务调用方式，它的工作原理如下：客户端发起远程 <code>RPC</code>调用请求，用户线程完成消息序列化之后，将消息投递到通信框架，然后同步阻塞，等待通信线程发送请求并接收到应答之后，唤醒同步等待的用户线程，用户线程获取到应答之后返回。它的工作原理图如下所示：</p>
<p>它的工作原理图如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/a5d922561c8e6520d6931e45e915deb0.jpg" alt="img"></p>
<p><em>同步 RPC 调用</em></p>
<p>主要流程如下：</p>
<p>1．消费者调用服务端发布的接口，接口调用由 <code>RPC</code> 框架包装成动态代理，发起远程<code>RPC</code> 调用。</p>
<p>2．消费者线程调用通信框架的消息发送接口之后，直接或者间接调用 <code>wait()</code>方法，同步阻塞等待应答。</p>
<p>3．通信框架的 <code>I/O</code>线程通过网络将请求消息发送给服务端。</p>
<p>4．服务端返回应答消息给消费者，由通信框架负责应答消息的反序列化。</p>
<p>5．<code>I/O</code>线程获取到应答消息之后，根据消息上下文找到之前同步阻塞的业务线程，notify() 阻塞的业务线程，返回应答给消费者，完成 <code>RPC</code> 调用。</p>
<h4 id="2-1-3-同步-RPC-调用面临的挑战"><a href="#2-1-3-同步-RPC-调用面临的挑战" class="headerlink" title="2.1.3. 同步 RPC 调用面临的挑战"></a>2.1.3. 同步 RPC 调用面临的挑战</h4><p>同步 <code>RPC</code>调用的主要缺点如下：</p>
<p>1．<strong>线程利用率低</strong>：线程资源是系统中非常重要的资源，在一个进程中线程总数是有限制的，提升线程使用率就能够有效提升系统的吞吐量，在同步 <code>RPC</code>调用中，如果服务端没有返回响应，客户端业务线程就会一直阻塞，无法处理其它业务消息。</p>
<p>2．<strong>纠结的超时时间</strong>：<code>RPC</code>调用的超时时间配置是个比较棘手的问题。如果配置的过大，一旦服务端返回响应慢，就容易把客户端挂死。如果配置的过小，则超时失败率会增加。即便参考测试环境的平均和最大时延来设置，由于生产环境数据、硬件等与测试环境的差异，也很难一次设置的比较合理。另外，考虑到客户端流量的变化、服务端依赖的数据库、缓存、第三方系统等的性能波动，这都会导致服务调用时延发生变化，因此，依靠超时时间来保障系统的可靠性，难度很大。</p>
<p>3．<strong>雪崩效应</strong>：在一个同步调用链中，只要下游某个服务返回响应慢，会导致故障沿着调用链向上游蔓延，最终把整个系统都拖垮，引起雪崩，示例如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/6cb9f6a55cd99e4ab964ea7f83ae92c1.jpg" alt="img"></p>
<p><em>同步 RPC 调用级联故障</em></p>
<h3 id="2-2-异步-RPC-调用"><a href="#2-2-异步-RPC-调用" class="headerlink" title="2.2. 异步 RPC 调用"></a>2.2. 异步 RPC 调用</h3><h4 id="2-2-1-异步-RPC-调用工作原理"><a href="#2-2-1-异步-RPC-调用工作原理" class="headerlink" title="2.2.1. 异步 RPC 调用工作原理"></a>2.2.1. 异步 RPC 调用工作原理</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>JDK</code> 原生的 <code>Future</code> 主要用于异步操作，它代表了异步操作的执行结果，用户可以通过调用它的 <code>get</code> 方法获取结果。如果当前操作没有执行完，<code>get</code>操作将阻塞调用线程。在实际项目中，往往会扩展<code>JDK</code>的 <code>Future</code>，提供 <code>Future-Listener</code> 机制，它支持主动获取和被动异步回调通知两种模式，适用于不同的业务场景。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于 <code>JDK</code> 的<code>Future-Listener</code>机制，可以实现异步 <code>RPC</code>调用，它的工作原理如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/01cd3bc5f04e09e515c646bef8c4a020.jpg" alt="img"></p>
<p><em>异步 RPC 调用原理图</em></p>
<p>异步 <code>RPC</code> 调用的工作流程如下：</p>
<p>1．消费者调用 <code>RPC</code> 服务端发布的接口，接口调用由 <code>RPC</code> 框架包装成动态代理，发起远程 <code>RPC</code> 调用。</p>
<p>2．通信框架异步发送请求消息，如果没有发生<code>I/O</code> 异常，返回。</p>
<p>3．请求消息发送成功后，<code>I/O</code>线程构造 <code>Future</code>对象，设置到 <code>RPC</code> 上下文中。</p>
<p>4．用户线程通过 <code>RPC</code> 上下文获取<code>Future</code>对象。</p>
<p>5．构造 <code>Listener</code>对象，将其添加到 <code>Future</code> 中，用于服务端应答异步回调通知。</p>
<p>6．用户线程返回，不阻塞等待应答。</p>
<p>7．服务端返回应答消息，通信框架负责反序列化等。</p>
<p>8．<code>I/O</code> 线程将应答设置到 <code>Future</code> 对象的操作结果中。</p>
<p>9．<code>Future</code> 对象扫描注册的监听器列表，循环调用监听器的<code>operationComplete</code>方法，将结果通知给监听器，监听器获取到结果之后，继续后续业务逻辑的执行，异步 <code>RPC</code> 调用结束。</p>
<h4 id="2-2-2-异步-RPC-调用编程模型的优化"><a href="#2-2-2-异步-RPC-调用编程模型的优化" class="headerlink" title="2.2.2. 异步 RPC 调用编程模型的优化"></a>2.2.2. 异步 RPC 调用编程模型的优化</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Java8</code>的<code>CompletableFuture</code>提供了非常丰富的异步功能，它可以帮助用户简化异步编程的复杂性，通过 <code>Lambda</code> 表达式可以方便的编写异步回调逻辑，除了普通的异步回调接口，它还提供了多个异步操作结果转换以及与或等条件表达式的编排能力，方便对多个异步操作结果进行逻辑编排。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>CompletableFuture</code> 提供了大约 20 类比较实用的异步 <code>API</code>，接口定义示例如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/95849ff159aa4e5fab446b56767a5a6a.jpg" alt="img"></p>
<p><em>CompletableFuture 异步 API 定义</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;利用 <code>JDK</code> 的 <code>CompletableFuture</code> 与 <code>Netty</code>的<code>NIO</code>，可以非常方便的实现异步<code>RPC</code>调用，设计思路如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/b0a3dc45e7998cb52c0dd2ecc4876364.jpg" alt="img"></p>
<p><em>异步 RPC 调用设计原理</em></p>
<p>异步<code>RPC</code> 调用的工作流程如下：</p>
<p>1．消费者通过 <code>RPC</code> 框架调用服务端。</p>
<p>2．<code>Netty</code> 异步发送 <code>HTTP</code> 请求消息，如果没有发生 <code>I/O</code> 异常就正常返回。</p>
<p>3．<code>HTTP</code> 请求消息发送成功后，<code>I/O</code>线程构造<code>CompletableFuture</code>对象，设置到<code>RPC</code> 上下文中。</p>
<p>4．用户线程通过 <code>RPC</code>上下文获取 <code>CompletableFuture</code> 对象。</p>
<p>5．不阻塞用户线程，立即返回 <code>CompletableFuture</code> 对象。</p>
<p>6．通过 <code>CompletableFuture</code> 编写 <code>Function</code> 函数，在<code>Lambda</code> 表达式中实现异步回调逻辑。</p>
<p>7．服务端返回 <code>HTTP</code> 响应，<code>Netty</code>负责反序列化工作。</p>
<p>8．<code>Netty I/O</code> 线程通过调用 <code>CompletableFuture</code>的 <code>complete</code> 方法将应答设置到 <code>CompletableFuture</code>对象的操作结果中。</p>
<p>9．<code>CompletableFuture</code> 通过 <code>whenCompleteAsync</code>等接口异步执行业务回调逻辑，实现 <code>RPC</code>调用的异步化。</p>
<h4 id="2-2-3-异步-RPC-调用的优势"><a href="#2-2-3-异步-RPC-调用的优势" class="headerlink" title="2.2.3. 异步 RPC 调用的优势"></a>2.2.3. 异步 RPC 调用的优势</h4><p>异步 <code>RPC</code>调用相比于同步调用有两个优点：</p>
<p>1．<strong>化串行为并行，提升 <code>RPC</code> 调用效率，减少业务线程阻塞时间</strong>。</p>
<p>2．<strong>化同步为异步，避免业务线程阻塞</strong>。</p>
<p>假如一次阅读首页访问需要调用多个服务接口，采用同步调用方式，它的调用流程如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/f34b635ed43044a4263a4ae692091f0e.jpg" alt="img"></p>
<p><em>同步调用多个服务场景</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于每次 <code>RPC</code> 调用都是同步阻塞，三次调用总耗时为<code>T = T1 + T2 + T3</code>。下面看下采用异步 <code>RPC</code> 调用之后的优化效果：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/ec362863844fc2af99392a1f268dc174.jpg" alt="img"></p>
<p><em>异步多服务调用场景</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;采用异步 <code>RPC</code>调用模式，最后调用三个异步操作结果 <code>Future</code>的 <code>get</code>方法同步等待应答，它的总执行时间 <code>T = Max(T1, T2,T3)</code>，相比于同步 <code>RPC</code>调用，性能提升效果非常明显。</p>
<h3 id="2-3-总结"><a href="#2-3-总结" class="headerlink" title="2.3. 总结"></a>2.3. 总结</h3><h4 id="2-3-1-异步-RPC-调用性能未必会更高"><a href="#2-3-1-异步-RPC-调用性能未必会更高" class="headerlink" title="2.3.1. 异步 RPC 调用性能未必会更高"></a>2.3.1. 异步 RPC 调用性能未必会更高</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常在实验室环境中测试，由于网络时延小、模拟业务又通常比较简单，所以异步 <code>RPC</code>调用并不一定性能更高，但在生产环境中，异步 <code>RPC</code> 调用往往性能更高、可靠性也更好。主要原因是网络环境相对恶劣、真实的 <code>RPC</code>调用耗时更多等，这种恶劣的运行环境正好可以发挥异步<code>RPC</code> 调用的优势。</p>
<h4 id="2-3-2-最佳实践"><a href="#2-3-2-最佳实践" class="headerlink" title="2.3.2. 最佳实践"></a>2.3.2. 最佳实践</h4><p>服务框架支持多种 <code>RPC</code> 调用方式，在实际项目中如何选择呢？建议从以下几个角度进行考虑：</p>
<p>1．降低业务<code>E2E</code> 时延：业务调用链是否太长、某些服务是否不太可靠，需要对服务调用流程进行梳理，看是否可以通过异步并行 <code>RPC</code>调用来提升调用效率，降低 <code>RPC</code> 调用时延。</p>
<p>2．可靠性角度：某些业务调用链上的关键服务不太可靠，一旦出故障会导致大量线程资源被挂住，可以考虑使用异步<code>RPC</code> 调用防止故障扩散。</p>
<p>3．传统的 <code>RPC</code> 调用：服务调用比较简单，对时延要求不高的场景，则可以考虑同步<code>RPC</code>调用，降低编程复杂度，以及调试难度，提升开发效率。</p>
<h2 id="3-异步-RPC-调用的应用场景"><a href="#3-异步-RPC-调用的应用场景" class="headerlink" title="3. 异步 RPC 调用的应用场景"></a>3. 异步 RPC 调用的应用场景</h2><h3 id="3-1-缩短长流程的调用时延"><a href="#3-1-缩短长流程的调用时延" class="headerlink" title="3.1 缩短长流程的调用时延"></a>3.1 缩短长流程的调用时延</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随着业务分布式架构的发展，系统间的系统调用日趋复杂，以电商的商品购买为例，前台界面的购买操作涉及到底层上百次服务调用，形成复杂的调用链，示例如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/729b0bfcb66d1349b6e53017c9ebd769.jpg" alt="img"></p>
<p><em>分布式消息调用链</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>对于一些逻辑上不存在互相依赖关系的服务，可以通过异步 <code>RPC</code> 调用，实现服务的并行调用，通过并行调用来降低服务调用总耗时</strong>，以手游购买道具流程为例，消费次数限制鉴权、账户余额鉴权和下载记录鉴权三个服务可以通过异步的方式并行调用，来降低游戏道具购买的耗时：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/a2bdcac2de3d0c927356e67bac75f640.jpg" alt="img"></p>
<p><em>购买道具异步 RPC 调用流程</em></p>
<h3 id="3-2-服务调用耗时波动较大场景"><a href="#3-2-服务调用耗时波动较大场景" class="headerlink" title="3.2 服务调用耗时波动较大场景"></a>3.2 服务调用耗时波动较大场景</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于一些业务场景，服务调用耗时与消息本身、调用的资源对象有关系，例如上传和下载接口，如果下载的资源较多则耗时就会相应的增加。对于这类场景，接口的调用超时时间比较难配置，如果配置过大，服务端自身响应慢之后会拖垮调用方，如果配置过小，万一遇到一个需要较长耗时的 <code>RPC</code> 调用就会超时。通过异步<code>RPC</code> 调用，就不用再担心调用方业务线程被阻塞，超时时间可以相应配置大一些，减少超时导致的失败。</p>
<h3 id="3-3-第三方接口调用"><a href="#3-3-第三方接口调用" class="headerlink" title="3.3 第三方接口调用"></a>3.3 第三方接口调用</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于大部分的第三方服务调用，都需要采用防御性编程，防止因为第三方故障导致自身不能正常工作。如果采用同步 <code>RPC</code> 方式调用第三方服务，一旦第三方服务的处理耗时增加，就会导致客户端调用线程被阻塞，当超时时间配置不合理时，系统很容易被阻塞。通过异步化的 <code>RPC</code> 调用，可以防止被第三方服务端阻塞，<code>Hystrix</code>的第三方故障隔离就是采用类似机制，只不过它底层创建了线程池，通过<code>Hystrix</code> 的线程池将第三方服务调用与业务线程做了隔离，实现了非侵入式的故障隔离。</p>
<h3 id="3-4-性能和资源利用率提升"><a href="#3-4-性能和资源利用率提升" class="headerlink" title="3.4 性能和资源利用率提升"></a>3.4 性能和资源利用率提升</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于一个同步串行化调用的系统，大量的业务线程都在等待服务端返回响应，系统的 <code>CPU</code>使用率很低，但是性能却无法有效提升，这个问题几乎是所有采用同步 <code>RPC</code> 调用的业务都遇到的一个通病。要想充分利用<code>CPU</code> 资源，需要让业务线程尽可能的跑满<code>CPU</code>，而不是经常性的处于同步等待状态。采用异步 <code>RPC</code>调用之后，在单位时间内业务线程可以接收并处理更多的请求消息，更充分的利用 <code>CPU</code> 资源，提升系统的吞吐量。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据一些公开的测试数据，一些业务采用异步 <code>RPC</code> 替换同步 <code>RPC</code>调用之后，综合性能提升 2-3 倍 +。</p>
<h2 id="4-异步-RPC-调用实践"><a href="#4-异步-RPC-调用实践" class="headerlink" title="4. 异步 RPC 调用实践"></a>4. 异步 RPC 调用实践</h2><h3 id="4-1-Tomcat-Servlet3-X-的异步化"><a href="#4-1-Tomcat-Servlet3-X-的异步化" class="headerlink" title="4.1 Tomcat + Servlet3.X 的异步化"></a>4.1 Tomcat + Servlet3.X 的异步化</h3><h4 id="4-1-1-工作原理"><a href="#4-1-1-工作原理" class="headerlink" title="4.1.1 工作原理"></a>4.1.1 工作原理</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>Servlet</code> 异步是指 <code>Servlet 3</code>规范中提供了对异步处理<code>Servlet</code>请求的支持，可以把<code>HTTP</code>协议处理线程和业务逻辑执行线程隔离开</strong>：</p>
<p>1．<code>Servlet3.0</code> 对异步的支持：<code>Servlet3</code> 之前一个 <code>HTTP</code> 请求消息的处理流程，包括：<code>HTTP</code> 请求消息的解析、<code>Read Body</code>、<code>Response Body</code>，以及后续的业务逻辑处理都是由 <code>Tomcat</code> 线程池中的工作线程处理。<strong><code>Servlet3</code> 之后可以让 <code>I/O</code>线程和业务处理线程分开，进而对业务做隔离和异步化处理</strong>。<strong>还可以根据业务重要性进行业务分级，同时把业务线程池分类，实现业务的优先级处理，隔离核心业务和普通业务，提升应用可靠性</strong>。</p>
<p>2．<code>Servlet3.1</code>对非阻塞<code>I/O</code>的支持：<code>Servlet3.1</code>以后增加了对非阻塞<code>I/O</code> 的支持，根据<code>Servlet3.1</code>规范中描述：非阻塞 <code>I/O</code> 仅对在 <code>Servlet</code> 中的异步处理请求有效，否则，当调用 <code>ServletInputStream.setReadListener 或 ServletOutputStream.setWriteListener</code> 方法时抛出 <code>IllegalStateException</code>异常。<code>Servlet3.1</code> 对非阻塞<code>I/O</code> 的支持是对之前异步化版本的增强，配套 <code>Tomcat8.X</code>版本。</p>
<p><code>Tomcat + Servlet3</code>的异步化处理原理如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/6d47236b4adffeb9683680f125f35ed6.jpg" alt="img"></p>
<p><em>Tomcat + Servlet3 异步处理原理</em></p>
<h4 id="4-1-2-异步化处理流程"><a href="#4-1-2-异步化处理流程" class="headerlink" title="4.1.2 异步化处理流程"></a>4.1.2 异步化处理流程</h4><p>关键处理流程如下：</p>
<p>1．声明 <code>Servlet</code>，增加 <code>asyncSupported</code> 属性，开启异步支持，例如 ：<code>@WebServlet(urlPatterns=“/AsyncLongRunningServlet”,asyncSupported=true)</code>。</p>
<p>2．通过 <code>request</code> 获取异步上下文<code>AsyncContext</code>， <code>AsyncContext context = request.startAsync()</code>, 相关接口定义如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/76fdc10dade77f4e9015090c4bb978b7.jpg" alt="img"></p>
<p>3．启动业务逻辑处理线程，并将 <code>AsyncContext</code>对象传递给业务线程。例如：<code>Executor.execute(()-&gt;{context, request, response…})</code>。</p>
<p>4．在业务线程中，通过获取 <code>request</code> 进行业务逻辑处理，完成之后填充 <code>response</code> 对象。</p>
<p>5．业务逻辑处理完成之后，调用 <code>AsyncContext</code>的 <code>complete()</code>方法完成响应消息的发送。</p>
<h3 id="4-2-Spring-MVC-异步化"><a href="#4-2-Spring-MVC-异步化" class="headerlink" title="4.2 Spring MVC 异步化"></a>4.2 Spring MVC 异步化</h3><h4 id="4-2-1-工作原理"><a href="#4-2-1-工作原理" class="headerlink" title="4.2.1 工作原理"></a>4.2.1 工作原理</h4><p><code>SpringMVC 3.2+</code> 版本基于<code>Servlet3</code>做了封装，以简化业务使用。它的工作原理如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/f296a43d4981071c53f8e35bbce28f90.jpg" alt="img"></p>
<p><em>SpringMVC 异步工作原理</em></p>
<h4 id="4-2-2-异步的几种实现方式"><a href="#4-2-2-异步的几种实现方式" class="headerlink" title="4.2.2 异步的几种实现方式"></a>4.2.2 异步的几种实现方式</h4><p><code>SpringMVC</code>支持多种异步化模式，常用的有两种：</p>
<p>1．<code>Controller</code> 的返回值为 <code>DeferredResult</code>，在业务<code>Controller</code>方法中构造 <code>DeferredResult</code>对象，然后将请求封装成 <code>Task</code> 投递到业务线程池中异步执行，业务执行完成之后，构造 <code>ModelAndView</code>，调用 <code>deferredResult.setResult(ModelAndView)</code>完成异步化处理和响应消息的发送。</p>
<p>2．<code>Controller</code> 的返回值为 <code>WebAsyncTask</code>，实现<code>Callable</code>, 在 <code>call</code> 方法中完成业务逻辑处理，由 <code>SpringMVC</code> 框架的线程池来异步执行业务逻辑（非 <code>Tomcat</code>工作线程）。</p>
<p>以 <code>DeferredResult</code>为例，它的异步处理流程如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/80c2e301535a3d81922ecae76856be0a.jpg" alt="img"></p>
<p><em>SpringMVC DeferredResult 工作原理</em></p>
<h3 id="4-3-Apache-ServiceComb-的异步化服务调用"><a href="#4-3-Apache-ServiceComb-的异步化服务调用" class="headerlink" title="4.3 Apache ServiceComb 的异步化服务调用"></a>4.3 Apache ServiceComb 的异步化服务调用</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Apache ServiceComb</code>是一个开箱即用、高性能、兼容流行生态、支持多语言的一站式开源微服务解决方案。它同时支持同步和异步服务调用，下面一起分析下它的异步化服务调用机制。</p>
<h4 id="4-3-1-纯-Reactive-模式"><a href="#4-3-1-纯-Reactive-模式" class="headerlink" title="4.3.1 纯 Reactive 模式"></a>4.3.1 纯 Reactive 模式</h4><p>纯 <code>Reactive</code>模式的特点是：</p>
<p>1．异步化接口，消费端不需要同步等待服务提供端返回响应，不会产生阻塞。</p>
<p>2．与传统流程不同的，所有功能都在 <code>eventloop</code> 中执行，并不会进行线程切换。</p>
<p>3．只要有任务，线程就不会停止，会一直执行任务，可以充分利用 <code>cpu</code>资源，也不会产生多余的线程切换，去无谓地消耗 <code>cpu</code>。</p>
<p>它的处理流程如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/e64c6dd0a374a8e23f17c60650354c8a.jpg" alt="img"></p>
<p><em>ServiceComb 的 Reactive 工作模式</em></p>
<p>关键流程解读：</p>
<p>1．异步：橙色箭头走完后，对本线程的占用即完成了，不会阻塞等待应答，该线程可以处理其他任务。</p>
<p>2．当收到远端应答后，由网络数据驱动开始走红色箭头的应答流程。</p>
<p>对应的代码示例如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/c865a24d7496f09f93681d0fd37398fa.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过代码示例可以看出，<code>ServiceComb</code> 的 <code>Reactive</code> 工作模式采用了<code>JDK8</code> 的 <code>CompletableFuture</code>作为异步编程模型，利用 <code>CompletableFuture</code>可以方便的对多个异步操作结果做编排，以及做级联异步操作，功能强大，使用灵活。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;纯<code>Reactive</code>模式的使用约束：所有在 <code>eventloop</code> 中执行的逻辑，不允许有任何的阻塞动作，包括不限于 <code>wait</code>、<code>sleep</code>、巨大循环、同步查询 DB 等等。实际上就是如果业务的微服务采用了 <code>Reactive</code>，则需要做全栈异步，否则会阻塞 <code>eventloop</code>线程，导致消息收发出现问题。如果业务的微服务想做异步化，但是由于数据库、缓存等原因无法实现全栈异步，则可以采用后面介绍的混合 <code>Reactive</code> 模式。</p>
<h4 id="4-3-2-混合-Reactive-模式"><a href="#4-3-2-混合-Reactive-模式" class="headerlink" title="4.3.2 混合 Reactive 模式"></a>4.3.2 混合 Reactive 模式</h4><p>混合 <code>Reactive</code> 模式的实现策略如下：</p>
<p>1．服务端接口返回值为<code>CompletableFuture</code>，这样采用透明 <code>RPC</code>调用时就可以实现异步化。</p>
<p>2．对于可能产生同步阻塞的业务逻辑代码，采用独立线程池的方式进行处理，防止阻塞平台的<code>eventloop</code>线程。</p>
<p>混合 <code>Reactive</code> 模式与纯<code>Reactive</code> 模式相比，主要有两点差异：</p>
<p>1．存在线程切换。</p>
<p>2．可能导致同步阻塞的业务逻辑放到独立的线程池中执行，纯 <code>Reactive</code>模式所有业务逻辑都在 <code>eventloop</code> 线程中执行（与 <code>I/O</code> 线程相同）。</p>
<p>它的处理流程如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/b24c1b854726e12f3d42884a4a3d1880.jpg" alt="img"></p>
<p><em>ServiceComb 的混合 Reactive 工作模式</em></p>
<h4 id="4-3-3-异步模式的几个特点"><a href="#4-3-3-异步模式的几个特点" class="headerlink" title="4.3.3 异步模式的几个特点"></a>4.3.3 异步模式的几个特点</h4><p>相比于其它的微服务框架（<code>RPC</code>框架），<code>ServiceComb</code> 的 <code>Reactive</code> 有如下几个特点：</p>
<p>对于微服务提供端：</p>
<p>1．<code>producer</code>是否使用<code>reactive</code>与 <code>consumer</code> 如何调用，没有任何联系。</p>
<p>2．当<code>operation</code> 返回值为 <code>CompletableFuture</code> 类型时，默认此 <code>operation</code> 工作于<code>reactive</code> 模式，此时如果需要强制此 <code>operation</code>工作于线程池模式，需要在微服务的配置文件中（<code>microservice.yaml</code>）中明确配置，指定业务线程池。这样业务逻辑的执行就可以由 <code>eventloop</code>线程（<code>I/O</code> 线程）切换到业务线程。</p>
<p>对于微服务消费端：</p>
<p>1．<code>consumer</code> 是否使用 <code>reactive</code> 与 <code>producer</code>如何实现，没有任何联系。</p>
<p>2．当前只支持透明 <code>RPC</code>模式，使用 <code>JDK</code>原生的 <code>CompletableFuture</code>来承载此功能<code>ompletableFuture</code> 的 <code>when</code>、<code>then</code> 等等功能都可直接使用。</p>
<p>对于 <code>ServiceComb</code>，无论服务端定义的接口是同步还是异步的，消费端都可以采用异步的方式调用它，对具体细节感兴趣的读者可以到 <code>ServiceComb</code> 官网下载 <code>Demo</code>示例学习。</p>
<h4 id="4-3-4-I-O-线程和业务线程的交互优化"><a href="#4-3-4-I-O-线程和业务线程的交互优化" class="headerlink" title="4.3.4 I/O 线程和业务线程的交互优化"></a>4.3.4 I/O 线程和业务线程的交互优化</h4><p><code>ServiceComb</code> 微服务的完整线程模型如下图所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/6c2f4793e2c851eeb22b26a1de30b374.jpg" alt="img"></p>
<p><em>I/O 线程和业务线程交互</em></p>
<p><code>ServiceComb</code>通过线程绑定技术来减少锁竞争，提升性能：</p>
<p>1．业务线程在第一次调用时会绑定某一个网络线程, 避免在不同网络线程之间切换, 无谓地增加线程冲突的概率。</p>
<p>2．业务线程绑定网络线程后, 会再绑定该网络线程内部的某个连接, 同样是为了避免线程冲突。</p>
<h3 id="4-4-gRPC-的异步化"><a href="#4-4-gRPC-的异步化" class="headerlink" title="4.4 gRPC 的异步化"></a>4.4 gRPC 的异步化</h3><p><code>gRPC</code> 的服务调用有三种方式：</p>
<ol>
<li><p>同步阻塞式服务调用，通常实现类是 <code>xxxBlockingStub</code>（基于 <code>proto</code> 定义生成）。</p>
</li>
<li><p>异步非阻塞调用，基于 <code>Future-Listener</code>机制，通常实现类是 <code>xxxFutureStub</code>。</p>
</li>
<li><p>异步非阻塞调用，基于 <code>Reactive</code> 的响应式编程模式，通常实现类是 <code>xxxStub</code>。</p>
</li>
</ol>
<h4 id="4-4-1-基于-Future-的异步-RPC-调用"><a href="#4-4-1-基于-Future-的异步-RPC-调用" class="headerlink" title="4.4.1 基于 Future 的异步 RPC 调用"></a>4.4.1 基于 Future 的异步 RPC 调用</h4><p>业务调用代码示例如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/cd437e10d1647116046349a25770936a.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;调用 <code>GreeterFutureStub</code>的 <code>sayHello</code>方法返回的不是应答，而是<code>ListenableFuture</code>，它继承自<code>JDK</code> 的<code>Future</code>，接口定义如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/bf6b77e30f672c245159cf914fe70e17.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将 <code>ListenableFuture</code>加入到 <code>gRPC</code> 的<code>Future</code>列表中，创建一个新的 <code>FutureCallback</code>对象，当 <code>ListenableFuture</code>获取到响应之后，<code>gRPC</code> 的<code>DirectExecutor</code> 线程池会调用新创建的<code>FutureCallback</code>，执行 <code>onSuccess</code> 或者 <code>onFailure</code>，实现异步回调通知。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接着我们分析下 <code>ListenableFuture</code>的实现原理，<code>ListenableFuture</code>的具体实现类是<code>GrpcFuture</code>，代码如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/cb6cc56b85ccf4cc1e3a9a28f94512f1.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;获取到响应之后，调用 <code>complete</code> 方法：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/9900c9e3f07e3e1238ac3b68a9762746.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将 <code>ListenableFuture</code> 加入到<code>Future</code> 列表中之后，同步获取响应（在 <code>gRPC</code> 线程池中阻塞，非业务调用方线程）：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/6a0642ea70bc9db39180527529247553.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;获取到响应之后，回调<code>callback</code> 的<code>onSuccess</code>，代码如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/715a0b31f985528326fe58461e8163ec.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了将 <code>ListenableFuture</code> 加入到 <code>Futures</code>中由 <code>gRPC</code>的线程池执行异步回调，也可以自定义线程池执行异步回调，代码示例如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/b694ad13d4e3422cdb0a25cc70d48ef4.jpg" alt="img"></p>
<h4 id="4-4-2-Reactive-风格异步-RPC-调用"><a href="#4-4-2-Reactive-风格异步-RPC-调用" class="headerlink" title="4.4.2.Reactive 风格异步 RPC 调用"></a>4.4.2.Reactive 风格异步 RPC 调用</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;业务调用代码示例如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/0c4b08aa24c4e3a09d2228973dedb1e3.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;构造响应 <code>StreamObserver</code>，通过响应式编程，处理正常和异常回调，接口定义如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/2f6a62e6364710f7b3523a144121eb3b.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将响应<code>StreamObserver</code>作为入参传递到异步服务调用中，该方法返回空，程序继续向下执行，不阻塞当前业务线程，代码如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/ad447c073351677aec338df85672908d.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面分析下基于<code>Reactive</code> 方式异步调用的代码实现，把响应<code>StreamObserver</code>对象作为入参传递到异步调用中，代码如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/0c3e00d9e843fcc8f44b5bc9ae0a4106.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当收到响应消息时，调用 <code>StreamObserver</code>的 <code>onNext</code>方法，代码如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/f5c65e298e54a2e509e33f97bfcf6c6e.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当 <code>Streaming</code> 关闭时，调用 <code>onCompleted</code>方法，如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/7fdb5d12ab83b23a02233ff074fbac0c.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过源码分析可以发现，<code>Reactive</code> 风格的异步调用，相比于 <code>Future</code>模式，没有任何同步阻塞点，无论是业务线程还是 <code>gRPC</code>框架的线程都不会同步等待，相比于 <code>Future</code>异步模式，<code>Reactive</code>风格的调用异步化更彻底一些。</p>
<h4 id="4-4-3-异步双向-streaming-调用"><a href="#4-4-3-异步双向-streaming-调用" class="headerlink" title="4.4.3 异步双向 streaming 调用"></a>4.4.3 异步双向 streaming 调用</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>gRPC</code> 的通信协议基于标准的<code>HTTP/2</code>设计，除了普通的<code>RPC</code> 调用，还支持<code>streaming</code>调用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端发送 N 个请求，服务端返回 N 个或者 M 个响应，利用该特性，可以充分利用 <code>HTTP/2.0</code> 的多路复用功能，在某个时刻，<code>HTTP/2.0</code> 链路上可以既有请求也有响应，实现了全双工通信（对比单行道和双向车道），示例如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/6481ceac00add9c3ac856b6449229d53.jpg" alt="img"></p>
<p><em>双向 streaming 模式</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>proto</code> 文件定义如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/6bd15f0ddb8fe301f9b91cb1c41005fc.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;业务代码示例如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/d28809c57d6cbc7716fe47ec33b340db.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;构造<code>Streaming</code> 响应对象 <code>StreamObserver</code>并实现 <code>onNext</code>等接口，由于服务端也是<code>Streaming</code> 模式，因此响应是多个的，也就是说 <code>onNext</code> 会被调用多次。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过在循环中调用 <code>requestObserver</code> 的 <code>onNext</code>方法，发送请求消息，代码如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/84ac756179e0be71e28d75d0134d7a65.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>requestObserver</code>的 <code>onNext</code>方法实际调用了<code>ClientCall</code>的消息发送方法，代码如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/2a9870e1f8ae0f10f090655303dcc8a8.jpg" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于双向 <code>Streaming</code>模式，只支持异步调用方式。</p>
<h4 id="4-4-4-总结"><a href="#4-4-4-总结" class="headerlink" title="4.4.4 总结"></a>4.4.4 总结</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>gRPC</code> 服务调用支持同步和异步方式，同时也支持普通的<code>RPC</code>和<code>streaming</code> 模式，可以最大程度的满足业务的需求。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于 <code>streaming</code> 模式，可以充分利用 <code>HTTP/2.0</code> 协议的多路复用功能，实现在一条<code>HTTP</code> 链路上并行双向传输数据，有效的解决了 <code>HTTP/1.X</code>的数据单向传输问题，在大幅减少 <code>HTTP</code>连接的情况下，充分利用单条链路的性能，可以媲美传统的 <code>RPC</code> 私有长连接协议：更少的链路、更高的性能：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/a43acabba14b20385467dfe1c0327d69.jpg" alt="img"></p>
<p><em>传统 RPC 和双向 streaming 模式的对比</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>gRPC</code> 的网络<code>I/O</code>通信基于 <code>Netty</code>构建，服务调用底层统一使用异步方式，同步调用是在异步的基础上做了上层封装。因此，<code>gRPC</code> 的异步化是比较彻底的，对于提升<code>I/O</code>密集型业务的吞吐量和可靠性有很大的帮助。</p>
<h2 id="5-异步化的一些技术难点"><a href="#5-异步化的一些技术难点" class="headerlink" title="5. 异步化的一些技术难点"></a>5. 异步化的一些技术难点</h2><h4 id="5-1-1-异步异常传递"><a href="#5-1-1-异步异常传递" class="headerlink" title="5.1.1 异步异常传递"></a>5.1.1 异步异常传递</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当采用异步编程之后，异步抛出的异常传递给调用方会变得非常困难，例如 <code>Runnable</code>, 当异步执行它时，异常需要在<code>run</code> 方法中捕获和处理，否则会导致线程跑飞，<code>run</code>方法中的异常是无法回传到调用方的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用<code>JDK8</code> 的 <code>CompletableFuture</code>之后，它的常用方法参数基本是 <code>Lambda</code>表达式，由于函数接口中的方法通常不允许检查期异常，在表达式中发生的异常无法回传给调用方，相比于以前同步调用可以将异常抛给调用方处理的方式有很大差异。</p>
<p>异步异常的解决策略：</p>
<p>1．如果异步的编程模型基于<code>JDK8</code>的 <code>CompletableFuture</code>，可以通过 <code>whenComplete</code>对返回值的异常进行非空判断，当异常非空时，进行异常逻辑处理，相关接口如下：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/504aa872a5921e2ef1be6d9aab28c58e.jpg" alt="img"></p>
<p>也可以通过<code>exceptionally</code>方法来处理异步执行发生的异常，相关接口如下所示：</p>
<p><img src="//blog.com/2019/07/27/深入剖析通信层和 RPC 调用的异步化/5eb1704acefff6f8ff8e4cee99463988.jpg" alt="img"></p>
<p>2．异步回调（<code>Lambda</code> 表达式）代码块中的异常处理有两种策略：</p>
<p>1）一定要通过 <code>exceptionally</code>方法或者 <code>whenComplete</code>对异常进行捕获处理，否则会导致<code>Lambda</code> 表达式异常退出，后续操作被忽略，最终导致业务逻辑跑飞。</p>
<p>2）运行期异常，通常是无法抛出来由调用方处理的，需要在发生异常的地方就地捕获和处理。</p>
<h4 id="5-1-2-超时控制"><a href="#5-1-2-超时控制" class="headerlink" title="5.1.2 超时控制"></a>5.1.2 超时控制</h4><p>异步代码块（<code>Lambda</code> 表达式）中可能会涉及到多种业务逻辑操作，例如：</p>
<p>1．<strong>数据库、缓存、<code>MQ</code>等中间件平台调用</strong>。</p>
<p>2．<strong>第三方接口调用</strong>。</p>
<p>3．<strong>级联嵌套其它微服务调用</strong>。</p>
<p>对于异步的超时控制，建议策略如下：</p>
<p>1．对单个原子的中间件、第三方接口、微服务做超时控制。</p>
<p>2．不建议直接对异步代码块（<code>Lambda</code> 表达式）整体做超时控制，例如包装出一个支持异步超时的<code>CompletableFuture</code>，主要原因如下：</p>
<ol>
<li>超时并不能确保中断当前正在执行的业务逻辑，例如同步 <code>Redis</code> 缓存调用。</li>
<li>如果超时发生时，正好又发起了一次异步 <code>RPC</code> 调用，创建了一个新的 <code>CompletableFuture</code>，外层超时之后，已经创建的 <code>CompletableFuture</code>异步回调仍然可能会被执行，这会带来各种混乱。</li>
<li>由于异步代码块（<code>Lambda</code>表达式）中的业务逻辑可能会非常复杂，所以超时之后的补偿操作非常困难。例如充值操作已经成功了，但是外层调用方超时失败了，这会给后续业务的处理带来很多困难，因为超时发生时调用方并不知道异步代码块中的哪些操作被执行，哪些没被执行。</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;没有超时控制之后，要确保 <code>CompletableFuture</code>能够正常或者异常的结束，否则会导致 <code>CompletableFuture</code> 积压，最终发生 <code>OOM</code>。</p>
<h4 id="5-1-3-上下文传递"><a href="#5-1-3-上下文传递" class="headerlink" title="5.1.3 上下文传递"></a>5.1.3 上下文传递</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在传统的同步 <code>RPC</code>调用时，业务往往通过线程变量来传递上下文，例如：<code>TraceID</code>、会话 <code>Session</code>、<code>IP</code>等信息。异步化之后，由于潜在的线程切换和线程被多个消息交叉复用，通常不建议继续使用线程变量传递上下文。</p>
<p>异步化之后，上下文传递的建议策略：</p>
<p>1．如果是 <code>Lambda</code> 表达式，可以直接引用局部变量，通过变量引用的方式将上下文信息传递到<code>Lambda</code>表达式中，后续可以通过方法传参等层层传递下去。</p>
<p>2．在所有发生线程切换的地方，显式的进行上下文信息的拷贝和清理，特别需要注意的是隐式线程切换，例如 <code>Hystrix</code>，底层会自己启线程池。</p>
<p>3．建议通过调用级的消息上下文来做参数传递，每个上下文都关联一次 <code>RPC</code> 调用，调用完成之后自动清理掉。</p>
<p>4．异步化之后，需要排重点查所有使用 <code>ThreadLocal</code>的地方，通常情况下都会存在问题，需要做改造。</p>
<h4 id="5-1-4-异步回调地狱问题"><a href="#5-1-4-异步回调地狱问题" class="headerlink" title="5.1.4 异步回调地狱问题"></a>5.1.4 异步回调地狱问题</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果使用的是<code>JDK8</code>的 <code>CompletableFuture</code>，它支持对异步操作结果做编排以及级联操作，能够比较好的解决类似 <code>JS</code> 和传统<code>Future-Listener</code>的回调地域问题，感兴趣的读者可以体会下 <code>CompletableFuture</code>的异步化接口。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/22/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><span class="page-number current">23</span><a class="page-number" href="/page/24/">24</a><span class="space">&hellip;</span><a class="page-number" href="/page/147/">147</a><a class="extend next" rel="next" href="/page/24/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">刘泽明</p>
              <p class="site-description motion-element" itemprop="description">做一个懂业务的程序员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">731</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">394</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">237</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘泽明</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
