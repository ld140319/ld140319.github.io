<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="搬运工 + 践行者" type="application/atom+xml">






<meta name="description" content="做一个懂业务的程序员">
<meta property="og:type" content="website">
<meta property="og:title" content="搬运工 + 践行者">
<meta property="og:url" content="http://blog.com/page/113/index.html">
<meta property="og:site_name" content="搬运工 + 践行者">
<meta property="og:description" content="做一个懂业务的程序员">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="搬运工 + 践行者">
<meta name="twitter:description" content="做一个懂业务的程序员">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.com/page/113/">





  <title>搬运工 + 践行者</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">搬运工 + 践行者</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">记录学习的技能和遇到的问题</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/23/Innodb中mysql如何快速删除2T的大表/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/23/Innodb中mysql如何快速删除2T的大表/" itemprop="url">Innodb中mysql如何快速删除2T的大表</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-23T12:12:57+08:00">
                2019-03-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/MySql/" itemprop="url" rel="index">
                    <span itemprop="name">MySql</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Innodb中mysql如何快速删除2T的大表"><a href="#Innodb中mysql如何快速删除2T的大表" class="headerlink" title="Innodb中mysql如何快速删除2T的大表"></a>Innodb中mysql如何快速删除2T的大表</h1><blockquote>
<p>原文地址：<a href="https://www.cnblogs.com/rjzheng/p/9497109.html" target="_blank" rel="noopener">https://www.cnblogs.com/rjzheng/p/9497109.html</a></p>
</blockquote>
<h3 id="小漫画"><a href="#小漫画" class="headerlink" title="小漫画"></a>小漫画</h3><p>来，先来看小漫画陶冶一下情操<br><img src="//blog.com/2019/03/23/Innodb中mysql如何快速删除2T的大表/o_manhua1.jpg" alt="img"><br>&nbsp;&nbsp;&nbsp;&nbsp;OK，这里就说了。假设，你有一个表<code>erp</code>,如果你直接进行下面的命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop table erp</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这个时候所有的mysql的相关进程都会停止，直到<code>drop</code>结束，mysql才会恢复执行。出现这个情况的原因就是因为，在<code>drop table</code>的时候，<code>innodb</code>维护了一个全局锁，<code>drop</code>完毕锁就释放了。这意味着，如果在白天，访问量非常大的时候，如果你在不做任何处理措施的情况下，执行了删大表的命令，整个<code>mysql</code>就挂在那了，在删表期间，<code>QPS</code>会严重下滑，然后产品经理就来找你喝茶了。所以才有了漫画中的一幕，<strong>你可以在晚上十二点，夜深人静的时候再删</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;当然，有的人不服，可能会说：”<strong>你可以写一个删除表的存储过程，在晚上没啥访问量的时候运行一次就行。</strong>“<br>我内心一惊，细想一下，只能说：”大家还是别抬杠了，还是听我说一下业内通用做法。”</p>
<h3 id="一个假设"><a href="#一个假设" class="headerlink" title="一个假设"></a>一个假设</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;先说明一下，在这里有一个前提，mysql开启了<strong>独立表空间</strong>，MySQL5.6.7之后默认开启。<br>也就是在<code>my.cnf</code>中，有这么一条配置(这些是属于mysql优化的知识，后期给大家介绍)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">innodb_file_per_table = 1</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;查看表空间状态，用下面的命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &apos;%per_table&apos;;  </span><br><span class="line">+-----------------------+-------+  </span><br><span class="line">| Variable_name         | Value |  </span><br><span class="line">+-----------------------+-------+  </span><br><span class="line">| innodb_file_per_table | OFF   |  </span><br><span class="line">+-----------------------+-------+</span><br></pre></td></tr></table></figure>
<p>如果<code>innodb_file_per_table</code>的<code>value</code>值为<code>OFF</code>，代表采用的是<strong>共享表空间</strong>。<br>如果<code>innodb_file_per_table</code>的<code>value</code>值为<code>ON</code> ，代表采用的是<strong>独立表空间</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;于是，大家要问我，<strong>独立表空间</strong>和<strong>共享表空间</strong>的区别？<br><strong>共享表空间</strong>：某一个数据库的所有的表数据，索引文件全部放在一个文件中，默认这个共享表空间的文件路径在data目录下。 默认的文件名为:ibdata1(此文件，可以扩展成多个)。<strong>注意</strong>，在这种方式下，运维超级不方便。你看，所有数据都在一个文件里，要对单表维护，十分不方便。另外，你在做<code>delete</code>操作的时候，文件内会留下很多间隙，ibdata1文件不会自动收缩。换句话说，使用<strong>共享表空间</strong>来存储数据，会遭遇<code>drop table</code>之后，空间无法释放的问题。</p>
<p><strong>独立表空间</strong>:每一个表都以独立方式来部署，每个表都有一个.frm表描述文件，还有一个.ibd文件。<br><strong>.frm文件：</strong>保存了每个表的元数据，包括表结构的定义等，该文件与数据库引擎无关。<br><strong>.ibd文件：</strong>保存了每个表的数据和索引的文件。</p>
<p><strong>注意</strong>，在这种方式下，每个表都有自已独立的表空间，这样运维起来方便，可以实现单表在不同数据库之间的移动。另外，在执行<code>drop table</code>操作的时候，是可以自动回收表空间。在执行<code>delete</code>操作后，可以通过<code>alter table TableName engine=innodb</code>可以整理碎片，回收部分表空间。</p>
<p>ps：<code>my.cnf</code>中的<code>datadir</code>就是用来设置数据存储目录</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;好了，上面巴拉巴拉了一大堆，我只想说一个<strong>事情</strong>:</p>
<blockquote>
<p><strong>在绝大部分情况下，运维一定会为mysql选择独立表空间的存储方式，因为采用独立表空间的方式，从性能优化和运维难易角度来说，实在强太多。</strong></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;所以，我在一开始所提到的前提，mysql需要开启<strong>独立表空间</strong>。这个假设，百分九十的情况下是成立的。如果真的遇到了，你们公司的mysql采用的是<strong>共享表空间</strong>的情况，请你和你们家的运维谈谈心，问问为啥用<strong>共享表空间</strong>。</p>
<h3 id="正确姿势"><a href="#正确姿势" class="headerlink" title="正确姿势"></a>正确姿势</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;假设，我们有<code>datadir = /data/mysql/</code>,另外，我们有有一个<code>database</code>,名为<code>mytest</code>。在数据库<code>mytest</code>中，有一个表，名为<code>erp</code>，执行下列命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; system ls -l /data/mysql/mytest/</span><br></pre></td></tr></table></figure>
<p>得到下面的输出(我过滤了一下)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-rw-r----- 1 mysql mysql          9023  8 18 05:21 erp.frm</span><br><span class="line">-rw-r----- 1 mysql mysql 2356792000512  8 18 05:21 erp.ibd</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<code>frm</code>和<code>ibd</code>的作用，上面介绍过了。现在就是<code>erp.ibd</code>文件太大，所以删除卡住了。</p>
<p><strong>如何解决这个问题呢？</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这里需要利用了linux中<strong>硬链接</strong>的知识，来进行快速删除。下面容我上《鸟哥的私房菜》中的一些内容，<br><strong>软链接</strong>其实大家可以类比理解为windows中的快捷方式，就不多介绍了，主要介绍一下硬链接。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;至于这个<strong>硬链接</strong>，我简单说一下，不想贴一大堆话过来，看起来太累。<br>就是对于真正存储的文件来说，有一个<br><img src="//blog.com/2019/03/23/Innodb中mysql如何快速删除2T的大表/1.png" alt="image"><br>然后呢有一个<code>文件名</code>指向上面的<code>node Index</code><br><img src="//blog.com/2019/03/23/Innodb中mysql如何快速删除2T的大表/2.png" alt="image"><br>&nbsp;&nbsp;&nbsp;&nbsp;那么，所谓的<strong>硬链接</strong>，就是不止一个<code>文件名</code>指向<code>node Index</code>，有好几个<code>文件名</code>指向<code>node Index</code>。<br>假设，这会又有一个<code>文件名</code>指向上面的<code>node Index</code>，即<br><img src="//blog.com/2019/03/23/Innodb中mysql如何快速删除2T的大表/3.png" alt="image"><br>&nbsp;&nbsp;&nbsp;&nbsp;这个时候，你做了删除<code>文件名(1)</code>的操作，linux系统检测到，还有一个<code>文件名(2)</code>指向<code>node Index</code>，因此并不会真正的把文件删了，而是把<code>步骤(2)</code>的引用给删了，这步操作非常快，毕竟只是删除引用。于是图就变成了这样<br><img src="//blog.com/2019/03/23/Innodb中mysql如何快速删除2T的大表/4.png" alt="image"><br>&nbsp;&nbsp;&nbsp;&nbsp;接下来，你再做删除<code>文件名(2)</code>的操作，linux系统检测到，没有其他<code>文件名</code>指向该<code>node Index</code>，就会删除真正的存储文件，这步操作，是删真正的文件，所以比较慢。</p>
<p>OK，我们用的就是上面的原理。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;先给<code>erp.ibd</code>建立一个硬链接，利用<code>ln</code>命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; system ln /data/mysql/mytest/erp.ibd /data/mysql/mytest/erp.ibd.hdlk</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;此时，文件目录如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-rw-r----- 1 mysql mysql          9023  8 18 05:21 erp.frm</span><br><span class="line">-rw-r----- 2 mysql mysql 2356792000512  8 18 05:21 erp.ibd</span><br><span class="line">-rw-r----- 2 mysql mysql 2356792000512  8 18 05:21 erp.ibd.hdlk</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;你会发现，多了一个<code>erp.ibd.hdlk</code>文件，且<code>erp.ibd</code>和<code>erp.ibd.hdlk</code>的inode均为2。<br>此时，你执行<code>drop table</code>操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; drop table erp;</span><br><span class="line">Query OK, 0 rows affected (0.99 sec)</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;你会发现，不到1秒就删除了。因为，此时有两个文件名称(<code>erp.ibd</code>和<code>erp.ibd.hdlk</code>),同时指向一个inode.这个时候，执行删除操作，只是把引用给删了，所以非常快。<br>&nbsp;&nbsp;&nbsp;&nbsp;那么，这时的删除，已经把table从mysql中删除。但是磁盘空间，还没释放，因为还剩一个文件<code>erp.ibd.hdlk</code>。</p>
<p><strong>如何正确的删除erp.ibd.hdlk呢？</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;如果你没啥经验，一定会回答我，用<code>rm</code>命令来删。这里需要说明的是，在生产环境，直接用<code>rm</code>命令来删大文件，会造成磁盘IO开销飙升,CPU负载过高，是会影响其他程序运行的。<br>&nbsp;&nbsp;&nbsp;&nbsp;那么，这种时候，就是应该用<code>truncate</code>命令来删，<code>truncate</code>命令在<code>coreutils</code>工具集中。<br>详情，大家可以去百度一下，有人对<code>rm</code>和<code>truncate</code>命令，专程测试过，<code>truncate</code>命令对磁盘<code>IO，CPU</code>负载几乎无影响。<br>删除脚本如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TRUNCATE=/usr/local/bin/truncate</span><br><span class="line">for i in `seq 2194 -10 10 `; </span><br><span class="line">do </span><br><span class="line">  sleep 2</span><br><span class="line">  $TRUNCATE -s $&#123;i&#125;G /data/mysql/mytest/erp.ibd.hdlk </span><br><span class="line">done</span><br><span class="line">rm -rf /data/mysql/mytest/erp.ibd.hdlk ;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;从2194G开始，每次缩减10G，停2秒，继续，直到文件只剩10G，最后使用<code>rm</code>命令删除剩余的部分。</p>
<h3 id="其他情况"><a href="#其他情况" class="headerlink" title="其他情况"></a>其他情况</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;这里指的是，如果数据库是部署在windows上怎么办。这个问题，我来回答，其实不够专业。因为我出道以来，还没碰到过，生产环境上，mysql是部在windows上的。假设真的碰到了，windows下有一个工具叫<code>mklink</code>，是在windows下创建硬链接锁用，应该能完成类似功能</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/23/Redis分布式锁进化史/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/23/Redis分布式锁进化史/" itemprop="url">Redis分布式锁进化史</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-23T12:12:57+08:00">
                2019-03-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/分布式锁/" itemprop="url" rel="index">
                    <span itemprop="name">分布式锁</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/分布式锁/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Redis分布式锁进化史"><a href="#Redis分布式锁进化史" class="headerlink" title="Redis分布式锁进化史"></a>Redis分布式锁进化史</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;近两年来微服务变得越来越热门，越来越多的应用部署在分布式环境中，在分布式环境中，数据一致性是一直以来需要关注并且去解决的问题，分布式锁也就成为了一种广泛使用的技术，常用的分布式实现方式为Redis，Zookeeper，其中基于Redis的分布式锁的使用更加广泛。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;但是在工作和网络上看到过各个版本的Redis分布式锁实现，每种实现都有一些不严谨的地方，甚至有可能是错误的实现，包括在代码中，如果不能正确的使用分布式锁，可能造成严重的生产环境故障，本文主要对目前遇到的各种分布式锁以及其缺陷做了一个整理，并对如何选择合适的Redis分布式锁给出建议。</p>
<h1 id="各个版本的Redis分布式锁"><a href="#各个版本的Redis分布式锁" class="headerlink" title="各个版本的Redis分布式锁"></a>各个版本的Redis分布式锁</h1><h2 id="V1-0"><a href="#V1-0" class="headerlink" title="V1.0"></a>V1.0</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tryLock()&#123;  </span><br><span class="line">    SETNX Key 1</span><br><span class="line">    EXPIRE Key Seconds</span><br><span class="line">&#125;</span><br><span class="line">release()&#123;  </span><br><span class="line">  DELETE Key</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这个版本应该是最简单的版本，也是出现频率很高的一个版本，首先给锁加一个过期时间操作是为了避免应用在服务重启或者异常导致锁无法释放后，不会出现锁一直无法被释放的情况。</p>
<p>这&nbsp;&nbsp;&nbsp;&nbsp;个方案的一个问题<strong>在于每次提交一个Redis请求，如果执行完第一条命令后应用异常或者重启，锁将无法过期</strong>，一种改善方案就是<strong>使用Lua脚本（包含SETNX和EXPIRE两条命令），但是如果Redis仅执行了一条命令后crash或者发生主从切换，依然会出现锁没有过期时间，最终导致无法释放</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;另外一个问题在于，很多同学在<strong>释放分布式锁的过程中，无论锁是否获取成功，都在finally中释放锁，这样是一个锁的错误使用</strong>，这个问题将在后续的V3.0版本中解决。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;针对锁无法释放问题的一个解决方案基于GETSET命令来实现</p>
<h2 id="V1-1-基于GETSET"><a href="#V1-1-基于GETSET" class="headerlink" title="V1.1 基于GETSET"></a>V1.1 基于GETSET</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tryLock()&#123;  </span><br><span class="line">    NewExpireTime=CurrentTimestamp+ExpireSeconds</span><br><span class="line">    if(SETNX Key NewExpireTime Seconds)&#123;</span><br><span class="line">         oldExpireTime = GET(Key)</span><br><span class="line">          if( oldExpireTime &lt; CurrentTimestamp)&#123;</span><br><span class="line">              NewExpireTime=CurrentTimestamp+ExpireSeconds</span><br><span class="line">              CurrentExpireTime=GETSET(Key,NewExpireTime)</span><br><span class="line">              if(CurrentExpireTime == oldExpireTime)&#123;</span><br><span class="line">                return 1;</span><br><span class="line">              &#125;else&#123;</span><br><span class="line">                return 0;</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">release()&#123;  </span><br><span class="line">        DELETE key</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p><strong>思路：</strong></p>
<ol>
<li>SETNX(Key,ExpireTime)获取锁</li>
<li>如果获取锁失败，通过GET(Key)返回的时间戳检查锁是否已经过期</li>
<li>GETSET(Key,ExpireTime)修改Value为NewExpireTime</li>
<li>检查GETSET返回的旧值，如果等于GET返回的值，则认为获取锁成功</li>
</ol>
<blockquote>
<p>注意：这个版本去掉了EXPIRE命令，改为通过Value时间戳值来判断过期</p>
</blockquote>
<p><strong>问题：</strong></p>
<ol>
<li><strong>在锁竞争较高的情况下，会出现Value不断被覆盖，但是没有一个Client获取到锁</strong></li>
<li>在获取锁的过程中不断的修改原有锁的数据，设想一种场景C1，C2竞争锁，C1获取到了锁，<strong>C2锁执行了GETSET操作修改了C1锁的过期时间，如果C1没有正确释放锁，锁的过期时间被延长，其它Client需要等待更久的时间</strong></li>
</ol>
<h2 id="V2-0-基于SETNX"><a href="#V2-0-基于SETNX" class="headerlink" title="V2.0 基于SETNX"></a>V2.0 基于SETNX</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tryLock()&#123;  </span><br><span class="line">    SETNX Key 1 Seconds</span><br><span class="line">&#125;</span><br><span class="line">release()&#123;  </span><br><span class="line">  DELETE Key</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Redis 2.6.12版本后<strong>SETNX增加过期时间参数，这样就解决了两条命令无法保证原子性的问题</strong>。但是设想下面一个场景：</p>
<ol>
<li>C1成功获取到了锁，之后C1因为GC进入等待或者未知原因导致任务执行过长，最后在锁失效前C1没有主动释放锁</li>
<li>C2在C1的锁超时后获取到锁，并且开始执行，这个时候C1和C2都同时在执行，会因<strong>重复执行造成数据不一致等未知情况</strong></li>
<li>C1如果先执行完毕，则会释放C2的锁，此时可能导致另外一个C3进程获取到了锁</li>
</ol>
<p>大致的流程图：</p>
<p><img src="//blog.com/2019/03/23/Redis分布式锁进化史/1.png" alt=""></p>
<p><strong>存在问题：</strong></p>
<ol>
<li><strong>由于C1的停顿导致C1 和C2同都获得了锁并且同时在执行，在业务实现间接要求必须保证幂等性</strong></li>
<li><strong>C1释放了不属于C1的锁</strong></li>
</ol>
<h2 id="V3-0"><a href="#V3-0" class="headerlink" title="V3.0"></a>V3.0</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tryLock()&#123;  </span><br><span class="line">    SETNX Key UnixTimestamp Seconds</span><br><span class="line">&#125;</span><br><span class="line">release()&#123;  </span><br><span class="line">    EVAL(</span><br><span class="line">      //LuaScript</span><br><span class="line">      if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then</span><br><span class="line">          return redis.call(&quot;del&quot;,KEYS[1])</span><br><span class="line">      else</span><br><span class="line">          return 0</span><br><span class="line">      end</span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这个方案通过指定Value为时间戳，并在释放锁的时候检查锁的Value是否为获取锁的Value，避免了V2.0版本中提到的C1释放了C2持有的锁的问题；另外在释放锁的时候因为涉及到多个Redis操作，并且<strong>考虑到Check And Set 模型的并发问题，所以使用Lua脚本来避免并发问题</strong>。</p>
<p><strong>存在问题：</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>如果在并发极高的场景下，比如抢红包场景，可能存在UnixTimestamp重复问题，另外由于不能保证分布式环境下的物理时钟一致性，也可能存在UnixTimestamp重复问题，只不过极少情况下会遇到</strong>。</p>
<h2 id="V3-1"><a href="#V3-1" class="headerlink" title="V3.1"></a>V3.1</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tryLock()&#123;  </span><br><span class="line">    SET Key UniqId Seconds</span><br><span class="line">&#125;</span><br><span class="line">release()&#123;  </span><br><span class="line">    EVAL(</span><br><span class="line">      //LuaScript</span><br><span class="line">      if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then</span><br><span class="line">          return redis.call(&quot;del&quot;,KEYS[1])</span><br><span class="line">      else</span><br><span class="line">          return 0</span><br><span class="line">      end</span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Redis 2.6.12后SET同样提供了一个NX参数，等同于SETNX命令，官方文档上提醒后面的版本有可能去掉SETNX, SETEX, PSETEX,并用SET命令代替，另外一个优化是<strong>使用一个自增的唯一UniqId代替时间戳来规避V3.0提到的时钟问题</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这个方案是目前最优的分布式锁方案，但是如果在Redis集群环境下依然存在问题：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>由于Redis集群数据同步为异步，假设在Master节点获取到锁后未完成数据同步情况下Master节点crash，此时在新的Master节点依然可以获取锁，所以多个Client同时获取到了锁</strong></p>
<h1 id="分布式Redis锁：Redlock"><a href="#分布式Redis锁：Redlock" class="headerlink" title="分布式Redis锁：Redlock"></a>分布式Redis锁：Redlock</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;V3.1的版本仅在单实例的场景下是安全的，针对如何实现分布式Redis的锁，国外的分布式专家有过激烈的讨论， antirez提出了分布式锁算法Redlock，在distlock话题下可以看到对Redlock的详细说明，下面是Redlock算法的一个中文说明（引用）：</p>
<p>假设有N个独立的Redis节点</p>
<ol>
<li>获取当前时间（毫秒数）。</li>
<li>按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。这里的失败，应该包含任何类型的失败，比如该Redis节点不可用，或者该Redis节点上的锁已经被其它客户端持有（注：Redlock原文中这里只提到了Redis节点不可用的情况，但也应该包含其它的失败情况）。</li>
<li>计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（&gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。</li>
<li>如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。</li>
<li>如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的Redis Lua脚本）。</li>
<li>释放锁：对所有的Redis节点发起释放锁操作</li>
</ol>
<p>然而Martin Kleppmann针对这个算法提出了质疑，提出应该基于fencing token机制（每次对资源进行操作都需要进行token验证）</p>
<blockquote>
<ol>
<li>Redlock在系统模型上尤其是在分布式时钟一致性问题上提出了假设，实际场景下存在时钟不一致和时钟跳跃问题，而Redlock恰恰是基于timing的分布式锁</li>
<li>另外Redlock由于是基于自动过期机制，依然没有解决长时间的gc pause等问题带来的锁自动失效，从而带来的安全性问题。</li>
</ol>
</blockquote>
<p>接着antirez又回复了Martin Kleppmann的质疑，给出了过期机制的合理性，以及实际场景中如果出现停顿问题导致多个Client同时访问资源的情况下如何处理。</p>
<p>针对Redlock的问题，基于Redis的分布式锁到底安全吗给出了详细的中文说明，并对Redlock算法存在的问题提出了分析。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>不论是基于SETNX版本的Redis单实例分布式锁，还是Redlock分布式锁，都是为了保证下特性</p>
<blockquote>
<ol>
<li>安全性：在同一时间不允许多个Client同时持有锁</li>
<li>活性<br>死锁：锁最终应该能够被释放，即使Client端crash或者出现网络分区（通常基于超时机制）<br>容错性：只要超过半数Redis节点可用，锁都能被正确获取和释放</li>
</ol>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;所以在开发或者使用分布式锁的过程中要保证安全性和活性，避免出现不可预测的结果。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;另外每个版本的分布式锁都存在一些问题，在锁的使用上要针对锁的实用场景选择合适的锁，通常情况下锁的使用场景包括：</p>
<p><strong>Efficiency(效率)：只需要一个Client来完成操作，不需要重复执行，这是一个对宽松的分布式锁，只需要保证锁的活性即可</strong>；</p>
<p><strong>Correctness(正确性)：多个Client保证严格的互斥性，不允许出现同时持有锁或者对同时操作同一资源，这种场景下需要在锁的选择和使用上更加严格，同时在业务代码上尽量做到幂等</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;采用Redis作为分布式锁控制器始终存在一个问题：<strong>在锁过期时，任务还未执行完成怎么处理？如果不做处理，可能导致任务重复执行</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;一个解决方案：<strong>看门狗机制</strong>，即在获得锁的时候，另外再起一个线程，不断检查锁的剩余有效时间，如果发现剩余1/3时，任务还未执行完成，延长锁的有效期。<strong>在PHP、Python等脚本语言中很难实施</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/22/“搜索”的原理，架构，实现，实践/" itemprop="url">“搜索”的原理，架构，实现，实践</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-22T12:12:57+08:00">
                2019-03-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/58架构分享/" itemprop="url" rel="index">
                    <span itemprop="name">58架构分享</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/58架构分享/搜索引擎/" itemprop="url" rel="index">
                    <span itemprop="name">搜索引擎</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="“搜索”的原理，架构，实现，实践"><a href="#“搜索”的原理，架构，实现，实践" class="headerlink" title="“搜索”的原理，架构，实现，实践"></a>“搜索”的原理，架构，实现，实践</h1><h2 id="全网搜索引擎架构与流程如何？"><a href="#全网搜索引擎架构与流程如何？" class="headerlink" title="全网搜索引擎架构与流程如何？"></a>全网搜索引擎架构与流程如何？</h2><p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/1.webp" alt="img"></p>
<p>全网搜索引擎的宏观架构如上图，核心子系统主要分为三部分（粉色部分）：</p>
<p>（1）<strong><code>spider</code>爬虫系统</strong>；</p>
<p>（2）<strong><code>search&amp;index</code>建立索引与查询索引系统</strong>，这个系统又主要分为两部分：</p>
<ul>
<li>一部分用于生成索引数据<code>build_index</code></li>
<li>一部分用于查询索引数据<code>search_index</code></li>
</ul>
<p>（3）<strong><code>rank</code>打分排序系统</strong>；</p>
<p>核心数据主要分为两部分（紫色部分）：</p>
<p>（1）<strong><code>web</code>网页库</strong>；</p>
<p>（2）<strong><code>index</code>索引数据</strong>；</p>
<p>全网搜索引擎的业务特点决定了，这是一个<strong>“写入”和“检索”</strong>分离的系统。</p>
<h3 id="写入是如何实施的？"><a href="#写入是如何实施的？" class="headerlink" title="写入是如何实施的？"></a>写入是如何实施的？</h3><p><strong><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/2.webp" alt="img"></strong></p>
<p><strong>系统组成</strong>：由<code>spider</code>与<code>search&amp;index</code>两个系统完成。</p>
<p><strong>输入</strong>：站长们生成的互联网网页。</p>
<p><strong>输出</strong>：正排倒排索引数据。</p>
<p><strong>流程</strong>：如架构图中的1，2，3，4：</p>
<p>​    （1）<code>spider</code>把互联网网页抓过来；</p>
<p>​    （2）<code>spider</code>把互联网网页存储到网页库中（这个对存储的要求很高，要存储几乎整个“万维网”的镜像）；</p>
<p>​    （3）<code>build_index</code>从网页库中读取数据，完成分词；</p>
<p>​    （4）<code>build_index</code>生成倒排索引；</p>
<h3 id="检索是如何实施的？"><a href="#检索是如何实施的？" class="headerlink" title="检索是如何实施的？"></a>检索是如何实施的？</h3><p><strong><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/3.webp" alt="img"></strong></p>
<p><strong>系统组成</strong>：由<code>search&amp;index</code>与<code>rank</code>两个系统完成。</p>
<p><strong>输入</strong>：用户的搜索词。</p>
<p><strong>输出</strong>：排好序的第一页检索结果。</p>
<p><strong>流程</strong>：如架构图中的<code>a，b，c，d</code>：</p>
<p>​    （a）<code>search_index</code>获得用户的搜索词，完成分词；</p>
<p>​    （b）<code>search_index</code>查询倒排索引，获得“字符匹配”网页，这是初筛的结果；</p>
<p>​    （c）<code>rank</code>对初筛的结果进行打分排序；</p>
<p>​    （d）<code>rank</code>对排序后的第一页结果返回；</p>
<h2 id="站内搜索引擎架构与流程如何？"><a href="#站内搜索引擎架构与流程如何？" class="headerlink" title="站内搜索引擎架构与流程如何？"></a>站内搜索引擎架构与流程如何？</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;做全网搜索的公司毕竟是少数，绝大部分公司要实现的其实只是一个<strong>站内搜索</strong>，以58同城100亿帖子的搜索为例，其整体架构如下：</p>
<p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/4.webp" alt="img"></p>
<p>站内搜索引擎的宏观架构如上图，与全网搜索引擎的宏观架构相比，<strong>差异只有写入的地方</strong>：</p>
<p>（1）全网搜索需要<code>spider</code>要<strong>被动去抓取数据</strong>；</p>
<p>（2）站内搜索是内部系统生成的数据，例如“发布系统”会将生成的帖子<strong>主动推</strong>给<code>build_data</code>系统；</p>
<p><code>画外音：看似“很小”的差异，架构实现上难度却差很多，全网搜索如何“实时”发现“全量”的网页是非常困难的，而站内搜索容易实时得到全部数据</code>。</p>
<p>对于<code>spider</code>、<code>search&amp;index</code>、<code>rank</code>三个系统：</p>
<p>（1）<code>spider</code>和<code>search&amp;index</code>是相对工程的系统；</p>
<p>（2）<strong>rank是和业务、策略紧密、算法相关的系统，搜索体验的差异主要在此</strong>，而业务、策略的优化是需要时间积累的，这里的启示是：</p>
<ul>
<li><code>Google</code>的体验比<code>Baidu</code>好，根本在于前者rank牛逼</li>
<li>国内互联网公司（例如<code>360</code>）短时间要搞一个体验超越<code>Baidu</code>的搜索引擎，是很难的，真心需要时间的积累</li>
</ul>
<h3 id="什么是正排索引（forward-index）？"><a href="#什么是正排索引（forward-index）？" class="headerlink" title="什么是正排索引（forward index）？"></a>什么是正排索引（forward index）？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;简言之，<strong>由key查询实体的过程，使用正排索引</strong>。</p>
<p>例如，用户表：</p>
<p><code>t_user(uid, name, passwd, age, sex)</code></p>
<p>由<code>uid</code>查询整行的过程，就时正排索引查询。</p>
<p>又例如，网页库：</p>
<p><code>t_web_page(url, page_content)</code></p>
<p>由<code>url</code>查询整个网页的过程，也是正排索引查询。</p>
<p>网页内容分词后，<code>page_content</code>会对应一个分词后的集合<code>list&lt;item&gt;</code>。</p>
<p>简易的，正排索引可以理解为：</p>
<p><code>Map&lt;url, list&lt;item&gt;&gt;</code></p>
<p>能够由网页<code>url</code>快速找到内容的一个数据结构。</p>
<p><code>画外音：时间复杂度可以认为是O(1)</code>。</p>
<h3 id="什么是倒排索引（inverted-index）？"><a href="#什么是倒排索引（inverted-index）？" class="headerlink" title="什么是倒排索引（inverted index）？"></a>什么是倒排索引（inverted index）？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与正排索引相反，<strong>由item查询key的过程，使用倒排索引</strong>。</p>
<p>对于网页搜索，倒排索引可以理解为：</p>
<p><code>Map&lt;item, list&lt;url&gt;&gt;</code></p>
<p>能够<strong>由查询词快速找到包含这个查询词的网页的数据结构</strong>。</p>
<p><code>画外音：时间复杂度也是O(1)。</code></p>
<p>举个例子，假设有3个网页：</p>
<blockquote>
<p>url1 -&gt; “我爱北京”</p>
<p>url2 -&gt; “我爱到家”</p>
<p>url3 -&gt; “到家美好”</p>
</blockquote>
<p>这是一个<strong>正排索引：</strong></p>
<p><code>Map&lt;url, page_content&gt;</code></p>
<p>分词之后：</p>
<blockquote>
<p>url1 -&gt; {我，爱，北京}</p>
<p>url2 -&gt; {我，爱，到家}</p>
<p>url3 -&gt; {到家，美好}</p>
</blockquote>
<p>这是一个<strong>分词后的正排索引：</strong></p>
<p><code>Map&lt;url, list&lt;item&gt;&gt;</code></p>
<p>分词后<strong>倒排索引</strong>：</p>
<blockquote>
<p>我 -&gt; {url1, url2}</p>
<p>爱 -&gt; {url1, url2}</p>
<p>北京 -&gt; {url1}</p>
<p>到家 -&gt; {url2, url3}</p>
<p>美好 -&gt; {url3}</p>
</blockquote>
<p><code>Map&lt;item, list&lt;url&gt;&gt;</code></p>
<p>由<strong>检索词item快速找到包含这个查询词的网页<code>Map&lt;item, list&lt;url&gt;&gt;</code>就是倒排索引</strong>。</p>
<p><code>画外音：明白了吧，词到url的过程，是倒排索引</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>正排索引和倒排索引是<code>spider和build_index</code>系统提前建立好的数据结构</strong>，为什么要使用这两种数据结构，是因为它能够快速的实现“用户网页检索”需求。</p>
<p>画外音，业务需求决定架构实现，查询起来都很快。</p>
<h3 id="检索的过程是什么样的？"><a href="#检索的过程是什么样的？" class="headerlink" title="检索的过程是什么样的？"></a>检索的过程是什么样的？</h3><p>假设搜索词是“我爱”：</p>
<p>（1）分词，“我爱”会分词为{我，爱}，时间复杂度为<code>O(1)</code>；</p>
<p>（2）每个分词后的<code>item</code>，从倒排索引查询包含这个<code>item</code>的网页<code>list&lt;url&gt;</code>，时间复杂度也是<code>O(1)</code>：</p>
<blockquote>
<p>我 -&gt; {url1, url2}</p>
<p>爱 -&gt; {url1, url2}</p>
</blockquote>
<p>（3）<strong>求<code>list&lt;url&gt;</code>的交集</strong>，就是符合所有查询词的结果网页，对于这个例子，<code>{url1, url2}</code>就是最终的查询结果；</p>
<p>画外音：<strong>检索的过程也很简单：分词，查倒排索引，求结果集交集</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;就结束了吗？其实不然，分词和倒排查询时间复杂度都是<code>O(1)</code>，<strong>整个搜索的时间复杂度取决于“求<code>list&lt;url&gt;</code>的交集”</strong>，<strong>问题转化为了求两个集合交集</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>字符型的url不利于存储与计算，一般来说每个<code>url</code>会有一个数值型的<code>url_id</code>来标识，后文为了方便描述，<code>list&lt;url&gt;</code>统一用<code>list&lt;url_id&gt;</code>替代</strong>。</p>
<h4 id="list1和list2，求交集怎么求？"><a href="#list1和list2，求交集怎么求？" class="headerlink" title="list1和list2，求交集怎么求？"></a>list1和list2，求交集怎么求？</h4><h5 id="方案一：for-for，土办法，时间复杂度O-n-n"><a href="#方案一：for-for，土办法，时间复杂度O-n-n" class="headerlink" title="方案一：for * for，土办法，时间复杂度O(n*n)"></a>方案一：for * for，土办法，时间复杂度O(n*n)</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每个搜索词命中的网页是很多的，<code>O(n*n)</code>的复杂度是明显不能接受的。倒排索引是在创建之初可以进行排序预处理，问题转化成两个有序的<code>list</code>求交集，就方便多了。</p>
<p><code>画外音：比较笨的方法</code>。</p>
<h5 id="方案二：有序list求交集，拉链法"><a href="#方案二：有序list求交集，拉链法" class="headerlink" title="方案二：有序list求交集，拉链法"></a>方案二：有序list求交集，拉链法</h5><p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/5.webp" alt="img"></p>
<p><code>有序集合1{1,3,5,7,8,9}</code></p>
<p><code>有序集合2{2,3,4,5,6,7}</code></p>
<p><strong>两个指针指向首元素，比较元素的大小</strong>：</p>
<p>（1）<strong>如果相同，放入结果集，随意移动一个指针</strong>；</p>
<p>（2）<strong>否则，移动值较小的一个指针，直到队尾</strong>；</p>
<p>这种方法的好处是：</p>
<p>（1）<strong>集合中的元素最多被比较一次</strong>，时间复杂度为<code>O(n)</code>；</p>
<p>（2）<strong>多个有序集合可以同时进行</strong>，这适用于多个分词的<code>item</code>求<code>url_id</code>交集；</p>
<p><strong>这个方法就像一条拉链的两边齿轮，一一比对就像拉链，故称为拉链法</strong>；</p>
<p>画外音：<strong>倒排索引是提前初始化的，可以利用“有序”这个特性</strong>。</p>
<h5 id="方案三：分桶并行优化"><a href="#方案三：分桶并行优化" class="headerlink" title="方案三：分桶并行优化"></a>方案三：分桶并行优化</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据量大时，<code>url_id</code>分桶水平切分+并行运算是一种常见的优化方法，如果能将<code>list1&lt;url_id&gt;</code>和<code>list2&lt;url_id&gt;</code>分成若干个桶区间，每个区间利用多线程并行求交集，各个线程结果集的并集，作为最终的结果集，能够大大的减少执行时间。</p>
<p>举例：</p>
<p><code>有序集合1{1,3,5,7,8,9,10,30,50,70,80,90}</code></p>
<p><code>有序集合2{2,3,4,5,6,7,20,30,40,50,60,70}</code></p>
<p>求交集，先进行分桶拆分：</p>
<p>桶1的范围为<code>[1, 9]</code></p>
<p>桶2的范围为<code>[10, 100]</code></p>
<p>桶3的范围为<code>[101, max_int]</code></p>
<p>于是：</p>
<p>集合1就拆分成</p>
<p><code>集合a{1,3,5,7,8,9}</code></p>
<p><code>集合b{10,30,50,70,80,90}</code></p>
<p><code>集合c{}</code></p>
<p>集合2就拆分成</p>
<p><code>集合d{2,3,4,5,6,7}</code></p>
<p><code>集合e{20,30,40,50,60,70}</code></p>
<p><code>集合f{}</code></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>每个桶内的数据量大大降低了，并且每个桶内没有重复元素，可以利用多线程并行计算</strong>：</p>
<p>桶1内的<code>集合a</code>和<code>集合d</code>的交集是<code>x{3,5,7}</code></p>
<p>桶2内的<code>集合b</code>和<code>集合e</code>的交集是<code>y{30, 50, 70}</code></p>
<p>桶3内的<code>集合c</code>和<code>集合f</code>的交集是<code>z{}</code></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最终，<strong><code>集合1</code>和<code>集合2</code>的交集，是<code>x与y与z的并集</code>，即<code>集合{3,5,7,30,50,70}</code></strong>。</p>
<p><code>画外音：多线程、水平切分都是常见的优化手段</code>。</p>
<p><strong>方案四：bitmap再次优化</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>数据进行了水平分桶拆分之后，每个桶内的数据一定处于一个范围之内，如果集合符合这个特点，就可以使用<code>bitmap</code>来表示集合</strong>：</p>
<p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/6.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图，假设<code>set1{1,3,5,7,8,9}</code>和<code>set2{2,3,4,5,6,7}</code>的所有元素都在桶值<code>[1, 16]</code>的范围之内，可以用<code>16个bit</code>来描述这两个集合，原集合中的<code>元素x</code>，在这个<code>16bitmap</code>中的<code>第x个bit为1</code>，此时<strong>两个<code>bitmap</code>求交集，只需要将两个<code>bitmap</code>进行“与”操作</strong>，结果集<code>bitmap</code>的3，5，7位是1，表明原集合的交集为<code>{3,5,7}</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>水平分桶，<code>bitmap</code>优化之后，能极大提高求交集的效率，但时间复杂度仍旧是<code>O(n)</code>。<code>bitmap</code>需要大量连续空间，占用内存较大</strong>。</p>
<p>画外音：<strong><code>bitmap能够表示集合，用它求集合交集速度非常快</code></strong>。</p>
<p><strong>方案五：跳表skiplist</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>有序链表集合求交集，跳表是最常用的数据结构，它可以将有序集合求交集的复杂度由O(n)降至接近<code>O(log(n))</code></strong>。</p>
<p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/7.webp" alt="img"></p>
<p><code>集合1{1,2,3,4,20,21,22,23,50,60,70}</code></p>
<p><code>集合2{50,70}</code></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;要求交集，如果用拉链法，会发现<code>1,2,3,4,20,21,22,23</code>都要被无效遍历一次，每个元素都要被比对，时间复杂度为<code>O(n)</code>，能不能每次比对“跳过一些元素”呢？</p>
<p>跳表就出现了：</p>
<p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/8.webp" alt="img"></p>
<p><code>集合1{1,2,3,4,20,21,22,23,50,60,70}</code>建立跳表时，一级只有<code>{1,20,50}</code>三个元素，二级与普通链表相同。</p>
<p><code>集合2{50,70}</code>由于元素较少，只建立了一级普通链表。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如此这般，<strong>在实施“拉链”求交集的过程中，<code>set1</code>的指针能够由1跳到20再跳到50，中间能够跳过很多元素，无需进行一一比对，跳表求交集的时间复杂度近似O(log(n))，这是搜索引擎中常见的算法</strong>。</p>
<h3 id="小结一下"><a href="#小结一下" class="headerlink" title="小结一下"></a>小结一下</h3><p>（1）<strong>全网搜索引擎系统</strong>由<code>spider</code>, <code>search&amp;index,</code>rank`三个子系统构成；</p>
<p>（2）<strong>站内搜索引擎</strong>与全网搜索引擎的差异在于，少了一个<code>spider</code>子系统；</p>
<p>（3）<code>spider</code>和<code>search&amp;index</code>系统是两个<strong>工程系统</strong>，<code>rank</code>系统的优化却需要长时间的<strong>调优和积累</strong>；</p>
<p>（4）<strong>正排索引</strong>（<code>forward index</code>）是由网页<code>url_id</code>快速找到分词后网页内容<code>list&lt;item&gt;</code>的过程；</p>
<p>（5）<strong>倒排索引</strong>（<code>inverted index</code>）是由分词<code>item</code>快速寻找包含这个分词的网页<code>list&lt;url_id&gt;</code>的过程；</p>
<p>（6）<strong>用户检索的过程</strong>，是先分词，再找到每个<code>item</code>对应的<code>list&lt;url_id&gt;</code>，最后进行集合求<strong>交集</strong>的过程；</p>
<p>（7）<strong>有序集合求交集</strong>的方法有：</p>
<ul>
<li>二重for循环法，时间复杂度<code>O(n*n)</code></li>
<li>拉链法，时间复杂度<code>O(n)</code></li>
<li>水平分桶，多线程并行</li>
<li><code>bitmap</code>，大大提高运算并行度，时间复杂度<code>O(n)</code></li>
<li>跳表，时间复杂度为<code>O(log(n))</code></li>
</ul>
<h2 id="在业务、流量、并发量逐步递增的各个阶段，应该如何实现检索需求呢？"><a href="#在业务、流量、并发量逐步递增的各个阶段，应该如何实现检索需求呢？" class="headerlink" title="在业务、流量、并发量逐步递增的各个阶段，应该如何实现检索需求呢？"></a>在业务、流量、并发量逐步递增的各个阶段，应该如何实现检索需求呢？</h2><h3 id="原始阶段-LIKE"><a href="#原始阶段-LIKE" class="headerlink" title="原始阶段-LIKE"></a>原始阶段-LIKE</h3><p>创业阶段，常常用这种方法来快速实现。</p>
<p>数据在数据库中可能是这么存储的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t_tiezi(tid, title, content)</span><br></pre></td></tr></table></figure>
<p>满足标题、内容的检索需求可以通过LIKE实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select tid from t_tiezi where content like ‘%天通苑%’</span><br></pre></td></tr></table></figure>
<p>这种方式确实能够快速满足业务需求，存在的问题也显而易见：</p>
<p>（1）<strong>效率低，每次需要全表扫描，计算量大，并发高时<code>cpu</code>容易100%</strong>；</p>
<p>（2）<strong>不支持分词</strong>；</p>
<h3 id="初级阶段-全文索引"><a href="#初级阶段-全文索引" class="headerlink" title="初级阶段-全文索引"></a>初级阶段-全文索引</h3><p>如何快速提高效率，支持分词，并对原有系统架构影响尽可能小呢，第一时间想到的是建立全文索引：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t_tiezi add fulltext(title,content)</span><br></pre></td></tr></table></figure>
<p>使用match和against实现索引字段上的查询需求。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;全文索引能够快速实现业务上分词的需求，并且快速提升性能（分词后倒排，至少不要全表扫描了），但也存在一些问题：</p>
<p>（1）<strong>只适用于MyISAM</strong>；</p>
<p>（2）由于全文索引利用的是数据库特性，搜索需求和普通CURD需求耦合在数据库中：<strong>检索需求并发大时，可能影响<code>CURD</code>的请求</strong>；<strong><code>CURD</code>并发大时，检索会非常的慢</strong>；</p>
<p>（3）数据量达到百万级别，性能还是会显著降低，<strong>查询返回时间很长，业务难以接受</strong>；</p>
<p>（4）<strong>比较难水平扩展</strong>；</p>
<h3 id="中级阶段-开源外置索引"><a href="#中级阶段-开源外置索引" class="headerlink" title="中级阶段-开源外置索引"></a>中级阶段-开源外置索引</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了解决全文索的局限性，当数据量增加到大几百万，千万级别时，就要考虑外置索引了。外置索引的<strong>核心思路</strong>是：<strong>索引数据与原始数据分离，前者满足搜索需求，后者满足<code>CURD</code>需求，通过一定的机制（双写，通知，定期重建）来保证数据的一致性</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;原始数据可以继续使用<code>Mysql</code>来存储，外置索引如何实施？<code>Solr</code>，<code>Lucene</code>，<code>ES</code>都是常见的开源方案。其中，<code>ES（ElasticSearch）</code>是目前最为流行的。</p>
<p><code>Lucene</code>虽好，潜在的不足是：</p>
<p>（1）<strong><code>Lucene</code>只是一个库，需要自己做服务</strong>，自己实现高可用/可扩展/负载均衡等复杂特性；</p>
<p>（2）<strong><code>Lucene</code>只支持<code>Java</code>，如果要支持其他语言，必须得自己做服务</strong>；</p>
<p>（3）<code>Lucene</code>不友好，这是很致命的，非常复杂，<strong>使用者往往需要深入了解搜索的知识来理解它的工作原理，为了屏蔽其复杂性，还是得自己做服务</strong>；</p>
<p>为了改善<code>Lucene</code>的各项不足，解决方案都是“<strong>封装一个接口友好的服务，屏蔽底层复杂性</strong>”，于是有了<code>ES</code>：</p>
<p>（1）<code>ES</code>是一个以<code>Lucene</code>为内核来实现搜索功能，<strong>提供<code>REStful</code>接口的服务</strong>；</p>
<p>（2）<code>ES</code>能够支持很大数据量的信息存储，<strong>支持很高并发的搜索请求</strong>；</p>
<p>（3）<strong><code>ES</code>支持集群，向使用者屏蔽高可用/可扩展/负载均衡等复杂特性</strong>；</p>
<p>目前，快狗打车使用<code>ES</code>作为核心的搜索服务，实现业务上的各类搜索需求，其中：</p>
<p>（1）数据量最大的“接口耗时数据收集”需求，数据量大概在10亿左右；</p>
<p>（2）并发量最大的“经纬度，地理位置搜索”需求，线上平均并发量大概在2000左右，压测数据并发量在8000左右；</p>
<p>所以，ES完全能满足10亿数据量，5k吞吐量的常见搜索业务需求。</p>
<h3 id="高级阶段-自研搜索引擎"><a href="#高级阶段-自研搜索引擎" class="headerlink" title="高级阶段-自研搜索引擎"></a>高级阶段-自研搜索引擎</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当数据量进一步增加，达到10亿、100亿数据量；并发量也进一步增加，达到每秒10万吞吐量；业务个性也逐步增加的时候，就需要自研搜索引擎了，定制化实现搜索内核了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;到了定制化自研搜索引擎的阶段，超大数据量、超高并发量为设计重点，为了达到“无限容量、无限并发”的需求，架构设计需要重点考虑“扩展性”，力争做到：增加机器就能扩容（数据量+并发量）。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;58同城的自研搜索引擎E-search初步架构图如下：</p>
<p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/9.webp" alt="img"></p>
<p>（1）上层<code>proxy</code>（粉色）是<strong>接入集群</strong>，为对外门户，接受搜索请求，其无状态性能够保证增加机器就能扩充<code>proxy</code>集群性能；</p>
<p>（2）中层<code>merger</code>（浅蓝色）是<strong>逻辑集群</strong>，主要用于实现搜索合并，以及打分排序，业务相关的<code>rank</code>就在这一层实现，其无状态性也能够保证增加机器就能扩充<code>merger</code>集群性能；</p>
<p>（3）底层<code>searcher</code>（暗红色大框）是检索集群，服务和索引数据部署在同一台机器上，服务启动时可以加载索引数据到内存，请求访问时从内存中<code>load</code>数据，访问速度很快：</p>
<ul>
<li>为了满足<strong>数据容量的扩展性</strong>，索引数据进行了水平切分，增加切分份数，就能够无限扩展性能，如上图<code>searcher</code>分为了4组</li>
<li>为了满足<strong>一份数据的性能扩展性</strong>，同一份数据进行了冗余，理论上做到增加机器就无限扩展性能，如上图每组<code>searche</code>r又冗余了2份</li>
<li></li>
</ul>
<p>如此设计，真正做到做到增加机器就能承载更多的数据量，响应更高的并发量。</p>
<h2 id="实时搜索引擎系统架构的要点是什么？"><a href="#实时搜索引擎系统架构的要点是什么？" class="headerlink" title="实时搜索引擎系统架构的要点是什么？"></a>实时搜索引擎系统架构的要点是什么？</h2><p>关于<strong>搜索的实时性</strong>：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;百度为何能实时检索出15分钟之前新出的新闻？58同城为何能实时检索出1秒钟之前发布的帖子？</p>
<p><strong>大数据量、高并发量情况下的搜索引擎为了保证实时性，架构设计上的两个要点</strong>：</p>
<p>（1）<strong>索引分级</strong>；</p>
<p>（2）<strong>dump&amp;merge</strong>；</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先，<strong>在数据量非常大的情况下，为了保证倒排索引的高效检索效率，任何对数据的更新，并不会实时修改索</strong>引。</p>
<p><code>画外音：因为，一旦产生碎片，会大大降低检索效率</code>。</p>
<h3 id="既然索引数据不能实时修改，如何保证最新的网页能够被索引到呢？"><a href="#既然索引数据不能实时修改，如何保证最新的网页能够被索引到呢？" class="headerlink" title="既然索引数据不能实时修改，如何保证最新的网页能够被索引到呢？"></a>既然索引数据不能实时修改，如何保证最新的网页能够被索引到呢？</h3><p>索引分级，分为全量库、日增量库、小时增量库。</p>
<p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/10.webp" alt="img"></p>
<p>如上图所述：</p>
<p>（1）300亿数据在全量索引库中；</p>
<p>（2）1000万1天内修改过的数据在天库中；</p>
<p>（3）50万1小时内修改过的数据在小时库中；</p>
<p><strong>当有修改请求发生时，只会操作最低级别的索引</strong>，例如小时库。</p>
<p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/11.webp" alt="img"></p>
<p><strong>当有查询请求发生时，会同时查询各个级别的索引，将结果合并，得到最新的数据</strong>：</p>
<p>（1）全量库是紧密存储的索引，无碎片，速度快；</p>
<p>（2）天库是紧密存储，速度快；</p>
<p>（3）小时库数据量小，速度也快；</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分级索引能够保证实时性，那么，新的问题来了，<strong>小时库数据何时反映到天库中，天库中的数据何时反映到全量库中呢？</strong></p>
<p><code>dump&amp;merge</code>，索引的导出与合并，由这两个异步的工具完成：</p>
<p><img src="//blog.com/2019/03/22/“搜索”的原理，架构，实现，实践/12.webp" alt="img"></p>
<p><strong>dumper</strong>：将在线的数据导出。</p>
<p><strong>merger</strong>：将离线的数据合并到高一级别的索引中去。</p>
<p>小时库，一小时一次，合并到天库中去；</p>
<p>天库，一天一次，合并到全量库中去；</p>
<p>这样就保证了小时库和天库的数据量都不会特别大；</p>
<p>如果数据量和并发量更大，还能增加星期库，月库来缓冲。</p>
<h3 id="小结一下-1"><a href="#小结一下-1" class="headerlink" title="小结一下"></a>小结一下</h3><p>超大数据量，超高并发量，实时搜索引擎的两个架构要点：</p>
<p>（1）索引分级；</p>
<p>（2）dump&amp;merge；</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/" itemprop="url">1万属性，100亿数据，每秒10万吞吐，架构如何设计？</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-22T12:12:57+08:00">
                2019-03-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/58架构分享/" itemprop="url" rel="index">
                    <span itemprop="name">58架构分享</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/58架构分享/类SKU问题处理/" itemprop="url" rel="index">
                    <span itemprop="name">类SKU问题处理</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1万属性，100亿数据，每秒10万吞吐，架构如何设计？"><a href="#1万属性，100亿数据，每秒10万吞吐，架构如何设计？" class="headerlink" title="1万属性，100亿数据，每秒10万吞吐，架构如何设计？"></a>1万属性，100亿数据，每秒10万吞吐，架构如何设计？</h1><blockquote>
<p>原文地址：<a href="https://mp.weixin.qq.com/s/msinJA9T3TR1uWrYx6M1iQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/msinJA9T3TR1uWrYx6M1iQ</a></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有一类业务场景，没有固定的<code>schema</code>存储，却有着海量的数据行数，架构上如何来实现这类业务的存储与检索呢？58最核心的数据“帖子”的架构实现技术细节，今天和大家聊一聊。</p>
<h2 id="一、背景描述及业务介绍"><a href="#一、背景描述及业务介绍" class="headerlink" title="一、背景描述及业务介绍"></a>一、背景描述及业务介绍</h2><p><strong>什么是58最核心的数据？</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;58是一个信息平台，有很多垂直品类：招聘、房产、二手物品、二手车、黄页等等，每个品类又有很多子品类，不管哪个品类，最核心的数据都是“帖子信息”。</p>
<p><code>画外音：像不像一个大论坛？</code></p>
<p><strong>各分类帖子的信息有什么特点？</strong></p>
<p>逛过58的朋友很容易了解到，这里的帖子信息：</p>
<p>（1）<strong>各品类的属性千差万别</strong>，招聘帖子和二手帖子属性完全不同，二手手机和二手家电的属性又完全不同，目前恐怕有近万个属性；</p>
<p>（2）<strong>数据量巨大</strong>，100亿级别；</p>
<p>（3）<strong>每个属性上都有查询需求</strong>，各组合属性上都可能有组合查询需求，招聘要查职位/经验/薪酬范围，二手手机要查颜色/价格/型号，二手要查冰箱/洗衣机/空调；</p>
<p>（4）<strong>吞吐量很大</strong>，每秒几10万吞吐；</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如何解决100亿数据量，1万属性，多属性组合查询，10万并发查询的技术难题呢？一步步来。</p>
<h2 id="二、最容易想到的方案"><a href="#二、最容易想到的方案" class="headerlink" title="二、最容易想到的方案"></a>二、最容易想到的方案</h2><p>每个公司的发展都是一个从小到大的过程，撇开并发量和数据量不谈，先看看</p>
<p>（1）<strong>如何实现属性扩展性需求</strong>；</p>
<p>（2）<strong>多属性组合查询需求</strong>；</p>
<p><code>画外音：公司初期并发量和数据量都不大，必须先解决业务问题。</code></p>
<p><strong>如何满足业务的存储需求呢？</strong></p>
<p>最开始，业务只有一个招聘品类，那帖子表可能是这么设计的：</p>
<p><code>tiezi(tid, uid, c1, c2, c3)</code>;</p>
<p><strong>那如何满足各属性之间的组合查询需求呢？</strong></p>
<p>最容易想到的是通过组合索引满足查询需求：</p>
<p><code>index_1(c1, c2)</code></p>
<p><code>index_2(c2, c3)</code></p>
<p><code>index_3(c1, c3)</code></p>
<p><strong>随着业务的发展，又新增了一个房产类别，存储问题又该如何解决呢？</strong></p>
<p>可以新增若干属性满足存储需求，于是帖子表变成了：</p>
<p><code>tiezi(tid, uid, c1, c2, c3, c10, c11, c12, c13)</code>; </p>
<p>其中：</p>
<ul>
<li><code>c1,c2,c3</code>是招聘类别属性</li>
<li><code>c10,c11,c12,c13</code>是房产类别属性</li>
</ul>
<p>通过扩展属性，可以解决存储的问题。</p>
<p><strong>查询需求，又该如何满足呢？</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先，<strong>跨业务属性一般没有组合查询需求</strong>。只能建立了若干组合索引，满足房产类别的查询需求。</p>
<p><code>画外音：不敢想有多少个索引能覆盖所有两属性查询，三属性查询。</code></p>
<p><strong>当业务越来越多时，是不是发现玩不下去了？</strong></p>
<h2 id="三、垂直拆分是一个思路"><a href="#三、垂直拆分是一个思路" class="headerlink" title="三、垂直拆分是一个思路"></a>三、垂直拆分是一个思路</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;新增属性是一种扩展方式，新增表也是一种方式，垂直拆分也是常见的存储扩展方案。</p>
<p><strong>如何按照业务进行垂直拆分？</strong></p>
<p>可以这么玩：</p>
<p><code>tiezi_zhaopin(tid, uid, c1, c2, c3)</code>;</p>
<p><code>tiezi_fangchan(tid, uid, c10, c11, c12, c13)</code>;</p>
<p><strong>在业务各异，数据量和吞吐量都巨大的情况下，垂直拆分会遇到什么问题呢？</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这些表，以及对应的服务维护在不同的部门，看上去各业务灵活性强，研发闭环，这恰恰是悲剧的开始：</p>
<p>（1）<strong>tid如何规范</strong>？</p>
<p>（2）<strong>属性如何规范</strong>？</p>
<p>（3）<strong>按照uid来查询怎么办</strong>（查询自己发布的所有帖子）？</p>
<p>（4）<strong>按照时间来查询怎么办</strong>（最新发布的帖子）？</p>
<p>（5）<strong>跨品类查询怎么办</strong>（例如首页搜索框）？</p>
<p>（6）<strong>技术范围的扩散</strong>，有的用<code>mongo</code>存储，有的用<code>mysql</code>存储，有的自研存储；</p>
<p>（7）<strong>重复开发了不少组件</strong>；</p>
<p>（8）<strong>维护成本过高</strong>；</p>
<p>（9）…</p>
<p><code>画外音：想想看，电商的商品表，不可能一个类目一个表的。</code></p>
<h2 id="四、58的玩法：三大中心服务"><a href="#四、58的玩法：三大中心服务" class="headerlink" title="四、58的玩法：三大中心服务"></a>四、58的玩法：三大中心服务</h2><h3 id="第一：统一帖子中心服务"><a href="#第一：统一帖子中心服务" class="headerlink" title="第一：统一帖子中心服务"></a>第一：统一帖子中心服务</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;平台型创业型公司，可能有多个品类，各品类有很多异构数据的存储需求，到底是分还是合，无需纠结：<strong>基础数据基础服务的统一</strong>，是一个很好的实践。</p>
<p><code>画外音：这里说的是平台型业务。</code></p>
<p><strong>如何将不同品类，异构的数据统一存储起来呢？</strong></p>
<p>（1）<strong>全品类通用属性统一存储</strong>；</p>
<p>（2）<strong>单品类特有属性，品类类型与通用属性json来进行存储</strong>；</p>
<p>更具体的：</p>
<p><code>tiezi(tid, uid, time, title, cate, subcate, xxid, ext)</code>;</p>
<p>（1）一些通用的字段抽取出来单独存储；</p>
<p>（2）通过<code>cate, subcate, xxid</code>等来定义<code>ext</code>是何种含义；</p>
<p><img src="//blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/1.webp" alt="img"></p>
<p>（3）通过<code>ext</code>来存储不同业务线的个性化需求</p>
<p>例如：</p>
<p>招聘的帖子，<code>ext</code>为：</p>
<p><code>{“job”:”driver”,”salary”:8000,”location”:”bj”}</code></p>
<p>而二手的帖子，<code>ext</code>为：</p>
<p><code>{”type”:”iphone”,”money”:3500}</code></p>
<p><img src="//blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/2.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;帖子数据，100亿的数据量，分256库，通过<code>ext</code>存储异构业务数据，使用<code>mysql</code>存储，上层架了一个帖子中心服务，使用<code>memcache</code>做缓存，就是这样一个并不复杂的架构，解决了业务的大问题。这是58最核心的帖子中心服务<code>IMC（Info Management Center）</code>。</p>
<p><code>画外音：该服务的底层存储在16年全面切换为了自研存储引擎，替换了mysql，但架构理念仍未变</code>。</p>
<p>解决了海量异构数据的存储问题，遇到的<strong>新问题</strong>是：</p>
<p>（1）<strong>每条记录ext内key都需要重复存储，占据了大量的空间，能否压缩存储</strong>；</p>
<p>（2）<strong>cateid已经不足以描述ext内的内容，品类有层级，深度不确定，ext能否具备自描述性</strong>；</p>
<p>（3）<strong>随时可以增加属性，保证扩展性</strong>；</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;解决完海量异构数据的存储问题，接下来，要解决的是<strong>类目的扩展性问题</strong>。</p>
<h3 id="第二：统一类目属性服务"><a href="#第二：统一类目属性服务" class="headerlink" title="第二：统一类目属性服务"></a>第二：统一类目属性服务</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>每个业务有多少属性，这些属性是什么含义，值的约束等，耦合到帖子服务里</strong>显然是不合理的，那怎么办呢？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>抽象出一个统一的类目、属性服务，单独来管理这些信息，而帖子库ext字段里json的key，统一由数字来表示，减少存储空间</strong>。</p>
<p><img src="//blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/3.webp" alt=""></p>
<p>画外音：<strong>帖子表只存元信息，不管业务含义</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，json里的key不再是”salary” ”location” ”money” 这样的长字符串了，取而代之的是数字1,2,3,4，这些<strong>数字是什么含义，属于哪个子分类，值的校验约束，统一都存储在类目、属性服务里</strong>。</p>
<p><img src="//blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/4.webp" alt="img"></p>
<p>画外音：<strong>类目表存业务信息，以及约束信息，与帖子表解耦</strong>。</p>
<p>这个表里对帖子中心服务里<code>ext</code>字段里的数字<code>key</code>进行了解释：</p>
<p>（1）1代表<code>job</code>，属于招聘品类下100子品类，其<code>value</code>必须是一个小于32的<code>[a-z]</code>字符；</p>
<p>（2）4代表<code>type</code>，属于二手品类下200子品类，其<code>value</code>必须是一个<code>short</code>；</p>
<p>这样就对原来帖子表<code>ext</code>扩展属性：</p>
<p><code>{“1”:”driver”,”2”:8000,”3”:”bj”}</code></p>
<p><code>{”4”:”iphone”,”5”:3500}</code></p>
<p>key和value都做了统一约束。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除此之外，如果<code>ext</code>里某个<code>key</code>的<code>value</code>不是正则校验的值，而是枚举值时，需要<strong>有一个对值进行限定的枚举表来进行校验</strong>：</p>
<p><img src="//blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/5.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个枚举校验，说明<code>key=4</code>的属性（对应属性表里二手，手机类型字段），其值不只是要进行“<code>short类型</code>”校验，而是<code>value</code>必须是固定的枚举值。</p>
<p><code>{”4”:”iphone”,”5”:3500}</code></p>
<p>这个<code>ext</code>就是不合法的，<code>key=4</code>的v<code>alue=iphone</code>不合法，而应该是枚举属性，合法的应该为：</p>
<p><code>{”4”:”5”,”5”:3500}</code></p>
<p>此外，类目属性服务还能记录类目之间的层级关系：</p>
<p>（1）一级类目是招聘、房产、二手…</p>
<p>（2）二手下有二级类目二手家具、二手手机…</p>
<p>（3）二手手机下有三级类目二手iphone，二手小米，二手三星…</p>
<p>（4）…</p>
<p><img src="//blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>类目服务解释了帖子数据，描述品类层级关系，保证各类目属性扩展性，保证各属性值合理性校验，就是58另一个统一的核心服务<code>CMC（Category Management Center）</code></strong>。</p>
<p>画外音：<strong>类目、属性服务像不像电商系统里的SKU扩展服务</strong>？</p>
<p><strong>（1）品类层级关系，对应电商里的类别层级体系；</strong></p>
<p><strong>（2）属性扩展，对应电商里各类别商品SKU的属性；</strong></p>
<p><strong>（3）枚举值校验，对应属性的枚举值</strong>，例如颜色：红，黄，蓝；*</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过品类服务，解决了<code>key压缩</code>，<code>key描述</code>，<code>key扩展</code>，<code>value校验</code>，<code>品类层级</code>的问题，还有这样的一个问题没有解决：每个品类下帖子的属性各不相同，查询需求各不相同，<strong>如何解决100亿数据量，1万属性的检索与联合检索需求呢？</strong></p>
<h3 id="第三：统一检索服务"><a href="#第三：统一检索服务" class="headerlink" title="第三：统一检索服务"></a>第三：统一检索服务</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据量很大的时候，不同属性上的查询需求，不可能通过组合索引来满足所有查询需求，“外置索引，统一检索服务”是一个很常用的实践：</p>
<p>（1）数据库提供“帖子id”的正排查询需求；</p>
<p>（2）<strong>所有非“帖子id”的个性化检索需求，统一走外置索引</strong>；</p>
<p><img src="//blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/7.webp" alt="img"></p>
<p>元数据与索引数据的操作遵循：</p>
<p>（1）对帖子进行tid正排查询，直接访问帖子服务；</p>
<p>（2）<strong>对帖子进行修改，帖子服务通知检索服务，同时对索引进行修改</strong>；</p>
<p>（3）对帖子进行复杂查询，通过检索服务满足需求；</p>
<p><code>画外音：这个检索服务，扛起了58同城80%的请求（不管来自PC还是APP，不管是主页、城市页、分类页、列表页、详情页，最终都会转化为一个检索请求），它就是58另一个统一的核心服务E-search，这个搜索引擎，是完全自研的</code>。</p>
<p>对于这个内核自研服务的搜索引擎架构，简单说明一下：</p>
<p><img src="//blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/8.webp" alt="img"></p>
<p>为应对100亿级别数据量、几十万级别的吞吐量，业务线各种复杂的复杂检索查询，扩展性是设计重点：</p>
<p>（1）统一的<strong>代理层</strong>，作为入口，其无状态性能够保证增加机器就能扩充系统性能；</p>
<p>（2）统一的<strong>结果聚合层</strong>，其无状态性也能够保证增加机器就能扩充系统性能；</p>
<p>（3）搜索内核<strong>检索层</strong>，服务和索引数据部署在同一台机器上，服务启动时可以加载索引数据到内存，请求访问时从内存中load数据，访问速度很快：</p>
<ul>
<li>为了满足数据容量的扩展性，索引数据进行了水平切分，增加切分份数，就能够无限扩展性能</li>
<li>为了满足一份数据的性能扩展性，同一份数据进行了冗余，理论上做到增加机器就无限扩展性能</li>
</ul>
<p>系统时延，100亿级别帖子检索，包含请求分合，拉链求交集，从聚合层均可以做到10ms返回。</p>
<p><code>画外音：入口层是Java研发的，聚合层与检索层都是C语言研发的</code>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>帖子业务，一致性不是主要矛盾，E-search会定期全量重建索引，以保证即使数据不一致，也不会持续很长的时间</strong>。</p>
<h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p><img src="//blog.com/2019/03/22/1万属性，100亿数据，每秒10万吞吐，架构如何设计？/9.webp" alt="img"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;面对100亿数据量，1万列属性，10万吞吐量的业务需求，可以采用了<strong>元数据服务、属性服务、搜索服务来</strong>解决：</p>
<ul>
<li>一个解决存储问题</li>
<li>一个解决品类解耦问题</li>
<li>一个解决检索问题</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/22/分库分表后如何部署上线/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/22/分库分表后如何部署上线/" itemprop="url">分库分表后如何部署上线</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-22T12:12:57+08:00">
                2019-03-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/分库分表/" itemprop="url" rel="index">
                    <span itemprop="name">分库分表</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="分库分表后如何部署上线"><a href="#分库分表后如何部署上线" class="headerlink" title="分库分表后如何部署上线"></a>分库分表后如何部署上线</h1><blockquote>
<p>原文地址：<a href="https://www.cnblogs.com/rjzheng/p/9597810.html" target="_blank" rel="noopener">https://www.cnblogs.com/rjzheng/p/9597810.html</a></p>
</blockquote>
<p>我们先来讲一个段子</p>
<blockquote>
<p><strong>面试官：“有并发的经验没？”</strong></p>
<p><strong>应聘者：“有一点。”面</strong></p>
<p><strong>试官：“那你们为了处理并发，做了哪些优化？</strong></p>
<p><strong>”应聘者：“前后端分离啊，限流啊，分库分表啊。。</strong></p>
<p><strong>”面试官:”谈谈分库分表吧？”应聘者：“bala。bala。bala。。”</strong></p>
<p><strong>面试官心理活动:这个仁兄讲的怎么这么像网上的博客抄的，容我再问问。</strong></p>
<p><strong>面试官:“你们分库分表后，如何部署上线的？”</strong></p>
<p><strong>应聘者：“这！！！！！！”</strong></p>
</blockquote>
<h2 id="如何部署"><a href="#如何部署" class="headerlink" title="如何部署"></a>如何部署</h2><h3 id="停机部署法"><a href="#停机部署法" class="headerlink" title="停机部署法"></a>停机部署法</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;大致思路就是，挂一个公告，半夜停机升级，然后半夜把服务停了，跑数据迁移程序，进行数据迁移。<br>步骤如下:<br>(1)出一个公告，比如“今晚00:00～6:00进行停机维护，暂停服务”<br>(2)写一个迁移程序，读<code>db-old</code>数据库，通过中间件写入新库<code>db-new1</code>和<code>db-new2</code>，具体如下图所示：<br><img src="//blog.com/2019/03/22/分库分表后如何部署上线/1.png" alt="image"><br>(3)校验迁移前后一致性，没问题就切该部分业务到新库。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;现在流行的分库分表的中间件有两种，一种是<code>proxy</code>形式的，例如<code>mycat</code>，是需要额外部署一台服务器的。还有一种是<code>client</code>形式的，例如当当出的<code>Sharding-JDBC</code>，就是一个jar包，使用起来十分轻便。我个人偏向<code>Sharding-JDBC</code>，这种方式，无需额外部署，无其他依赖，DBA也无需改变原有的运维方式。</p>
<p>评价：<br>&nbsp;&nbsp;&nbsp;&nbsp;大家不要觉得这种方法low，我其实一直觉得这种方法<strong>可靠性很强</strong>。而且我相信各位读者所在的公司一定不是什么很牛逼的互联网公司，如果你们的产品凌晨1点的用户活跃数还有超过1000的，你们握个爪！毕竟不是所有人都在什么电商公司的，<strong>大部分产品半夜都没啥流量</strong>。所以此方案，并非没有可取之处。<br>&nbsp;&nbsp;&nbsp;&nbsp;但是此方案有一个缺点，<strong>累！</strong>不止身体累，心也累！你想想看，本来定六点结束，你五点把数据库迁移好，但是不知怎么滴，程序切新库就是有点问题。于是，眼瞅着天就要亮了，赶紧把数据库切回老库。第二个晚上继续这么干，简直是身心俱疲。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<code>ps：</code>这里教大家一些技巧啊，如果你真的没做过分库分表，又想吹一波，涨一下工资，建议答这个方案。因为这个方案比较low，low到没什么东西可以深挖的，所以答这个方案，比较靠谱。</p>
<p>另外，如果面试官的问题是</p>
<blockquote>
<p><strong>你们怎么进行分库分表的？</strong></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这个问题问的很泛，所以回答这个问题建议自己<strong>主动把分表的策略，以及如何部署的方法讲出来</strong>。因为这么答，显得严谨一些。<br>&nbsp;&nbsp;&nbsp;&nbsp;不过，很多面试官为了卖弄自己的技术，喜欢这么问</p>
<blockquote>
<p><strong>分表有哪些策略啊？你们用哪种啊？</strong></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;ok。。这个问题具体指向了分库分表的某个方向了，你不要主动答如何进行部署的。等面试官问你，你再答。如果面试官没问，在面试最后一个环节，面试官会让你问让几个问题。你就问</p>
<blockquote>
<p><strong>你刚才刚好有提到分库分表的相关问题，我们当时部署的时候，先停机。然后半夜迁移数据，然后第二天将流量切到新库，这种方案太累，不知道贵公司有没有什么更好的方案？</strong></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;那么这种情况下，面试官会有两种回答。第一种，面试官硬着头皮随便扯。第二种，面试官真的做过，据实回答。记住，面试官怎么回答的不重要。重点的是，你这个问题出去，会给面试官一种错觉:”这个小伙子真的做过分库分表。”</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;如果你担心进去了，真派你去做分库分表怎么办？OK，不要怕。我赌你试用期碰不到这个活。因为能进行分库分表，必定对业务非常熟。还在试用期的你，必定对业务不熟，如果领导给你这种活，我只能说他有一颗大心脏。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;ok，指点到这里。面试本来就是一场斗智斗勇的过程，扯远了，回到我们的主题。</p>
<h3 id="旧数据直接迁移-消息队列缓存"><a href="#旧数据直接迁移-消息队列缓存" class="headerlink" title="旧数据直接迁移 + 消息队列缓存"></a>旧数据直接迁移 + 消息队列缓存</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;这个就是不停机部署法，这里我需要先引进两个概念:<strong>历史数据</strong>和<strong>增量数据</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;假设，我们是对一张叫做<code>test_tb</code>的表进行拆分，因为你要进行双写，系统里头和<code>test_tb</code>表有关的业务之前必定会加入一段双写代码，同时往老库和消息队列中写，然后进行部署，那么</p>
<p><strong>历史数据</strong>:在该次部署前，数据库表<code>test_tb</code>的有关数据，我们称之为历史数据。<br><strong>增量数据</strong>:在该次部署后，数据库表<code>test_tb</code>的新产生的数据，我们称之为增量数据。</p>
<p>然后迁移流程如下：<br>(1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先计算你要迁移的那张表的<code>max(主键)</code>。在迁移过程中，只迁移<code>db-old</code>中<code>test_tb</code>表里，<strong>主键小等于该<code>max(主键)</code>的值，也就是所谓的历史数据</strong>。<br>&nbsp;&nbsp;&nbsp;&nbsp;这里有特殊情况，如果你的表用的是uuid，没法求出<code>max(主键)</code>，那就<strong>以创建时间作为划分历史数据和增量数据的依据</strong>。如果你的表用的是uuid,又没有创建时间这个字段，我相信机智的你，一定有办法区分出历史数据和增量数据。</p>
<p>(2) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在代码中，与<code>test_tb</code>有关的业务，<strong>多加一条往消息队列中发消息的代码，将操作的sql发送到消息队列中</strong>，至于消息体如何组装，大家自行考虑。需要注意的是，只发写请求的sql，只发写请求的sql，只发写请求的sql。重要的事情说三遍！</p>
<p>原因有二:</p>
<ul>
<li>(1)<strong>只有写请求的sql对恢复数据才有用</strong>。</li>
<li>(2)系统中，绝大部分的业务需求是读请求，<strong>写请求比较少</strong>。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;注意了，在这个阶段，我们<strong>不消费消息队列里的数据</strong>。我们只发写请求，消息队列的消息堆积情况不会太严重！</p>
<p>(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;系统上线。另外，写一段迁移程序，迁移<code>db-old</code>中<code>test_tb</code>表里，主键小于该<code>max(主键)</code>的数据，也就是所谓的历史数据。<br>上面步骤(1)～步骤(3)的过程如下<br><img src="//blog.com/2019/03/22/分库分表后如何部署上线/2.png" alt="image"><br>等到<code>db-old</code>中的<strong>历史数据迁移完毕，则开始迁移增量数据</strong>，也就是在消息队列里的数据。</p>
<p>(4)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将迁移程序下线，写一段订阅程序订阅消息队列中的数据</p>
<p>(5)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;订阅程序将订阅到到数据，通过中间件写入新库</p>
<p>(6)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;新老库一致性验证，去除代码中的写消息队列代码，将涉及到<code>test_tb</code>表的读写操作，指向新库。<strong>注意一点：这里的切换可能仍然要停机几分钟</strong></p>
<p>上面步骤(4)～步骤(6)的过程如下<br><img src="//blog.com/2019/03/22/分库分表后如何部署上线/3.png" alt="image"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这里大家可能会有一个问题，在步骤(1)～步骤(3),系统对历史数据进行操作，会造成不一致的问题么？<br>OK，不会。这里我们对<code>delete</code>操作和<code>update</code>操作做分析，因为只有这两个操作才会造成历史数据变动，<code>insert</code>进去的数据都是属于增量数据。</p>
<p>(1)对<code>db-old</code>的<code>test_tb</code>表的历史数据发出<code>delete</code>操作，数据还未删除，就被迁移程序给迁走了。此时<code>delete</code>操作在消息队列里还有记录，后期订阅程序订阅到该<code>delete</code>操作，可以进行删除。</p>
<p>(2)对<code>db-old</code>的<code>test_tb</code>表的历史数据发出<code>delete</code>操作，数据已经删除，迁移程序迁不走该行数据。此时<code>delete</code>操作在消息队列里还有记录，后期订阅程序订阅到该<code>delete</code>操作，再执行一次<code>delete</code>，并不会对一致性有影响。<br>对<code>update</code>的操作类似，不赘述。</p>
<h3 id="旧数据直接迁移-订阅binlog"><a href="#旧数据直接迁移-订阅binlog" class="headerlink" title="旧数据直接迁移 + 订阅binlog"></a>旧数据直接迁移 + 订阅binlog</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;上面的方法有一个硬伤，注意我有一句话</p>
<blockquote>
<p><strong>(2)在代码中，与test_tb有关的业务，多加一条往消息队列中发消息的代码，将操作的sql发送到消息队列中，至于消息体如何组装，大家自行考虑。</strong></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;大家想一下，这么做，是不是造成了严重的<strong>代码入侵</strong>。将非业务代码嵌入业务代码，这么做，后期删代码的时候特别累。</p>
<p><strong>有没什么方法，可以避免这个问题的?</strong></p>
<blockquote>
<p><strong>记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志。binlog不会记录SELECT和SHOW这类操作，因为这类操作对据本身并没有修改。</strong></p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;在方法二中，往消息队列里发的消息，都是写操作的消息。而<strong><code>binlog</code>日志记录的也是写操作</strong>。所以订阅该日志，也能满足我们的需求。<br>步骤如下：<br>(1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;打开binlog日志，系统正常上线就好。<strong>刷新log日志,自此刻开始产生一个新编号的<em>binlog</em>日志文件 </strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; flush logs;</span><br></pre></td></tr></table></figure>
<p>(2)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;还是写一个迁移程序，迁移历史数据。步骤和上面类似，不啰嗦了。</p>
<p>步骤(1)~步骤(2)流程图如下<br><img src="//blog.com/2019/03/22/分库分表后如何部署上线/4.png" alt="image"><br>(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;写一个订阅程序，订阅binlog(mysql中有<code>canal</code>)。然后将订阅到到数据通过中间件，写入新库。</p>
<p>(4)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;检验一致性，没问题就切库。<strong>注意一点：这里的切换可能仍然要停机几分钟</strong></p>
<p>步骤(3)~步骤(4)流程图如下<br><img src="//blog.com/2019/03/22/分库分表后如何部署上线/5.png" alt="image"></p>
<h3 id="怎么验数据一致性"><a href="#怎么验数据一致性" class="headerlink" title="怎么验数据一致性"></a>怎么验数据一致性</h3><p>(1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先验<strong>数量是否一致</strong>，因为验数量比较快。</p>
<p>至于验具体的字段，有两种方法:</p>
<p>(2.1)有一种方法是，只<strong>验关键性的几个字段是否一致</strong>。</p>
<p>(2.2)还有一种是 ，一次取50条(不一定50条，具体自己定，我只是举例),然后像拼字符串一样，拼在一起。用md5进行加密，得到一串数值。新库一样如法炮制，也得到一串数值，比较两串数值是否一致。如果一致，继续比较下50条数据。如果发现不一致，用二分法确定不一致的数据在0-25条，还是26条-50条。以此类推，找出不一致的数据，进行记录即可。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/112/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/112/">112</a><span class="page-number current">113</span><a class="page-number" href="/page/114/">114</a><span class="space">&hellip;</span><a class="page-number" href="/page/147/">147</a><a class="extend next" rel="next" href="/page/114/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">刘泽明</p>
              <p class="site-description motion-element" itemprop="description">做一个懂业务的程序员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">731</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">394</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">237</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘泽明</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
