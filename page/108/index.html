<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="搬运工 + 践行者" type="application/atom+xml">






<meta name="description" content="做一个懂业务的程序员">
<meta property="og:type" content="website">
<meta property="og:title" content="搬运工 + 践行者">
<meta property="og:url" content="http://blog.com/page/108/index.html">
<meta property="og:site_name" content="搬运工 + 践行者">
<meta property="og:description" content="做一个懂业务的程序员">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="搬运工 + 践行者">
<meta name="twitter:description" content="做一个懂业务的程序员">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.com/page/108/">





  <title>搬运工 + 践行者</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">搬运工 + 践行者</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">记录学习的技能和遇到的问题</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/30/缓存穿透、缓存击穿、缓存雪崩、热点数据失效/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/缓存穿透、缓存击穿、缓存雪崩、热点数据失效/" itemprop="url">缓存穿透、缓存击穿、缓存雪崩、热点数据失效</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-30T12:12:57+08:00">
                2019-03-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/架构/缓存/" itemprop="url" rel="index">
                    <span itemprop="name">缓存</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="缓存穿透、缓存击穿、缓存雪崩、热点数据失效"><a href="#缓存穿透、缓存击穿、缓存雪崩、热点数据失效" class="headerlink" title="缓存穿透、缓存击穿、缓存雪崩、热点数据失效"></a>缓存穿透、缓存击穿、缓存雪崩、热点数据失效</h1><h2 id="业务系统的调用流程"><a href="#业务系统的调用流程" class="headerlink" title="业务系统的调用流程"></a>业务系统的调用流程</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;当我们查询一条数据时，先去查询缓存，如果缓存有就直接返回，如果没有就去查询数据库，然后返回并写入缓存。</p>
<p><img src="//blog.com/2019/03/30/缓存穿透、缓存击穿、缓存雪崩、热点数据失效/1.png" alt=""></p>
<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><h3 id="什么是缓存穿透？"><a href="#什么是缓存穿透？" class="headerlink" title="什么是缓存穿透？"></a>什么是缓存穿透？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;正常情况下，我们去查询数据都是只有两种可能：</p>
<ol>
<li><p>缓存存在，取出，理想情况</p>
</li>
<li><p>缓存不存在，查询数据库，取出数据，写入缓存</p>
</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;若请求去查询一条压根儿数据库中根本就不存在的数据，也就是<strong>缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去</strong>。</p>
<p>结果：<strong>数据库由于压力过大而宕掉</strong></p>
<h3 id="如何解决缓存穿透？"><a href="#如何解决缓存穿透？" class="headerlink" title="如何解决缓存穿透？"></a>如何解决缓存穿透？</h3><h4 id="缓存空对象"><a href="#缓存空对象" class="headerlink" title="缓存空对象"></a>缓存空对象</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都到数据库去了。</p>
<p>可以<strong>把这些key设置为null 丢到缓存里面去，并且设置一个过期时间</strong>。后面再出现查询这个key 的请求的时候，直接返回null 。这样，就不用在到数据库去查询了。</p>
<h4 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;BloomFilter 类似于一个set ，用来判断某个元素（key）是否存在于某个集合中。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;在缓存之前在加一层 BloomFilter ，将所有可能存在的数据缓存放到布隆过滤器中，当访问不存在的缓存时迅速返回，避免缓存及DB挂掉。在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回null，存在再走查缓存 -&gt; 查 DB。</p>
<p><img src="//blog.com/2019/03/30/缓存穿透、缓存击穿、缓存雪崩、热点数据失效/2.png" alt=""></p>
<hr>
<p>&nbsp;&nbsp;&nbsp;&nbsp;针对于一些恶意攻击，攻击带过来的大量key 是不存在的，那么我们采用第一种方案就会缓存大量不存在key的数据。此时我们采用第一种方案就不合适了，我们完全可以先对使用第二种方案进行过滤掉这些key。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;针对这种key异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;而对于空数据的key有限的，重复率比较高的，我们则可以采用第一种方式进行缓存。</p>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><h4 id="什么是缓存击穿？"><a href="#什么是缓存击穿？" class="headerlink" title="什么是缓存击穿？"></a>什么是缓存击穿？</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;在平常高并发的系统中，<strong>大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去</strong>。这种现象我们称为缓存击穿。</p>
<p>结果：<strong>会造成某一时刻数据库请求量过大，压力剧增</strong></p>
<h4 id="如何解决缓存击穿？"><a href="#如何解决缓存击穿？" class="headerlink" title="如何解决缓存击穿？"></a>如何解决缓存击穿？</h4><h5 id="设置不同的失效时间"><a href="#设置不同的失效时间" class="headerlink" title="设置不同的失效时间"></a>设置不同的失效时间</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>在设置缓存有效时间时，添加一个随机值</strong></p>
<h5 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h5><p>​    在发现缓存不存在时，首先进行加锁，然后再进行数据库查询。其它请求在发现锁存在时，休眠n秒，然后再去请求缓存，拿取数据。    </p>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><h3 id="什么是缓存雪崩？"><a href="#什么是缓存雪崩？" class="headerlink" title="什么是缓存雪崩？"></a>什么是缓存雪崩？</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;当某一时刻<strong>发生大规模的缓存失效的情况</strong>，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面。</p>
<p>结果：<strong>所有的查询请求压力都压到了数据库</strong></p>
<h3 id="如何解决缓存雪崩？"><a href="#如何解决缓存雪崩？" class="headerlink" title="如何解决缓存雪崩？"></a>如何解决缓存雪崩？</h3><h4 id="缓存高可用"><a href="#缓存高可用" class="headerlink" title="缓存高可用"></a>缓存高可用</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>使用集群缓存，保证缓存服务的高可用</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>使用 主从+哨兵 ，Redis Cluster 来避免 Redis 全盘崩溃的情况</strong></p>
<h4 id="多级缓存"><a href="#多级缓存" class="headerlink" title="多级缓存"></a>多级缓存</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;对于访问频率特别高的数据，可以加入<strong>本地缓存</strong>。如：java的ehcache 、php的apc</p>
<h4 id="限流降级策略"><a href="#限流降级策略" class="headerlink" title="限流降级策略"></a>限流降级策略</h4><p>一个网上朋友的图，几种策略结合使用：</p>
<p><img src="//blog.com/2019/03/30/缓存穿透、缓存击穿、缓存雪崩、热点数据失效/3.png" alt=""></p>
<h2 id="热点数据集中失效问题"><a href="#热点数据集中失效问题" class="headerlink" title="热点数据集中失效问题"></a>热点数据集中失效问题</h2><h5 id="设置不同的失效时间-1"><a href="#设置不同的失效时间-1" class="headerlink" title="设置不同的失效时间"></a>设置不同的失效时间</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>在设置缓存有效时间时，添加一个随机值</strong></p>
<h5 id="互斥锁-1"><a href="#互斥锁-1" class="headerlink" title="互斥锁"></a>互斥锁</h5><p>​    在发现缓存不存在时，首先进行加锁，然后再进行数据库查询。其它请求在发现锁存在时，休眠n秒，然后再去请求缓存，拿取数据。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/30/Redis过期策略及实现原理/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/Redis过期策略及实现原理/" itemprop="url">Redis过期策略及实现原理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-30T12:12:57+08:00">
                2019-03-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Redis过期策略及实现原理"><a href="#Redis过期策略及实现原理" class="headerlink" title="Redis过期策略及实现原理"></a>Redis过期策略及实现原理</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;我们在使用redis时，一般会设置一个过期时间，当然也有不设置过期时间的，也就是永久不过期。</p>
<p>当我们设置了过期时间，redis是如何判断是否过期，以及根据什么策略来进行删除的。</p>
<h2 id="redis设置过期时间："><a href="#redis设置过期时间：" class="headerlink" title="redis设置过期时间："></a>redis设置过期时间：</h2><p><strong>expire key time(以秒为单位)–这是最常用的方式</strong></p>
<p><strong>setex(String key, int seconds, String value)–字符串独有的方式</strong></p>
<blockquote>
<p>注：</p>
<p>   除了字符串自己独有设置过期时间的方法外，其他方法都需要依靠expire方法来设置时间</p>
<p>   如果没有设置时间，那缓存就是永不过期</p>
<p>   如果设置了过期时间，之后又想让缓存永不过期，使用persist key</p>
</blockquote>
<h2 id="三种过期策略："><a href="#三种过期策略：" class="headerlink" title="三种过期策略："></a>三种过期策略：</h2><h3 id="定时删除"><a href="#定时删除" class="headerlink" title="定时删除"></a>定时删除</h3><p><strong>含义：</strong>在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除</p>
<p><strong>优点：</strong>保证内存被尽快释放</p>
<p><strong>缺点：</strong></p>
<ul>
<li>若过期key很多，删除这些key会占用很多的CPU时间，在CPU时间紧张的情况下，CPU不能把所有的时间用来做要紧的事儿，还需要去花时间删除这些key</li>
<li>定时器的创建耗时，若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生），性能影响严重</li>
</ul>
<h3 id="懒汉式式删除"><a href="#懒汉式式删除" class="headerlink" title="懒汉式式删除"></a>懒汉式式删除</h3><p><strong>含义：</strong>key过期的时候不删除，每次通过key获取值的时候去检查是否过期，若过期，则删除，返回null。</p>
<p><strong>优点：</strong>删除操作只发生在通过key取值的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了）</p>
<p><strong>缺点：</strong>若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存）</p>
<h3 id="定期删除"><a href="#定期删除" class="headerlink" title="定期删除"></a>定期删除</h3><p><strong>含义：</strong>每隔一段时间执行一次删除过期key操作</p>
<p><strong>优点：</strong></p>
<ul>
<li>通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用–处理”定时删除”的缺点</li>
<li>定期删除过期key–处理”懒汉式删除”的缺点</li>
</ul>
<p><strong>缺点：</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;在内存友好方面，不如”定时删除”（会造成一定的内存占用，但是没有懒汉式那么占用内存）  在CPU时间友好方面，不如”懒汉式删除”（会定期的去进行比较和删除操作，cpu方面不如懒汉式，但是比定时好）</p>
<p><strong>难点：</strong>合理设置删除操作的执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除）（这个要根据服务器运行情况来定了），每次执行时间太长，或者执行频率太高对cpu都是一种压力。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>每次进行定期删除操作执行之后，需要记录遍历循环到了哪个标志位，以便下一次定期时间来时，从上次位置开始进行循环遍历</strong></p>
<blockquote>
<p><strong>说明：</strong> memcached只是用了惰性删除，而redis同时使用了惰性删除与定期删除，这也是二者的一个不同点（可以看做是redis优于memcached的一点）；</p>
<p>​     对于懒汉式删除而言，并不是只有获取key的时候才会检查key是否过期，在某些设置key的方法上也会检查（eg.setnx key2 value2：该方法类似于memcached的add方法，如果设置的key2已经存在，那么该方法返回false，什么都不做；如果设置的key2不存在，那么该方法设置缓存key2-value2。假设调用此方法的时候，发现redis中已经存在了key2，但是该key2已经过期了，如果此时不执行删除操作的话，setnx方法将会直接返回false，也就是说此时并没有重新设置key2-value2成功，所以对于一定要在setnx执行之前，对key2进行过期检查）。</p>
</blockquote>
<h2 id="Redis采用的过期策略"><a href="#Redis采用的过期策略" class="headerlink" title="Redis采用的过期策略"></a>Redis采用的过期策略</h2><h3 id="懒汉式删除-定期删除"><a href="#懒汉式删除-定期删除" class="headerlink" title="懒汉式删除+定期删除"></a>懒汉式删除+定期删除</h3><h4 id="懒汉式删除流程："><a href="#懒汉式删除流程：" class="headerlink" title="懒汉式删除流程："></a>懒汉式删除流程：</h4><ul>
<li>在进行get或setnx等操作时，先检查key是否过期；</li>
<li>若过期，删除key，然后执行相应操作；</li>
<li>若没过期，直接执行相应操作；</li>
</ul>
<h4 id="定期删除流程（简单而言，对指定个数个库的每一个库随机删除小于等于指定个数个过期key）："><a href="#定期删除流程（简单而言，对指定个数个库的每一个库随机删除小于等于指定个数个过期key）：" class="headerlink" title="定期删除流程（简单而言，对指定个数个库的每一个库随机删除小于等于指定个数个过期key）："></a>定期删除流程（简单而言，对指定个数个库的每一个库随机删除小于等于指定个数个过期key）：</h4><ul>
<li>遍历每个数据库（就是redis.conf中配置的”database”数量，默认为16）</li>
<li>检查当前库中的指定个数个key（默认是每个库检查20个key，注意相当于该循环执行20次，循环体是下边的描述）</li>
<li>如果当前库中没有一个key设置了过期时间，直接执行下一个库的遍历</li>
<li>随机获取一个设置了过期时间的key，检查该key是否过期，如果过期，删除key</li>
<li>判断定期删除操作是否已经达到指定时长，若已经达到，直接退出定期删除。</li>
</ul>
<p>​    对于定期删除，在程序中有一个全局变量current_db来记录下一个将要遍历的库，假设有16个库，我们这一次定期删除遍历了10个，那此时的current_db就是11，下一次定期删除就从第11个库开始遍历，假设current_db等于15了，那么之后遍历就再从0号库开始（此时current_db==0）</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;在实际中，如果我们要自己设计过期策略，<strong>在使用懒汉式删除+定期删除时，控制时长和频率这个尤为关键，需要结合服务器性能，已经并发量等情况进行调整，以致最佳。</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/30/什么是Zero-Copy？/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/什么是Zero-Copy？/" itemprop="url">什么是Zero-Copy？</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-30T12:12:57+08:00">
                2019-03-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/系统调优/" itemprop="url" rel="index">
                    <span itemprop="name">系统调优</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/系统调优/网络编程/" itemprop="url" rel="index">
                    <span itemprop="name">网络编程</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="什么是Zero-Copy？"><a href="#什么是Zero-Copy？" class="headerlink" title="什么是Zero-Copy？"></a>什么是Zero-Copy？</h1><blockquote>
<p>原文地址：<a href="https://blog.csdn.net/u013256816/article/details/52589524/" target="_blank" rel="noopener">https://blog.csdn.net/u013256816/article/details/52589524/</a></p>
</blockquote>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="先从Linux的普通I-O过程说起"><a href="#先从Linux的普通I-O过程说起" class="headerlink" title="先从Linux的普通I/O过程说起"></a>先从Linux的普通I/O过程说起</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;考虑这样一种常用的情形：你需要将静态内容（类似图片、文件）展示给用户。那么这个情形就意味着你需要先将静态内容从磁盘中拷贝出来放到一个内存buf中，然后将这个buf通过socket传输给用户，进而用户或者静态内容的展示。这看起来再正常不过了，但是实际上这是很低效的流程，我们把上面的这种情形抽象成下面的过程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">read(file, tmp_buf, len);</span><br><span class="line">write(socket, tmp_buf, len);</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;首先调用read将静态内容，这里假设为文件A，读取到tmp_buf, 然后调用write将tmp_buf写入到socket中，如图：</p>
<p><img src="//blog.com/2019/03/30/什么是Zero-Copy？/1.png" alt="图片"></p>
<ol>
<li>首先，调用read时，文件A拷贝到了kernel模式；</li>
<li>之后，CPU控制将kernel模式数据copy到user模式下；</li>
<li>调用write时，先将user模式下的内容copy到kernel模式下的socket的buffer中；</li>
<li>最后将kernel模式下的socket buffer的数据copy到网卡设备中传送；</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;从上面的过程可以看出，数据白白从kernel模式到user模式走了一圈，浪费了2次copy(<strong>第一次，从kernel模式拷贝到user模式；第二次从user模式再拷贝回kernel模式，即上面4次过程的第2和3步骤</strong>)。而且上面的过程中kernel和user模式的上下文的切换也是4次。</p>
<blockquote>
<ol>
<li>程序使用read()系统调用，系统由用户态转换为内核态，磁盘中的数据由DMA（Direct memory access）的方式读取到内核读缓冲区（kernel buffer）。DMA过程中CPU不需要参与数据的读写，而是DMA处理器直接将硬盘数据通过总线传输到内核读缓冲区中。</li>
<li>系统由内核态转为用户态，当程序要读的数据已经完全存入内核读缓冲区以后，程序会将数据由内核读缓冲区，写入到用户缓冲区，这个过程需要CPU参与数据的读写。</li>
<li>程序使用write()系统调用，系统由用户态切换到内核态，数据从用户缓冲区写入到网络缓冲区（Socket Buffer），这个过程需要CPU参与数据的读写。</li>
<li>系统由内核态切换到用户态，网络缓冲区的数据通过DMA的方式传输到网卡的驱动（存储缓冲区）中（protocol engine）</li>
</ol>
<p>​    可以看到，普通的拷贝过程经历了四次内核态和用户态的切换（上下文切换），两次CPU从内存中进行数据的读写过程，这种拷贝过程相对来说比较消耗系统资源。</p>
</blockquote>
<h3 id="内存映射方式I-O"><a href="#内存映射方式I-O" class="headerlink" title="内存映射方式I/O"></a>内存映射方式I/O</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmp_buf = mmap(file, len);</span><br><span class="line">write(socket, tmp_buf, len);</span><br></pre></td></tr></table></figure>
<p><img src="//blog.com/2019/03/30/什么是Zero-Copy？/7.png" alt=""></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这是使用的系统调用方法，这种方式的I/O原理就是<strong>将用户缓冲区（user buffer）的内存地址和内核缓冲区（kernel buffer）的内存地址做一个映射，也就是说系统在用户态可以直接读取并操作内核空间的数据</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;mmap()系统调用首先会使用DMA的方式将磁盘数据读取到内核缓冲区，然后通过内存映射的方式，使用户缓冲区和内核读缓冲区的内存地址为同一内存地址，也就是说<strong>不需要CPU再讲数据从内核读缓冲区复制到用户缓冲区</strong>。<br>&nbsp;&nbsp;&nbsp;&nbsp;当使用write()系统调用的时候，cpu将内核缓冲区（等同于用户缓冲区）的数据直接写入到网络发送缓冲区（socket buffer），然后通过DMA的方式将数据传入到网卡驱动程序中准备发送。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;可以看到这种内存映射的方式<strong>减少了CPU的读写次数</strong>，但是用户态到内核态的切换（上下文切换）依旧有四次，同时需要注意在进行这种内存映射的时候，有可能会出现并发线程操作同一块内存区域而导致的严重的数据不一致问题，所以需要进行合理的并发编程来解决这些问题。</p>
<h3 id="理想状态下的零拷贝I-O"><a href="#理想状态下的零拷贝I-O" class="headerlink" title="理想状态下的零拷贝I/O"></a>理想状态下的零拷贝I/O</h3><p><img src="//blog.com/2019/03/30/什么是Zero-Copy？/8.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sendfile(socket, file, len);</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;通过sendfile()系统调用，可以做到内核空间内部直接进行I/O传输。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;sendfile()系统调用也会引起用户态到内核态的切换，与内存映射方式不同的是，<strong>用户空间此时是无法看到或修改数据内容</strong>，也就是说这是一次完全意义上的数据传输过程。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;从磁盘读取到内核读缓冲区是DMA的方式，<strong>从内核读缓冲区读取到网络发送缓冲区，依旧需要CPU参与拷贝</strong>，而从网络发送缓冲区到网卡中的缓冲区依旧是DMA方式。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>内核读缓冲区依旧有一次CPU进行数据拷贝，两次用户态和内核态的切换操作</strong>，相比较于内存映射的方式有了很大的进步，但问题是程序不能对数据进行修改，而只是单纯地进行了一次数据的传输过程。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;幸运的是，你可以用一种叫做Zero-Copy的技术来去掉这些无谓的copy。应用程序用<strong>Zero-Copy来请求kernel直接把disk的data传输给socket，而不是通过应用程序传输</strong>。Zero-Copy大大提高了应用程序的性能，并且减少了kernel和user模式上下文的切换。</p>
<hr>
<h2 id="详述"><a href="#详述" class="headerlink" title="详述"></a>详述</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;Zero-Copy技术<strong>省去了将操作系统的read buffer拷贝到程序的buffer，以及从程序buffer拷贝到socket buffer的步骤，直接将read buffer拷贝到socket buffer</strong>. </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Java NIO中的FileChannal.transferTo()方法就是这样的实现，这个实现是依赖于操作系统底层的sendFile()实现的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public void transferTo(long position, long count, WritableByteChannel target);</span><br></pre></td></tr></table></figure>
<p>他底层的调用时系统调用<strong>sendFile()</strong>方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;sys/socket.h&gt;</span><br><span class="line">ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);</span><br></pre></td></tr></table></figure>
<p>下图展示了在transferTo()之后的数据流向：</p>
<p><img src="//blog.com/2019/03/30/什么是Zero-Copy？/2.png" alt="图片"></p>
<p>下图展示了在使用transferTo()之后的上下文切换：</p>
<p><img src="//blog.com/2019/03/30/什么是Zero-Copy？/3.png" alt="图片"></p>
<p>使用了Zero-Copy技术之后，整个过程如下：</p>
<ol>
<li>transferTo()方法使得文件A的内容直接拷贝到一个read buffer（kernel buffer）中；</li>
<li>然后数据(kernel buffer)拷贝到socket buffer中。</li>
<li>最后将socket buffer中的数据拷贝到网卡设备（protocol engine）中传输； 这显然是一个伟大的进步：这里把<strong>上下文的切换次数从4次减少到2次，同时也把数据copy的次数从4次降低到了3次</strong>。</li>
</ol>
<p>但是这是Zero-Copy么，答案是否定的。</p>
<hr>
<h2 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h2><p>Linux 2.1内核开始引入了sendfile函数（上一节有提到）,用于将文件通过socket传送。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sendfile(socket, file, len);</span><br></pre></td></tr></table></figure>
<p>该函数通过一次系统调用完成了文件的传送，减少了原来read/write方式的模式切换。此外更是减少了数据的copy, sendfile的详细过程如图：</p>
<p><img src="//blog.com/2019/03/30/什么是Zero-Copy？/4.png" alt="图片"></p>
<ol>
<li>首先（通过DMA）将数据从磁盘读取到kernel buffer中；</li>
<li>然后将kernel buffer拷贝到socket buffer中；</li>
<li>最后将socket buffer中的数据copy到网卡设备（protocol engine）中发送；</li>
</ol>
<p>这个过程就是第二节（详述）中的那个步骤。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;sendfile与read/write模式相比，少了一次copy。但是从上述过程中也可以发现<strong>从kernel buffer中将数据copy到socket buffer是没有必要的</strong>。</p>
<p>Linux2.4 内核对sendfile做了改进，如图：</p>
<p><img src="//blog.com/2019/03/30/什么是Zero-Copy？/5.png" alt="图片"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;可以看到，这是<strong>真正意义上的零拷贝，因为其间CPU已经不参与数据的拷贝过程</strong>，也就是说完全通过其他硬件和中断的方式来实现数据的读写过程吗，但是这样的过程<strong>需要硬件的支持才能实现</strong>。</p>
<blockquote>
<p>借助于硬件上的帮助，我们是可以办到的。之前我们是把页缓存的数据拷贝到socket缓存中，实际上，我们<strong>仅仅需要把缓冲区描述符传到socket缓冲区，再把数据长度传过去，这样DMA控制器直接将页缓存中的数据打包发送到网络中就可以了</strong>。</p>
</blockquote>
<blockquote>
<p>可以看到在这种模式下，是没有一次CPU进行数据拷贝的，所以就做到了真正意义上的零拷贝，虽然和前一种是同一个系统调用，但是这种模式实现起来需要硬件的支持，但对<strong>于基于操作系统的用户来讲，操作系统已经屏蔽了这种差异，它会根据不同的硬件平台来实现这个系统调用</strong></p>
</blockquote>
<p>改进后的处理过程如下：</p>
<ol>
<li><p><strong>将文件拷贝到kernel buffer中</strong>；</p>
</li>
<li><p>向socket buffer中追加当前要发生的数据在kernel buffer中的位置和偏移量；</p>
</li>
<li><p>根据socket buffer中的位置和偏移量直接<strong>将kernel buffer的数据copy到网卡设备（protocol engine）中</strong>；</p>
</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;经过上述过程，数据只经过了<strong>2次copy</strong>就从磁盘传送出去了。这个才是真正的Zero-Copy(<strong>这里的零拷贝是针对kernel来讲的，数据在kernel模式下是Zero-Copy</strong>)。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;系统调用sendfile()发起后，磁盘数据通过DMA方式读取到内核缓冲区，<strong>内核缓冲区中的数据通过DMA聚合网络缓冲区，然后一齐发送到网卡中</strong>。</p>
<p>正是Linux2.4的内核做了改进，Java中的TransferTo()实现了Zero-Copy,如下图：</p>
<p><img src="//blog.com/2019/03/30/什么是Zero-Copy？/6.png" alt="图片"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Zero-Copy技术的使用场景有很多，比如Kafka, 又或者是Netty等，可以大大提升程序的性能。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/30/秒杀系统架构优化思路/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/秒杀系统架构优化思路/" itemprop="url">秒杀系统架构优化思路</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-30T12:12:57+08:00">
                2019-03-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/架构/秒杀/" itemprop="url" rel="index">
                    <span itemprop="name">秒杀</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="秒杀系统架构优化思路"><a href="#秒杀系统架构优化思路" class="headerlink" title="秒杀系统架构优化思路"></a>秒杀系统架构优化思路</h1><p><br></p>
<blockquote>
<p>参考地址：<a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651959391&amp;idx=1&amp;sn=fb28fd5e5f0895ddb167406d8a735548&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651959391&amp;idx=1&amp;sn=fb28fd5e5f0895ddb167406d8a735548&amp;scene=21#wechat_redirect</a><br><br></p>
</blockquote>
<h2 id="一、秒杀业务为什么难做"><a href="#一、秒杀业务为什么难做" class="headerlink" title="一、秒杀业务为什么难做"></a>一、秒杀业务为什么难做</h2><p>1）im系统，例如qq或者微博，每个人都读自己的数据（好友列表、群列表、个人信息）；</p>
<p>2）微博系统，每个人读你关注的人的数据，一个人读多个人的数据；</p>
<p>3）秒杀系统，库存只有一份，所有人会在集中的时间读和写这些数据，多个人读一个数据。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;例如：小米手机每周二的秒杀，可能手机只有1万部，但瞬时进入的流量可能是几百几千万。</p>
<p>又例如：12306抢票，票是有限的，库存一份，瞬时流量非常多，都读相同的库存。<strong>读写冲突，锁非常严重，这是秒杀业务难的地方</strong>。那我们怎么优化秒杀业务的架构呢？</p>
<h2 id="二、优化方向"><a href="#二、优化方向" class="headerlink" title="二、优化方向"></a><strong>二、优化方向</strong></h2><p>（1）<strong>将请求尽量拦截在系统上游</strong>（不要让锁冲突落到数据库上去）。传统秒杀系统之所以挂，请求都压倒了后端数据层，数据读写锁冲突严重，并发高响应慢，几乎所有请求都超时，流量虽大，下单成功的有效流量甚小。以12306为例，一趟火车其实只有2000张票，200w个人来买，基本没有人能买成功，请求有效率为0。</p>
<p>（2）<strong>充分利用缓存</strong>，秒杀买票，这是一个典型的<strong>读多写少</strong>的应用场景，大部分请求是车次查询，票查询，下单和支付才是写请求。一趟火车其实只有2000张票，200w个人来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%，非常适合使用缓存来优化。</p>
<h2 id="三、常见秒杀架构"><a href="#三、常见秒杀架构" class="headerlink" title="三、常见秒杀架构"></a><strong>三、常见秒杀架构</strong></h2><p>常见的站点架构基本是这样的（绝对不画忽悠类的架构图）</p>
<p><img src="//blog.com/2019/03/30/秒杀系统架构优化思路/1.webp" alt="img"></p>
<p>（1）<strong>浏览器端</strong>，最上层，会执行到一些JS代码</p>
<p>（2）<strong>站点层</strong>，这一层会访问后端数据，拼html页面返回给浏览器</p>
<p>（3）<strong>服务层</strong>，向上游屏蔽底层数据细节，提供数据访问</p>
<p>（4）<strong>数据层</strong>，最终的库存是存在这里的，mysql是一个典型（当然还有会缓存）</p>
<h2 id="四、各层次优化细节"><a href="#四、各层次优化细节" class="headerlink" title="四、各层次优化细节"></a><strong>四、各层次优化细节</strong></h2><h3 id="第一层，客户端怎么优化（浏览器层，APP层）"><a href="#第一层，客户端怎么优化（浏览器层，APP层）" class="headerlink" title="第一层，客户端怎么优化（浏览器层，APP层）"></a>第一层，客户端怎么优化（浏览器层，APP层）</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;问大家一个问题，大家都玩过微信的摇一摇抢红包对吧，每次摇一摇，就会往后端发送请求么？回顾我们下单抢票的场景，点击了“查询”按钮之后，系统那个卡呀，进度条涨的慢呀，作为用户，我会不自觉的再去点击“查询”，对么？继续点，继续点，点点点。。。有用么？平白无故的增加了系统负载，一个用户点5次，80%的请求是这么多出来的，怎么整？</p>
<p>（a）<strong>产品层面</strong>，用户点击“查询”或者“购票”后，<strong>按钮置灰，禁止用户重复提交请求</strong>；</p>
<p>（b）<strong>JS层面</strong>，<strong>限制用户在x秒之内只能提交一次请求</strong>；</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;APP层面，可以做类似的事情，虽然你疯狂的在摇微信，其实x秒才向后端发起一次请求。这就是所谓的“将请求尽量拦截在系统上游”，越上游越好，浏览器层，APP层就给拦住，这样就能挡住80%+的请求，这种办法只能拦住普通用户（但99%的用户是普通用户）对于群内的高端程序员是拦不住的。firebug一抓包，http长啥样都知道，js是万万拦不住程序员写for循环，调用http接口的，这部分请求怎么处理？</p>
<h3 id="第二层，站点层面的请求拦截"><a href="#第二层，站点层面的请求拦截" class="headerlink" title="第二层，站点层面的请求拦截"></a>第二层，站点层面的请求拦截</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;怎么拦截？怎么防止程序员写for循环调用，有去重依据么？ip？cookie-id？…想复杂了，这类业务都需要登录，用uid即可。在<strong>站点层面</strong>，对uid进行请求计数和去重，甚至不需要统一存储计数，直接站点层内存存储（这样计数会不准，但最简单）。一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;5s只透过一个请求，其余的请求怎么办？<strong>缓存，页面缓存，同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面</strong>。同一个item的查询，例如车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面。如此限流，既能保证用户有良好的用户体验（没有返回404）又能保证系统的健壮性（利用页面缓存，把请求拦截在站点层了）。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;页面缓存不一定要保证所有站点返回一致的页面，直接放在每个站点的内存也是可以的。优点是简单，坏处是http请求落到不同的站点，返回的车票数据可能不一样，这是站点层的请求拦截与缓存优化。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;好，这个方式拦住了写for循环发http请求的程序员，有些高端程序员（黑客）控制了10w个肉鸡，手里有10w个uid，同时发请求（先不考虑实名制的问题，小米抢手机不需要实名制），这下怎么办，站点层按照uid限流拦不住了。<strong>防止不了肉鸡用户</strong></p>
<p><strong>两个关键指标：ip、uid</strong>，注意ip作为去重依据时，有误杀风险，同一个出口ip</p>
<p>方案一：nginx + lua + redis</p>
<p>方案二：php + redis</p>
<h3 id="第三层，服务层来拦截（反正就是不要让请求落到数据库上去）"><a href="#第三层，服务层来拦截（反正就是不要让请求落到数据库上去）" class="headerlink" title="第三层，服务层来拦截（反正就是不要让请求落到数据库上去）"></a>第三层，服务层来拦截（反正就是不要让请求落到数据库上去）</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;服务层怎么拦截？大哥，我是服务层，我清楚的知道小米只有1万部手机，我清楚的知道一列火车只有2000张车票，我透10w个请求去数据库有什么意义呢？没错，<strong>消息队列！</strong></p>
<blockquote>
<p>1w 部手机，只透1w个下单请求去db</p>
<p>3k 张火车票，只透3k个下单请求去db</p>
</blockquote>
<p><strong>原作者的方案：</strong></p>
<p><strong>对于写请求，做请求队列，每次只透有限的写请求去数据层（下订单，支付这样的写业务）</strong></p>
<p><strong>如果均成功再放下一批，如果库存不够，则队列里的写请求全部返回“已售完”</strong>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">如果均成功再放下一批，如果库存不够，则队列里的写请求全部返回“已售完”  </span><br><span class="line"></span><br><span class="line">这里我不是很理解：  我的理解就是库存校验，然后再写队列</span><br><span class="line"></span><br><span class="line">改为： 如果库存不够，则后续的请求全部返回“已售完”     这样是否更好理解？</span><br></pre></td></tr></table></figure>
<p><strong>我的方案：</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>对于写请求，做请求队列，先判断库存是否为0，如果不为0，库存扣减，将写请求放入消息队列，异步去请求数据层（下订单，支付这样的写业务）</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在这里有一个细节需要考虑：</span><br><span class="line"></span><br><span class="line">1. 库存存放到redis，且需要在秒杀活动开始前做预热，库存扣减采用decr来进行</span><br><span class="line"></span><br><span class="line">2. 判断库存是否为0以及库存扣减需要用到lua script保证原子性   保证在库存&gt;1且扣减成功时返回true  其它返回  false</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;对于读请求，怎么优化？cache抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的。如此限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99.9%的请求被拦住了</p>
<h3 id="数据库层"><a href="#数据库层" class="headerlink" title="数据库层"></a>数据库层</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;浏览器拦截了80%，站点层拦截了99.9%并做了页面缓存，服务层又做了写请求队列与数据缓存，每次透到数据库层的请求都是可控的。db基本就没什么压力了，闲庭信步，单机也能扛得住，还是那句话，库存是有限的，小米的产能有限，透这么多请求来数据库没有意义。</p>
<h3 id="业务规则上的一些优化"><a href="#业务规则上的一些优化" class="headerlink" title="业务规则上的一些优化"></a>业务规则上的一些优化</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;例如12306所做的，分时分段售票，原来统一10点卖票，现在8点，8点半，9点，…每隔半个小时放出一批：<strong>将流量摊匀</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;其次，<strong>数据粒度的优化</strong>：你去购票，对于余票查询这个业务，票剩了58张，还是26张，你真的关注么，其实我们只关心有票和无票？流量大的时候，做一个粗粒度的“有票”“无票”缓存即可。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>一些业务逻辑的异步</strong>：例如下单业务与 支付业务的分离。</p>
<h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a><strong>五、总结</strong></h2><p>两个架构优化思路：</p>
<p>（1）<strong>尽量将请求拦截在系统上游</strong>（越上游越好）；</p>
<p>（2）<strong>读多写少的常用多使用缓存</strong>（缓存抗读压力）；</p>
<p>浏览器和APP：做限速</p>
<p>站点层：按照uid做限速，做页面缓存</p>
<p>服务层：按照业务做写请求队列控制流量，做数据缓存</p>
<p>数据层：闲庭信步</p>
<p>并且：结合业务做优化</p>
<h2 id="六、Q-amp-A"><a href="#六、Q-amp-A" class="headerlink" title="六、Q&amp;A"></a><strong>六、Q&amp;A</strong></h2><p><strong>问题1</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;按你的架构，其实压力最大的反而是站点层，假设真实有效的请求数有1000万，不太可能限制请求连接数吧，那么这部分的压力怎么处理？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：每秒钟的并发可能没有1kw，假设有1kw，解决方案2个：</p>
<p>（1）站点层是可以通过加机器扩容的，最不济1k台机器来呗。</p>
<p>（2）如果机器不够，抛弃请求，抛弃50%（50%直接返回稍后再试），原则是要保护系统，不能让所有用户都失败。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">优化方案-：</span><br><span class="line"></span><br><span class="line">nginx的两种限流策略：</span><br><span class="line"></span><br><span class="line">limit_conn_zone 限制并发连接数</span><br><span class="line"></span><br><span class="line">limit_req_zone  限制请求速率</span><br><span class="line"></span><br><span class="line">   可以尝试：nginx+lua+redis直接达到分布式限流，ip为唯一标识可以做到，但是以uid作为唯一标识还没有做过，因为要获取cookie或者session</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">方案二：php + redis  分布式限流</span><br></pre></td></tr></table></figure>
<p><strong>问题2</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;“控制了10w个肉鸡，手里有10w个uid，同时发请求”这个问题怎么解决哈？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：<strong>服务层写请求队列控制</strong>，但是会导致正常用户秒杀失败，失去活动的意义，拓展用户</p>
<p><strong>问题3</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;限制访问频次的缓存，是否也可以用于搜索？例如A用户搜索了“手机”，B用户搜索“手机”，优先使用A搜索后生成的缓存页面？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：这个是可以的，这个方法也经常用在“动态”运营活动页，例如短时间推送4kw用户app-push运营活动，做页面缓存。</p>
<p><strong>问题4</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;如果队列处理失败，如何处理？肉鸡把队列被撑爆了怎么办？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：处理失败返回下单失败，让用户再试。队列成本很低，爆了很难吧。<strong>最坏的情况下，缓存了若干请求之后，后续请求都直接返回“无票”</strong>（队列里已经有100w请求了，都等着，再接受请求也没有意义了）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">这里存在两个问题：</span><br><span class="line">1. 需要消息队列支持实时获取堆积消息数量， 而且消息是在实时消费的，这个数量是不正确的，因为用户一旦下单成功就会去支付，对于消息处理异步减数据库库存、生成订单的时延是要尽可能短的</span><br><span class="line"></span><br><span class="line">2. 就算允许消息队列满了以后在消费，在消息队列写入过程中，也要加入分布式锁来控制，否则存在溢出的风险，方案复杂</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">这里解释一下：</span><br><span class="line">    原作者的方案是将所有经过限流策略后的请求均直接写到消息队列，并没有借助redis判断库存，而是有数据库层来判断的。这里对于数据库层的压力取决于消费进程的个数。但又引入了另外一个问题，多进程消费的情况下如何防止超卖？</span><br><span class="line"></span><br><span class="line">1. for update 悲观锁</span><br><span class="line">2. update 表名 set 库存=库存-1 where 库存 - 1 &gt;= 0 and 产品id=xxx</span><br><span class="line"></span><br><span class="line">	这种方案还有一个缺点：需要反向通知站点层是否扣减库存成功  方案复杂，容易出错，因为在用户层面，肯定是同步的，需要立刻知晓下单是否成功。我们很难将结果通过相应的http响应反馈给用户。</span><br></pre></td></tr></table></figure>
<p><strong>我的方案：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    对于写请求，做请求队列，先判断库存是否为0，如果不为0，库存扣减，将写请求放入消息队列，异步去请求数据层（下订单，支付这样的写业务）</span><br><span class="line"></span><br><span class="line">在这里有一个细节需要考虑：</span><br><span class="line"></span><br><span class="line">1. 库存存放到redis，且需要在秒杀活动开始前做预热，库存扣减采用decr来进行</span><br><span class="line"></span><br><span class="line">2. 判断库存是否为0以及库存扣减需要用到lua script保证原子性   保证在库存&gt;1且扣减成功时返回true  其它返回  false</span><br></pre></td></tr></table></figure>
<p><strong>问题5</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;站点层过滤的话，是把uid请求数单独保存到各个站点的内存中么？如果是这样的话，怎么处理多台服务器集群经过负载均衡器将相同用户的响应分布到不同服务器的情况呢？还是说将站点层的过滤放到负载均衡前？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：可以放在内存，这样的话看似一台服务器限制了5s一个请求，全局来说（假设有10台机器），其实是限制了5s 10个请求，解决办法：</p>
<p>1）<strong>redis全局限流</strong></p>
<p>2）在nginx层做7层均衡，让一个uid的请求尽量落到同一个机器上  <strong>upstream iphash  负载均衡策略</strong></p>
<p><strong>问题6</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;服务层过滤的话，队列是服务层统一的一个队列？还是每个提供服务的服务器各一个队列？如果是统一的一个队列的话，需不需要在各个服务器提交的请求入队列前进行锁控制？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：可以不用统一个队列，这样的话每个服务透过更少量的请求（总票数/服务个数），这样简单。统一一个队列又复杂了。</p>
<p><strong>问题7</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;秒杀之后的支付完成，以及未支付取消占位，如何对剩余库存做及时的控制更新？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：数据库里一个状态，未支付。如果超过时间，例如45分钟，库存会重新会恢复（大家熟知的“<strong>回仓”</strong>），给我们抢票的启示是，<strong>开动秒杀后，45分钟之后再试试看，说不定又有票哟</strong>~</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">技术方案实现：</span><br><span class="line">1. rabbitmq 延迟队列</span><br><span class="line"></span><br><span class="line">2. 层级时间轮处理</span><br><span class="line"></span><br><span class="line">3. redis key notification  key过期事件通知  key为订单id ttl为最大允许的支付时间，如：上面提到的45分钟即45*60</span><br><span class="line"></span><br><span class="line">4. redis zset  zset的score为过期时间对应的时间戳，值为订单id</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这种允许方案带来了一个问题：<strong>无法控制秒杀活动的结束时间</strong>，因为永远都有可能<strong>用户未支付 =》 回仓 =》 用户购买</strong>  =》 用户未支付  ……，这是一个<strong>死循环</strong></p>
<p><strong>问题8</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>不同的用户浏览同一个商品</strong>落在不同的缓存实例， <strong>显示的库存不完全一样</strong>？请问老师怎么做缓存数据一致或者是<strong>允许脏读</strong>？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：目前的架构设计，请求落到不同的站点上，数据可能不一致（页面缓存不一样），这个业务场景能接受。但<strong>保证数据库层面真实数据是没问题的</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;我的观点：<strong>秒杀业务的核心保证是不超卖、尽量过滤非法用户</strong>，所以缓存页面的数据允许存在一定的不一致</p>
<p><strong>问题9</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;就算处于业务把优化考虑“3k张火车票，只透3k个下单请求去db”那这3K个订单就不会发生拥堵了吗？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：（1）数据库抗3k个写请求还是ok的；</p>
<p>​        （2）可以数据拆分；</p>
<p>​            （3）如果3k扛不住，服务层可以控制透过去的并发数量，根据压测情况来吧，3k只是举例；</p>
<p><strong>问题10</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;如果在站点层或者服务层处理后台失败的话，需不需要考虑对这批处理失败的请求做重放？还是就直接丢弃？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：别重放了，返回用户查询失败或者下单失败吧，架构设计原则之一是<strong>“fail fast”</strong>。</p>
<p><strong>问题11</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;对于大型系统的秒杀，比如12306<strong>，同时进行的秒杀活动很多，如何分流？</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：<strong>垂直拆分</strong>，以服务的形式进行拆分，如：订单服务、用户服务、产品服务……，针对不同的服务独立部署，进行压测，对存在性能瓶颈的服务进行扩容和优化</p>
<p><strong>问题12</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;额外又想到一个问题。这套流程做成同步还是异步的？如果是同步的话，应该还存在会有响应反馈慢的情况。但<strong>如果是异步的话，如何控制能够将响应结果返回正确的请求方？</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;答：<strong>用户层面肯定是同步的（用户的http请求是夯住的），服务层面可以同步可以异步</strong>。</p>
<p><strong>问题13</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;秒杀群提问：<strong>减库存是在那个阶段减呢？</strong>如果是下单锁库存的话，大量恶意用户下单锁库存而不支付如何处理呢？</p>
<p>答：<strong>下单时，扣减库存</strong>。<strong>下单不支付，等时间过完再“回仓”</strong>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.com/2019/03/30/聊聊 TCP 长连接和心跳那些事/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘泽明">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="搬运工 + 践行者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/聊聊 TCP 长连接和心跳那些事/" itemprop="url">聊聊 TCP 长连接和心跳那些事</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-30T12:12:57+08:00">
                2019-03-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/网络/" itemprop="url" rel="index">
                    <span itemprop="name">网络</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/网络/Tcp/" itemprop="url" rel="index">
                    <span itemprop="name">Tcp</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/网络/Tcp/长连接/" itemprop="url" rel="index">
                    <span itemprop="name">长连接</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/网络/Tcp/长连接/心跳包/" itemprop="url" rel="index">
                    <span itemprop="name">心跳包</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="聊聊-TCP-长连接和心跳那些事"><a href="#聊聊-TCP-长连接和心跳那些事" class="headerlink" title="聊聊 TCP 长连接和心跳那些事"></a>聊聊 TCP 长连接和心跳那些事</h1><blockquote>
<p>原文地址：<a href="https://www.cnkirito.moe/tcp-talk/" target="_blank" rel="noopener">https://www.cnkirito.moe/tcp-talk/</a></p>
</blockquote>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;可能很多 Java 程序员对 TCP 的理解只有一个三次握手，四次握手的认识，我觉得这样的原因主要在于 TCP 协议本身稍微有点抽象（相比较于应用层的 HTTP 协议）；其次，非框架开发者不太需要接触到 TCP 的一些细节。其实我个人对 TCP 的很多细节也并没有完全理解，这篇文章主要针对微信交流群里有人提出的长连接，心跳问题，做一个统一的整理。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;在 Java 中，使用 TCP 通信，大概率会涉及到 Socket、Netty，本文将借用它们的一些 API 和设置参数来辅助介绍。</p>
<h3 id="长连接与短连接"><a href="#长连接与短连接" class="headerlink" title="长连接与短连接"></a>长连接与短连接</h3><p><strong>TCP 本身并没有长短连接的区别</strong>，长短与否，完全取决于我们怎么用它。</p>
<ul>
<li>短连接：每次通信时，创建 Socket；一次通信结束，调用 socket.close()。这就是一般意义上的短连接，<strong>短连接的好处是管理起来比较简单，存在的连接都是可用的连接，不需要额外的控制手段</strong>。</li>
<li>长连接：每次通信完毕后，不会关闭连接，这样可以做到连接的复用。<strong>长连接的好处是省去了创建连接的耗时。</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;短连接和长连接的优势，分别是对方的劣势。想要图简单，不追求高性能，使用短连接合适，这样我们就不需要操心连接状态的管理；想要追求性能，使用长连接，我们就需要担心各种问题：比如<strong>端对端连接的维护，连接的保活</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;长连接还常常被用来做数据的推送，我们大多数时候对通信的认知还是 request/response 模型，但 TCP 双工通信的性质决定了它还可以被用来做双向通信。<strong>在长连接之下，可以很方便的实现 push 模型</strong>，长连接的这一特性在本文并不会进行探讨，有兴趣的同学可以专门去搜索相关的文章。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;短连接没有太多东西可以讲，所以下文我们将目光聚焦在长连接的一些问题上。纯讲理论未免有些过于单调，所以下文我借助一些 RPC 框架的实践来展开 TCP 的相关讨论。</p>
<h3 id="服务治理框架中的长连接"><a href="#服务治理框架中的长连接" class="headerlink" title="服务治理框架中的长连接"></a>服务治理框架中的长连接</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;前面已经提到过，追求性能时，必然会选择使用长连接，所以借助 Dubbo 可以很好的来理解 TCP。我们开启两个 Dubbo 应用，一个 server 负责监听本地 20880 端口（众所周知，这是 Dubbo 协议默认的端口），一个 client 负责循环发送请求。执行 <code>lsof -i:20880</code> 命令可以查看端口的相关使用情况：</p>
<p><img src="//blog.com/2019/03/30/聊聊 TCP 长连接和心跳那些事/image-20190106203341694.png" alt="image-20190106203341694"></p>
<ul>
<li><code>*:20880 (LISTEN)</code> 说明了 Dubbo 正在监听本地的 20880 端口，处理发送到本地 20880 端口的请求</li>
<li>后两条信息说明请求的发送情况，验证了 TCP 是一个双向的通信过程，由于我是在同一个机器开启了两个 Dubbo 应用，所以你能够看到是本地的 53078 端口与 20880 端口在通信。我们并没有手动设置 53078 这个客户端端口，它是随机的。通过这两条信息，阐释了一个事实：<strong>即使是发送请求的一方，也需要占用一个端口</strong>。</li>
<li>稍微说一下 FD 这个参数，他代表了<strong>文件句柄</strong>，<strong>每新增一条连接都会占用新的文件句柄</strong>，如果你在使用 TCP 通信的过程中出现了 <code>open too many files</code> 的异常，那就应该检查一下，你是不是创建了太多连接，而没有关闭。细心的读者也会联想到<strong>长连接的另一个好处，那就是会占用较少的文件句柄</strong>。</li>
</ul>
<h3 id="长连接的维护"><a href="#长连接的维护" class="headerlink" title="长连接的维护"></a>长连接的维护</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;因为客户端请求的服务可能分布在多个服务器上，客户端自然需要跟对端创建多条长连接，我们遇到的第一个问题就是如何维护长连接。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 客户端</span><br><span class="line">public class NettyHandler extends SimpleChannelHandler &#123;</span><br><span class="line"></span><br><span class="line">    private final Map&lt;String, Channel&gt; channels = new ConcurrentHashMap&lt;String, Channel&gt;(); // &lt;ip:port, channel&gt;</span><br><span class="line">&#125;</span><br><span class="line">// 服务端</span><br><span class="line">public class NettyServer extends AbstractServer implements Server &#123;</span><br><span class="line">    private Map&lt;String, Channel&gt; channels; // &lt;ip:port, channel&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;在 Dubbo 中，客户端和服务端都使用 <code>ip:port</code> 维护了端对端的长连接，Channel 便是对连接的抽象。我们主要关注 NettyHandler 中的长连接，服务端同时维护一个长连接的集合是 Dubbo 的额外设计，我们将在后面提到。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这里插一句，解释下为什么我认为客户端的连接集合要重要一点。TCP 是一个双向通信的协议，任一方都可以是发送者，接受者，那为什么还抽象了 Client 和 Server 呢？因为<strong>建立连接这件事就跟谈念爱一样，必须要有主动的一方，你主动我们就会有故事</strong>。Client 可以理解为主动建立连接的一方，实际上两端的地位可以理解为是对等的。</p>
<h3 id="连接的保活"><a href="#连接的保活" class="headerlink" title="连接的保活"></a>连接的保活</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;这个话题就有的聊了，会牵扯到比较多的知识点。首先需要明确一点，为什么需要连接的保活？当双方已经建立了连接，但因为网络问题，链路不通，这样长连接就不能使用了。<strong>需要明确的一点是，通过 netstat，lsof 等指令查看到连接的状态处于 <code>ESTABLISHED</code> 状态并不是一件非常靠谱的事，因为连接可能已死，但没有被系统感知到，更不用提假死这种疑难杂症了</strong>。如何保证长连接可用是一件技术活。</p>
<h3 id="连接的保活：KeepAlive"><a href="#连接的保活：KeepAlive" class="headerlink" title="连接的保活：KeepAlive"></a>连接的保活：KeepAlive</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;首先想到的是 <code>TCP</code> 中的<code>KeepAlive</code>机制。KeepAlive 并不是 TCP 协议的一部分，但是大多数操作系统都实现了这个机制（所以需要在操作系统层面设置 <code>KeepAlive</code> 的相关参数）。<code>KeepAlive</code> 机制开启后，在一定时间内（一般时间为 7200s，参数 <code>tcp_keepalive_time</code>）在链路上没有数据传送的情况下，<code>TCP</code> 层将发送相应的 <code>KeepAlive</code> 探针以确定连接可用性，探测失败后重试 10（参数 <code>tcp_keepalive_probes</code>）次，每次间隔时间 75s（参数 <code>tcp_keepalive_intvl</code>），所有探测失败后，才认为当前连接已经不可用。</p>
<p>在 Netty 中开启 KeepAlive：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.option(ChannelOption.SO_KEEPALIVE, true)</span><br></pre></td></tr></table></figure>
<p>Linux 操作系统中设置 KeepAlive 相关参数，修改 <code>/etc/sysctl.conf</code> 文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_keepalive_time=90</span><br><span class="line">net.ipv4.tcp_keepalive_intvl=15</span><br><span class="line">net.ipv4.tcp_keepalive_probes=2</span><br></pre></td></tr></table></figure>
<p><strong>KeepAlive 机制是在网络层面保证了连接的可用性</strong>，但站在应用框架层面我们认为这还不够。主要体现在三个方面：</p>
<ul>
<li><strong>KeepAlive 的开关是在应用层开启的，但是具体参数（如重试测试，重试间隔时间）的设置却是操作系统级别的，位于操作系统的 <code>/etc/sysctl.conf</code> 配置中，这对于应用来说不够灵活</strong>。</li>
<li><strong>KeepAlive 的保活机制只在链路空闲的情况下才会起到作用</strong>，假如此时有数据发送，且物理链路已经不通，操作系统这边的链路状态还是 <code>ESTABLISHED</code>，这时会发生什么？自然会走 TCP 重传机制，要知道默认的 TCP 超时重传，指数退避算法也是一个相当长的过程。</li>
<li><strong>KeepAlive 本身是面向网络的，并不面向于应用，当连接不可用，可能是由于应用本身的 GC 频繁，系统 load 高等情况，但网络仍然是通的，此时，应用已经失去了活性，连接应该被认为是不可用的</strong>。</li>
</ul>
<p>我们已经为应用层面的连接保活做了足够的铺垫，下面就来一起看看，怎么在应用层做连接保活。</p>
<h3 id="连接的保活：应用层心跳"><a href="#连接的保活：应用层心跳" class="headerlink" title="连接的保活：应用层心跳"></a>连接的保活：应用层心跳</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;终于点题了，文题中提到的<strong>心跳</strong>便是一个本文想要重点强调的另一个重要的知识点。上一节我们已经解释过了，网络层面的 KeepAlive 不足以支撑应用级别的连接可用性，本节就来聊聊应用层的心跳机制是实现连接保活的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;如何理解应用层的心跳？简单来说，就是<strong>客户端会开启一个定时任务，定时对已经建立连接的对端应用发送请求（这里的请求是特殊的心跳请求），服务端则需要特殊处理该请求，返回响应。如果心跳持续多次没有收到响应，客户端会认为连接不可用，主动断开连接</strong>。不同的服务治理框架对心跳，建连，断连，拉黑的机制有不同的策略，但大多数的服务治理框架都会在应用层做心跳，<code>Dubbo/HSF</code> 也不例外。</p>
<h3 id="应用层心跳的设计细节"><a href="#应用层心跳的设计细节" class="headerlink" title="应用层心跳的设计细节"></a>应用层心跳的设计细节</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;以 Dubbo 为例，支持应用层的心跳，客户端和服务端都会开启一个 <code>HeartBeatTask</code>，客户端在 <code>HeaderExchangeClient</code> 中开启，服务端将在 <code>HeaderExchangeServer</code> 开启。文章开头埋了一个坑：Dubbo 为什么在服务端同时维护 <code>Map&lt;String,Channel&gt;</code> 呢？主要就是<strong>为了给心跳做贡献，心跳定时任务在发现连接不可用时，会根据当前是客户端还是服务端走不同的分支，客户端发现不可用，是重连；服务端发现不可用，是直接 close</strong>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// HeartBeatTask</span><br><span class="line">if (channel instanceof Client) &#123;</span><br><span class="line">    ((Client) channel).reconnect();</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    channel.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Dubbo 2.7.x 相比 2.6.x 做了定时心跳的优化，使用 <code>HashedWheelTimer</code> 更加精准的控制了只在连接闲置时发送心跳。</p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;再看看 HSF 的实现，并没有设置应用层的心跳，准确的说，是在 HSF2.2 之后，使用 Netty 提供的 <code>IdleStateHandler</code> 更加优雅的实现了应用的心跳。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ch.pipeline()</span><br><span class="line">        .addLast(&quot;clientIdleHandler&quot;, new IdleStateHandler(getHbSentInterval(), 0, 0));</span><br></pre></td></tr></table></figure>
<p>处理 <code>userEventTriggered</code> 中的 <code>IdleStateEvent</code> 事件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123;</span><br><span class="line">    if (evt instanceof IdleStateEvent) &#123;</span><br><span class="line">        callConnectionIdleListeners(client, (ClientStream) StreamUtils.streamOfChannel(ctx.channel()));</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        super.userEventTriggered(ctx, evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;对于客户端，HSF 使用 <code>SendHeartbeat</code> 来进行心跳，每次失败累加心跳失败的耗时，当超过最大限制时断开乱接；对于服务端 HSF 使用 <code>CloseIdle</code> 来处理闲置连接，直接关闭连接。一般来说，服务端的闲置时间会设置的稍长。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;熟悉其他 <code>RPC</code> 框架的同学会发现，不同框架的心跳机制真的是差距非常大。心跳设计还跟连接创建，重连机制，黑名单连接相关，还需要具体框架具体分析。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;除了定时任务的设计，还需要在协议层面支持心跳。最简单的例子可以参考 nginx 的健康检查，而针对 Dubbo 协议，自然也需要做心跳的支持，如果将心跳请求识别为正常流量，会造成服务端的压力问题，干扰限流等诸多问题。</p>
<p><img src="//blog.com/2019/03/30/聊聊 TCP 长连接和心跳那些事/359310b9-b980-3254-aed6-78aa6c482e53.png" alt="image-20190106203341694"></p>
<p>其中 Flag 代表了 Dubbo 协议的标志位，一共 8 个地址位。低四位用来表示消息体数据用的序列化工具的类型（默认 hessian），高四位中，第一位为1表示是 request 请求，第二位为 1 表示双向传输（即有返回response），<strong>第三位为 1 表示是心跳事件</strong>。</p>
<blockquote>
<p>心跳请求应当和普通请求区别对待。</p>
</blockquote>
<h3 id="注意和-HTTP-的-KeepAlive-区别对待"><a href="#注意和-HTTP-的-KeepAlive-区别对待" class="headerlink" title="注意和 HTTP 的 KeepAlive 区别对待"></a>注意和 HTTP 的 KeepAlive 区别对待</h3><ul>
<li>HTTP 协议的 KeepAlive 意图在于连接复用，同一个连接上串行方式传递请求-响应数据</li>
<li>TCP 的 KeepAlive 机制意图在于保活、心跳，检测连接错误。</li>
</ul>
<p>这压根是两个概念。</p>
<h3 id="KeepAlive-常见错误"><a href="#KeepAlive-常见错误" class="headerlink" title="KeepAlive 常见错误"></a>KeepAlive 常见错误</h3><p>启用 <code>TCP KeepAlive</code>的应用程序，一般可以捕获到下面几种类型错误</p>
<ol>
<li><p><code>ETIMEOUT</code> 超时错误，在发送一个探测保护包经过 (<code>tcp_keepalive_time + tcp_keepalive_intvl * tcp_keepalive_probes</code>)时间后仍然没有接收到 ACK 确认情况下触发的异常，套接字被关闭</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: Connection timed out</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>EHOSTUNREACH host unreachable</code>(主机不可达)错误，这个应该是 ICMP 汇报给上层应用的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: No route to host</span><br></pre></td></tr></table></figure>
</li>
<li><p>链接被重置，终端可能崩溃死机重启之后，接收到来自服务器的报文，然物是人非，前朝往事，只能报以无奈重置宣告之。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: Connection reset by peer</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>有三种使用 KeepAlive 的实践方案：</p>
<ol>
<li><p>默认情况下使用 <code>KeepAlive</code> 周期为 2 个小时，如不选择更改，属于误用范畴，造成资源浪费：内核会为每一个连接都打开一个保活计时器，N 个连接会打开 N 个保活计时器。 优势很明显：</p>
<ul>
<li><code>TCP</code> 协议层面保活探测机制，系统内核完全替上层应用自动给做好了</li>
<li>内核层面计时器相比上层应用，更为高效</li>
<li>上层应用只需要处理数据收发、连接异常通知即可</li>
<li>数据包将更为紧凑</li>
</ul>
</li>
<li><p><strong>关闭 TCP 的 KeepAlive，完全使用应用层心跳保活机制</strong>。由应用掌管心跳，更灵活可控，比如可以<strong>在应用级别设置心跳周期，适配私有协议</strong>。</p>
</li>
<li><p>业务心跳 + <code>TCP KeepAlive</code> 一起使用，互相作为补充，但 TCP 保活探测周期和应用的心跳周期要协调，以互补方可，不能够差距过大，否则将达不到设想的效果。</p>
</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;各个框架的设计都有所不同，例如 <code>Dubbo</code> 使用的是方案三，但阿里内部的 <code>HSF</code>框架则没有设置 <code>TC</code>P 的 <code>KeepAlive</code>，仅仅由应用心跳保活。和心跳策略一样，这和框架整体的设计相关。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/107/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/107/">107</a><span class="page-number current">108</span><a class="page-number" href="/page/109/">109</a><span class="space">&hellip;</span><a class="page-number" href="/page/147/">147</a><a class="extend next" rel="next" href="/page/109/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">刘泽明</p>
              <p class="site-description motion-element" itemprop="description">做一个懂业务的程序员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">731</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">394</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">237</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘泽明</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
